{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to PyCauset","text":"<p>PyCauset is a high-performance Python library for numerical Causal Set Theory. It is designed to bridge the gap between abstract mathematical models and large-scale numerical simulations.</p>"},{"location":"#the-philosophy-tiered-storage","title":"The Philosophy: Tiered Storage","text":"<p>Causal sets are computationally demanding. For a set of size \\(N\\), the causal matrix is \\(O(N^2)\\). For \\(N=100,000\\), a dense matrix requires gigabytes of memory.</p> <p>PyCauset solves this with a Hybrid Architecture: 1.  RAM-First: Small matrices behave exactly like NumPy arrays. 2.  Disk-Backed: Large matrices can automatically spill by switching to temporary memory-mapped backing files (for example <code>.tmp</code> files under the backing directory). Saving a portable <code>.pycauset</code> snapshot is explicit. 3.  Bit-Packing: Causal relations are stored as single bits, reducing memory usage by 64x compared to standard integers.</p>"},{"location":"#documentation-structure","title":"Documentation Structure","text":""},{"location":"#user-guides","title":"\ud83d\udcd8 User Guides","text":"<p>Practical tutorials and conceptual explanations. *   Installation: Install PyCauset. *   User Guide: First steps and core workflow. *   Causal Sets: Working with the core <code>CausalSet</code> object. *   Field Theory: Simulating quantum fields and propagators. *   Visualization: Interactive 3D plotting. *   Performance: GPU acceleration and precision tuning. *   Storage: Understanding the file formats and memory management.</p>"},{"location":"#api-reference","title":"\u2699\ufe0f API Reference","text":"<p>Detailed documentation of classes and functions. *   Classes: <code>CausalSet</code>, <code>Matrix</code>, <code>Vector</code>, <code>Spacetime</code>. *   Functions: <code>matmul</code>, <code>inverse</code>.</p>"},{"location":"#internals","title":"\ud83e\udde0 Internals","text":"<p>Deep dive into the C++ core for contributors. *   Compute Architecture: CPU/GPU dispatch and solvers. *   Memory Architecture: Tiered storage, Governor, and CoW. *   Memory &amp; Data: The <code>.pycauset</code> container format and memory mapping. *   Algorithms: Mathematical derivations and implementation details.</p>"},{"location":"#project","title":"\ud83d\ude80 Project","text":"<ul> <li>Philosophy: Design mantras.</li> <li>Contributing: How to build and test.</li> <li>Roadmap: Future plans.</li> </ul>"},{"location":"#dev-handbook","title":"\ud83e\uddf0 Dev Handbook","text":"<p>High-signal onboarding for contributors. *   Restructure Plan: The approved reorganization plan and gates.</p>"},{"location":"#citation","title":"Citation","text":"<p>If you use PyCauset in your research, please cite the repository: https://github.com/BrorH/pycauset</p>"},{"location":"dev/","title":"Dev Handbook (Start Here)","text":"<p>This section is the canonical onboarding path for contributors working on PyCauset.</p>"},{"location":"dev/#what-this-is","title":"What this is","text":"<ul> <li>A high-signal, low-ambiguity set of docs describing how the project is structured, how to contribute safely, and what invariants must not be violated.</li> <li>Written to support long-running work across many sessions and many contributors.</li> </ul>"},{"location":"dev/#read-order","title":"Read order","text":"<ol> <li>dev/Restructure Plan</li> <li>dev/Codebase Structure</li> <li>dev/Python Internals</li> <li>guides/Storage and Memory</li> <li>dev/Build System</li> <li>dev/Bindings &amp; Dispatch</li> <li>dev/Warnings &amp; Exceptions</li> <li>dev/Testing &amp; Benchmarks</li> <li>dev/Repository Hygiene</li> <li>internals/Streaming Manager</li> </ol>"},{"location":"dev/#related","title":"Related","text":"<ul> <li>project/Philosophy (core mantras)</li> <li>project/protocols/ (definition-of-done for docs/changes)</li> <li>internals/index (architecture deep dives)</li> </ul>"},{"location":"dev/Bindings%20%26%20Dispatch/","title":"Bindings &amp; Dispatch (Python \u2194 C++ Engine)","text":"<p>This page explains how Python calls reach the C++ engine, and how CPU/GPU dispatch works.</p>"},{"location":"dev/Bindings%20%26%20Dispatch/#high-level-architecture","title":"High-level architecture","text":"<ul> <li>Python public API lives at <code>pycauset.*</code>.</li> <li>Native extension module is imported as <code>pycauset._pycauset</code>.</li> <li>C++ engine provides:</li> <li>storage/memory mapping,</li> <li>matrix/vector types,</li> <li>compute dispatch (CPU/GPU),</li> <li>solvers (BLAS/LAPACK, streaming kernels, CUDA plugin).</li> </ul>"},{"location":"dev/Bindings%20%26%20Dispatch/#dispatch-path-device-selection","title":"Dispatch path (device selection)","text":"<ul> <li><code>ComputeContext</code> owns the active device configuration.</li> <li><code>AutoSolver</code> routes operations:</li> <li>CPU for small problems or unsupported types,</li> <li>GPU for large problems when available and supported.</li> <li>\u201cDirect vs streaming\u201d selection is coordinated by memory/governor logic and solvers.</li> </ul>"},{"location":"dev/Bindings%20%26%20Dispatch/#why-bindings-are-a-high-risk-zone","title":"Why bindings are a high-risk zone","text":"<p>Bindings are where drift happens: - Python may assume a class/function exists in native code. - Native bindings may expose a different name or only a subset.</p> <p>Rule: if Python expects a native symbol, it must be guaranteed (or Python must provide a deliberate fallback with tests).</p>"},{"location":"dev/Bindings%20%26%20Dispatch/#binding-checklist-when-adding-a-new-feature","title":"Binding checklist (when adding a new feature)","text":"<p>When adding a new matrix type, dtype, or operation:</p> <ol> <li>C++ engine: implement or route the capability.</li> <li>Bindings: expose the capability to Python.</li> <li>Python surface: ensure it is reachable via a top-level API (<code>pycauset.*</code>).</li> <li>Tests: add/extend tests under <code>tests/python/</code>.</li> <li>Docs: update <code>documentation/docs/</code>, <code>documentation/guides/</code>, and (if architectural) <code>documentation/internals/</code>.</li> </ol>"},{"location":"dev/Bindings%20%26%20Dispatch/#bindings-layout-modular-translation-units","title":"Bindings layout (modular translation units)","text":"<p>The native extension is built as one module, but the binding code is intentionally split across multiple translation units:</p> <ul> <li><code>src/bindings.cpp</code> is a thin <code>PYBIND11_MODULE</code> entrypoint.</li> <li><code>src/bindings/</code> contains the binding implementations, grouped by subsystem.</li> <li>Examples include: <code>bind_core.cpp</code>, <code>bind_matrix.cpp</code>, <code>bind_vector.cpp</code>, <code>bind_causet.cpp</code>, <code>bind_complex.cpp</code>.</li> </ul> <p>When adding a new bound type or function:</p> <ul> <li>Put the binding code in the most appropriate <code>src/bindings/bind_*.cpp</code> file (or add a new one if needed).</li> <li>Ensure the symbol is exported under the expected name in <code>pycauset._pycauset</code>.</li> <li>Add/extend a Python test that imports it through the intended public surface (usually <code>pycauset.*</code>).</li> </ul>"},{"location":"dev/Bindings%20%26%20Dispatch/#drift-check-native-exports","title":"Drift check (native exports)","text":"<p>Bindings refactors can silently drop exports that Python relies on.</p> <p>Run the repo-level drift check from the project root:</p> <ul> <li><code>python tools/check_native_exports.py</code></li> </ul> <p>It imports the in-tree Python package (<code>python/pycauset</code>) and asserts that <code>pycauset._pycauset</code> exports the required symbols.</p> <p>Options:</p> <ul> <li><code>python tools/check_native_exports.py --no-smoke</code> (presence-only)</li> <li><code>python tools/check_native_exports.py --strict</code> (fail on optional exports too)</li> </ul>"},{"location":"dev/Bindings%20%26%20Dispatch/#naming-rule-public-api-stability","title":"Naming rule (public API stability)","text":"<p>Internal modules/folders may be reorganized. Prefer keeping the user entrypoints stable and top-level: - <code>pycauset.matrix</code> - <code>pycauset.causal_matrix</code> - <code>pycauset.matmul</code> - <code>pycauset.inverse</code> / <code>~M</code> - <code>MatrixBase.trace</code> / <code>MatrixBase.determinant</code></p> <p>Pre-alpha note: the surface may change if it improves the architecture, but treat it as a major design decision: get explicit approval and update Philosophy + Protocols + tests.</p>"},{"location":"dev/Build%20System/","title":"Build System (Canonical Workflow)","text":"<p>This page documents how PyCauset is built and where build configuration lives.</p>"},{"location":"dev/Build%20System/#canonical-build-pip-scikit-build-core","title":"Canonical build: pip + scikit-build-core","text":"<p>PyCauset\u2019s canonical build path is Python packaging via <code>pyproject.toml</code> using scikit-build-core, which drives CMake.</p> <p>That means: - The \u201creal\u201d build configuration lives in <code>CMakeLists.txt</code>. - Running <code>pip install .</code> or <code>pip install -e .</code> will configure and build the C++ extension.</p>"},{"location":"dev/Build%20System/#why-this-matters","title":"Why this matters","text":"<ul> <li>It prevents having multiple divergent build systems.</li> <li>It matches how users install from PyPI (prebuilt wheels or source builds).</li> <li>It reduces version/installation confusion by making \u201cpip build\u201d the source of truth.</li> </ul>"},{"location":"dev/Build%20System/#where-compiler-flags-and-warnings-live","title":"Where compiler flags and warnings live","text":"<ul> <li>Compiler flags / warning suppressions / link settings live in <code>CMakeLists.txt</code>.</li> <li>When we migrate scripts (e.g., <code>build.ps1</code>) to be pip wrappers, we are not losing these flags: pip \u2192 scikit-build-core \u2192 CMake uses them.</li> </ul>"},{"location":"dev/Build%20System/#developer-workflows","title":"Developer workflows","text":""},{"location":"dev/Build%20System/#editable-install-recommended-for-development","title":"Editable install (recommended for development)","text":"<ul> <li><code>pip install -e .</code></li> </ul> <p>This builds the native extension and installs the Python package in editable mode.</p>"},{"location":"dev/Build%20System/#non-editable-build-local-install","title":"Non-editable build (local install)","text":"<ul> <li><code>pip install .</code></li> </ul>"},{"location":"dev/Build%20System/#passing-cmake-options","title":"Passing CMake options","text":"<p>scikit-build-core supports passing CMake configuration through environment variables.</p> <p>Common patterns:</p> <ul> <li>Set CMake arguments:</li> <li> <p><code>CMAKE_ARGS=\"-DENABLE_CUDA=ON\" pip install -e .</code></p> </li> <li> <p>Choose build type (platform-dependent):</p> </li> <li>On Windows/MSVC, CMake uses multi-config generators; Release/Debug are selected at build time.</li> <li>On single-config generators (many Linux setups), you pass <code>-DCMAKE_BUILD_TYPE=Release</code>.</li> </ul> <p>(Exact invocation details may vary by OS/toolchain; keep this page updated as we standardize.)</p>"},{"location":"dev/Build%20System/#wrapper-scripts-policy","title":"Wrapper scripts policy","text":"<p>We may keep convenience scripts like <code>build.ps1</code>, but they must remain wrappers around the canonical pip-based commands.</p> <ul> <li>Allowed: \u201cone-liner wrappers\u201d calling pip with standard args.</li> <li>Not allowed: scripts that introduce separate build flags, separate output layouts, or separate dependency logic.</li> </ul>"},{"location":"dev/Build%20System/#buildps1","title":"build.ps1","text":"<p><code>build.ps1</code> is intentionally small and only wraps <code>pip</code>.</p> <ul> <li>Editable install (default): <code>./build.ps1</code></li> <li>Non-editable install: <code>./build.ps1 -Action install</code></li> <li>Build a wheel into <code>dist/</code>: <code>./build.ps1 -Action wheel</code></li> </ul>"},{"location":"dev/Build%20System/#choosing-a-python","title":"Choosing a Python","text":"<ul> <li>Resolve via Windows py launcher: <code>./build.ps1 -PythonVersion 3.12</code></li> <li>Use an explicit interpreter: <code>./build.ps1 -PythonExe C:\\\\Path\\\\To\\\\python.exe</code></li> </ul>"},{"location":"dev/Build%20System/#passing-cmake-arguments","title":"Passing CMake arguments","text":"<p>Use <code>-CMakeArg</code> to add flags for this run (it appends to <code>CMAKE_ARGS</code> for the pip build):</p> <ul> <li><code>./build.ps1 -CMakeArg \"-DENABLE_CUDA=ON\"</code></li> <li><code>./build.ps1 -CMakeArg \"-DCMAKE_BUILD_TYPE=Release\"</code></li> </ul>"},{"location":"dev/Codebase%20Structure/","title":"Codebase Structure (Overview)","text":"<p>This page explains where things live in the repository and how the pieces fit together.</p>"},{"location":"dev/Codebase%20Structure/#core-philosophy-non-negotiable","title":"Core philosophy (non-negotiable)","text":"<ul> <li>PyCauset is \u201cNumPy for causal sets\u201d. Users interact with top-level Python APIs: <code>pycauset.matrix</code>, <code>pycauset.causal_matrix</code>, <code>pycauset.matmul</code>, etc.</li> <li>Storage, dtype selection, backend dispatch (CPU/GPU), and performance optimizations are automatic and behind the scenes.</li> <li>Internal code organization may change, but the public surface stays stable.</li> </ul>"},{"location":"dev/Codebase%20Structure/#repository-map","title":"Repository map","text":""},{"location":"dev/Codebase%20Structure/#python-package-user-facing","title":"Python package (user-facing)","text":"<ul> <li><code>python/pycauset/</code></li> <li>Public Python API and higher-level convenience wrappers.</li> <li><code>python/pycauset/__init__.py</code> is the public facade (stable <code>pycauset.*</code> entrypoints).</li> <li><code>python/pycauset/_internal/</code> contains non-public implementation modules that the facade delegates to.<ul> <li>Rule of thumb: if you\u2019re adding a new helper that is not meant to be imported by end users, it belongs in <code>_internal/</code>.</li> <li>See dev/Python Internals for the current internal module layout and extension rules.</li> </ul> </li> <li>The native extension is imported as <code>pycauset._pycauset</code>.</li> <li>Note: native exports can vary by build configuration; Python code should avoid import-time crashes by guarding optional symbols.</li> </ul>"},{"location":"dev/Codebase%20Structure/#c-core-engine","title":"C++ core (engine)","text":"<ul> <li><code>include/pycauset/</code> \u2014 public C++ headers (engine API)</li> <li><code>src/</code> \u2014 C++ implementations</li> <li><code>src/core/</code> \u2014 memory mapping, storage utils, I/O accelerator, system utils</li> <li><code>src/matrix/</code> \u2014 matrix types (dense, triangular, bit, etc.)</li> <li><code>src/vector/</code> \u2014 vector types</li> <li><code>src/compute/</code> \u2014 compute dispatch architecture<ul> <li><code>ComputeContext</code> (singleton)</li> <li><code>AutoSolver</code> (routes CPU vs GPU)</li> <li><code>cpu/</code> (CPU device + solvers)</li> </ul> </li> <li><code>src/accelerators/cuda/</code> \u2014 optional CUDA plugin (loaded dynamically)</li> <li><code>src/bindings.cpp</code> \u2014 Python extension entrypoint (pybind11 module)</li> <li><code>src/bindings/</code> \u2014 modular binding translation units (e.g. <code>bind_matrix.cpp</code>)</li> </ul>"},{"location":"dev/Codebase%20Structure/#tests-benchmarks","title":"Tests &amp; benchmarks","text":"<ul> <li><code>tests/python/</code> \u2014 Python interface + integration tests</li> <li><code>tests/*.cpp</code> \u2014 C++ unit tests (engine-level)</li> <li><code>benchmarks/</code> \u2014 performance scripts and comparison suites</li> </ul>"},{"location":"dev/Codebase%20Structure/#build-system","title":"Build system","text":"<ul> <li><code>pyproject.toml</code> \u2014 canonical Python build entry (scikit-build-core)</li> <li><code>CMakeLists.txt</code> \u2014 C++ build configuration and compiler flags</li> <li><code>build.ps1</code> \u2014 thin wrapper around the canonical pip build commands</li> </ul>"},{"location":"dev/Codebase%20Structure/#how-a-user-call-flows-through-the-stack","title":"How a user call flows through the stack","text":""},{"location":"dev/Codebase%20Structure/#example-c-a-b-matrix-multiplication","title":"Example: <code>C = A @ B</code> (matrix multiplication)","text":"<ol> <li>User code calls <code>A @ B</code> (Python operator) or <code>pycauset.matmul(A, B)</code>.</li> <li>Python calls into the native extension (<code>pycauset._pycauset</code>) or a thin Python wrapper.</li> <li>Native code performs:</li> <li>type resolution / allocation,</li> <li>device dispatch (CPU vs GPU) via <code>ComputeContext</code> + <code>AutoSolver</code>,</li> <li>algorithm selection (direct vs streaming) via <code>MemoryGovernor</code> and solver logic.</li> <li>The result is returned as a Python object that wraps a C++ <code>MatrixBase</code> implementation.</li> </ol>"},{"location":"dev/Codebase%20Structure/#example-out-of-core-optimization","title":"Example: out-of-core optimization","text":"<p>When a matrix is disk-backed (memory-mapped), solvers can: - emit access-pattern hints (sequential/strided), - trigger prefetching via the I/O accelerator, - avoid page-fault thrashing during streaming kernels.</p>"},{"location":"dev/Codebase%20Structure/#ownership-rules-where-new-code-should-go","title":"Ownership rules (where new code should go)","text":""},{"location":"dev/Codebase%20Structure/#if-you-addchange-a-user-facing-python-api","title":"If you add/change a user-facing Python API","text":"<ul> <li>Add docs under <code>documentation/docs/</code> + <code>documentation/guides/</code>.</li> <li>Keep the public entrypoint top-level (<code>pycauset.*</code>).</li> <li>Prefer a thin wrapper that delegates to the C++ engine.</li> </ul>"},{"location":"dev/Codebase%20Structure/#if-you-addchange-an-engine-feature","title":"If you add/change an engine feature","text":"<ul> <li>Update the relevant C++ subsystem:</li> <li>storage/memory: <code>src/core/</code>, <code>include/pycauset/core/</code></li> <li>matrix/vector types: <code>src/matrix/</code>, <code>src/vector/</code></li> <li>compute/dispatch: <code>src/compute/</code></li> <li>CUDA: <code>src/accelerators/cuda/</code></li> <li>Update internals docs under <code>documentation/internals/</code>.</li> </ul>"},{"location":"dev/Codebase%20Structure/#if-you-addchange-bindings","title":"If you add/change bindings","text":"<ul> <li>Update bindings code and ensure tests cover the Python-level behavior.</li> <li>Add/update the binding checklist in dev/Bindings &amp; Dispatch.</li> </ul>"},{"location":"dev/Codebase%20Structure/#roadmap-constraint-nxm-matrices","title":"Roadmap constraint: NxM matrices","text":"<p>Today, much of the engine assumes square matrices (NxN). The roadmap includes NxM support for all matrix types (dense, triangular, symmetric, bit, etc.), while explicitly avoiding N-D arrays.</p> <p>When reorganizing or refactoring, avoid hard-coding \u201csquare-only\u201d assumptions into new architecture layers.</p>"},{"location":"dev/PyCauset%20Container%20Format/","title":"PyCauset Container Format","text":"<p>This page specifies the on-disk container format for <code>.pycauset</code> files.</p> <p>If you want a conceptual and user-oriented explanation (how to save/load safely, copying rules, mental model), start here:</p> <ul> <li>guides/Storage and Memory</li> </ul>"},{"location":"dev/PyCauset%20Container%20Format/#goals","title":"Goals","text":"<p>The container format is designed to satisfy three constraints at once:</p> <p>1) mmap-friendly payload: large payload bytes live at a stable, aligned offset. 2) deterministic load: loading selects an active header slot in \\(O(1)\\). 3) crash-consistent metadata updates: metadata updates are append-only and committed by flipping a header slot.</p>"},{"location":"dev/PyCauset%20Container%20Format/#high-level-layout","title":"High-level layout","text":"<p>1) Fixed 4096-byte header with a preamble + two header slots (A/B). 2) Payload region at <code>payload_offset</code> (aligned to 4096 bytes). 3) Append-only metadata block at <code>metadata_offset</code> (aligned to 16 bytes).</p>"},{"location":"dev/PyCauset%20Container%20Format/#endianness","title":"Endianness","text":"<ul> <li>Containers are little-endian only.</li> <li>A header endian marker allows fast failure on unsupported endianness.</li> </ul>"},{"location":"dev/PyCauset%20Container%20Format/#alignment","title":"Alignment","text":"<ul> <li><code>payload_offset</code> is aligned to 4096 bytes.</li> <li><code>metadata_offset</code> is aligned to 16 bytes.</li> </ul>"},{"location":"dev/PyCauset%20Container%20Format/#fixed-header-4096-bytes","title":"Fixed header (4096 bytes)","text":"<p>The file begins with a fixed header region:</p> <ul> <li>A 16-byte preamble.</li> <li>Two 128-byte header slots (A and B).</li> <li>The remainder reserved (zero in the current format).</li> </ul>"},{"location":"dev/PyCauset%20Container%20Format/#preamble-offset-0","title":"Preamble (offset 0)","text":"Field Type Notes <code>magic</code> 8 bytes ASCII <code>PYCAUSET</code> <code>format_version</code> u32 current = 1 <code>endian</code> u8 1 = little-endian <code>header_bytes</code> u16 current = 4096 <code>reserved0</code> u8[1] must be 0"},{"location":"dev/PyCauset%20Container%20Format/#header-slots-a-and-b","title":"Header slots (A and B)","text":"<p>Each slot is 128 bytes and stores the authoritative pointers.</p> Field Type Notes <code>generation</code> u64 monotonic; higher wins <code>payload_offset</code> u64 aligned to 4096 <code>payload_length</code> u64 bytes <code>metadata_offset</code> u64 aligned to 16 <code>metadata_length</code> u64 bytes <code>hot_offset</code> u64 0 in v1 <code>hot_length</code> u64 0 in v1 <code>slot_crc32</code> u32 CRC32 of the first 7 fields (56 bytes) <code>slot_reserved</code> u8[68] must be 0 <p>Slot validity (v1):</p> <ul> <li><code>slot_crc32</code> matches</li> <li>offsets/lengths are in-range for file size</li> <li>alignment constraints satisfied</li> </ul> <p>Active slot selection:</p> <ul> <li>Choose the valid slot with the highest <code>generation</code>.</li> <li>If neither slot is valid, loading fails.</li> </ul>"},{"location":"dev/PyCauset%20Container%20Format/#payload-region","title":"Payload region","text":"<p>The payload is raw bytes suitable for memory mapping:</p> <ul> <li>Starts at <code>payload_offset</code>.</li> <li>Spans <code>payload_length</code> bytes.</li> <li>Interpretation is defined by identity metadata (shape, dtype, matrix type, <code>payload_layout</code>).</li> </ul>"},{"location":"dev/PyCauset%20Container%20Format/#metadata-blocks-append-only","title":"Metadata blocks (append-only)","text":"<p>Metadata is stored as blocks after the payload. The active header slot points to the authoritative block.</p>"},{"location":"dev/PyCauset%20Container%20Format/#metadata-framing-at-metadata_offset","title":"Metadata framing (at <code>metadata_offset</code>)","text":"Field Type Notes <code>block_magic</code> 4 bytes ASCII <code>PCMB</code> <code>block_version</code> u32 v1 = 1 <code>encoding_version</code> u32 typed-metadata encoding version; v1 = 1 <code>reserved0</code> u32 must be 0 <code>payload_length</code> u64 bytes of encoded metadata payload <code>payload_crc32</code> u32 CRC32 of encoded metadata payload <code>reserved1</code> u32 must be 0 <code>payload</code> bytes length = <code>payload_length</code> <p>If framing or CRC fails, loading fails deterministically.</p>"},{"location":"dev/PyCauset%20Container%20Format/#typed-metadata-map-v1","title":"Typed metadata map (v1)","text":"<p>The encoded metadata payload is a single top-level map with string keys.</p> <p>Reserved namespaces:</p> <ul> <li>identity/header keys: <code>rows</code>, <code>cols</code>, <code>matrix_type</code>, <code>data_type</code>, <code>payload_layout</code>, <code>payload_uuid</code>, ...</li> <li><code>view</code>: system-managed view-state</li> <li><code>properties</code>: user-facing gospel assertions</li> <li><code>cached</code>: cached-derived values plus validity metadata</li> <li><code>provenance</code>: optional non-semantic provenance</li> </ul> <p>Readers ignore unknown keys.</p>"},{"location":"dev/PyCauset%20Container%20Format/#crash-consistent-metadata-update-rule","title":"Crash-consistent metadata update rule","text":"<p>To update metadata without scanning:</p> <p>1) Append the new metadata block to the end of the file. 2) Ensure it is fully written (and flushed if applicable). 3) Write the inactive header slot with <code>generation = active.generation + 1</code> and the new metadata pointer. 4) Optionally flush the header region.</p> <p>This guarantees deterministic \\(O(1)\\) load and never moves the payload region.</p>"},{"location":"dev/PyCauset%20Container%20Format/#debugging-notes","title":"Debugging notes","text":""},{"location":"dev/PyCauset%20Container%20Format/#when-a-pycauset-file-fails-to-load","title":"When a <code>.pycauset</code> file fails to load","text":"<p>1) Confirm magic <code>PYCAUSET</code> and version. 2) Inspect header slot A/B:     - CRC valid?     - offsets/lengths in-range?     - alignments satisfied?     - which slot is active? 3) Validate the metadata block framing and CRC.</p> <p>Developer tooling:</p> <ul> <li><code>python/pycauset/_internal/storage_debug.py</code> exposes <code>summarize_container(path)</code>.</li> </ul>"},{"location":"dev/Python%20Internals/","title":"Python Internals (How the public API stays clean)","text":"<p>PyCauset\u2019s public Python surface is intentionally small and NumPy-like: users import and call <code>pycauset.*</code>.</p> <p>To keep that surface stable while still allowing rapid refactors, most implementation code lives under:</p> <ul> <li><code>python/pycauset/_internal/</code></li> </ul> <p>Nothing in <code>_internal/</code> should be treated as a public API.</p>"},{"location":"dev/Python%20Internals/#design-rules","title":"Design rules","text":"<ul> <li><code>python/pycauset/__init__.py</code> is the public facade.</li> <li><code>_internal/</code> contains implementation modules that the facade delegates to.</li> <li>When adding functionality, default to putting helper logic into <code>_internal/</code> and re-exporting only the intended entrypoint at <code>pycauset.*</code>.</li> <li>If you change the public surface (names, semantics, import paths), treat it as a major decision: get explicit approval and update tests + docs.</li> </ul>"},{"location":"dev/Python%20Internals/#current-_internal-modules-what-they-own","title":"Current <code>_internal/</code> modules (what they own)","text":"<p>These modules exist today and are the canonical homes for their responsibilities:</p> <ul> <li><code>python/pycauset/_internal/runtime.py</code></li> <li>Runtime/bootstrap policy (platform checks, environment setup).</li> <li><code>python/pycauset/_internal/native.py</code></li> <li>Native import helpers and thin wrappers around <code>pycauset._pycauset</code>.</li> <li><code>python/pycauset/_internal/persistence.py</code></li> <li>Persistence and storage helpers used by the public API.</li> <li><code>python/pycauset/_internal/linalg_cache.py</code></li> <li>Linear algebra caching/glue (Python-level).</li> <li><code>python/pycauset/_internal/factories.py</code></li> <li>Object construction helpers (Matrix/Vector creation, convenience factories).</li> <li><code>python/pycauset/_internal/ops.py</code></li> <li>Operation \u201cglue\u201d that keeps the top-level API thin.</li> <li>Examples (as of today): <code>matmul</code>, <code>compute_k</code>, <code>bitwise_not</code>, <code>invert</code>.</li> <li><code>python/pycauset/_internal/coercion.py</code></li> <li>Argument coercion and dtype-like normalization for Python entrypoints.</li> <li><code>python/pycauset/_internal/patching.py</code></li> <li>Patch/update helpers (used by persistence and runtime/storage workflows).</li> <li><code>python/pycauset/_internal/formatting.py</code></li> <li>String formatting / repr helpers.</li> <li><code>python/pycauset/_internal/matrix_api.py</code></li> <li>Python-side Matrix API helpers (methods/properties that wrap native behavior).</li> </ul> <p>If you\u2019re unsure where a new helper belongs, prefer <code>_internal/</code> first.</p>"},{"location":"dev/Python%20Internals/#how-to-add-a-new-top-level-function-safely","title":"How to add a new top-level function safely","text":"<ol> <li>Implement the logic in an <code>_internal/</code> module.</li> <li>Add a thin wrapper/re-export at <code>pycauset.&lt;name&gt;</code> in <code>python/pycauset/__init__.py</code>.</li> <li>Add or update a Python test under <code>tests/python/</code> that imports the symbol from <code>pycauset.*</code>.</li> <li>If the feature relies on native bindings, update dev/Bindings &amp; Dispatch and run the drift check (<code>python tools/check_native_exports.py</code>).</li> </ol>"},{"location":"dev/Python%20Internals/#status-note","title":"Status note","text":"<p>The repo has already moved a lot of logic into <code>_internal/</code>. Ongoing work should continue shrinking <code>python/pycauset/__init__.py</code> into a readable facade and keeping this doc aligned with the current layout.</p>"},{"location":"dev/Repository%20Hygiene/","title":"Repository Hygiene (Source vs Artifacts)","text":""},{"location":"dev/Repository%20Hygiene/#rule-do-not-commit-compiled-artifacts","title":"Rule: do not commit compiled artifacts","text":"<p>PyCauset is a compiled extension project. The repository should contain: - source code, - documentation, - tests, - build configuration.</p> <p>It should not contain compiled build outputs such as: - <code>_pycauset.pyd</code> / <code>_pycauset.so</code>, - <code>.dll</code> / <code>.so</code> / <code>.dylib</code> runtime libraries, - CMake build directories.</p>"},{"location":"dev/Repository%20Hygiene/#why","title":"Why","text":"<p>Committing binaries causes: - stale engine confusion (Python imports an old binary while you edit new C++ code), - noisy diffs, - installation/version mismatch issues.</p> <p>Since users install via <code>pip install pycauset</code> (wheels), binaries belong in release artifacts, not in git.</p>"},{"location":"dev/Repository%20Hygiene/#enforcement","title":"Enforcement","text":"<ul> <li>Add <code>.gitignore</code> rules to exclude these artifacts.</li> <li>Purge previously committed artifacts from git history (single-maintainer repo).</li> </ul>"},{"location":"dev/Repository%20Hygiene/#history-purge-executed-in-this-repo","title":"History purge (executed in this repo)","text":"<p>This repo previously contained committed compiled artifacts. The history has been rewritten to remove them.</p> <p>Practical implications:</p> <ul> <li>If you have an old clone, do not try to \u201cmerge forward\u201d across the rewrite. Re-clone instead.</li> <li>If you have local work based on the old history, copy patches across manually (or re-apply commits on top of the new history).</li> </ul> <p>Preferred tool: <code>git filter-repo</code>.</p> <p>High-level steps (to be executed deliberately): 1. Remove tracked binaries from the current tree. 2. Run filter-repo to excise them from history. 3. Force-push the cleaned history. 4. Re-clone locally.</p> <p>Because this repo is single-maintainer, the usual collaboration risks are minimal.</p>"},{"location":"dev/Restructure%20Plan/","title":"Restructure (what changed)","text":"<p>This page summarizes the executed codebase restructure work that landed alongside the Release 1 foundations.</p> <p>The goal is contributor clarity: where things live, what the canonical build/test workflows are, and which tooling prevents drift.</p>"},{"location":"dev/Restructure%20Plan/#what-changed","title":"What changed","text":"<ul> <li>Developer handbook exists and is canonical: the repo now has a dedicated <code>documentation/dev/</code> section covering build, bindings, testing, and hygiene.</li> <li>Python internals are modularized: implementation code lives under <code>python/pycauset/_internal/</code>, while the public surface remains <code>pycauset.*</code>.</li> <li>Bindings are modularized: <code>src/bindings.cpp</code> is a thin entrypoint and binding logic is split across <code>src/bindings/*</code> by subsystem.</li> <li>Drift prevention tooling exists: <code>tools/check_native_exports.py</code> helps catch mismatches between Python expectations and native exports.</li> </ul>"},{"location":"dev/Restructure%20Plan/#how-to-navigate-the-codebase-now","title":"How to navigate the codebase now","text":"<ul> <li>Python public facade: <code>python/pycauset/__init__.py</code></li> <li>Python implementation modules: <code>python/pycauset/_internal/</code></li> <li>Native bindings: <code>src/bindings/</code></li> <li>Native core and compute: <code>src/</code> and <code>include/pycauset/</code></li> </ul> <p>See Codebase Structure for the canonical map.</p>"},{"location":"dev/Restructure%20Plan/#build-and-test-are-documented-workflows","title":"Build and test are documented workflows","text":"<p>The documented source-of-truth build workflow is pip/scikit-build-core.</p> <p>See:</p> <ul> <li>Build System</li> <li>Testing &amp; Benchmarks</li> </ul>"},{"location":"dev/Restructure%20Plan/#approval-gate-note","title":"Approval gate note","text":"<p>Some additional restructure work was intentionally deferred behind an explicit approval gate. The execution record and remaining proposals live in:</p> <ul> <li>Internals: Restructure execution record</li> </ul>"},{"location":"dev/Restructure%20Plan/#see-also","title":"See also","text":"<ul> <li>Dev Handbook</li> <li>Python Internals</li> <li>Bindings &amp; Dispatch</li> <li>Repository Hygiene</li> <li>Documentation Protocol</li> </ul>"},{"location":"dev/Square-only%20Assumptions/","title":"Square-only assumptions (NxN)","text":"<p>PyCauset supports rectangular dense matrices (rows\u00d7cols) in the core engine, including bit-packed boolean matrices. This document tracks what is still square-only, either by mathematical definition or by implementation constraints.</p>"},{"location":"dev/Square-only%20Assumptions/#c-engine-remaining-square-only-areas","title":"C++ engine: remaining square-only areas","text":""},{"location":"dev/Square-only%20Assumptions/#square-only-types-by-definition","title":"Square-only types (by definition)","text":"<p>Some matrix families are inherently square:</p> <ul> <li>Triangular matrices (including causal matrices)</li> <li>Symmetric / antisymmetric matrices</li> <li>Diagonal matrices</li> </ul> <p>Identity matrices are shape-flexible in PyCauset: <code>IdentityMatrix(rows, cols)</code> (and <code>pycauset.identity([rows, cols])</code>) creates an identity-like matrix with ones on the diagonal up to <code>min(rows, cols)</code>.</p> <p>The factory enforces this at creation time: these <code>MatrixType</code>s reject <code>rows != cols</code> (triangular/causal, diagonal, symmetric/antisymmetric).</p>"},{"location":"dev/Square-only%20Assumptions/#densebitmatrix-is-bit-packed-implementation-detail","title":"DenseBitMatrix is bit-packed (implementation detail)","text":"<p><code>DenseBitMatrix</code> (<code>DenseMatrix&lt;bool&gt;</code>) is stored in bit-packed row layout with a per-row stride determined by <code>cols</code> (not by <code>n</code>). Rectangular <code>(rows, cols)</code> shapes are supported.</p>"},{"location":"dev/Square-only%20Assumptions/#square-only-operations","title":"Square-only operations","text":"<p>Some operations require square matrices even for dense numeric types:</p> <ul> <li>Determinant</li> <li>Inverse</li> </ul> <p>These should fail fast with a clear error when <code>rows != cols</code>.</p>"},{"location":"dev/Square-only%20Assumptions/#optional-algorithms-build-dependent-apis","title":"Optional algorithms / build-dependent APIs","text":"<p>Some higher-level solvers (for example, eigensolvers) are build-dependent. Tests and docs should treat these as optional and skip/disable features when the bindings are not present.</p>"},{"location":"dev/Square-only%20Assumptions/#triangular-types-are-inherently-square","title":"Triangular types are inherently square","text":"<ul> <li>Triangular matrices (and causal matrices) are square by definition.</li> </ul> <p>Implication: NxM support does not apply to triangular/causal matrices as a general concept; NxM primarily targets dense/symmetric/rectangular operations.</p>"},{"location":"dev/Square-only%20Assumptions/#what-is-no-longer-square-only-phase-1","title":"What is no longer square-only (Phase 1)","text":"<ul> <li><code>MatrixBase</code> / <code>PersistentObject</code> track <code>rows</code> and <code>cols</code>; <code>size()</code> is total elements (<code>rows * cols</code>).</li> <li>Dense numeric matrices support rectangular storage and indexing.</li> <li><code>ObjectFactory::create_matrix(rows, cols, ...)</code> exists and is used in core math paths.</li> <li>Persistence stores <code>rows</code>/<code>cols</code> in typed metadata and loaders prefer rectangular constructors.</li> <li>Python allocation (<code>zeros</code> / <code>ones</code> / <code>empty</code>) supports rectangular shapes for dense numeric dtypes.</li> </ul>"},{"location":"dev/Square-only%20Assumptions/#python-layer-remaining-square-only-surfaces","title":"Python layer: remaining square-only surfaces","text":"<ul> <li>Triangular/causal matrix constructors are square-only by definition.</li> </ul>"},{"location":"dev/Square-only%20Assumptions/#see-also","title":"See also","text":"<ul> <li>pycauset.MatrixBase</li> <li>internals/Memory and Data</li> <li>pycauset.zeros</li> <li>pycauset.matmul</li> </ul>"},{"location":"dev/Square-only%20Assumptions/#bindings","title":"Bindings","text":"<ul> <li>The pybind <code>shape</code> property is derived from <code>rows()</code> and <code>cols()</code>, so rectangular dense numeric matrices surface correct <code>(rows, cols)</code> shapes in Python.</li> </ul>"},{"location":"dev/Storage%20Semantics/","title":"Storage Semantics (Release 1)","text":"<p>This page is the developer-facing hub for how storage works in Release 1. User-facing guidance lives in guides/Storage and Memory, but the mechanics and invariants are captured here.</p>"},{"location":"dev/Storage%20Semantics/#canonical-references","title":"Canonical references","text":"<ul> <li>guides/Storage and Memory (user workflow + container overview)</li> <li>R1_STORAGE_PLAN (frozen container contract)</li> <li>R1_PROPERTIES_PLAN (metadata semantics and gospel properties)</li> </ul>"},{"location":"dev/Storage%20Semantics/#release-1-guarantees-storage","title":"Release 1 guarantees (storage)","text":"<ul> <li>Single-file <code>.pycauset</code> container, little-endian, with a 4096-byte header holding two slots (A/B). The valid slot with the highest generation is active; CRC mismatch or out-of-range pointers fail deterministically.</li> <li>Payload offset is aligned (\u22654096) and never moves after creation. Metadata offset is aligned (\u226516). Updates append metadata and flip the inactive header slot; no scanning is required.</li> <li>Typed metadata is a single sparse map with reserved namespaces: <code>view</code>, <code>properties</code>, <code>cached</code>, <code>provenance</code>, plus identity/header keys (<code>rows</code>, <code>cols</code>, <code>matrix_type</code>, <code>data_type</code>, <code>payload_layout</code>). Missing keys stay missing (tri-state semantics).</li> <li>Block matrices persist as a base container plus a sidecar <code>&lt;name&gt;.pycauset.blocks/</code>; the manifest pins child <code>payload_uuid</code> values to avoid mixed snapshots.</li> </ul>"},{"location":"dev/Storage%20Semantics/#snapshot-mutation-semantics","title":"Snapshot + mutation semantics","text":"<ul> <li><code>.pycauset</code> files are immutable snapshots; <code>load()</code> returns a snapshot-backed object.</li> <li>Mutations use copy-on-write working copies; payload bytes in the snapshot are not overwritten implicitly.</li> <li>Frequently changing runtime epochs stay in memory; header <code>hot_offset</code>/<code>hot_length</code> remain 0 in R1.</li> <li>Saving writes a new snapshot (base file, plus sidecar for block matrices). Overwrites replace the header slot generation and metadata pointer but keep the payload offset stable.</li> </ul>"},{"location":"dev/Storage%20Semantics/#cache-semantics-small-big-blobs","title":"Cache semantics (small + big blobs)","text":"<ul> <li><code>payload_uuid</code> identifies the persisted payload snapshot; <code>view_signature</code> captures view-state (<code>scalar</code>, <code>is_transposed</code>, <code>is_conjugated</code>). Both are used to validate cached-derived values without scanning.</li> <li>Small cached-derived values live under <code>cached.*</code> with a validity signature and surface into <code>obj.properties</code> on load when valid.</li> <li>Big-blob caches are persisted as independent <code>.pycauset</code> objects in <code>BASE.pycauset.objects/&lt;object_id&gt;.pycauset</code>; the base metadata stores a typed reference (<code>ref_kind = sibling_object_store</code>, <code>object_id</code>, <code>signature</code>). Missing/unreadable/stale references raise <code>PyCausetStorageWarning</code> and are treated as cache misses (ignored), with no implicit recomputation.</li> </ul>"},{"location":"dev/Storage%20Semantics/#crash-consistent-update-path","title":"Crash-consistent update path","text":"<p>1) Append the new typed metadata block (framing: <code>PCMB</code>, block_version=1, encoding_version=1, payload_crc32 validated). 2) Flush if the implementation uses explicit flush. 3) Write the inactive header slot with <code>generation = active + 1</code> and the new metadata pointer; include slot CRC32. 4) Optionally flush the header region.</p> <p>Load is \\(O(1)\\): pick the highest-generation valid slot, validate pointers/CRCs, read metadata, mmap payload at <code>payload_offset</code>.</p>"},{"location":"dev/Storage%20Semantics/#debugging-checklist","title":"Debugging checklist","text":"<ul> <li>Confirm magic/version/endian in the preamble (<code>PYCAUSET</code>, version 1, little-endian).</li> <li>Validate header slots: CRC, pointer ranges, alignment (payload 4096-aligned, metadata 16-aligned), choose highest valid generation.</li> <li>Validate metadata framing: <code>PCMB</code>, versions supported, payload length within file, CRC32 matches.</li> <li>Validate payload pointer: <code>payload_offset + payload_length</code> within file; payload is mmap-friendly at that offset.</li> <li>Developer helper: <code>python/pycauset/_internal/storage_debug.py::summarize_container(path)</code> (used by <code>tests/python/test_storage_debug_tool.py</code>).</li> </ul>"},{"location":"dev/Storage%20Semantics/#see-also","title":"See also","text":"<ul> <li>guides/Storage and Memory</li> <li>MemoryArchitecture</li> <li>Memory and Data</li> <li>Documentation Protocol</li> </ul>"},{"location":"dev/Streaming%20Manager/","title":"Streaming Manager","text":"<p>The streaming manager is the shared policy engine for out-of-core execution. It decides when to stream, how to tile, how deep to queue, and records what happened so tests and users can see the plan. Matmul, invert, eigvalsh, eigh, and eigvals_arnoldi register descriptors that plug in access patterns, guards, and resource budgets.</p>"},{"location":"dev/Streaming%20Manager/#what-the-manager-owns","title":"What the manager owns","text":"<ul> <li>Routing: picks <code>route</code> (<code>streaming</code> or <code>direct</code>) and <code>reason</code>, combining IO observability thresholds with per-op guards.</li> <li>Planning: fills plan fields (<code>tile_shape</code>, <code>queue_depth</code>, <code>plan.access_pattern</code>, <code>trace_tag</code>, <code>events</code>, <code>storage</code> summary).</li> <li>Execution glue: best-effort prefetch/discard for streaming routes and <code>impl=...</code> annotations for the chosen implementation.</li> <li>Registry: per-op <code>StreamingDescriptor</code> entries that provide access patterns and policy hooks.</li> </ul>"},{"location":"dev/Streaming%20Manager/#lifecycle-at-a-glance","title":"Lifecycle at a glance","text":"<ol> <li>plan(op, operands, allow_huge=False): snapshots operands, chooses route, runs the descriptor guard, and computes tiles/queue depth.</li> <li>prefetch(plan, operands): only when <code>route == \"streaming\"</code>; defaults to calling accelerators on backing files.</li> <li>compute: the op executes (native, Python fallback, or BlockMatrix orchestration). The manager can annotate the implementation (<code>impl=...</code>).</li> <li>discard(plan, operands, result): only when streaming; best-effort discard on backing ranges.</li> <li>inspect: <code>pc.last_io_trace(...)</code> returns the plan and event timeline for debugging and tests.</li> </ol>"},{"location":"dev/Streaming%20Manager/#plan-schema-recorded-via-io-observability","title":"Plan schema (recorded via IO observability)","text":"<ul> <li><code>route</code> / <code>reason</code>: routing choice and justification.</li> <li><code>tile_shape</code>: <code>(rows, cols)</code> when streaming; <code>None</code> when direct. Tiles clamp to operand shapes.</li> <li><code>queue_depth</code>: bounded to <code>[1, 8]</code> when streaming; <code>0</code> when direct.</li> <li><code>plan.access_pattern</code>: descriptor-supplied tag (e.g., <code>blocked_rowcol</code>).</li> <li><code>trace_tag</code>: monotonic tag per op (<code>op:N</code>).</li> <li><code>events</code>: list of <code>{type, detail, reason?}</code>; includes plan/prefetch/discard/compute annotations.</li> <li><code>storage</code>: backing files, temporary flags, and storage roots gathered from operand snapshots.</li> </ul>"},{"location":"dev/Streaming%20Manager/#routing-rules","title":"Routing rules","text":"<ul> <li>File-backed operands: force <code>streaming</code> with reason <code>file-backed operand</code>.</li> <li>allow_huge=True: force <code>direct</code> with reason <code>allow_huge bypassed threshold</code>.</li> <li>Threshold set: any estimated operand bytes over threshold \u2192 <code>streaming</code> with <code>estimated bytes exceed threshold</code>.</li> <li>Threshold None: <code>direct</code> with <code>no threshold configured</code> unless a guard overrides.</li> <li>Guards: per-op hooks can override route/reason. Example: non-square invert/eig* \u2192 <code>direct</code> with <code>non_square</code>; matmul mismatched shapes \u2192 <code>direct</code> with <code>shape_mismatch</code>.</li> </ul>"},{"location":"dev/Streaming%20Manager/#descriptor-catalog-current","title":"Descriptor catalog (current)","text":"op access_pattern guard tile budget queue depth notes matmul blocked_rowcol shape mismatch \u2192 direct budgeted square tiles clamped to shapes 3 when streaming Python tiling fallback annotates <code>impl=streaming_python</code> invert invert_dense non-square \u2192 direct default square tile 1 when streaming Fallback annotates <code>impl=streaming_python</code> eigvalsh symmetric_eigvals non-square \u2192 direct default square tile 1 when streaming Fallback annotates <code>impl=streaming_python</code> eigh symmetric_eigh non-square \u2192 direct default square tile 1 when streaming Fallback annotates <code>impl=streaming_python</code> eigvals_arnoldi arnoldi_topk non-square \u2192 direct default square tile 1 when streaming Fallback annotates <code>impl=streaming_python</code>"},{"location":"dev/Streaming%20Manager/#hooks-and-defaults","title":"Hooks and defaults","text":"<ul> <li><code>tile_budget_fn(threshold_bytes, snapshots)</code>: derives tiles from the memory threshold and itemsize; matmul halves budget across A/B and clamps to shapes; square ops reuse the default derivation.</li> <li><code>queue_depth_fn(route, snapshots)</code>: returns depth before coercion; manager caps to <code>[1, 8]</code> and zeroes when direct.</li> <li><code>guard(operands, snapshots, allow_huge)</code>: may override route/reason early; does not materialize data, uses snapshots.</li> <li><code>prefetch</code> / <code>discard</code>: optional per-op hooks; defaults call accelerator prefetch/discard on backing files.</li> <li><code>annotate_impl(record, label)</code>: attaches <code>impl=label</code> and records a compute event.</li> </ul>"},{"location":"dev/Streaming%20Manager/#safety-guarantees","title":"Safety guarantees","text":"<ul> <li>No streaming queue depth above 8; non-streaming queues are 0.</li> <li>Tile shapes always finite and clamped to operand extents; failures fall back to conservative defaults.</li> <li>Guards run before tiling so invalid shapes revert to direct routes instead of crashing in streaming codepaths.</li> <li>IO observability storage summaries remain intact for spill/backing-file diagnostics.</li> </ul>"},{"location":"dev/Streaming%20Manager/#debugging-and-tests","title":"Debugging and tests","text":"<ul> <li><code>pc.last_io_trace()</code> shows the latest plan; <code>pc.last_io_trace(\"matmul\")</code> fetches by op.</li> <li>Event timeline should contain <code>plan</code> plus <code>io</code> (prefetch/discard) and <code>compute</code> (impl) entries for streaming routes.</li> <li>Threshold-driven scenarios: set <code>pc.set_io_streaming_threshold(bytes)</code> to force streaming in tests; set to <code>None</code> to validate the direct path.</li> <li>File-backed fakes should force streaming regardless of threshold, exercising the guardrail for spill-backed inputs.</li> </ul>"},{"location":"dev/Streaming%20Manager/#extending","title":"Extending","text":"<ul> <li>Add a new op by registering a <code>StreamingDescriptor</code> in <code>pycauset.__init__</code> with an access pattern, guard, and budget/queue hooks.</li> <li>Keep guards deterministic and non-materializing (only consult snapshots and metadata).</li> <li>Prefer small, conservative tile/queue defaults; tighten once end-to-end tests validate throughput.</li> </ul>"},{"location":"dev/Testing%20%26%20Benchmarks/","title":"Testing &amp; Benchmarks","text":"<p>This page documents how to validate correctness and performance.</p>"},{"location":"dev/Testing%20%26%20Benchmarks/#test-layers","title":"Test layers","text":""},{"location":"dev/Testing%20%26%20Benchmarks/#1-python-tests-primary-user-surface-validation","title":"1) Python tests (primary user-surface validation)","text":"<p>Location: - <code>tests/python/</code></p> <p>These tests validate: - top-level <code>pycauset.*</code> API behavior, - interoperability (NumPy integration), - storage/persistence behavior, - GPU feature gating, - out-of-core behaviors.</p>"},{"location":"dev/Testing%20%26%20Benchmarks/#2-c-unit-tests-engine-invariants","title":"2) C++ unit tests (engine invariants)","text":"<p>Location: - <code>tests/*.cpp</code></p> <p>These tests validate: - memory governor behavior, - I/O accelerator behavior, - core matrix invariants.</p>"},{"location":"dev/Testing%20%26%20Benchmarks/#benchmarks","title":"Benchmarks","text":"<p>Location: - <code>benchmarks/</code></p> <p>Benchmarks exist to compare: - PyCauset vs NumPy for in-memory matrices, - direct vs streaming paths, - CPU vs GPU paths.</p> <p>Key harnesses: - <code>benchmarks/benchmark_numpy_parity.py</code>: Critical. Measures 1:1 throughput vs NumPy for import/export gates. - <code>benchmarks/benchmark_io_smoke.py</code>: Measures basic save/load wall time and MB/s.</p> <p>Recommended baseline: - run the \u201cCPU vs NumPy\u201d benchmark suite after solver changes.</p>"},{"location":"dev/Testing%20%26%20Benchmarks/#protocol","title":"Protocol","text":"<ul> <li>Correctness first: tests must pass before trusting benchmarks.</li> <li>Benchmarks should be run with stable conditions:</li> <li>consistent seeds,</li> <li>clear dtype,</li> <li>documented hardware.</li> </ul>"},{"location":"dev/Testing%20%26%20Benchmarks/#link-to-optimization-tracking","title":"Link to optimization tracking","text":"<p>The authoritative checklist for dtype/op coverage and readiness gates is:</p> <ul> <li><code>documentation/internals/plans/SUPPORT_READINESS_FRAMEWORK.md</code></li> </ul> <p>When a checklist item changes status: - ensure a corresponding test exists (or is added), - ensure a benchmark script exists (or is updated).</p>"},{"location":"dev/Testing%20%26%20Benchmarks/#3-safety-tests-r1_safety","title":"3) Safety Tests (R1_SAFETY)","text":"<p>Location: - <code>tests/python/test_safety.py</code> (Basic smoke tests) - <code>tests/python/test_r1_safety_comprehensive.py</code> (Extensive stress/fuzzing suite)</p> <p>These tests validate: - Corrupt Load: Ensuring <code>pc.load()</code> rejects files with invalid headers or magic bytes (Fuzzing 50+ iterations). - Spill Integrity: Verifying that internal <code>.tmp</code> files (with Simple Headers) are read correctly. - Leak Detection: Verifying that large alloc/free cycles do not cause OOM (validating <code>OfferVirtualMemory</code> logic). - Concurrency: Threaded I/O stress testing to ensure thread-safety of file operations. - Persistence: Verifying physical disk writes via explicit flush checks.</p>"},{"location":"dev/Warnings%20%26%20Exceptions/","title":"Warnings &amp; Exceptions","text":"<p>PyCauset is designed for scale-first workloads. As a result, we must be explicit when the runtime does something that is:</p> <ul> <li>surprising (dtype underpromotion, accumulator widening),</li> <li>potentially expensive (slow fallback paths), or</li> <li>potentially unsafe (overflow risk).</li> </ul> <p>This page defines the project-wide conventions for user-facing warnings and exceptions.</p>"},{"location":"dev/Warnings%20%26%20Exceptions/#when-to-warn-vs-raise","title":"When to warn vs. raise","text":""},{"location":"dev/Warnings%20%26%20Exceptions/#use-warnings-when","title":"Use warnings when","text":"<p>Warnings are for cases where execution can continue correctly, but the user should be informed.</p> <ul> <li>Policy surprises (e.g., underpromotion within floats, reduction accumulator widening)</li> <li>Heuristic risk checks (e.g., integer matmul overflow-risk preflight)</li> <li>Performance hazards (e.g., a fallback that will be much slower than expected)</li> <li>Example: a cached-derived value (including a \u201cbig blob cache\u201d like an inverse) cannot be loaded because its referenced storage object is missing/corrupt; the runtime will warn and ignore the cached entry (no implicit recompute).</li> </ul> <p>Warnings should be:</p> <ul> <li>actionable (tell the user what happened and what they can do),</li> <li>deduplicated (warn-once policy),</li> <li>filterable (PyCauset-specific warning categories).</li> </ul>"},{"location":"dev/Warnings%20%26%20Exceptions/#raise-exceptions-when","title":"Raise exceptions when","text":"<p>Exceptions are for correctness and contract failures.</p> <ul> <li>Invalid arguments / shape mismatches</li> <li>Unsupported dtype/structure combinations (unless there is an explicit, documented fallback)</li> <li>Integer overflow (policy: no silent wrap, no silent output widening)</li> </ul> <p>Exceptions must be deterministic and should include stable, specific messages.</p>"},{"location":"dev/Warnings%20%26%20Exceptions/#warning-categories-python","title":"Warning categories (Python)","text":"<p>PyCauset warnings must use a package-specific category so users can filter them without suppressing unrelated warnings.</p> <p>Defined in <code>python/pycauset/_internal/warnings.py</code> and re-exported from <code>pycauset</code>:</p> <ul> <li><code>pycauset.PyCausetWarning</code> (base)</li> <li><code>pycauset.PyCausetDTypeWarning</code> (promotion/accumulator dtype notifications)</li> <li><code>pycauset.PyCausetOverflowRiskWarning</code> (heuristic overflow risk preflights)</li> <li><code>pycauset.PyCausetPerformanceWarning</code> (slow-path / performance notifications)</li> <li><code>pycauset.PyCausetStorageWarning</code> (storage/mmap/cache notifications)</li> </ul>"},{"location":"dev/Warnings%20%26%20Exceptions/#filtering-examples","title":"Filtering examples","text":"<p>Users can suppress specific warning families:</p> <ul> <li><code>warnings.filterwarnings(\"ignore\", category=pycauset.PyCausetOverflowRiskWarning)</code></li> </ul>"},{"location":"dev/Warnings%20%26%20Exceptions/#warning-message-standard","title":"Warning message standard","text":"<p>Warnings should follow this format:</p> <ul> <li>Start with <code>pycauset &lt;op&gt; ...</code> or <code>pycauset &lt;op&gt; preflight ...</code></li> <li>Include operation name (e.g., <code>matmul</code>, <code>dot</code>)</li> <li>Include relevant dtypes / structures (even if the current engine is only int32/float32/float64)</li> <li>State what was changed:</li> <li>accumulator dtype,</li> <li>output dtype/storage behavior (explicitly say if it did not change)</li> <li>State the reason (e.g., \u201creduction-aware integer width\u201d, \u201cheuristic bound indicates plausible overflow\u201d)</li> <li>Provide a mitigation hint when reasonable (e.g., scale inputs, use float output)</li> </ul> <p>Noise control requirements:</p> <ul> <li>Use a warn-once mechanism keyed by a stable identifier (usually <code>op + dtype tuple</code>).</li> <li>Prefer <code>stacklevel</code> so the warning points to user code.</li> </ul>"},{"location":"dev/Warnings%20%26%20Exceptions/#storagecache-warning-guidance","title":"Storage/cache warning guidance","text":"<p>When a cached-derived value cannot be used (missing/stale/malformed signature; referenced big-blob object missing or corrupt), execution can typically continue correctly by ignoring the cached entry. If you want the derived result again, you must request it explicitly (and optionally re-persist it).</p> <p>Policy:</p> <ul> <li>Prefer a warning (not an exception) when the runtime can safely ignore the cached entry without changing user-visible results.</li> <li>Use <code>pycauset.PyCausetStorageWarning</code> for missing/corrupt/stale cached storage objects (including big-blob caches).</li> </ul> <p>Slicing/indexing assignment warnings</p> <ul> <li>When <code>M[slice] = X</code> triggers dtype conversion or promotion, emit <code>PyCausetDTypeWarning</code> (and <code>PyCausetOverflowRiskWarning</code> if the conversion increases overflow risk) while applying the NumPy broadcast/shape rules for the indexed region. Shape-changing assignments must raise.</li> </ul> <p>Suggested message pattern:</p> <ul> <li><code>pycauset invert cache unavailable (missing/corrupt cached object); cached entry ignored</code></li> </ul>"},{"location":"dev/Warnings%20%26%20Exceptions/#where-warnings-should-be-emitted","title":"Where warnings should be emitted","text":"<p>Goal: warnings must fire for the real user entrypoints, not only for convenience wrappers.</p> <ul> <li>Prefer emitting warnings at the binding funnel for Python operator calls.</li> <li>Example: <code>MatrixBase.__matmul__</code> and <code>pycauset._pycauset.matmul</code>.</li> <li>Emit warnings in Python wrappers only when the Python wrapper is the canonical entrypoint.</li> <li>Avoid emitting warnings deep inside hot kernels.</li> </ul> <p>Rationale:</p> <ul> <li>The binding funnel has enough context to format user-facing messages.</li> <li>The kernel should remain tight; warnings there are hard to dedupe and may hurt performance.</li> </ul>"},{"location":"dev/Warnings%20%26%20Exceptions/#exception-conventions","title":"Exception conventions","text":""},{"location":"dev/Warnings%20%26%20Exceptions/#c-python-mapping","title":"C++ \u2192 Python mapping","text":"<p>We rely on pybind11\u2019s standard exception translation and a small amount of explicit translation.</p> <ul> <li><code>std::invalid_argument</code> \u2192 <code>ValueError</code> (via <code>translate_invalid_argument</code> where used)</li> <li><code>std::out_of_range</code> \u2192 <code>IndexError</code>/<code>ValueError</code> depending on binding usage</li> <li><code>std::overflow_error</code> \u2192 <code>OverflowError</code></li> <li>Other <code>std::runtime_error</code> \u2192 <code>RuntimeError</code></li> </ul> <p>Policy notes:</p> <ul> <li>Integer overflow must raise (no wrap). Prefer <code>std::overflow_error</code>.</li> <li>Prefer <code>std::invalid_argument</code> for shape/contract violations so Python sees <code>ValueError</code>.</li> </ul>"},{"location":"dev/Warnings%20%26%20Exceptions/#error-messages","title":"Error messages","text":"<ul> <li>Keep messages stable and specific.</li> <li>Prefer: <code>\"Integer matmul overflow: ...\"</code> over generic <code>\"overflow\"</code>.</li> </ul>"},{"location":"dev/Warnings%20%26%20Exceptions/#current-implemented-warnings-phase-1-work","title":"Current implemented warnings (Phase 1 work)","text":"<ul> <li><code>int32 @ int32</code> matmul accumulator notification (<code>PyCausetDTypeWarning</code>)</li> <li>mixed <code>float32/float64</code> underpromotion notification (<code>PyCausetDTypeWarning</code>)</li> <li>integer matmul overflow-risk preflight warning (<code>PyCausetOverflowRiskWarning</code>)</li> </ul> <p>As dtype expansion progresses, these will generalize to the resolver-selected dtype tuples.</p>"},{"location":"dev/performance_optimizations/","title":"Performance Optimizations (R1_PERF)","text":"<p>This document details the performance optimizations implemented to achieve &gt;0.90x NumPy parity for I/O and data handling, and to optimize compute throughput.</p>"},{"location":"dev/performance_optimizations/#1-threading-model-dynamic-scheduling","title":"1. Threading Model (Dynamic Scheduling)","text":"<p>Problem: Static partitioning caused stalls when one thread was slower (e.g., page fault). Solution: Implemented dynamic work-stealing approximation in <code>ParallelFor</code>. - Mechanism: Threads atomically claim small chunks of work (<code>grain_size</code>) from a shared index. - Benefit: Load balancing is automatic. If one thread stalls, others continue claiming work. - File: <code>include/pycauset/core/ParallelUtils.hpp</code></p>"},{"location":"dev/performance_optimizations/#2-io-optimization-the-import-gap","title":"2. I/O Optimization (The \"Import Gap\")","text":"<p>Problem: Creating large files on disk was slow due to OS zero-filling (security feature). Solution: - Windows: Used <code>SetFileValidData</code> to extend file size without zero-filling. Requires <code>SE_MANAGE_VOLUME_NAME</code> privilege (enabled automatically). - Linux: Used <code>fallocate</code> to pre-allocate blocks. - Prefetching: Used <code>PrefetchVirtualMemory</code> (Windows) and <code>MAP_POPULATE</code> (Linux) to pre-populate page tables. - File: <code>src/core/MemoryMapper.cpp</code>, <code>src/core/PersistentObject.cpp</code></p>"},{"location":"dev/performance_optimizations/#3-avx-512-optimizations","title":"3. AVX-512 Optimizations","text":"<p>Problem: Bit-matrix operations were not utilizing modern CPU instructions. Solution: - Alignment: <code>DenseBitMatrix</code> strides are now aligned to 64 bytes (512 bits). - Intrinsics: Implemented <code>_mm512_popcnt_epi64</code> and <code>_mm512_and_si512</code> for bit-matrix multiplication. - Runtime Dispatch: <code>CpuSolver</code> checks for AVX-512 support at runtime using <code>__cpuid</code>. - File: <code>src/matrix/DenseBitMatrix.cpp</code>, <code>src/compute/cpu/CpuSolver.cpp</code></p>"},{"location":"dev/performance_optimizations/#4-memory-governor-direct-path-anti-nanny","title":"4. Memory Governor &amp; Direct Path (\"Anti-Nanny\")","text":"<p>Problem: The \"Streaming Solver\" (out-of-core) has overhead. For datasets that fit in RAM, this overhead is unnecessary. Solution: - Direct Path: If <code>total_operation_bytes &lt; available_ram</code>, the solver bypasses the streaming logic and calls BLAS/LAPACK directly. - Pinning: <code>try_pin_memory</code> attempts to lock pages in RAM to prevent swapping during critical compute sections. - File: <code>src/core/MemoryGovernor.cpp</code>, <code>src/compute/cpu/CpuSolver.cpp</code></p>"},{"location":"dev/performance_optimizations/#validation","title":"Validation","text":"<ul> <li>Tests: <code>tests/test_parallel_utils.cpp</code></li> <li>Benchmarks: <code>benchmarks/benchmark_io_throughput.py</code></li> </ul>"},{"location":"docs/","title":"API Reference","text":"<p>This section contains the detailed API documentation for the PyCauset library.</p>"},{"location":"docs/#core-modules","title":"Core Modules","text":"<ul> <li>pycauset.CausalSet: The main class representing a causal set.</li> <li>pycauset.spacetime: Spacetime manifolds and geometry.</li> <li>pycauset.vis: Visualization tools.</li> <li>pycauset.field: Quantum field helpers.</li> </ul>"},{"location":"docs/#data-structures","title":"Data Structures","text":"<ul> <li>Matrix classes: Dense, triangular, bit-packed, and structured matrices.</li> <li>Vector classes: Disk-backed and specialized vectors.</li> </ul>"},{"location":"docs/#functions","title":"Functions","text":"<ul> <li>pycauset.matrix / pycauset.vector: Construct from data.</li> <li>pycauset.zeros / pycauset.ones / pycauset.empty: Allocate with explicit <code>dtype</code>.</li> <li>pycauset.causal_matrix: Create a causal matrix (triangular bit matrix).</li> <li>pycauset.causet: Convenience constructor for pycauset.CausalSet.</li> <li>pycauset.matmul: Matrix multiplication.</li> <li>pycauset.invert: Matrix inversion.</li> <li>pycauset.load / pycauset.save: Persistence.</li> <li>pycauset.compute_k: Propagator-related helper.</li> </ul>"},{"location":"docs/classes/","title":"Classes","text":"<ul> <li>Core</li> <li>Field</li> <li>Matrix</li> <li>Spacetime</li> <li>Vector</li> </ul>"},{"location":"docs/classes/AntiSymmetricMatrix/","title":"AntiSymmetricMatrix","text":"<p>The <code>AntiSymmetricMatrix</code> class represents a square matrix \\(A\\) where \\(A_{ij} = -A_{ji}\\).</p> <p>It is optimized for storage efficiency, storing only the upper triangular part in memory. This reduces memory usage by approximately 50% compared to a dense matrix.</p>"},{"location":"docs/classes/AntiSymmetricMatrix/#class-hierarchy","title":"Class Hierarchy","text":"<ul> <li>Inherits from: <code>SymmetricMatrix</code> -&gt; <code>TriangularMatrixBase</code> -&gt; <code>MatrixBase</code> -&gt; <code>PersistentObject</code></li> </ul>"},{"location":"docs/classes/AntiSymmetricMatrix/#constructors","title":"Constructors","text":""},{"location":"docs/classes/AntiSymmetricMatrix/#antisymmetricmatrixn-scalar00","title":"<code>AntiSymmetricMatrix(n, scalar=0.0)</code>","text":"<p>Creates a new anti-symmetric matrix.</p> <ul> <li>n (int): The number of rows/columns (matrix is \\(N \\times N\\)).</li> <li>scalar (float or complex, optional): A scalar multiplier associated with the matrix. Defaults to 0.0.</li> </ul>"},{"location":"docs/classes/AntiSymmetricMatrix/#from_triangularsource","title":"<code>from_triangular(source)</code>","text":"<p>Static method to create an AntiSymmetricMatrix from a TriangularMatrix. It copies the upper triangular part (excluding diagonal) of the source matrix. The resulting matrix \\(A\\) satisfies \\(A_{ij} = \\text{source}_{ij}\\) for \\(i &lt; j\\), \\(A_{ji} = -A_{ij}\\), and \\(A_{ii} = 0\\).</p> <p>This is particularly useful for computing the Pauli-Jordan function \\(\\Delta = K - K^T\\) where \\(K\\) is a triangular propagator.</p> <ul> <li>source (TriangularMatrix): The source matrix.</li> </ul>"},{"location":"docs/classes/AntiSymmetricMatrix/#properties","title":"Properties","text":""},{"location":"docs/classes/AntiSymmetricMatrix/#is_antisymmetric","title":"<code>is_antisymmetric</code>","text":"<ul> <li>Type: <code>bool</code></li> <li>Description: Always returns <code>True</code>.</li> </ul>"},{"location":"docs/classes/AntiSymmetricMatrix/#shape","title":"<code>shape</code>","text":"<ul> <li>Type: <code>tuple</code></li> <li>Description: Returns <code>(n, n)</code>.</li> </ul>"},{"location":"docs/classes/AntiSymmetricMatrix/#t","title":"<code>T</code>","text":"<ul> <li>Type: <code>AntiSymmetricMatrix</code></li> <li>Description: Returns the transpose (\\(A^T = -A\\)).</li> </ul>"},{"location":"docs/classes/AntiSymmetricMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/AntiSymmetricMatrix/#indexing","title":"Indexing","text":"<p>Read elements using NumPy-style indexing: <code>x = A[i, j]</code>. *   i, j (int): Indices. *   Returns: The value at \\((i, j)\\).     *   If \\(i &gt; j\\), returns \\(-A_{ji}\\).     *   If \\(i == j\\), returns 0.</p> <p>Write elements using NumPy-style indexing: <code>A[i, j] = value</code>. *   i, j (int): Indices. *   value: The value to set.     *   If \\(i &gt; j\\), it sets \\(A_{ji} = -value\\).     *   Note: The diagonal (\\(i=j\\)) must be 0. Attempting to set a non-zero diagonal value will raise an error.</p>"},{"location":"docs/classes/AntiSymmetricMatrix/#copy","title":"<code>copy()</code>","text":"<p>Creates a copy of the matrix.</p>"},{"location":"docs/classes/AntiSymmetricMatrix/#close","title":"<code>close()</code>","text":"<p>Closes the memory map and releases resources.</p>"},{"location":"docs/classes/AntiSymmetricMatrix/#usage-example","title":"Usage Example","text":"<pre><code>import pycauset as pc\n\n# Create an Anti-Symmetric Matrix (e.g., Pauli-Jordan Delta)\nDelta = pc.AntiSymmetricMatrix(100)\nDelta[10, 5] = 2.0\nprint(Delta[5, 10])  # Output: -2.0\nprint(Delta[5, 5])   # Output: 0.0\n</code></pre>"},{"location":"docs/classes/SymmetricMatrix/","title":"SymmetricMatrix","text":"<p>The <code>SymmetricMatrix</code> class represents a square matrix \\(A\\) where \\(A_{ij} = A_{ji}\\).</p> <p>It is optimized for storage efficiency, storing only the upper triangular part (including the diagonal) in memory. This reduces memory usage by approximately 50% compared to a dense matrix.</p>"},{"location":"docs/classes/SymmetricMatrix/#class-hierarchy","title":"Class Hierarchy","text":"<ul> <li>Inherits from: <code>TriangularMatrixBase</code> -&gt; <code>MatrixBase</code> -&gt; <code>PersistentObject</code></li> </ul>"},{"location":"docs/classes/SymmetricMatrix/#constructors","title":"Constructors","text":""},{"location":"docs/classes/SymmetricMatrix/#symmetricmatrixn-scalar00","title":"<code>SymmetricMatrix(n, scalar=0.0)</code>","text":"<p>Creates a new symmetric matrix.</p> <ul> <li>n (int): The number of rows/columns (matrix is \\(N \\times N\\)).</li> <li>scalar (float or complex, optional): A scalar multiplier associated with the matrix. Defaults to 0.0.</li> </ul>"},{"location":"docs/classes/SymmetricMatrix/#from_triangularsource","title":"<code>from_triangular(source)</code>","text":"<p>Static method to create a SymmetricMatrix from a TriangularMatrix. It copies the upper triangular part (including diagonal) of the source matrix. The resulting matrix \\(S\\) satisfies \\(S_{ij} = S_{ji} = \\text{source}_{ij}\\) for \\(i \\le j\\).</p> <ul> <li>source (TriangularMatrix): The source matrix.</li> </ul>"},{"location":"docs/classes/SymmetricMatrix/#properties","title":"Properties","text":""},{"location":"docs/classes/SymmetricMatrix/#is_antisymmetric","title":"<code>is_antisymmetric</code>","text":"<ul> <li>Type: <code>bool</code></li> <li>Description: Returns <code>False</code>.</li> </ul>"},{"location":"docs/classes/SymmetricMatrix/#shape","title":"<code>shape</code>","text":"<ul> <li>Type: <code>tuple</code></li> <li>Description: Returns <code>(n, n)</code>.</li> </ul>"},{"location":"docs/classes/SymmetricMatrix/#t","title":"<code>T</code>","text":"<ul> <li>Type: <code>SymmetricMatrix</code></li> <li>Description: Returns the transpose (which is a copy of itself for symmetric matrices).</li> </ul>"},{"location":"docs/classes/SymmetricMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/SymmetricMatrix/#indexing","title":"Indexing","text":"<p>Read elements using NumPy-style indexing: <code>x = S[i, j]</code>. *   i, j (int): Indices. *   Returns: The value at \\((i, j)\\).     *   If \\(i &gt; j\\), it accesses the stored value at \\((j, i)\\).</p> <p>Write elements using NumPy-style indexing: <code>S[i, j] = value</code>. *   i, j (int): Indices. *   value: The value to set.     *   If \\(i &gt; j\\), it sets the stored value at \\((j, i)\\).</p>"},{"location":"docs/classes/SymmetricMatrix/#copy","title":"<code>copy()</code>","text":"<p>Creates a copy of the matrix.</p>"},{"location":"docs/classes/SymmetricMatrix/#close","title":"<code>close()</code>","text":"<p>Closes the memory map and releases resources.</p>"},{"location":"docs/classes/SymmetricMatrix/#usage-example","title":"Usage Example","text":"<pre><code>import pycauset as pc\n\n# Create a Symmetric Matrix\nS = pc.SymmetricMatrix(100)\nS[10, 5] = 3.14\nprint(S[5, 10])  # Output: 3.14\n</code></pre>"},{"location":"docs/classes/core/","title":"Core","text":"<p>This section describes behaviors that apply to PyCauset's storage-backed objects.</p> <p>In Release 1, the user-facing base types are:</p> <ul> <li>pycauset.MatrixBase</li> <li>pycauset.VectorBase</li> </ul> <p>For persistence, snapshots, and caches, see:</p> <ul> <li>Storage and Memory</li> </ul>"},{"location":"docs/classes/core/pycauset.PersistentObject/","title":"Persistent objects (base behavior)","text":"<p>PyCauset objects are typically backed by either RAM or a memory-mapped file, and they can be persisted as <code>.pycauset</code> snapshots.</p> <p>There is no stable public Python class named <code>pycauset.PersistentObject</code> in Release 1.</p> <p>Instead, these behaviors surface through:</p> <ul> <li>pycauset.MatrixBase</li> <li>pycauset.VectorBase</li> </ul>"},{"location":"docs/classes/core/pycauset.PersistentObject/#storage-concepts","title":"Storage concepts","text":"<ul> <li>Backed by disk or RAM: the API is the same either way.</li> <li>Snapshots are immutable by default: <code>load()</code> does not implicitly overwrite the file you loaded.</li> <li>Metadata-first: shape, dtype, view-state, and semantic properties are stored/propagated without scanning payload.</li> </ul> <p>The canonical Release 1 persistence semantics and container format are documented in:</p> <ul> <li>Storage and Memory</li> </ul>"},{"location":"docs/classes/core/pycauset.PersistentObject/#semantic-properties","title":"Semantic properties","text":"<p>Matrices and vectors expose <code>obj.properties</code>, a typed mapping used for:</p> <ul> <li>gospel semantic assertions (e.g. <code>is_upper_triangular=True</code>), and</li> <li>cached-derived values (e.g. <code>trace</code>, <code>determinant</code>, <code>norm</code>) with strict validity.</li> </ul> <p>See R1 Properties for the user-facing contract.</p>"},{"location":"docs/classes/core/pycauset.PersistentObject/#see-also","title":"See also","text":"<ul> <li>pycauset.save</li> <li>pycauset.load</li> <li>Storage and Memory</li> <li>R1 Properties</li> </ul>"},{"location":"docs/classes/field/","title":"Field","text":"<ul> <li>Field</li> <li>ScalarField</li> </ul>"},{"location":"docs/classes/field/pycauset.field.Field/","title":"pycauset.field.Field","text":"<pre><code>class Field(abc.ABC)\n</code></pre> <p>Abstract base class for all fields defined on a Causal Set.</p> <p>A <code>Field</code> represents the matter content (or vacuum state) imposed on the spacetime geometry of a <code>CausalSet</code>. It separates the physical field parameters (like mass) from the geometric parameters of the set itself.</p>"},{"location":"docs/classes/field/pycauset.field.Field/#properties","title":"Properties","text":""},{"location":"docs/classes/field/pycauset.field.Field/#causet","title":"causet","text":"<p><pre><code>@property\ncauset: CausalSet\n</code></pre> The causal set instance on which this field is defined.</p>"},{"location":"docs/classes/field/pycauset.field.Field/#methods","title":"Methods","text":""},{"location":"docs/classes/field/pycauset.field.Field/#propagator","title":"propagator","text":"<p><pre><code>@abc.abstractmethod\ndef propagator(self) -&gt; MatrixBase\n</code></pre> Computes the propagator (Green's function) for this field. The specific type of propagator (Retarded, Feynman, etc.) depends on the subclass implementation.</p>"},{"location":"docs/classes/field/pycauset.field.ScalarField/","title":"pycauset.field.ScalarField","text":"<pre><code>class ScalarField(Field)\n</code></pre> <p>Represents a massive scalar field defined on a Causal Set.</p> <p>This class implements the generalized Retarded Propagator \\(K_R\\) for a scalar field \\(\\phi\\) satisfying the Klein-Gordon equation on the discrete causal set structure.</p>"},{"location":"docs/classes/field/pycauset.field.ScalarField/#constructor","title":"Constructor","text":"<pre><code>ScalarField(causet: CausalSet, mass: float = 0.0)\n</code></pre> <ul> <li>causet (CausalSet): The causal set on which the field lives. Must have density information available.</li> <li>mass (float): The mass of the field (\\(m\\)). Defaults to 0.0 (massless).</li> </ul>"},{"location":"docs/classes/field/pycauset.field.ScalarField/#methods","title":"Methods","text":""},{"location":"docs/classes/field/pycauset.field.ScalarField/#propagator","title":"propagator","text":"<pre><code>def propagator(self, a: float = None, b: float = None) -&gt; TriangularFloatMatrix\n</code></pre> <p>Computes the Retarded Propagator \\(K_R\\).</p> <p>The propagator is defined as: $$ K_R = \\Phi(I - b\\Phi)^{-1} $$ where \\(\\Phi = a C\\).</p> <p>Automatic Coefficient Derivation: If <code>a</code> and <code>b</code> are not provided, they are automatically calculated based on the <code>spacetime</code> dimension (\\(d\\)), the sprinkling density (\\(\\rho\\)), and the field mass (\\(m\\)).</p> <ul> <li>For \\(d=2\\) (Minkowski):     $$ a = 1/2, \\quad b = -m^2/\\rho $$</li> <li>For \\(d=4\\) (Minkowski):     $$ a = \\frac{\\sqrt{\\rho}}{2\\pi\\sqrt{6}}, \\quad b = -m^2/\\rho $$</li> </ul> <p>Parameters:</p> <ul> <li>a (float, optional): Manual override for coefficient \\(a\\).</li> <li>b (float, optional): Manual override for coefficient \\(b\\).</li> </ul> <p>Returns:</p> <ul> <li>TriangularFloatMatrix: The computed propagator matrix.</li> </ul> <p>Raises:</p> <ul> <li>ValueError: If the causal set density is unknown and coefficients are not manually provided.</li> <li>NotImplementedError: If the spacetime dimension/type is not supported for automatic derivation.</li> </ul>"},{"location":"docs/classes/field/pycauset.field.ScalarField/#pauli_jordan","title":"pauli_jordan","text":"<pre><code>def pauli_jordan(self) -&gt; AntiSymmetricFloat64Matrix\n</code></pre> <p>Computes the Pauli-Jordan function \\(i\\Delta\\), where \\(\\Delta = K - K^T\\).</p> <p>This function returns an <code>AntiSymmetricFloat64Matrix</code> representing the operator \\(i\\Delta\\). The matrix stores the values of \\(\\Delta\\), but its <code>scalar</code> property is set to <code>1j</code> (the imaginary unit), so that accessing elements or performing arithmetic operations treats it as \\(i\\Delta\\).</p> <p>Returns:</p> <ul> <li>AntiSymmetricFloat64Matrix: The matrix \\(i\\Delta\\).</li> </ul>"},{"location":"docs/classes/matrix/","title":"Matrix","text":"<ul> <li>pycauset.matrix</li> <li>pycauset.MatrixBase</li> <li>pycauset.causal_matrix</li> <li>pycauset.IdentityMatrix</li> <li>pycauset.DenseBitMatrix</li> <li>pycauset.TriangularMatrix</li> <li>pycauset.TriangularBitMatrix</li> <li>pycauset.TriangularIntegerMatrix</li> <li>pycauset.TriangularFloatMatrix</li> <li>pycauset.SymmetricMatrix</li> <li>pycauset.IntegerMatrix</li> <li>pycauset.Int8Matrix</li> <li>pycauset.Int16Matrix</li> <li>pycauset.Int64Matrix</li> <li>pycauset.UInt8Matrix</li> <li>pycauset.UInt16Matrix</li> <li>pycauset.UInt32Matrix</li> <li>pycauset.UInt64Matrix</li> <li>pycauset.FloatMatrix</li> <li>pycauset.Float32Matrix</li> <li>pycauset.Float16Matrix</li> <li>pycauset.ComplexFloat64Matrix</li> <li>pycauset.ComplexFloat32Matrix</li> <li>pycauset.ComplexFloat16Matrix</li> </ul>"},{"location":"docs/classes/matrix/pycauset.ComplexFloat16Matrix/","title":"pycauset.ComplexFloat16Matrix","text":"<p>A memory-mapped dense matrix storing complex numbers in <code>complex_float16</code> format (two-plane float16: real + imaginary). Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.ComplexFloat16Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.ComplexFloat16Matrix(n: int)\npycauset.ComplexFloat16Matrix(rows: int, cols: int)\npycauset.ComplexFloat16Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>complex64</code> or <code>complex128</code>.</p>"},{"location":"docs/classes/matrix/pycauset.ComplexFloat16Matrix/#notes","title":"Notes","text":"<p>Complex support is limited to complex floats. Supported operations are gated by the support matrix (see <code>documentation/internals/DType System.md</code>).</p>"},{"location":"docs/classes/matrix/pycauset.ComplexFloat32Matrix/","title":"pycauset.ComplexFloat32Matrix","text":"<p>A memory-mapped dense matrix storing complex numbers in <code>complex_float32</code> format (equivalent to NumPy <code>complex64</code>). Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.ComplexFloat32Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.ComplexFloat32Matrix(n: int)\npycauset.ComplexFloat32Matrix(rows: int, cols: int)\npycauset.ComplexFloat32Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>complex64</code>.</p>"},{"location":"docs/classes/matrix/pycauset.ComplexFloat32Matrix/#notes","title":"Notes","text":"<p>Complex support is limited to complex floats. Supported operations are gated by the support matrix (see <code>documentation/internals/DType System.md</code>).</p>"},{"location":"docs/classes/matrix/pycauset.ComplexFloat64Matrix/","title":"pycauset.ComplexFloat64Matrix","text":"<p>A memory-mapped dense matrix storing complex numbers in <code>complex_float64</code> format (equivalent to NumPy <code>complex128</code>). Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.ComplexFloat64Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.ComplexFloat64Matrix(n: int)\npycauset.ComplexFloat64Matrix(rows: int, cols: int)\npycauset.ComplexFloat64Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>complex128</code>.</p>"},{"location":"docs/classes/matrix/pycauset.ComplexFloat64Matrix/#notes","title":"Notes","text":"<p>Complex support is limited to complex floats. Supported operations are gated by the support matrix (see <code>documentation/internals/DType System.md</code>).</p>"},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/","title":"pycauset.DenseBitMatrix","text":"<p>A memory-mapped dense matrix storing boolean values (bits). Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.DenseBitMatrix(n: int)\n</code></pre>"},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#static-methods","title":"Static Methods","text":""},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#randomn-int-density-float-seed-int-none-densebitmatrix","title":"<code>random(n: int, density: float, seed: int = None) -&gt; DenseBitMatrix</code>","text":"<p>Create a random dense bit matrix.</p>"},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#indexing","title":"Indexing","text":"<p>Element access uses NumPy-style indexing:</p> <pre><code>x = M[i, j]\nM[i, j] = value\n</code></pre>"},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#multiplyother-densebitmatrix-integermatrix","title":"<code>multiply(other: DenseBitMatrix) -&gt; IntegerMatrix</code>","text":"<p>Multiply this matrix by another <code>DenseBitMatrix</code>.</p> <p>Returns: *   <code>IntegerMatrix</code>: The result of the multiplication. Note that this performs integer matrix multiplication (counting paths), not boolean multiplication. The result at \\((i, j)\\) is the number of paths of length 1 from \\(i\\) to \\(j\\) (which is just the dot product).</p> <p>GPU Acceleration: This operation is GPU-accelerated if a compatible NVIDIA GPU is detected. The implementation uses a highly optimized bit-packed kernel that performs 64 operations per cycle per thread.</p> <p>CPU Fallback: If no GPU is available, the operation uses optimized AVX-512/NEON <code>popcount</code> instructions on the CPU, providing significant speedups over standard loops.</p>"},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#__invert__-densebitmatrix","title":"<code>__invert__() -&gt; DenseBitMatrix</code>","text":"<p>Compute the bitwise NOT of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.DenseBitMatrix/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>String representation of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.Float16Matrix/","title":"pycauset.Float16Matrix","text":"<p>A memory-mapped dense matrix storing 16-bit floating point numbers (half precision). Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.Float16Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.Float16Matrix(n: int)\npycauset.Float16Matrix(rows: int, cols: int)\npycauset.Float16Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>float16</code>.</p>"},{"location":"docs/classes/matrix/pycauset.Float16Matrix/#notes","title":"Notes","text":"<p>Half precision is primarily a storage and bandwidth optimization. Supported operations are gated by the support matrix (see <code>documentation/internals/DType System.md</code>).</p>"},{"location":"docs/classes/matrix/pycauset.Float32Matrix/","title":"pycauset.Float32Matrix","text":"<pre><code>class Float32Matrix(MatrixBase)\n</code></pre> <p>A dense matrix storing 32-bit floating point numbers (<code>float</code>).</p>"},{"location":"docs/classes/matrix/pycauset.Float32Matrix/#overview","title":"Overview","text":"<p>This class is functionally identical to pycauset.FloatMatrix (which uses 64-bit doubles) but uses half the storage.</p> <p>To allocate a <code>Float32Matrix</code>, use <code>pycauset.empty((rows, cols), dtype=\"float32\")</code> or <code>pycauset.zeros((rows, cols), dtype=\"float32\")</code>.</p> <p>Use this class for large matrices where memory/disk I/O is the bottleneck and extreme precision is not required.</p> <p>GPU Acceleration: Matrix multiplication (<code>multiply</code> or <code>@</code>) is GPU-accelerated for <code>Float32Matrix</code>. It is significantly faster than <code>FloatMatrix</code> (Double Precision) on consumer GPUs (e.g., GeForce series) which often have much higher FP32 throughput than FP64.</p>"},{"location":"docs/classes/matrix/pycauset.Float32Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.Float32Matrix(n: int)\npycauset.Float32Matrix(rows: int, cols: int)\npycauset.Float32Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>float32</code>.</p> <ul> <li><code>n</code>: The size of a square matrix (\\(N \\times N\\)).</li> <li><code>rows</code>, <code>cols</code>: The shape of a rectangular matrix.</li> </ul>"},{"location":"docs/classes/matrix/pycauset.Float32Matrix/#methods","title":"Methods","text":"<p>Inherits all methods from pycauset.MatrixBase.</p> <ul> <li>Indexing: read with <code>M[i, j]</code>, write with <code>M[i, j] = value</code>.</li> <li><code>inverse()</code> / <code>invert()</code>: Computes the inverse (square-only; requires <code>rows == cols</code>).</li> </ul>"},{"location":"docs/classes/matrix/pycauset.Float32Matrix/#see-also","title":"See Also","text":"<ul> <li>pycauset.FloatMatrix</li> <li>pycauset.MatrixBase</li> <li>pycauset.zeros</li> <li>Matrix Guide</li> </ul>"},{"location":"docs/classes/matrix/pycauset.FloatMatrix/","title":"pycauset.FloatMatrix","text":"<p>A memory-mapped dense matrix storing 64-bit floating point numbers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.FloatMatrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.FloatMatrix(n: int)\npycauset.FloatMatrix(rows: int, cols: int)\npycauset.FloatMatrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>float64</code>.</p>"},{"location":"docs/classes/matrix/pycauset.FloatMatrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.FloatMatrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.FloatMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/matrix/pycauset.FloatMatrix/#indexing","title":"Indexing","text":"<p>Element access uses NumPy-style indexing:</p> <pre><code>x = M[i, j]\nM[i, j] = value\n</code></pre>"},{"location":"docs/classes/matrix/pycauset.FloatMatrix/#multiplyother-floatmatrix-floatmatrix","title":"<code>multiply(other: FloatMatrix) -&gt; FloatMatrix</code>","text":"<p>Multiply this matrix by another <code>FloatMatrix</code>.</p>"},{"location":"docs/classes/matrix/pycauset.FloatMatrix/#invert-floatmatrix","title":"<code>invert() -&gt; FloatMatrix</code>","text":"<p>Compute the inverse of the matrix.</p> <p>This is a square-only operation and will raise for non-square shapes.</p>"},{"location":"docs/classes/matrix/pycauset.FloatMatrix/#see-also","title":"See also","text":"<ul> <li>pycauset.MatrixBase</li> <li>pycauset.zeros</li> <li>pycauset.matmul</li> <li>Matrix Guide</li> </ul>"},{"location":"docs/classes/matrix/pycauset.IdentityMatrix/","title":"pycauset.IdentityMatrix","text":"<pre><code>class pycauset.IdentityMatrix(x)\nclass pycauset.IdentityMatrix(n)\nclass pycauset.IdentityMatrix(rows, cols)\n</code></pre> <p>A memory-efficient representation of an Identity Matrix. It stores no data on disk (only a header) and generates values on the fly (\\(1.0\\) on the diagonal, \\(0.0\\) elsewhere).</p> <p>Inherits from pycauset.MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.IdentityMatrix/#parameters","title":"Parameters","text":"<ul> <li>x (int | [rows, cols] | Matrix | Vector): Convenience form. Accepts:<ul> <li><code>N</code> (int) -&gt; \\(N \\times N\\)</li> <li><code>[rows, cols]</code> -&gt; <code>rows \u00d7 cols</code></li> <li>matrix -&gt; <code>(x.rows(), x.cols())</code></li> <li>vector -&gt; \\(N \\times N\\) where \\(N = x.size()\\)</li> </ul> </li> <li>n (int): The dimension of the matrix (\\(N \\times N\\)).</li> <li>rows (int): Number of rows.</li> <li>cols (int): Number of columns.</li> </ul> <p><code>pycauset.identity(x)</code> is an equivalent lower-case convenience factory.</p>"},{"location":"docs/classes/matrix/pycauset.IdentityMatrix/#properties","title":"Properties","text":"<ul> <li>shape (tuple): The dimensions of the matrix <code>(rows, cols)</code>.</li> <li>size() (int): Total element count (\\(rows \\times cols\\)).</li> <li>scalar (float): The scaling factor of the matrix. Default is 1.0.</li> </ul>"},{"location":"docs/classes/matrix/pycauset.IdentityMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/matrix/pycauset.IdentityMatrix/#indexing","title":"Indexing","text":"<p>Element reads use NumPy-style indexing: <code>x = I[i, j]</code>.</p> <ul> <li>Returns <code>scalar</code> if \\(i == j\\) and \\(i &lt; \\min(rows, cols)\\).</li> <li>Returns <code>0.0</code> if \\(i \\neq j\\).</li> </ul>"},{"location":"docs/classes/matrix/pycauset.IdentityMatrix/#multiplyother","title":"<code>multiply(other)</code>","text":"<p>Multiplies this matrix by another matrix. *   If other is an <code>IdentityMatrix</code>, returns a new <code>IdentityMatrix</code> with multiplied scalars. *   If other is another matrix type, performs standard matrix multiplication (result type depends on operands).</p>"},{"location":"docs/classes/matrix/pycauset.IdentityMatrix/#notes","title":"Notes","text":"<p>There is no separate integer <code>IdentityMatrix</code> variant in the public Python API.</p> <pre><code># (no IdentityMatrixInt public binding)\n</code></pre>"},{"location":"docs/classes/matrix/pycauset.IdentityMatrix/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\n# Explicit shape\nI35 = pc.IdentityMatrix(3, 5)\n\n# Shape derived from an existing object\nA = pc.FloatMatrix(2, 4)\nIA = pc.identity(A)          # 2x4 identity-like\n\nv = pc.IntegerVector(7)\nIv = pc.identity(v)          # 7x7\n</code></pre>"},{"location":"docs/classes/matrix/pycauset.IdentityMatrix/#see-also","title":"See also","text":"<ul> <li>pycauset.identity</li> <li>pycauset.MatrixBase</li> <li>pycauset.matmul</li> <li>Matrix Guide</li> </ul>"},{"location":"docs/classes/matrix/pycauset.Int16Matrix/","title":"pycauset.Int16Matrix","text":"<p>A memory-mapped dense matrix storing 16-bit signed integers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.Int16Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.Int16Matrix(n: int)\npycauset.Int16Matrix(rows: int, cols: int)\npycauset.Int16Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>int16</code>.</p>"},{"location":"docs/classes/matrix/pycauset.Int16Matrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.Int16Matrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.Int16Matrix/#methods","title":"Methods","text":"<p>Inherits the common matrix interface from pycauset.MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.Int64Matrix/","title":"pycauset.Int64Matrix","text":"<p>A memory-mapped dense matrix storing 64-bit signed integers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.Int64Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.Int64Matrix(n: int)\npycauset.Int64Matrix(rows: int, cols: int)\npycauset.Int64Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>int64</code>.</p>"},{"location":"docs/classes/matrix/pycauset.Int64Matrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.Int64Matrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.Int64Matrix/#methods","title":"Methods","text":"<p>Inherits the common matrix interface from pycauset.MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.Int8Matrix/","title":"pycauset.Int8Matrix","text":"<p>A memory-mapped dense matrix storing 8-bit signed integers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.Int8Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.Int8Matrix(n: int)\npycauset.Int8Matrix(rows: int, cols: int)\npycauset.Int8Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>int8</code>.</p>"},{"location":"docs/classes/matrix/pycauset.Int8Matrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.Int8Matrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.Int8Matrix/#methods","title":"Methods","text":"<p>Inherits the common matrix interface from pycauset.MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.IntegerMatrix/","title":"pycauset.IntegerMatrix","text":"<p>A memory-mapped dense matrix storing 32-bit integers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.IntegerMatrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.IntegerMatrix(n: int)\npycauset.IntegerMatrix(rows: int, cols: int)\npycauset.IntegerMatrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>int32</code>.</p>"},{"location":"docs/classes/matrix/pycauset.IntegerMatrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.IntegerMatrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.IntegerMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/matrix/pycauset.IntegerMatrix/#indexing","title":"Indexing","text":"<p>Element access uses NumPy-style indexing:</p> <pre><code>x = M[i, j]\nM[i, j] = value\n</code></pre>"},{"location":"docs/classes/matrix/pycauset.IntegerMatrix/#multiplyother-integermatrix-integermatrix","title":"<code>multiply(other: IntegerMatrix) -&gt; IntegerMatrix</code>","text":"<p>Multiply this matrix by another <code>IntegerMatrix</code>.</p>"},{"location":"docs/classes/matrix/pycauset.IntegerMatrix/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>String representation of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.IntegerMatrix/#see-also","title":"See also","text":"<ul> <li>pycauset.MatrixBase</li> <li>pycauset.zeros</li> <li>pycauset.matmul</li> <li>Matrix Guide</li> </ul>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/","title":"pycauset.MatrixBase","text":"<pre><code>class pycauset.MatrixBase\n</code></pre> <p>The abstract base class for all matrix types in <code>pycauset</code>. It manages the storage (memory-mapped file or RAM), lifecycle, and common properties like scaling.</p> <p><code>MatrixBase</code> is rectangular-aware: every matrix has a logical <code>(rows, cols)</code> shape, and transpose is usually represented as a metadata view.</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#shape-and-size","title":"Shape and size","text":"<ul> <li><code>shape</code> is a property returning <code>(rows, cols)</code>.</li> <li><code>rows()</code> / <code>cols()</code> are methods returning the logical dimensions.</li> <li><code>size()</code> is a method returning the total element count: \\(\\text{rows} \\times \\text{cols}\\).</li> </ul>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#elementwise-operations-and-broadcasting","title":"Elementwise operations and broadcasting","text":"<p>Elementwise operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>) follow NumPy-style 2D broadcasting:</p> <ul> <li>Two shapes <code>(a_rows, a_cols)</code> and <code>(b_rows, b_cols)</code> are compatible if each dimension is either equal or one of them is <code>1</code>.</li> <li>The result shape is <code>(max(a_rows, b_rows), max(a_cols, b_cols))</code>.</li> <li>When mixing a matrix with a 1D NumPy array in an elementwise operation, the array is treated as a row vector with shape <code>(1, n)</code>.</li> </ul>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#indexing-slicing-and-assignment","title":"Indexing, slicing, and assignment","text":"<p><code>MatrixBase</code> implements NumPy-aligned 2D indexing for dense matrices (basic indexing as views, advanced indexing as copies). Structured/triangular matrices currently reject slicing.</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#reads-__getitem__","title":"Reads (<code>__getitem__</code>)","text":"<ul> <li>Basic indexing (views): integers (with negative wrap), <code>:</code>, <code>slice</code> with step (positive/negative), and <code>...</code> return a view that shares backing storage when both row/col steps are <code>1</code>. Transpose/conjugate metadata is preserved.</li> <li>Advanced indexing (copies): 1D integer arrays (negative wrap) and 1D boolean masks per axis are supported. Any use of arrays (alone or mixed with basic) returns a copy with NumPy shape rules. Two array axes must have equal length or length-1 to broadcast; otherwise an error is raised.</li> <li>Empty and OOB: Empty slices are allowed; out-of-bounds indices raise <code>IndexError</code>.</li> <li>Not supported: <code>None</code>/newaxis is rejected (matrices stay 2D-only).</li> </ul>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#writes-__setitem__","title":"Writes (<code>__setitem__</code>)","text":"<ul> <li>Right-hand side forms: scalar, NumPy arrays (0D/1D/2D), or another dense matrix.</li> <li>Broadcasting: RHS must broadcast to the indexed region using NumPy 2D rules; otherwise a <code>ValueError</code> is raised.</li> <li>Dtype/overflow warnings: Casting RHS arrays to the target dtype raises <code>PyCausetDTypeWarning</code>; narrowing or float\u2192int casts also raise <code>PyCausetOverflowRiskWarning</code>.</li> <li>View vs copy: Basic targets write through views (shared backing). Advanced targets write into the selected elements of the original matrix (index arrays are copies of indices, not of data).</li> <li>Not supported: <code>None</code>/newaxis targets; structured/triangular matrix slicing.</li> </ul>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#interaction-with-compute-kernels","title":"Interaction with compute kernels","text":"<p>Views that include storage offsets are rejected by <code>matmul</code>, <code>qr</code>, <code>lu</code>, and <code>inverse</code> until offset-aware kernels land. Materialize with <code>copy()</code> before calling those ops.</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#properties","title":"Properties","text":"<ul> <li>scalar (float or complex): A scaling factor applied to all elements when accessed as doubles. Defaults to <code>1.0</code>. Setting this property updates the file header instantly.</li> <li>seed (int): The random seed used to generate the matrix, if applicable. Read-only. Returns <code>0</code> if no seed was recorded.</li> <li>is_temporary (bool): Indicates whether the backing storage is temporary (RAM or temp file) and should be deleted/released on exit.</li> <li>shape (tuple[int, int]): The dimensions of the matrix <code>(rows, cols)</code>.</li> <li>backing_file (str): Absolute path to the backing file on disk.</li> <li> <p>properties (MutableMapping[str, Any]): Semantic properties and cached-derived values.</p> <ul> <li>Gospel assertions are authoritative (not truth-validated).</li> <li>Boolean-like keys use tri-state semantics: unset means the key is absent.</li> <li>Incompatible asserted states raise immediately (no payload scan).</li> </ul> <p>See R1 Properties and Storage and Memory.</p> </li> </ul>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#methods","title":"Methods","text":""},{"location":"docs/classes/matrix/pycauset.MatrixBase/#rows-cols-size","title":"<code>rows()</code> / <code>cols()</code> / <code>size()</code>","text":"<ul> <li><code>rows()</code> and <code>cols()</code> report the logical shape.</li> <li><code>size()</code> reports the total element count.</li> </ul>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#close","title":"<code>close()</code>","text":"<p>Releases the memory-mapped file handle or frees the RAM buffer. The matrix object becomes unusable after calling this method.</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#fillvalue","title":"<code>fill(value)</code>","text":"<p>Fill the matrix with a scalar value.</p> <p>This is an explicit full write. On very large disk-backed matrices, this can be a long I/O operation.</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#get_backing_file","title":"<code>get_backing_file()</code>","text":"<p>Returns the absolute path to the backing file on disk.</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#get_element_as_doublei-j","title":"<code>get_element_as_double(i, j)</code>","text":"<p>Returns the element at \\((i, j)\\) as a double-precision float, multiplied by <code>scalar</code>.</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#trace","title":"<code>trace()</code>","text":"<p>Returns the trace of the matrix (sum of diagonal elements).</p> <p>For rectangular matrices, this uses the diagonal length \\(\\min(\\text{rows}, \\text{cols})\\). *   Caching: The result is cached in memory. Subsequent calls return the cached value instantly. *   Persistence: When the matrix is saved using <code>save()</code>, cached-derived values may be written to the file\u2019s typed metadata and automatically restored upon loading.</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#determinant","title":"<code>determinant()</code>","text":"<p>Returns the determinant of the matrix.</p> <p>This is a square-only operation and will raise for non-square shapes. *   Caching: The result is cached in memory. *   Persistence: May be saved to typed metadata and restored upon loading.</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#transpose-t","title":"<code>transpose()</code> / <code>T</code>","text":"<p>Returns a transposed view of the same underlying storage (usually metadata-only; no element-wise copy).</p>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#indexing-mi-j","title":"Indexing (<code>M[i, j]</code>)","text":"<p>Element access uses NumPy-style indexing:</p> <ul> <li>Read: <code>x = M[i, j]</code></li> <li>Write: <code>M[i, j] = value</code></li> </ul>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\nA = pc.zeros((2, 3), dtype=\"float64\")\nassert A.shape == (2, 3)\nassert A.rows() == 2\nassert A.cols() == 3\nassert A.size() == 6\n\nAT = A.T\nassert AT.shape == (3, 2)\n</code></pre>"},{"location":"docs/classes/matrix/pycauset.MatrixBase/#see-also","title":"See also","text":"<ul> <li>pycauset.zeros</li> <li>pycauset.ones</li> <li>pycauset.empty</li> <li>pycauset.matmul</li> <li>Memory and Data</li> <li>Matrix Guide</li> <li>NumPy Alignment Protocol</li> </ul>"},{"location":"docs/classes/matrix/pycauset.SymmetricMatrix/","title":"pycauset.SymmetricMatrix","text":"<pre><code>class pycauset.SymmetricMatrix(TriangularMatrix)\n</code></pre> <p>A matrix where \\(A_{ij} = A_{ji}\\).</p> <p>This class stores only the upper triangular part of the matrix (including the diagonal) to save memory. It supports both symmetric and anti-symmetric matrices.</p>"},{"location":"docs/classes/matrix/pycauset.SymmetricMatrix/#parameters","title":"Parameters","text":"<ul> <li>n (int): The number of rows/columns (matrix is square).</li> </ul> <p>Note: For anti-symmetric matrices, use pycauset.AntiSymmetricMatrix instead.</p>"},{"location":"docs/classes/matrix/pycauset.SymmetricMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/matrix/pycauset.SymmetricMatrix/#indexing","title":"Indexing","text":"<p>Element access uses NumPy-style indexing:</p> <ul> <li>Read: <code>x = A[i, j]</code> (if <code>i &gt; j</code>, reads from the stored upper triangle)</li> <li>Write: <code>A[i, j] = value</code> (if <code>i &gt; j</code>, writes into the stored upper triangle)</li> </ul> <p>Note: For anti-symmetric matrices, the diagonal must be zero.</p>"},{"location":"docs/classes/matrix/pycauset.SymmetricMatrix/#transpose","title":"<code>transpose()</code>","text":"<p>Returns a new matrix representing the transpose. *   For symmetric matrices, this returns a copy of itself.</p> <p>For anti-symmetric matrices, see pycauset.AntiSymmetricMatrix.</p>"},{"location":"docs/classes/matrix/pycauset.SymmetricMatrix/#storage","title":"Storage","text":"<p>Uses a packed upper-triangular format. The storage size is approximately \\(N(N+1)/2\\) elements.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularBitMatrix/","title":"pycauset.TriangularBitMatrix","text":"<pre><code>class pycauset.TriangularBitMatrix(n)\n</code></pre> <p>The primary class for representing causal structures. It stores boolean values in a strictly upper triangular format (\\(i &lt; j\\)), using bit-packing for efficiency (1 bit per element).</p> <p>Inherits from pycauset.TriangularMatrix.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularBitMatrix/#parameters","title":"Parameters","text":"<ul> <li>n (int): The dimension of the matrix (\\(N \\times N\\)).</li> </ul>"},{"location":"docs/classes/matrix/pycauset.TriangularBitMatrix/#properties","title":"Properties","text":"<ul> <li>shape (tuple): The dimensions of the matrix <code>(N, N)</code>.</li> <li>size() (int): Total logical element count (\\(N \\times N\\)).</li> </ul>"},{"location":"docs/classes/matrix/pycauset.TriangularBitMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/matrix/pycauset.TriangularBitMatrix/#indexing","title":"Indexing","text":"<p>Element access uses NumPy-style indexing:</p> <ul> <li>Read: <code>x = M[i, j]</code> (returns <code>False</code> if \\(i \\ge j\\))</li> <li>Write: <code>M[i, j] = value</code> (raises <code>ValueError</code> if \\(i \\ge j\\))</li> </ul>"},{"location":"docs/classes/matrix/pycauset.TriangularBitMatrix/#multiplyother","title":"<code>multiply(other)</code>","text":"<p>Multiplies this matrix by another <code>TriangularBitMatrix</code>. *   other: Another <code>TriangularBitMatrix</code>. *   Returns: A pycauset.TriangularIntegerMatrix. *   Performance Note: This operation is highly optimized on the CPU using <code>popcount</code> instructions. It is typically faster than GPU execution for sparse boolean matrices.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularBitMatrix/#elementwise_multiplyother","title":"<code>elementwise_multiply(other)</code>","text":"<p>Performs elementwise logical AND. *   Returns: A new <code>TriangularBitMatrix</code>.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularBitMatrix/#get_element_as_doublei-j","title":"<code>get_element_as_double(i, j)</code>","text":"<p>Returns the element as a double, applying the internal scalar. *   Optimized to avoid multiplication if <code>scalar == 1.0</code>.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularBitMatrix/#see-also","title":"See also","text":"<ul> <li>pycauset.causal_matrix</li> <li>pycauset.TriangularIntegerMatrix</li> <li>pycauset.MatrixBase</li> </ul>"},{"location":"docs/classes/matrix/pycauset.TriangularFloatMatrix/","title":"pycauset.TriangularFloatMatrix","text":"<p>A memory-mapped upper triangular matrix storing 64-bit floating point numbers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularFloatMatrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.TriangularFloatMatrix(n: int, has_diagonal: bool = False)\n</code></pre> <p>Creates a new triangular matrix of size <code>n x n</code>.</p> <ul> <li><code>n</code>: The number of rows/columns.</li> <li><code>has_diagonal</code>: If <code>True</code>, the matrix stores and allows access to the diagonal elements. If <code>False</code> (default), the matrix is strictly upper triangular (diagonal is implicitly 0).</li> </ul>"},{"location":"docs/classes/matrix/pycauset.TriangularFloatMatrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.TriangularFloatMatrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularFloatMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/matrix/pycauset.TriangularFloatMatrix/#indexing","title":"Indexing","text":"<p>Element access uses NumPy-style indexing:</p> <pre><code>x = M[i, j]\nM[i, j] = value\n</code></pre>"},{"location":"docs/classes/matrix/pycauset.TriangularFloatMatrix/#multiplyother-triangularfloatmatrix-triangularfloatmatrix","title":"<code>multiply(other: TriangularFloatMatrix) -&gt; TriangularFloatMatrix</code>","text":"<p>Multiply this matrix by another <code>TriangularFloatMatrix</code>.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularFloatMatrix/#invert-triangularfloatmatrix","title":"<code>invert() -&gt; TriangularFloatMatrix</code>","text":"<p>Compute the inverse of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularFloatMatrix/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>String representation of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularIntegerMatrix/","title":"pycauset.TriangularIntegerMatrix","text":"<p>A memory-mapped upper triangular matrix storing 32-bit integers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularIntegerMatrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.TriangularIntegerMatrix(n: int, has_diagonal: bool = False)\n</code></pre> <p>Creates a new triangular matrix of size <code>n x n</code>.</p> <ul> <li><code>n</code>: The number of rows/columns.</li> <li><code>has_diagonal</code>: If <code>True</code>, the matrix stores and allows access to the diagonal elements. If <code>False</code> (default), the matrix is strictly upper triangular (diagonal is implicitly 0).</li> </ul>"},{"location":"docs/classes/matrix/pycauset.TriangularIntegerMatrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.TriangularIntegerMatrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularIntegerMatrix/#methods","title":"Methods","text":""},{"location":"docs/classes/matrix/pycauset.TriangularIntegerMatrix/#indexing","title":"Indexing","text":"<p>Element access uses NumPy-style indexing:</p> <pre><code>x = M[i, j]\nM[i, j] = value\n</code></pre>"},{"location":"docs/classes/matrix/pycauset.TriangularIntegerMatrix/#invert-triangularintegermatrix","title":"<code>invert() -&gt; TriangularIntegerMatrix</code>","text":"<p>Compute the inverse of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularIntegerMatrix/#__invert__-triangularintegermatrix","title":"<code>__invert__() -&gt; TriangularIntegerMatrix</code>","text":"<p>Compute the bitwise NOT of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularIntegerMatrix/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>String representation of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.TriangularMatrix/","title":"pycauset.TriangularMatrix","text":"<pre><code>class pycauset.TriangularMatrix(Matrix)\n</code></pre> <p>Abstract base class for all triangular matrices.</p> <p>This class serves as a common interface for <code>TriangularBitMatrix</code>, <code>TriangularIntegerMatrix</code>, and <code>TriangularFloatMatrix</code>.</p>"},{"location":"docs/classes/matrix/pycauset.UInt16Matrix/","title":"pycauset.UInt16Matrix","text":"<p>A memory-mapped dense matrix storing 16-bit unsigned integers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.UInt16Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.UInt16Matrix(n: int)\npycauset.UInt16Matrix(rows: int, cols: int)\npycauset.UInt16Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>uint16</code>.</p>"},{"location":"docs/classes/matrix/pycauset.UInt16Matrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.UInt16Matrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.UInt16Matrix/#methods","title":"Methods","text":"<p>Inherits the common matrix interface from pycauset.MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.UInt32Matrix/","title":"pycauset.UInt32Matrix","text":"<p>A memory-mapped dense matrix storing 32-bit unsigned integers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.UInt32Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.UInt32Matrix(n: int)\npycauset.UInt32Matrix(rows: int, cols: int)\npycauset.UInt32Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>uint32</code>.</p>"},{"location":"docs/classes/matrix/pycauset.UInt32Matrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.UInt32Matrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.UInt32Matrix/#methods","title":"Methods","text":"<p>Inherits the common matrix interface from pycauset.MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.UInt64Matrix/","title":"pycauset.UInt64Matrix","text":"<p>A memory-mapped dense matrix storing 64-bit unsigned integers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.UInt64Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.UInt64Matrix(n: int)\npycauset.UInt64Matrix(rows: int, cols: int)\npycauset.UInt64Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>uint64</code>.</p>"},{"location":"docs/classes/matrix/pycauset.UInt64Matrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.UInt64Matrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.UInt64Matrix/#methods","title":"Methods","text":"<p>Inherits the common matrix interface from pycauset.MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.UInt8Matrix/","title":"pycauset.UInt8Matrix","text":"<p>A memory-mapped dense matrix storing 8-bit unsigned integers. Inherits from MatrixBase.</p>"},{"location":"docs/classes/matrix/pycauset.UInt8Matrix/#constructor","title":"Constructor","text":"<pre><code>pycauset.UInt8Matrix(n: int)\npycauset.UInt8Matrix(rows: int, cols: int)\npycauset.UInt8Matrix(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-2 with dtype <code>uint8</code>.</p>"},{"location":"docs/classes/matrix/pycauset.UInt8Matrix/#properties","title":"Properties","text":""},{"location":"docs/classes/matrix/pycauset.UInt8Matrix/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple <code>(rows, cols)</code> representing the dimensions of the matrix.</p>"},{"location":"docs/classes/matrix/pycauset.UInt8Matrix/#methods","title":"Methods","text":"<p>Inherits the common matrix interface from pycauset.MatrixBase.</p>"},{"location":"docs/classes/spacetime/","title":"Spacetime","text":"<ul> <li>CausalSet</li> <li>CausalSpacetime</li> <li>MinkowskiBox</li> <li>MinkowskiCylinder</li> <li>MinkowskiDiamond</li> <li>spacetime</li> </ul>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/","title":"pycauset.CausalSet","text":"<pre><code>class CausalSet(n=None, density=None, spacetime=None, seed=None)\n</code></pre> <p>The <code>CausalSet</code> class represents a causal set generated by sprinkling points into a spacetime manifold. It uses a memory-efficient \"stateless\" sprinkling algorithm that allows for the generation of extremely large causal sets (billions of elements) without storing the coordinates of the points in RAM.</p>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#parameters","title":"Parameters","text":"<ul> <li>n (int, optional): The number of elements (points) to sprinkle.</li> <li>density (float, optional): The density of the sprinkling. If provided, \\(N\\) is calculated as a Poisson random variable with mean \\(\\text{density} \\times \\text{volume}\\). You must provide either <code>n</code> or <code>density</code>.</li> <li>spacetime (CausalSpacetime, optional): The spacetime manifold to sprinkle into. If <code>None</code>, defaults to a 2-dimensional Minkowski Diamond.</li> <li>seed (int, optional): The random seed for the sprinkling process. If <code>None</code>, a random seed is generated.</li> </ul>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#properties","title":"Properties","text":""},{"location":"docs/classes/spacetime/pycauset.CausalSet/#causal_matrix","title":"causal_matrix","text":"<pre><code>@property\ndef causal_matrix(self) -&gt; TriangularBitMatrix\n</code></pre> <p>(Alias: <code>C</code>)</p> <p>Returns the causal matrix of the set. This is the primary \"product\" of the <code>CausalSet</code> instance. It is a <code>TriangularBitMatrix</code> where <code>M[i, j] = 1</code> if element <code>i</code> causally precedes element <code>j</code> (\\(i \\prec j\\)), and 0 otherwise.</p> <p>Storage Note: The <code>CausalSet</code> instance itself is very lightweight. It stores only the metadata (\\(N\\), seed, spacetime definition) and a handle to this matrix. The matrix itself is backed by a file on disk (memory-mapped), so creating a <code>CausalSet</code> does not load the entire structure into RAM. The coordinates of the sprinkled points are not stored; they are generated transiently to compute this matrix and then discarded.</p>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#n","title":"n","text":"<pre><code>@property\ndef n(self) -&gt; int\n</code></pre> <p>(Alias: <code>N</code>)</p> <p>The number of elements in the causal set.</p>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#density","title":"density","text":"<pre><code>@property\ndef density(self) -&gt; float\n</code></pre> <p>(Alias: <code>rho</code>)</p> <p>The density of the sprinkling, calculated as \\(N / V\\), where \\(V\\) is the volume of the spacetime region.</p>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#spacetime","title":"spacetime","text":"<pre><code>@property\ndef spacetime(self) -&gt; CausalSpacetime\n</code></pre> <p>The spacetime manifold object used for sprinkling.</p>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#methods","title":"Methods","text":""},{"location":"docs/classes/spacetime/pycauset.CausalSet/#__init__","title":"__init__","text":"<pre><code>def __init__(self, n: int = None, density: float = None, spacetime=None, seed: int = None, matrix=None)\n</code></pre> <p>Initializes the causal set.</p> <ul> <li>Sprinkling Mode: Provide <code>n</code> (or <code>density</code>), and optionally <code>spacetime</code> and <code>seed</code>. The set will be generated by sprinkling points.</li> <li>Loading Mode: Used internally by <code>load()</code>. Provide <code>n</code>, <code>spacetime</code>, <code>seed</code>, and <code>matrix</code>.</li> </ul>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#compute_k","title":"compute_k","text":"<pre><code>def compute_k(self, a: float = 1.0) -&gt; TriangularFloatMatrix\n</code></pre> <p>Compute the K-matrix (retarded propagator) for this causal set.</p> <ul> <li>a (float): The non-locality scale parameter. Defaults to 1.0.</li> <li>Returns: A <code>TriangularFloatMatrix</code> representing \\(K = C(aI + C)^{-1}\\).</li> </ul>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#save","title":"save","text":"<pre><code>def save(self, path: str)\n</code></pre> <p>Save the <code>CausalSet</code> to a single-file <code>.pycauset</code> container.</p> <ul> <li>path (str): The destination path.</li> </ul>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#load","title":"load","text":"<pre><code>@staticmethod\ndef load(path: str) -&gt; CausalSet\n</code></pre> <p>Load a <code>CausalSet</code> from a <code>.pycauset</code> container. This reconstructs the <code>CausalSet</code> object with the exact same parameters and matrix as the saved instance, without re-running the sprinkling process.</p> <ul> <li>path (str): Path to the <code>.pycauset</code> file.</li> <li>Returns: A new <code>CausalSet</code> instance.</li> </ul>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#__len__","title":"__len__","text":"<pre><code>def __len__(self) -&gt; int\n</code></pre> <p>Returns the number of elements (\\(N\\)).</p>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#examples","title":"Examples","text":"<pre><code>import pycauset\n\n# 1. Create and Save\nc = pycauset.CausalSet(1000, seed=42)\nc.save(\"my_universe\")\n\n# 2. Load\nc_loaded = pycauset.CausalSet.load(\"my_universe.pycauset\")\nprint(f\"Loaded N={len(c_loaded)}\")\n\n# 3. Compute K\nK = c.compute_k(a=1.5)\n</code></pre>"},{"location":"docs/classes/spacetime/pycauset.CausalSet/#examples_1","title":"Examples","text":"<pre><code>import pycauset\n\n# Create a causal set with 1000 elements in 2D Minkowski space\nc = pycauset.CausalSet(1000)\n\n# Access the causal matrix (using the alias C)\nM = c.C\n\n# Check if element 0 precedes element 10\nis_causal = M[0, 10]\n\n# Create a causal set with a specific seed for reproducibility\nc_repro = pycauset.causet(n=500, seed=42)\nprint(c_repro.causal_matrix)\n</code></pre>"},{"location":"docs/classes/spacetime/pycauset.spacetime.CausalSpacetime/","title":"pycauset.spacetime.CausalSpacetime","text":"<pre><code>class CausalSpacetime\n</code></pre> <p>The abstract base class for all spacetime manifolds in PyCauset.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.CausalSpacetime/#description","title":"Description","text":"<p>This class defines the interface that all spacetime implementations must adhere to. It allows the <code>Sprinkler</code> to generate points and determine causal relations without knowing the details of the underlying geometry.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.CausalSpacetime/#methods","title":"Methods","text":""},{"location":"docs/classes/spacetime/pycauset.spacetime.CausalSpacetime/#dimension","title":"dimension","text":"<pre><code>def dimension(self) -&gt; int\n</code></pre> <p>Returns the number of spacetime dimensions (e.g., 2 for 1+1 dimensions).</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.CausalSpacetime/#volume","title":"volume","text":"<pre><code>def volume(self) -&gt; float\n</code></pre> <p>Returns the total spacetime volume of the region represented by this object. This is used by the sprinkler to calculate the expected number of elements for a given density.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/","title":"pycauset.spacetime.MinkowskiBox","text":"<pre><code>class MinkowskiBox(dimension: int, time_extent: float, space_extent: float)\n</code></pre> <p>Inherits from: pycauset.spacetime.CausalSpacetime</p> <p>Represents a rectangular region (block) in flat Minkowski space with hard boundaries.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#description","title":"Description","text":"<p>Unlike the <code>MinkowskiDiamond</code>, which is defined by null boundaries (light rays), the <code>MinkowskiBox</code> is defined by coordinate planes. This is useful for studying finite-size effects with spatial boundaries.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#parameters","title":"Parameters","text":"<ul> <li>dimension (int): The dimension of the spacetime.</li> <li>time_extent (float): The duration of the region in the time coordinate (\\(t \\in [0, T]\\)).</li> <li>space_extent (float): The length of the region in the spatial coordinates (\\(x_i \\in [0, L]\\)).</li> </ul>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#properties","title":"Properties","text":""},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#time_extent","title":"time_extent","text":"<pre><code>@property\ndef time_extent(self) -&gt; float\n</code></pre> <p>The temporal extent of the box.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#space_extent","title":"space_extent","text":"<pre><code>@property\ndef space_extent(self) -&gt; float\n</code></pre> <p>The spatial extent of the box.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#methods","title":"Methods","text":""},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#dimension","title":"dimension","text":"<pre><code>def dimension(self) -&gt; int\n</code></pre> <p>Returns the dimension of the spacetime.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#volume","title":"volume","text":"<pre><code>def volume(self) -&gt; float\n</code></pre> <p>Returns the volume of the box (\\(T \\times L^{d-1}\\)).</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#transform_coordinates","title":"transform_coordinates","text":"<pre><code>def transform_coordinates(self, coords: np.ndarray) -&gt; np.ndarray\n</code></pre> <p>(Extension) Returns the coordinates as-is (identity transform), as they are already Cartesian.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiBox/#get_boundary","title":"get_boundary","text":"<pre><code>def get_boundary(self) -&gt; List[np.ndarray]\n</code></pre> <p>(Extension) Returns the rectangular boundary of the box for visualization.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/","title":"pycauset.spacetime.MinkowskiCylinder","text":"<pre><code>class MinkowskiCylinder(dimension: int, height: float, circumference: float)\n</code></pre> <p>Inherits from: pycauset.spacetime.CausalSpacetime</p> <p>Represents a flat Minkowski spacetime with periodic spatial boundary conditions (\\(S^1 \\times \\mathbb{R}\\)).</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#description","title":"Description","text":"<p>This topology is often used to study effects of spatial compactness. The spatial dimension wraps around, creating a cylinder-like structure in spacetime.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#parameters","title":"Parameters","text":"<ul> <li>dimension (int): The dimension of the spacetime. Currently, only \\(d=2\\) is supported.</li> <li>height (float): The temporal duration of the region (\\(t \\in [0, h]\\)).</li> <li>circumference (float): The spatial circumference of the cylinder (\\(x \\in [0, c]\\)).</li> </ul>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#properties","title":"Properties","text":""},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#height","title":"height","text":"<pre><code>@property\ndef height(self) -&gt; float\n</code></pre> <p>The temporal height of the cylinder.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#circumference","title":"circumference","text":"<pre><code>@property\ndef circumference(self) -&gt; float\n</code></pre> <p>The spatial circumference of the cylinder.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#methods","title":"Methods","text":""},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#dimension","title":"dimension","text":"<pre><code>def dimension(self) -&gt; int\n</code></pre> <p>Returns the dimension of the spacetime.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#transform_coordinates","title":"transform_coordinates","text":"<pre><code>def transform_coordinates(self, coords: np.ndarray) -&gt; np.ndarray\n</code></pre> <p>(Extension) Transforms raw coordinates to a visualization-friendly basis. For 2D, this maps \\((t, x)\\) to 3D cylindrical coordinates \\((z, x, y)\\).</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#get_boundary","title":"get_boundary","text":"<pre><code>def get_boundary(self) -&gt; List[np.ndarray]\n</code></pre> <p>(Extension) Returns the boundary rings (top and bottom) of the cylinder in the transformed coordinate system.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiCylinder/#volume","title":"volume","text":"<pre><code>def volume(self) -&gt; float\n</code></pre> <p>Returns the volume of the cylinder, calculated as \\(height \\times circumference\\).</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiDiamond/","title":"pycauset.spacetime.MinkowskiDiamond","text":"<pre><code>class MinkowskiDiamond(dimension: int)\n</code></pre> <p>Inherits from: pycauset.spacetime.CausalSpacetime</p> <p>Represents a causal diamond (Alexandrov interval) in flat Minkowski space.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiDiamond/#description","title":"Description","text":"<p>A causal diamond is the intersection of the future of a point \\(p\\) and the past of a point \\(q\\), where \\(p \\prec q\\). In PyCauset, this is typically the standard unit diamond defined by the interval \\([0, 1]^d\\) in lightcone coordinates.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiDiamond/#parameters","title":"Parameters","text":"<ul> <li>dimension (int): The dimension of the spacetime. Currently, only \\(d=2\\) is fully supported for causal checks.</li> </ul>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiDiamond/#methods","title":"Methods","text":""},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiDiamond/#dimension","title":"dimension","text":"<pre><code>def dimension(self) -&gt; int\n</code></pre> <p>Returns the dimension of the spacetime.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiDiamond/#volume","title":"volume","text":"<pre><code>def volume(self) -&gt; float\n</code></pre> <p>Returns the volume of the diamond. For the standard unit diamond in lightcone coordinates, the volume is normalized to 1.0.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiDiamond/#transform_coordinates","title":"transform_coordinates","text":"<pre><code>def transform_coordinates(self, coords: np.ndarray) -&gt; np.ndarray\n</code></pre> <p>(Extension) Transforms raw lightcone coordinates to a visualization-friendly basis. For 2D, this rotates \\((u, v)\\) to Cartesian \\((t, x)\\).</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime.MinkowskiDiamond/#get_boundary","title":"get_boundary","text":"<pre><code>def get_boundary(self) -&gt; List[np.ndarray]\n</code></pre> <p>(Extension) Returns the boundary of the spacetime region in the transformed coordinate system. Used by visualization functions to draw the diamond edges.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime/","title":"pycauset.spacetime","text":"<p>The <code>pycauset.spacetime</code> module contains classes representing different spacetime manifolds.</p>"},{"location":"docs/classes/spacetime/pycauset.spacetime/#classes","title":"Classes","text":"<ul> <li>pycauset.spacetime.CausalSpacetime: The abstract base class for all spacetimes.</li> <li>pycauset.spacetime.MinkowskiDiamond: A causal diamond in flat space.</li> <li>pycauset.spacetime.MinkowskiCylinder: Flat space with periodic spatial boundaries.</li> <li>pycauset.spacetime.MinkowskiBox: A rectangular block in flat space.</li> </ul>"},{"location":"docs/classes/vector/","title":"Vector","text":"<ul> <li>pycauset.vector</li> <li>pycauset.VectorBase</li> <li>pycauset.UnitVector</li> <li>pycauset.BitVector</li> <li>pycauset.IntegerVector</li> <li>pycauset.Int8Vector</li> <li>pycauset.Int16Vector</li> <li>pycauset.Int64Vector</li> <li>pycauset.UInt8Vector</li> <li>pycauset.UInt16Vector</li> <li>pycauset.UInt32Vector</li> <li>pycauset.UInt64Vector</li> <li>pycauset.FloatVector</li> <li>pycauset.Float32Vector</li> <li>pycauset.Float16Vector</li> <li>pycauset.ComplexFloat64Vector</li> <li>pycauset.ComplexFloat32Vector</li> <li>pycauset.ComplexFloat16Vector</li> </ul>"},{"location":"docs/classes/vector/pycauset.BitVector/","title":"pycauset.BitVector","text":"<p>A memory-mapped vector storing boolean values (bits). Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.BitVector/#constructor","title":"Constructor","text":"<pre><code>pycauset.BitVector(n: int)\n</code></pre>"},{"location":"docs/classes/vector/pycauset.BitVector/#properties","title":"Properties","text":""},{"location":"docs/classes/vector/pycauset.BitVector/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple representing the dimensions of the vector.</p>"},{"location":"docs/classes/vector/pycauset.BitVector/#methods","title":"Methods","text":""},{"location":"docs/classes/vector/pycauset.BitVector/#__getitem__i-int-bool","title":"<code>__getitem__(i: int) -&gt; bool</code>","text":"<p>Get the value at index <code>i</code>.</p>"},{"location":"docs/classes/vector/pycauset.BitVector/#__setitem__i-int-value-bool","title":"<code>__setitem__(i: int, value: bool)</code>","text":"<p>Set the value at index <code>i</code>.</p>"},{"location":"docs/classes/vector/pycauset.BitVector/#__len__-int","title":"<code>__len__() -&gt; int</code>","text":"<p>Get the size of the vector.</p>"},{"location":"docs/classes/vector/pycauset.BitVector/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>String representation of the vector.</p>"},{"location":"docs/classes/vector/pycauset.ComplexFloat16Vector/","title":"pycauset.ComplexFloat16Vector","text":"<p>A memory-mapped vector storing complex numbers in <code>complex_float16</code> format (two-plane float16: real + imaginary). Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.ComplexFloat16Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.ComplexFloat16Vector(n: int)\npycauset.ComplexFloat16Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>complex64</code> or <code>complex128</code>.</p>"},{"location":"docs/classes/vector/pycauset.ComplexFloat16Vector/#notes","title":"Notes","text":"<p>Complex support is limited to complex floats. Supported operations are gated by the support matrix (see <code>documentation/internals/DType System.md</code>).</p>"},{"location":"docs/classes/vector/pycauset.ComplexFloat32Vector/","title":"pycauset.ComplexFloat32Vector","text":"<p>A memory-mapped vector storing complex numbers in <code>complex_float32</code> format (equivalent to NumPy <code>complex64</code>). Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.ComplexFloat32Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.ComplexFloat32Vector(n: int)\npycauset.ComplexFloat32Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>complex64</code>.</p>"},{"location":"docs/classes/vector/pycauset.ComplexFloat32Vector/#notes","title":"Notes","text":"<p>Complex support is limited to complex floats. Supported operations are gated by the support matrix (see <code>documentation/internals/DType System.md</code>).</p>"},{"location":"docs/classes/vector/pycauset.ComplexFloat64Vector/","title":"pycauset.ComplexFloat64Vector","text":"<p>A memory-mapped vector storing complex numbers in <code>complex_float64</code> format (equivalent to NumPy <code>complex128</code>). Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.ComplexFloat64Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.ComplexFloat64Vector(n: int)\npycauset.ComplexFloat64Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>complex128</code>.</p>"},{"location":"docs/classes/vector/pycauset.ComplexFloat64Vector/#notes","title":"Notes","text":"<p>Complex support is limited to complex floats. Supported operations are gated by the support matrix (see <code>documentation/internals/DType System.md</code>).</p>"},{"location":"docs/classes/vector/pycauset.Float16Vector/","title":"pycauset.Float16Vector","text":"<p>A memory-mapped vector storing 16-bit floating point numbers (half precision). Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.Float16Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.Float16Vector(n: int)\npycauset.Float16Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>float16</code>.</p>"},{"location":"docs/classes/vector/pycauset.Float16Vector/#notes","title":"Notes","text":"<p>Half precision is primarily a storage and bandwidth optimization. Supported operations are gated by the support matrix (see <code>documentation/internals/DType System.md</code>).</p>"},{"location":"docs/classes/vector/pycauset.Float32Vector/","title":"pycauset.Float32Vector","text":"<p>A memory-mapped vector storing 32-bit floating point numbers (single precision). Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.Float32Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.Float32Vector(n: int)\npycauset.Float32Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>float32</code>.</p>"},{"location":"docs/classes/vector/pycauset.Float32Vector/#methods","title":"Methods","text":"<p>Inherits the common vector interface from pycauset.VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.FloatVector/","title":"pycauset.FloatVector","text":"<p>A memory-mapped vector storing 64-bit floating point numbers. Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.FloatVector/#constructor","title":"Constructor","text":"<pre><code>pycauset.FloatVector(n: int)\npycauset.FloatVector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>float64</code>.</p>"},{"location":"docs/classes/vector/pycauset.FloatVector/#properties","title":"Properties","text":""},{"location":"docs/classes/vector/pycauset.FloatVector/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple representing the dimensions of the vector.</p>"},{"location":"docs/classes/vector/pycauset.FloatVector/#methods","title":"Methods","text":""},{"location":"docs/classes/vector/pycauset.FloatVector/#__getitem__i-int-float","title":"<code>__getitem__(i: int) -&gt; float</code>","text":"<p>Get the value at index <code>i</code>.</p>"},{"location":"docs/classes/vector/pycauset.FloatVector/#__setitem__i-int-value-float","title":"<code>__setitem__(i: int, value: float)</code>","text":"<p>Set the value at index <code>i</code>.</p>"},{"location":"docs/classes/vector/pycauset.FloatVector/#__len__-int","title":"<code>__len__() -&gt; int</code>","text":"<p>Get the size of the vector.</p>"},{"location":"docs/classes/vector/pycauset.FloatVector/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>String representation of the vector.</p>"},{"location":"docs/classes/vector/pycauset.Int16Vector/","title":"pycauset.Int16Vector","text":"<p>A memory-mapped vector storing 16-bit signed integers. Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.Int16Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.Int16Vector(n: int)\npycauset.Int16Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>int16</code>.</p>"},{"location":"docs/classes/vector/pycauset.Int16Vector/#methods","title":"Methods","text":"<p>Inherits the common vector interface from pycauset.VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.Int64Vector/","title":"pycauset.Int64Vector","text":"<p>A memory-mapped vector storing 64-bit signed integers. Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.Int64Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.Int64Vector(n: int)\npycauset.Int64Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>int64</code>.</p>"},{"location":"docs/classes/vector/pycauset.Int64Vector/#methods","title":"Methods","text":"<p>Inherits the common vector interface from pycauset.VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.Int8Vector/","title":"pycauset.Int8Vector","text":"<p>A memory-mapped vector storing 8-bit signed integers. Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.Int8Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.Int8Vector(n: int)\npycauset.Int8Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>int8</code>.</p>"},{"location":"docs/classes/vector/pycauset.Int8Vector/#methods","title":"Methods","text":"<p>Inherits the common vector interface from pycauset.VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.IntegerVector/","title":"pycauset.IntegerVector","text":"<p>A memory-mapped vector storing 32-bit integers. Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.IntegerVector/#constructor","title":"Constructor","text":"<pre><code>pycauset.IntegerVector(n: int)\npycauset.IntegerVector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>int32</code>.</p>"},{"location":"docs/classes/vector/pycauset.IntegerVector/#properties","title":"Properties","text":""},{"location":"docs/classes/vector/pycauset.IntegerVector/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple representing the dimensions of the vector.</p>"},{"location":"docs/classes/vector/pycauset.IntegerVector/#methods","title":"Methods","text":""},{"location":"docs/classes/vector/pycauset.IntegerVector/#__getitem__i-int-int","title":"<code>__getitem__(i: int) -&gt; int</code>","text":"<p>Get the value at index <code>i</code>.</p>"},{"location":"docs/classes/vector/pycauset.IntegerVector/#__setitem__i-int-value-int","title":"<code>__setitem__(i: int, value: int)</code>","text":"<p>Set the value at index <code>i</code>.</p>"},{"location":"docs/classes/vector/pycauset.IntegerVector/#__len__-int","title":"<code>__len__() -&gt; int</code>","text":"<p>Get the size of the vector.</p>"},{"location":"docs/classes/vector/pycauset.IntegerVector/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>String representation of the vector.</p>"},{"location":"docs/classes/vector/pycauset.UInt16Vector/","title":"pycauset.UInt16Vector","text":"<p>A memory-mapped vector storing 16-bit unsigned integers. Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.UInt16Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.UInt16Vector(n: int)\npycauset.UInt16Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>uint16</code>.</p>"},{"location":"docs/classes/vector/pycauset.UInt16Vector/#methods","title":"Methods","text":"<p>Inherits the common vector interface from pycauset.VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.UInt32Vector/","title":"pycauset.UInt32Vector","text":"<p>A memory-mapped vector storing 32-bit unsigned integers. Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.UInt32Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.UInt32Vector(n: int)\npycauset.UInt32Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>uint32</code>.</p>"},{"location":"docs/classes/vector/pycauset.UInt32Vector/#methods","title":"Methods","text":"<p>Inherits the common vector interface from pycauset.VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.UInt64Vector/","title":"pycauset.UInt64Vector","text":"<p>A memory-mapped vector storing 64-bit unsigned integers. Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.UInt64Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.UInt64Vector(n: int)\npycauset.UInt64Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>uint64</code>.</p>"},{"location":"docs/classes/vector/pycauset.UInt64Vector/#methods","title":"Methods","text":"<p>Inherits the common vector interface from pycauset.VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.UInt8Vector/","title":"pycauset.UInt8Vector","text":"<p>A memory-mapped vector storing 8-bit unsigned integers. Inherits from VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.UInt8Vector/#constructor","title":"Constructor","text":"<pre><code>pycauset.UInt8Vector(n: int)\npycauset.UInt8Vector(array: numpy.ndarray)\n</code></pre> <p>When constructed from a NumPy array, the array must be rank-1 with dtype <code>uint8</code>.</p>"},{"location":"docs/classes/vector/pycauset.UInt8Vector/#methods","title":"Methods","text":"<p>Inherits the common vector interface from pycauset.VectorBase.</p>"},{"location":"docs/classes/vector/pycauset.UnitVector/","title":"pycauset.UnitVector","text":"<p>A storage-less vector representing a standard basis vector \\(e_k\\) (all zeros except a 1 at index \\(k\\)). Inherits from VectorBase.</p> <p>This vector type uses 0 bytes of disk storage. It stores the active index \\(k\\) in metadata.</p>"},{"location":"docs/classes/vector/pycauset.UnitVector/#constructor","title":"Constructor","text":"<pre><code>pycauset.UnitVector(n: int, active_index: int)\n</code></pre> <ul> <li><code>n</code>: The size of the vector.</li> <li><code>active_index</code>: The index where the value is 1. Must be \\(0 \\le k &lt; n\\).</li> </ul>"},{"location":"docs/classes/vector/pycauset.UnitVector/#properties","title":"Properties","text":""},{"location":"docs/classes/vector/pycauset.UnitVector/#shape","title":"<code>shape</code>","text":"<p>Returns a tuple representing the dimensions of the vector.</p>"},{"location":"docs/classes/vector/pycauset.UnitVector/#methods","title":"Methods","text":""},{"location":"docs/classes/vector/pycauset.UnitVector/#__getitem__i-int-float","title":"<code>__getitem__(i: int) -&gt; float</code>","text":"<p>Get the value at index <code>i</code>. Returns 1.0 if <code>i == active_index</code>, else 0.0.</p>"},{"location":"docs/classes/vector/pycauset.UnitVector/#__len__-int","title":"<code>__len__() -&gt; int</code>","text":"<p>Get the size of the vector.</p>"},{"location":"docs/classes/vector/pycauset.UnitVector/#__repr__-str","title":"<code>__repr__() -&gt; str</code>","text":"<p>String representation of the vector.</p>"},{"location":"docs/classes/vector/pycauset.UnitVector/#arithmetic","title":"Arithmetic","text":"<ul> <li><code>UnitVector + UnitVector</code>:<ul> <li>If active indices match: Returns a <code>UnitVector</code> (scaled).</li> <li>If active indices differ: Returns a <code>DenseVector</code> (e.g., \\(e_1 + e_2\\)).</li> </ul> </li> <li><code>UnitVector + DenseVector</code>: Returns a <code>DenseVector</code>.</li> </ul>"},{"location":"docs/classes/vector/pycauset.VectorBase/","title":"pycauset.VectorBase","text":"<p>Base class for all vector types.</p> <p>Vectors are persistent objects (RAM-backed for small sizes; disk-backed for large sizes) and integrate with matrix operations.</p>"},{"location":"docs/classes/vector/pycauset.VectorBase/#shape-and-transposes","title":"Shape and transposes","text":"<ul> <li>A non-transposed vector behaves like a 1D array with shape <code>(n,)</code>.</li> <li><code>v.T</code> returns a transposed view (row-vector semantics).</li> <li>For complex vector types, <code>v.H</code> returns the conjugate-transpose view.</li> </ul>"},{"location":"docs/classes/vector/pycauset.VectorBase/#properties","title":"Properties","text":""},{"location":"docs/classes/vector/pycauset.VectorBase/#properties_1","title":"<code>properties</code>","text":"<p>Vectors expose <code>v.properties</code>, a typed mapping used for:</p> <ul> <li>gospel assertions (e.g. ordering-related hints such as <code>is_sorted</code>), and</li> <li>cached-derived values (e.g. <code>norm</code>, <code>sum</code>) with strict validity.</li> </ul> <p>Gospel assertions are authoritative (not truth-validated), and incompatible asserted states raise immediately (no payload scan).</p> <p>See R1 Properties and Storage and Memory.</p>"},{"location":"docs/classes/vector/pycauset.VectorBase/#fill","title":"Fill","text":""},{"location":"docs/classes/vector/pycauset.VectorBase/#fillvalue","title":"<code>fill(value)</code>","text":"<p>Fill the vector with a scalar value.</p> <p>This is an explicit full write. On very large disk-backed vectors, this can be a long I/O operation.</p>"},{"location":"docs/classes/vector/pycauset.VectorBase/#common-operations","title":"Common operations","text":""},{"location":"docs/classes/vector/pycauset.VectorBase/#dot-product","title":"Dot product","text":"<pre><code>v.dot(other) -&gt; float | complex\n</code></pre> <p>Computes the dot product. For complex vectors this returns a complex number.</p> <p>Notes:</p> <ul> <li>No implicit conjugation is applied. For a Hermitian-style inner product, use <code>v.conj().dot(other)</code> or <code>v.H @ other</code>.</li> </ul>"},{"location":"docs/classes/vector/pycauset.VectorBase/#matrix-multiplication-operator","title":"Matrix multiplication operator (<code>@</code>)","text":"<p>Vector <code>@</code> uses NumPy-like semantics:</p> <ul> <li><code>v @ w</code> (vector @ vector) returns a scalar dot product.</li> <li><code>v @ w.T</code> (column @ row) returns an outer-product matrix.</li> </ul>"},{"location":"docs/classes/vector/pycauset.VectorBase/#scalar-arithmetic","title":"Scalar arithmetic","text":"<p>Vectors support scalar arithmetic via Python operators:</p> <ul> <li><code>v + s</code> / <code>s + v</code></li> <li><code>v * s</code> / <code>s * v</code></li> </ul> <p>Supported scalar types depend on the vector dtype (real vs complex).</p>"},{"location":"docs/classes/vector/pycauset.VectorBase/#numpy-interoperability","title":"NumPy interoperability","text":""},{"location":"docs/classes/vector/pycauset.VectorBase/#__array__","title":"<code>__array__()</code>","text":"<p>Converts the vector to a NumPy array.</p> <p>Note: this materializes the full vector in memory.</p>"},{"location":"docs/classes/vector/pycauset.VectorBase/#see-also","title":"See also","text":"<ul> <li>pycauset.dot</li> <li>pycauset.sum</li> <li>pycauset.vector</li> <li>Vector Guide</li> </ul>"},{"location":"docs/functions/","title":"Functions","text":"<ul> <li>pycauset.I</li> <li>pycauset.identity</li> <li>pycauset.matrix</li> <li>pycauset.vector</li> <li>pycauset.zeros</li> <li>pycauset.ones</li> <li>pycauset.empty</li> <li>pycauset.causal_matrix</li> <li>pycauset.causet</li> <li>bitwise_not</li> <li>compute_k</li> <li>compute_k_matrix</li> <li>dot</li> <li>divide</li> <li>norm</li> <li>sum</li> <li>get_precision_mode</li> <li>get_memory_threshold</li> <li>get_num_threads</li> <li>invert</li> <li>solve</li> <li>lstsq</li> <li>solve_triangular</li> <li>lu</li> <li>cholesky</li> <li>svd</li> <li>pinv</li> <li>slogdet</li> <li>cond</li> <li>eigh</li> <li>eigvalsh</li> <li>load</li> <li>convert_file</li> <li>to_numpy</li> <li>matmul</li> <li>save</li> <li>set_export_max_bytes</li> <li>set_memory_threshold</li> <li>set_precision_mode</li> <li>set_num_threads</li> <li>precision_mode</li> </ul>"},{"location":"docs/functions/pycauset.I/","title":"pycauset.I","text":"<pre><code>class pycauset.I(x)\nclass pycauset.I(n: int)\nclass pycauset.I(rows: int, cols: int)\n</code></pre> <p>Alias for pycauset.IdentityMatrix.</p> <p><code>pycauset.I(x)</code> accepts the same input forms as pycauset.identity:</p> <ul> <li><code>N</code> (int) -&gt; \\(N \\times N\\)</li> <li><code>[rows, cols]</code> -&gt; <code>rows \u00d7 cols</code></li> <li>matrix -&gt; <code>(x.rows(), x.cols())</code></li> <li>vector -&gt; \\(N \\times N\\) where \\(N = x.size()\\)</li> </ul>"},{"location":"docs/functions/pycauset.I/#usage","title":"Usage","text":"<pre><code>import pycauset\n\n# Create a 1000x1000 identity matrix\nidentity = pycauset.I(1000)\n\n# Create a rectangular identity-like matrix (ones on the diagonal up to min(rows, cols))\nrect_id = pycauset.I(3, 5)\n\n# Also supported:\nrect_id2 = pycauset.I([3, 5])\n\nA = pycauset.FloatMatrix(2, 4)\nIA = pycauset.I(A)          # 2x4\n\nv = pycauset.IntegerVector(7)\nIv = pycauset.I(v)          # 7x7\n</code></pre>"},{"location":"docs/functions/pycauset.bitwise_not/","title":"pycauset.bitwise_not","text":"<pre><code>pycauset.bitwise_not(matrix: Any) -&gt; Any\n</code></pre> <p>Compute the bitwise inversion (NOT) of a matrix.</p>"},{"location":"docs/functions/pycauset.bitwise_not/#parameters","title":"Parameters","text":"<ul> <li>matrix (MatrixBase or array-like): The matrix to invert. Must be a <code>TriangularBitMatrix</code>, <code>IntegerMatrix</code>, or similar bit-supporting type.</li> </ul>"},{"location":"docs/functions/pycauset.bitwise_not/#returns","title":"Returns","text":"<ul> <li>MatrixBase or array-like: A new matrix with inverted bits.</li> </ul>"},{"location":"docs/functions/pycauset.bitwise_not/#raises","title":"Raises","text":"<ul> <li>TypeError: If the object does not support bitwise inversion.</li> </ul>"},{"location":"docs/functions/pycauset.causal_matrix/","title":"pycauset.causal_matrix","text":"<pre><code>pycauset.causal_matrix(n, populate=True, **kwargs)\n</code></pre> <p>Factory function for creating a pycauset.TriangularBitMatrix suitable for representing a causal relation.</p>"},{"location":"docs/functions/pycauset.causal_matrix/#parameters","title":"Parameters","text":"<ul> <li>n (int): The dimension of the causal set (<code>n\u00d7n</code>).</li> <li>populate (bool): If <code>True</code> (default), fills with random bits (<code>p=0.5</code>). If <code>False</code>, returns an all-zeros matrix.</li> <li>kwargs: Passed through to the backend constructor.</li> </ul>"},{"location":"docs/functions/pycauset.causal_matrix/#returns","title":"Returns","text":"<ul> <li>TriangularBitMatrix: A new instance of pycauset.TriangularBitMatrix.</li> </ul>"},{"location":"docs/functions/pycauset.causal_matrix/#example","title":"Example","text":"<pre><code>import pycauset\n\nc = pycauset.causal_matrix(1000)\nc_empty = pycauset.causal_matrix(1000, populate=False)\n</code></pre>"},{"location":"docs/functions/pycauset.causet/","title":"pycauset.causet","text":"<pre><code>pycauset.causet(*, n=None, density=None, spacetime=None, seed=None, matrix=None) -&gt; CausalSet\n</code></pre> <p>Lower-case convenience factory that returns a pycauset.CausalSet.</p>"},{"location":"docs/functions/pycauset.causet/#parameters","title":"Parameters","text":"<p>See pycauset.CausalSet for parameter details.</p>"},{"location":"docs/functions/pycauset.causet/#returns","title":"Returns","text":"<ul> <li>CausalSet: A new instance of pycauset.CausalSet.</li> </ul>"},{"location":"docs/functions/pycauset.causet/#example","title":"Example","text":"<pre><code>import pycauset\n\nc = pycauset.causet(n=1000, seed=42)\n</code></pre>"},{"location":"docs/functions/pycauset.cholesky/","title":"pycauset.cholesky","text":"<p>This function is currently not available.</p>"},{"location":"docs/functions/pycauset.compute_k/","title":"pycauset.compute_k","text":"<pre><code>pycauset.compute_k(matrix: TriangularBitMatrix, a: float) -&gt; TriangularFloatMatrix\n</code></pre> <p>Compute the matrix \\(K = C(aI + C)^{-1}\\) for a causal matrix \\(C\\) and scalar \\(a\\).</p> <p>This function uses an optimized column-independent backward substitution algorithm that exploits the binary and sparse nature of \\(C\\).</p>"},{"location":"docs/functions/pycauset.compute_k/#parameters","title":"Parameters","text":"<ul> <li>matrix (TriangularBitMatrix): The input causal matrix \\(C\\).</li> <li>a (float): The scalar parameter \\(a\\).</li> </ul>"},{"location":"docs/functions/pycauset.compute_k/#returns","title":"Returns","text":"<ul> <li>TriangularFloatMatrix: The result matrix \\(K\\).</li> </ul>"},{"location":"docs/functions/pycauset.compute_k_matrix/","title":"pycauset.compute_k_matrix","text":"<pre><code>pycauset.compute_k_matrix(C: TriangularBitMatrix, a: float, num_threads: int = 0) -&gt; TriangularFloatMatrix\n</code></pre> <p>Compute the matrix \\(K = C(aI + C)^{-1}\\) for a causal matrix \\(C\\) and scalar \\(a\\).</p> <p>This function uses an optimized column-independent backward substitution algorithm that exploits the binary and sparse nature of \\(C\\).</p>"},{"location":"docs/functions/pycauset.compute_k_matrix/#parameters","title":"Parameters","text":"<ul> <li>C (TriangularBitMatrix): The input causal matrix.</li> <li>a (float): The scalar parameter \\(a\\).</li> <li>num_threads (int, optional): Number of threads to use. Defaults to 0 (auto-detect).</li> </ul>"},{"location":"docs/functions/pycauset.compute_k_matrix/#returns","title":"Returns","text":"<ul> <li>TriangularFloatMatrix: The result matrix \\(K\\).</li> </ul>"},{"location":"docs/functions/pycauset.cond/","title":"pycauset.cond","text":"<pre><code>pycauset.cond(a, p=None)\n</code></pre> <p>Compute a condition number estimate.</p>"},{"location":"docs/functions/pycauset.cond/#parameters","title":"Parameters","text":"<ul> <li>a (MatrixBase): Input matrix.</li> <li>p: Currently not supported (must be <code>None</code>).</li> </ul>"},{"location":"docs/functions/pycauset.cond/#returns","title":"Returns","text":"<ul> <li>float: A condition number estimate computed as <code>norm(a) * norm(invert(a))</code>.</li> </ul>"},{"location":"docs/functions/pycauset.convert_file/","title":"pycauset.convert_file","text":"<pre><code>pycauset.convert_file(src_path, dst_path, *, dst_format=None, allow_huge=False, dtype=None, npz_key=None)\n</code></pre> <p>Convert between PyCauset snapshots and NumPy container formats.</p> <ul> <li>Supported formats: <code>.pycauset</code> (canonical snapshot), <code>.npy</code>, <code>.npz</code>.</li> <li><code>dst_format</code> defaults from <code>dst_path</code> when omitted; must be one of the supported suffixes.</li> <li><code>.npz</code> imports default to the first key; set <code>npz_key</code> to choose a specific array name.</li> <li>Exports honor the NumPy materialization guard: pass <code>allow_huge=True</code> only when you intentionally want to load spill/file-backed operands into RAM.</li> <li>Optional <code>dtype</code> casts on export (to NumPy formats) before writing.</li> </ul>"},{"location":"docs/functions/pycauset.convert_file/#exceptions-warnings","title":"Exceptions / warnings","text":"<ul> <li><code>ValueError</code> if source or destination format is not one of <code>.pycauset</code>, <code>.npy</code>, <code>.npz</code> (or cannot be inferred from the suffix).</li> <li><code>RuntimeError</code> if NumPy is unavailable when exporting to <code>.npy</code>/<code>.npz</code>.</li> <li>Materialization guard: exporting spill/file-backed objects to NumPy formats raises unless <code>allow_huge=True</code>.</li> </ul>"},{"location":"docs/functions/pycauset.convert_file/#parameters","title":"Parameters","text":"<ul> <li>src_path (str | Path): Source file path; suffix must be <code>.pycauset</code>, <code>.npy</code>, or <code>.npz</code>.</li> <li>dst_path (str | Path): Destination file path; suffix or <code>dst_format</code> selects the output format.</li> <li>dst_format (str, optional): Override destination format (<code>\"pycauset\"</code>, <code>\"npy\"</code>, or <code>\"npz\"</code>). If omitted, inferred from <code>dst_path</code>.</li> <li>allow_huge (bool, default <code>False</code>): Forwarded to NumPy export helpers; required when exporting spill/file-backed objects to avoid surprise materialization.</li> <li>dtype (optional): Override dtype on export to NumPy formats.</li> <li>npz_key (str, optional): Key to read from/write to when the source or destination is <code>.npz</code>. Defaults to the first key on import and to <code>\"array\"</code> on export.</li> </ul>"},{"location":"docs/functions/pycauset.convert_file/#returns","title":"Returns","text":"<ul> <li>Path: The destination path.</li> </ul>"},{"location":"docs/functions/pycauset.convert_file/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\n# Snapshot (.pycauset) -&gt; NumPy .npy -&gt; snapshot\npc.convert_file(\"A.pycauset\", \"A.npy\")\npc.convert_file(\"A.npy\", \"A_roundtrip.pycauset\")\n\n# Extract from an npz archive into a snapshot\npc.convert_file(\"bundle.npz\", \"vec.pycauset\", npz_key=\"vector0\")\n\n# Export to npz with explicit dtype and large-export opt-in\npc.convert_file(\"big.pycauset\", \"big.npz\", allow_huge=True, dtype=\"float32\", npz_key=\"arr\")\n</code></pre>"},{"location":"docs/functions/pycauset.convert_file/#future-format-targets-not-implemented-yet","title":"Future format targets (not implemented yet)","text":"<p>These are under consideration for later releases; they are not supported by <code>convert_file</code> today:</p> <ul> <li>MatrixMarket <code>.mtx</code> (sparse/text interchange)</li> <li>MATLAB <code>.mat</code> (engineering/scientific interop)</li> <li>Parquet / Arrow / CSV (tabular pipelines; CSV mainly for debugging)</li> <li>HDF5/NetCDF (only if a low-maintenance reader fits the budget)</li> </ul>"},{"location":"docs/functions/pycauset.convert_file/#see-also","title":"See Also","text":"<ul> <li>pycauset.save</li> <li>pycauset.load</li> <li>Storage and Memory</li> <li>NumPy Integration</li> <li>NumPy helpers in the Python API: <code>load_npy</code>, <code>load_npz</code>, <code>save_npy</code>, <code>save_npz</code></li> </ul>"},{"location":"docs/functions/pycauset.divide/","title":"pycauset.divide","text":"<pre><code>pycauset.divide(a, b) -&gt; Any\n</code></pre> <p>Elementwise division.</p> <p>This is a convenience wrapper around the <code>/</code> operator and follows NumPy-style 2D broadcasting for matrix inputs.</p>"},{"location":"docs/functions/pycauset.divide/#parameters","title":"Parameters","text":"<ul> <li><code>a</code>: Left operand (typically a matrix).</li> <li><code>b</code>: Right operand (matrix, scalar, or NumPy array depending on the operator overload).</li> </ul>"},{"location":"docs/functions/pycauset.divide/#returns","title":"Returns","text":"<ul> <li>A new <code>pycauset</code> object containing the elementwise division result.</li> </ul>"},{"location":"docs/functions/pycauset.divide/#broadcasting-rules-2d","title":"Broadcasting rules (2D)","text":"<p>Two shapes <code>(a_rows, a_cols)</code> and <code>(b_rows, b_cols)</code> are compatible if each dimension is either equal or one of them is <code>1</code>. The result shape is:</p> <ul> <li><code>(max(a_rows, b_rows), max(a_cols, b_cols))</code></li> </ul> <p>When mixing a matrix with a 1D NumPy array in an elementwise operation, the array is treated as a row vector of shape <code>(1, n)</code>.</p>"},{"location":"docs/functions/pycauset.divide/#dtype-behavior","title":"Dtype behavior","text":"<ul> <li>If either operand is float/complex, the result is a float/complex type.</li> <li>If neither operand is float/complex (e.g. int/uint/bit), the result promotes to a float dtype based on the current promotion precision mode:</li> <li><code>lowest</code> (default): <code>float32</code></li> <li><code>highest</code>: <code>float64</code></li> </ul>"},{"location":"docs/functions/pycauset.divide/#exceptions","title":"Exceptions","text":"<ul> <li>Raises <code>TypeError</code> if the operand types are not supported by the <code>/</code> operator.</li> <li>Raises <code>ValueError</code> / <code>RuntimeError</code> on invalid shapes or unsupported dtype combinations.</li> </ul>"},{"location":"docs/functions/pycauset.divide/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport pycauset as pc\n\nA = pc.zeros((3, 4), dtype=\"float64\")\nrow = np.arange(4, dtype=np.float64)\n\nB = pc.divide(A, row)   # broadcasts (3,4) / (1,4)\nC = A / row             # equivalent\n</code></pre>"},{"location":"docs/functions/pycauset.divide/#see-also","title":"See also","text":"<ul> <li>pycauset.precision_mode</li> <li>pycauset.matmul</li> <li>pycauset.MatrixBase</li> </ul>"},{"location":"docs/functions/pycauset.dot/","title":"pycauset.dot","text":"<pre><code>pycauset.dot(a: VectorBase, b: VectorBase) -&gt; float | complex\n</code></pre> <p>Compute the dot product of two vectors.</p> <p>This is a convenience wrapper around <code>a.dot(b)</code>.</p> <p>Notes:</p> <ul> <li>For real vectors, the result is a <code>float</code>.</li> <li>For complex vectors, the result is a <code>complex</code>.</li> <li>No implicit conjugation is applied. For a Hermitian-style inner product, use <code>a.conj().dot(b)</code> or <code>a.H @ b</code>.</li> </ul>"},{"location":"docs/functions/pycauset.dot/#parameters","title":"Parameters","text":"<ul> <li><code>a</code>: The first vector.</li> <li><code>b</code>: The second vector.</li> </ul>"},{"location":"docs/functions/pycauset.dot/#returns","title":"Returns","text":"<p>The dot product of the two vectors.</p>"},{"location":"docs/functions/pycauset.dot/#exceptions","title":"Exceptions","text":"<ul> <li>Raises <code>TypeError</code> if <code>a</code> is not a vector (does not provide <code>.dot(...)</code>).</li> <li>Raises <code>ValueError</code> if vector sizes do not match.</li> </ul>"},{"location":"docs/functions/pycauset.dot/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport pycauset as pc\n\nv = pc.vector([1.0, 2.0, 3.0], dtype=\"float64\")\nassert pc.dot(v, v) == 14.0\n\nz = pc.ComplexFloat64Vector(np.array([1 + 2j, 3 - 4j], dtype=np.complex128))\nassert pc.dot(z, z) == (1 + 2j) * (1 + 2j) + (3 - 4j) * (3 - 4j)\nassert pc.dot(z.conj(), z) == np.conj(pc.dot(z, z))\n</code></pre>"},{"location":"docs/functions/pycauset.dot/#see-also","title":"See also","text":"<ul> <li>pycauset.VectorBase</li> <li>pycauset.matmul</li> <li>pycauset.norm</li> </ul>"},{"location":"docs/functions/pycauset.eig/","title":"pycauset.eig","text":"<p>This function is currently not available in pre-alpha builds.</p> <p>It is present as a stub API and will raise <code>NotImplementedError</code>.</p> <p>Alternatives:</p> <ul> <li>For symmetric/Hermitian inputs: <code>pycauset.eigh</code>, <code>pycauset.eigvalsh</code> (NumPy fallback).</li> </ul>"},{"location":"docs/functions/pycauset.eigh/","title":"pycauset.eigh","text":"<pre><code>pycauset.eigh(a)\n</code></pre> <p>Eigen-decomposition for symmetric (or Hermitian) matrices.</p>"},{"location":"docs/functions/pycauset.eigh/#returns","title":"Returns","text":"<p>A pair <code>(w, v)</code> where:</p> <ul> <li><code>w</code> is a vector of eigenvalues</li> <li><code>v</code> is a matrix whose columns are eigenvectors</li> </ul>"},{"location":"docs/functions/pycauset.eigh/#notes","title":"Notes","text":"<p>Current implementation uses a NumPy fallback (<code>numpy.linalg.eigh</code>).</p>"},{"location":"docs/functions/pycauset.eigvals/","title":"pycauset.eigvals","text":"<p>This function is currently not available in pre-alpha builds.</p> <p>It is present as a stub API and will raise <code>NotImplementedError</code>.</p> <p>Alternatives: <code>MatrixBase.trace()</code>, <code>MatrixBase.determinant()</code>, <code>pycauset.eigh</code>, <code>pycauset.eigvalsh</code>, and <code>pycauset.invert()</code> (where applicable).</p>"},{"location":"docs/functions/pycauset.eigvals_arnoldi/","title":"pycauset.eigvals_arnoldi","text":"<p>This function is currently not available in pre-alpha builds.</p> <p>It is present as a stub API and will raise <code>NotImplementedError</code>.</p>"},{"location":"docs/functions/pycauset.eigvals_skew/","title":"pycauset.eigvals_skew","text":"<p>This function is currently not available in pre-alpha builds.</p> <p>It is present as a stub API and will raise <code>NotImplementedError</code>.</p>"},{"location":"docs/functions/pycauset.eigvalsh/","title":"pycauset.eigvalsh","text":"<pre><code>pycauset.eigvalsh(a)\n</code></pre> <p>Eigenvalues for symmetric (or Hermitian) matrices.</p>"},{"location":"docs/functions/pycauset.eigvalsh/#returns","title":"Returns","text":"<ul> <li>VectorBase: Eigenvalues.</li> </ul>"},{"location":"docs/functions/pycauset.eigvalsh/#notes","title":"Notes","text":"<p>Current implementation uses a NumPy fallback (<code>numpy.linalg.eigvalsh</code>).</p>"},{"location":"docs/functions/pycauset.empty/","title":"pycauset.empty","text":"<pre><code>pycauset.empty(shape, *, dtype, **kwargs)\n</code></pre> <p>Allocate a vector or matrix without guaranteeing initialization.</p> <p>Note: for some backends this may still be zero-initialized.</p> <p><code>dtype</code> is required.</p>"},{"location":"docs/functions/pycauset.empty/#parameters","title":"Parameters","text":"<ul> <li> <p>shape (int or tuple):</p> <ul> <li><code>n</code> allocates a length-<code>n</code> vector.</li> <li><code>(n,)</code> allocates a length-<code>n</code> vector.</li> <li><code>(n, m)</code> allocates an <code>n\u00d7m</code> matrix.</li> </ul> <p>Notes: *   Rectangular allocation is supported for dense numeric matrix types. *   <code>dtype=\"bool\"</code>/<code>dtype=\"bit\"</code> uses bit-packed storage (<code>DenseBitMatrix</code>) and supports rectangular <code>(rows, cols)</code> shapes. *   dtype (str or type): Storage dtype token. *   kwargs: Passed through to the backend allocator.</p> </li> </ul>"},{"location":"docs/functions/pycauset.empty/#returns","title":"Returns","text":"<ul> <li>VectorBase or MatrixBase: A newly allocated object.</li> </ul>"},{"location":"docs/functions/pycauset.empty/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\ntmp = pc.empty((256, 64), dtype=\"float32\")\n</code></pre>"},{"location":"docs/functions/pycauset.empty/#see-also","title":"See also","text":"<ul> <li>pycauset.zeros</li> <li>pycauset.ones</li> <li>pycauset.MatrixBase</li> <li>Matrix Guide</li> </ul>"},{"location":"docs/functions/pycauset.get_memory_threshold/","title":"pycauset.get_memory_threshold","text":"<pre><code>pycauset.get_memory_threshold() -&gt; int\n</code></pre> <p>Get the current memory threshold in bytes.</p>"},{"location":"docs/functions/pycauset.get_memory_threshold/#returns","title":"Returns","text":"<ul> <li>int: The current threshold in bytes.</li> </ul>"},{"location":"docs/functions/pycauset.get_num_threads/","title":"pycauset.get_num_threads","text":"<p>Gets the current number of threads used for parallel operations.</p>"},{"location":"docs/functions/pycauset.get_num_threads/#syntax","title":"Syntax","text":"<pre><code>n = pycauset.get_num_threads()\n</code></pre>"},{"location":"docs/functions/pycauset.get_num_threads/#returns","title":"Returns","text":"Type Description <code>int</code> The current number of threads."},{"location":"docs/functions/pycauset.get_num_threads/#description","title":"Description","text":"<p>Returns the number of threads currently configured for the global thread pool. If <code>set_num_threads</code> has not been called, this returns the default value (usually the number of hardware threads).</p>"},{"location":"docs/functions/pycauset.get_num_threads/#example","title":"Example","text":"<pre><code>import pycauset\n\nn = pycauset.get_num_threads()\nprint(f\"PyCauset is using {n} threads.\")\n</code></pre>"},{"location":"docs/functions/pycauset.get_precision_mode/","title":"pycauset.get_precision_mode","text":"<pre><code>pycauset.get_precision_mode() -&gt; str\n</code></pre> <p>Return the current thread-local promotion precision mode.</p>"},{"location":"docs/functions/pycauset.get_precision_mode/#returns","title":"Returns","text":"<ul> <li><code>str</code>: Either <code>\"lowest\"</code> or <code>\"highest\"</code>.</li> </ul>"},{"location":"docs/functions/pycauset.get_precision_mode/#example","title":"Example","text":"<pre><code>import pycauset as pc\n\nmode = pc.get_precision_mode()\nprint(mode)\n</code></pre>"},{"location":"docs/functions/pycauset.get_precision_mode/#see-also","title":"See also","text":"<ul> <li>pycauset.set_precision_mode</li> <li>pycauset.precision_mode</li> </ul>"},{"location":"docs/functions/pycauset.identity/","title":"pycauset.identity","text":"<pre><code>pycauset.identity(x)\n</code></pre> <p>Creates an identity-like matrix (ones on the diagonal, zeros elsewhere) with shape derived from <code>x</code>.</p> <p>This is a convenience factory around pycauset.IdentityMatrix and supports multiple input forms.</p>"},{"location":"docs/functions/pycauset.identity/#parameters","title":"Parameters","text":"<p><code>x</code> can be:</p> <ol> <li>Integer <code>N</code></li> <li> <p>Returns an \\(N \\times N\\) identity matrix.</p> </li> <li> <p>Shape sequence <code>[rows, cols]</code></p> </li> <li>Returns a <code>rows \u00d7 cols</code> identity-like matrix.</li> <li> <p>The diagonal is filled with ones up to \\(\\min(rows, cols)\\).</p> </li> <li> <p>A Matrix or Vector</p> </li> <li>If <code>x</code> is a matrix, returns an identity-like matrix with shape <code>(x.rows(), x.cols())</code>.</li> <li>If <code>x</code> is a vector, returns an \\(N \\times N\\) identity matrix where \\(N = x.size()\\).</li> </ol>"},{"location":"docs/functions/pycauset.identity/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\n# 1) Integer input\nI5 = pc.identity(5)            # 5x5\n\n# 2) Rectangular shape input\nI35 = pc.identity([3, 5])      # 3x5\n\n# 3) Matrix input\nA = pc.FloatMatrix(2, 4)\nIA = pc.identity(A)            # 2x4\n\n# 3) Vector input\nv = pc.IntegerVector(7)\nIv = pc.identity(v)            # 7x7\n</code></pre>"},{"location":"docs/functions/pycauset.identity/#see-also","title":"See also","text":"<ul> <li>pycauset.IdentityMatrix</li> <li>pycauset.I</li> </ul>"},{"location":"docs/functions/pycauset.invert/","title":"Matrix Inversion (Linear Algebra)","text":"<p>PyCauset provides an interface for computing the mathematical inverse (\\(A^{-1}\\)) of a matrix.</p> <p>Implementation note (current reality): the public <code>invert</code> entrypoint is correctness-first and may fall back to a NumPy CPU implementation (<code>numpy.linalg.inv</code>) if a native inversion path is unavailable or fails.</p>"},{"location":"docs/functions/pycauset.invert/#usage","title":"Usage","text":"<p>You can use the <code>.invert()</code> method on a matrix object or the pycauset.invert function.</p> <pre><code>import pycauset as pc\n\n# Create a matrix (must be invertible)\n# Note: TriangularBitMatrix and IntegerMatrix are strictly upper triangular\n# and therefore singular (determinant is 0). They cannot be inverted.\n\ntry:\n    m = pc.TriangularBitMatrix(5)\n    inv = m.invert()\n    # OR\n    inv = pc.invert(m)\nexcept RuntimeError as e:\n    print(f\"Inversion failed: {e}\")\n</code></pre>"},{"location":"docs/functions/pycauset.invert/#singularity-of-triangular-matrices","title":"Singularity of Triangular Matrices","text":"<p>The triangular matrix types in PyCauset (pycauset.TriangularBitMatrix, pycauset.TriangularFloatMatrix) are strictly upper triangular. </p> <p>A strictly upper triangular matrix has zeros on the main diagonal. The determinant of a triangular matrix is the product of its diagonal entries. Therefore, the determinant of any strictly upper triangular matrix is 0, making it singular (non-invertible).</p> <p>Attempting to invert these matrices will raise a <code>RuntimeError</code>.</p>"},{"location":"docs/functions/pycauset.invert/#dense-matrix-inversion","title":"Dense Matrix Inversion","text":"<p>The pycauset.FloatMatrix class supports general matrix inversion.</p>"},{"location":"docs/functions/pycauset.invert/#algorithms","title":"Algorithms","text":"<ol> <li>CPU: Uses a parallel Block Gauss-Jordan elimination algorithm. This allows you to invert dense matrices efficiently, leveraging multiple CPU cores.</li> <li>GPU: If a CUDA-capable GPU is detected, PyCauset uses cuSOLVER (LU Decomposition).<ul> <li>In-Core: For matrices that fit in VRAM, it uses standard dense solvers.</li> <li>Out-of-Core: For massive matrices, it uses a Streaming Blocked LU algorithm that streams data between Disk/RAM and GPU, allowing inversion of matrices larger than GPU memory.</li> </ul> </li> </ol> <p>Performance Note: The inversion algorithm is highly parallelized. For large matrices (\\(N \\ge 1000\\)), it will automatically utilize all available threads or the GPU.</p> <p>Note: pycauset.IntegerMatrix and pycauset.DenseBitMatrix are also dense, but direct inversion is not supported to avoid ambiguity (integer inversion usually results in floats). To invert them, convert them to pycauset.FloatMatrix first.</p> <pre><code>import pycauset as pc\n\n# Create a dense FloatMatrix\n# [ [4, 7],\n#   [2, 6] ]\nm = pc.FloatMatrix(2)\nm[0, 0] = 4.0\nm[0, 1] = 7.0\nm[1, 0] = 2.0\nm[1, 1] = 6.0\n\n# Compute Inverse\n# [ [ 0.6, -0.7],\n#   [-0.2,  0.4] ]\ninv = m.invert()\n\nprint(inv[0, 0]) # 0.6\n</code></pre>"},{"location":"docs/functions/pycauset.invert/#implementation-details","title":"Implementation Details","text":"<ul> <li>Algorithm: Gaussian elimination with partial pivoting.</li> <li>Parallelism: The row operations are parallelized using OpenMP for performance on large matrices.</li> <li>Storage: The operation may create temporary backing files (for example <code>.tmp</code>) for intermediates and/or the result. These session files are normally cleaned up on interpreter exit (unless <code>pycauset.keep_temp_files = True</code>). Use <code>save()</code> to persist a portable <code>.pycauset</code> snapshot.</li> <li>Scalars: If the input matrix has a scalar factor \\(S\\), the resulting inverse will have a scalar factor \\(1/S\\).</li> </ul>"},{"location":"docs/functions/pycauset.invert/#errors","title":"Errors","text":"<p>A <code>RuntimeError</code> will be raised if: *   The matrix is singular (determinant is 0). *   The matrix is nearly singular (pivot element is close to zero, within a tolerance of 1e-12).</p>"},{"location":"docs/functions/pycauset.load/","title":"pycauset.load","text":"<pre><code>pycauset.load(path: str)\n</code></pre> <p>Loads a matrix, vector, block matrix, or <code>CausalSet</code> from a binary file created by PyCauset.</p>"},{"location":"docs/functions/pycauset.load/#parameters","title":"Parameters","text":"<ul> <li>path (str): The path to the file to load.</li> </ul>"},{"location":"docs/functions/pycauset.load/#returns","title":"Returns","text":"<ul> <li> <p>Matrix/vector/BlockMatrix/CausalSet: The appropriate object for the container\u2019s contents.</p> <p>For <code>matrix_type = \"BLOCK\"</code>, this returns a <code>BlockMatrix</code> reconstructed from a manifest stored in the container file and child blocks stored in a sibling <code>.blocks/</code> directory.</p> </li> </ul>"},{"location":"docs/functions/pycauset.load/#description","title":"Description","text":"<p><code>pycauset.load()</code> opens a <code>.pycauset</code> file and returns an object backed by the file\u2019s memory-mapped payload.</p> <p>Snapshot semantics:</p> <ul> <li>A <code>.pycauset</code> file is treated as an immutable snapshot.</li> <li>Mutating an object loaded from disk does not implicitly overwrite the on-disk snapshot.</li> <li>Persisting payload changes requires an explicit save.</li> </ul> <p>Caching:</p> <ul> <li>Cached-derived values are restored from typed metadata when valid.</li> </ul>"},{"location":"docs/functions/pycauset.load/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\nA = pc.matrix(((1.0, 2.0), (3.0, 4.0)))\npc.save(A, \"A.pycauset\")\nA2 = pc.load(\"A.pycauset\")\nassert A2.shape == (2, 2)\n\n# Block matrix load\nblk = pc.matrix(((1.0, 0.0), (0.0, 1.0)))\nBM = pc.matrix(((blk, blk), (blk, blk)))\npc.save(BM, \"bm.pycauset\")\nBM2 = pc.load(\"bm.pycauset\")\nassert BM2.shape == (4, 4)\n</code></pre>"},{"location":"docs/functions/pycauset.load/#block-matrices-sidecar-layout","title":"Block matrices (sidecar layout)","text":"<p>If the container is a block matrix (<code>matrix_type = \"BLOCK\"</code>), load expects:</p> <ul> <li><code>bm.pycauset</code> (container file)</li> <li><code>bm.pycauset.blocks/</code> (sidecar directory)<ul> <li><code>block_r{r}_c{c}.pycauset</code> children</li> </ul> </li> </ul> <p>The block manifest pins each child\u2019s <code>payload_uuid</code>; load validates these pins and fails deterministically on mismatch. Missing sidecar entries or mismatched child files error rather than silently mixing snapshots. View blocks are loaded from the materialized child files (no view references on disk in Release 1).</p> <p>See Block Matrices for details.</p>"},{"location":"docs/functions/pycauset.load/#see-also","title":"See Also","text":"<ul> <li> <p><code>pycauset.CausalSet.load</code>: For loading <code>CausalSet</code> objects from <code>.pycauset</code> containers (see pycauset.CausalSet).</p> </li> <li> <p>guides/Storage and Memory: Overview of persistence, caching, and mutation semantics.</p> </li> <li> <p>Block Matrices</p> </li> </ul>"},{"location":"docs/functions/pycauset.lstsq/","title":"pycauset.lstsq","text":"<pre><code>pycauset.lstsq(a, b)\n</code></pre> <p>Compute a least-squares solution \\(x\\) that approximately minimizes:</p> \\[ \\|Ax - b\\|_2 \\]"},{"location":"docs/functions/pycauset.lstsq/#parameters","title":"Parameters","text":"<ul> <li>a (MatrixBase): Coefficient matrix.</li> <li>b (VectorBase or MatrixBase): Right-hand side.</li> </ul>"},{"location":"docs/functions/pycauset.lstsq/#returns","title":"Returns","text":"<ul> <li>VectorBase or MatrixBase: The solution \\(x\\).</li> </ul>"},{"location":"docs/functions/pycauset.lstsq/#notes","title":"Notes","text":"<p>This is an endpoint-first baseline.</p> <ul> <li>It currently returns only <code>x</code> (unlike <code>numpy.linalg.lstsq</code>, which returns a tuple).</li> <li>The baseline implementation uses normal equations: \\(x = (A^T A)^{-1} A^T b\\).</li> </ul>"},{"location":"docs/functions/pycauset.lu/","title":"pycauset.lu","text":"<p>This function is currently not available.</p>"},{"location":"docs/functions/pycauset.matmul/","title":"pycauset.matmul","text":"<pre><code>pycauset.matmul(a, b)\n</code></pre> <p>Perform matrix multiplication.</p> <p>For native objects, this routes through the standard compute boundary (AutoSolver / device routing) and dispatches to optimized C++ implementations.</p> <p>For block matrices (constructed via <code>pycauset.matrix(block_grid)</code> where every element is matrix-like), <code>pycauset.matmul(a, b)</code> preserves \u201conce block, always block\u201d by returning a thunked block-matrix result with partition refinement (union of shared boundaries via <code>SubmatrixView</code> tiling).</p> <p>This function is NumPy-like:</p> <ul> <li>matrix-matrix: <code>(m, k) @ (k, n) -&gt; (m, n)</code></li> <li>matrix-vector: <code>(m, k) @ (k,) -&gt; (m,)</code></li> <li>vector-matrix: <code>(k,) @ (k, n) -&gt; (1, n)</code> (row-vector semantics)</li> <li>vector-vector: <code>(k,) @ (k,) -&gt; scalar</code> (dot)</li> </ul>"},{"location":"docs/functions/pycauset.matmul/#parameters","title":"Parameters","text":"<ul> <li>a (MatrixBase or VectorBase or BlockMatrix): Left operand.</li> <li>b (MatrixBase or VectorBase or BlockMatrix): Right operand.</li> </ul> <p>Shape rule: <code>a.cols() == b.rows()</code>.</p>"},{"location":"docs/functions/pycauset.matmul/#returns","title":"Returns","text":"<ul> <li>MatrixBase or VectorBase or scalar: The result. The specific type and shape depend on input ranks.</li> </ul> <p>When either operand is a <code>BlockMatrix</code>, the result is a <code>BlockMatrix</code> (typically holding lazy <code>ThunkBlock</code> output blocks).</p>"},{"location":"docs/functions/pycauset.matmul/#evaluation-block-matrices","title":"Evaluation (block matrices)","text":"<p>Block-matrix results are semi-lazy:</p> <ul> <li>Triggers (evaluate minimal required blocks): element access (e.g. <code>C[i, j]</code>), conversion to NumPy (<code>np.asarray(C)</code>), persistence (<code>pycauset.save(C, ...)</code>), and crossing the compute boundary.</li> <li>Non-triggers: <code>repr(C)</code>, <code>str(C)</code>, and partition metadata access.</li> </ul> <p>Determinism:</p> <ul> <li>Fixed <code>k</code> order for each output block\u2019s accumulation.</li> <li>Accumulator dtype is chosen from operand dtype metadata only (folding add-result dtype across terms) before evaluation.</li> <li>Leaf matmul runs through the public compute boundary (AutoSolver) per block; complex blocks route to CPU on CUDA builds.</li> </ul> <p>See Block Matrices for details.</p>"},{"location":"docs/functions/pycauset.matmul/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\n# Dense matmul\nA = pc.matrix(((1.0, 2.0), (3.0, 4.0)))\nB = pc.matrix(((5.0,), (6.0,)))\nC = pc.matmul(A, B)\nassert C.shape == (2, 1)\n\n# Block matmul (returns a BlockMatrix)\nblk = pc.matrix(((1.0, 0.0), (0.0, 1.0)))\nBM = pc.matrix(((blk, blk), (blk, blk)))\nout = pc.matmul(BM, BM)\n\n# Accessing an element triggers evaluation of the needed output block\n_ = out[0, 0]\n</code></pre>"},{"location":"docs/functions/pycauset.matmul/#see-also","title":"See also","text":"<ul> <li>pycauset.MatrixBase</li> <li>pycauset.matrix</li> <li>Matrix Guide</li> <li>Block Matrices</li> </ul>"},{"location":"docs/functions/pycauset.matrix/","title":"pycauset.matrix","text":"<pre><code>pycauset.matrix(source, dtype=None, **kwargs)\n</code></pre> <p>Create a 2D matrix from matrix-like input.</p> <p>This is a data constructor (aligned with <code>np.array(...)</code> semantics). </p> <p>If <code>source</code> is 2D, returns a matrix. If <code>source</code> is 1D, returns a vector.</p> <p><code>pycauset.matrix(...)</code> also supports constructing a block matrix when given a 2D grid of matrix objects.</p> <p>Rectangular shapes are supported for dense matrices, including numeric dtypes (int/uint/float/complex) and boolean/bit matrices. Boolean 2D inputs use bit-packed storage (<code>DenseBitMatrix</code>).</p>"},{"location":"docs/functions/pycauset.matrix/#block-grid-construction","title":"Block-grid construction","text":"<p>For a 2D nested sequence (e.g. list-of-lists), <code>pycauset.matrix(...)</code> disambiguates between:</p> <ul> <li>Dense data constructor: a 2D grid of numeric scalars (no matrix objects).</li> <li>Block matrix constructor: a 2D grid where every element is matrix-like.</li> <li>Error: a 2D grid that mixes matrices and scalars.</li> </ul> <p>The \u201cmatrix-like\u201d check accepts native matrices plus block-matrix helper objects (views/thunks).</p> <p>Rules:</p> <ul> <li>If any element is matrix-like and not all elements are matrix-like: raise <code>TypeError</code> (ambiguous input).</li> <li>If all elements are matrix-like: return a <code>BlockMatrix</code>.<ul> <li><code>dtype</code> and <code>**kwargs</code> are rejected for block-grid input.</li> <li>Block-grid validation requires each block-row to share height and each block-col to share width; shape mismatches raise deterministically.</li> <li>Block matrices support element access and block-aware slicing; slices tile with <code>SubmatrixView</code> blocks (no silent densify) and may error if a view cannot be represented.</li> </ul> </li> </ul>"},{"location":"docs/functions/pycauset.matrix/#parameters","title":"Parameters","text":"<ul> <li>source (sequence or numpy.ndarray): 1D nested data (e.g. list) / 1D NumPy array, or 2D nested data (e.g. list-of-lists) / 2D NumPy array.</li> <li>dtype (str or type, optional): Coerce storage dtype (e.g. <code>\"float64\"</code>, <code>\"int32\"</code>, <code>float</code>, <code>int</code>).</li> <li>kwargs: Passed through to the backend constructor.</li> </ul>"},{"location":"docs/functions/pycauset.matrix/#returns","title":"Returns","text":"<ul> <li> <p>MatrixBase or VectorBase or BlockMatrix: A concrete native matrix/vector for numeric data input, or a block matrix when <code>source</code> is a 2D grid of matrices.</p> <p>For block-grid input, the return is a <code>BlockMatrix</code>.</p> </li> </ul>"},{"location":"docs/functions/pycauset.matrix/#examples","title":"Examples","text":"<pre><code>import pycauset\n\nm = pycauset.matrix(((1, 2), (3, 4)))\n\n# 1D input returns a vector\nv = pycauset.matrix((1, 2, 3))\n\n# Coerce dtype\nm_f32 = pycauset.matrix(((1, 2), (3, 4)), dtype=\"float32\")\n\n# Block matrix (2D grid of matrices)\nA = pycauset.matrix(((1.0, 0.0), (0.0, 1.0)))\nB = pycauset.matrix(((2.0, 3.0), (4.0, 5.0)))\nBM = pycauset.matrix(((A, B), (B, A)))\n\n# Mixed matrices + scalars is rejected\ntry:\n    pycauset.matrix(((A, 0.0),))\nexcept TypeError:\n    pass\n</code></pre>"},{"location":"docs/functions/pycauset.matrix/#see-also","title":"See also","text":"<ul> <li>pycauset.MatrixBase</li> <li>pycauset.matmul</li> <li>Matrix Guide</li> <li>Block Matrices</li> </ul>"},{"location":"docs/functions/pycauset.norm/","title":"pycauset.norm","text":"<pre><code>pycauset.norm(x) -&gt; float\n</code></pre> <p>Compute the norm of a vector or matrix.</p> <ul> <li>Vector input: returns the \\(\\ell_2\\) (Euclidean) norm.</li> <li>Matrix input: returns the Frobenius norm.</li> </ul>"},{"location":"docs/functions/pycauset.norm/#parameters","title":"Parameters","text":"<ul> <li><code>x</code>: A vector or matrix.</li> </ul>"},{"location":"docs/functions/pycauset.norm/#returns","title":"Returns","text":"<ul> <li><code>float</code>: The computed norm.</li> </ul>"},{"location":"docs/functions/pycauset.norm/#exceptions","title":"Exceptions","text":"<ul> <li>Raises <code>TypeError</code> if <code>x</code> is not a <code>VectorBase</code> or <code>MatrixBase</code>.</li> </ul>"},{"location":"docs/functions/pycauset.norm/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\nv = pc.vector([3.0, 4.0], dtype=\"float64\")\nassert pc.norm(v) == 5.0\n\nA = pc.matrix(\n    [\n        [3.0, 4.0],\n        [0.0, 0.0],\n    ],\n    dtype=\"float64\",\n)\nassert pc.norm(A) == 5.0\n</code></pre>"},{"location":"docs/functions/pycauset.norm/#see-also","title":"See also","text":"<ul> <li>pycauset.dot</li> <li>pycauset.matmul</li> <li>pycauset.sum</li> </ul>"},{"location":"docs/functions/pycauset.ones/","title":"pycauset.ones","text":"<pre><code>pycauset.ones(shape, *, dtype, **kwargs)\n</code></pre> <p>Allocate a vector or matrix filled with ones.</p> <p><code>dtype</code> is required.</p>"},{"location":"docs/functions/pycauset.ones/#parameters","title":"Parameters","text":"<ul> <li> <p>shape (int or tuple):</p> <ul> <li><code>n</code> allocates a length-<code>n</code> vector.</li> <li><code>(n,)</code> allocates a length-<code>n</code> vector.</li> <li><code>(n, m)</code> allocates an <code>n\u00d7m</code> matrix.</li> </ul> <p>Notes: *   Rectangular allocation is supported for dense numeric matrix types. *   <code>dtype=\"bool\"</code>/<code>dtype=\"bit\"</code> uses bit-packed storage (<code>DenseBitMatrix</code>) and supports rectangular <code>(rows, cols)</code> shapes. *   dtype (str or type): Storage dtype token. *   kwargs: Passed through to the backend allocator.</p> </li> </ul>"},{"location":"docs/functions/pycauset.ones/#returns","title":"Returns","text":"<ul> <li>VectorBase or MatrixBase: A newly allocated object.</li> </ul>"},{"location":"docs/functions/pycauset.ones/#examples","title":"Examples","text":"<pre><code>import pycauset\n\nv = pycauset.ones((5,), dtype=\"int32\")\nm = pycauset.ones((3, 7), dtype=\"float64\")\n</code></pre>"},{"location":"docs/functions/pycauset.ones/#see-also","title":"See also","text":"<ul> <li>pycauset.zeros</li> <li>pycauset.empty</li> <li>pycauset.MatrixBase</li> <li>Matrix Guide</li> </ul>"},{"location":"docs/functions/pycauset.pinv/","title":"pycauset.pinv","text":"<p>This function is currently not available.</p>"},{"location":"docs/functions/pycauset.precision_mode/","title":"pycauset.precision_mode","text":"<p>A context manager that temporarily overrides the current thread-local promotion precision mode.</p>"},{"location":"docs/functions/pycauset.precision_mode/#syntax","title":"Syntax","text":"<pre><code>with pycauset.precision_mode(mode):\n    ...\n</code></pre>"},{"location":"docs/functions/pycauset.precision_mode/#parameters","title":"Parameters","text":"Parameter Type Description <code>mode</code> <code>str</code> Either <code>\"lowest\"</code> or <code>\"highest\"</code>."},{"location":"docs/functions/pycauset.precision_mode/#description","title":"Description","text":"<p>This is the recommended way to override promotion policy for a specific block of code, including expressions that use Python operators like <code>a + b</code> or <code>a @ b</code>.</p> <p>On exit, the previous precision mode is restored.</p> <p>Notes:</p> <ul> <li>This controls storage dtype selection (the dtype of the resulting matrix/vector).</li> <li>It does not directly control accelerator internal compute dtype.</li> </ul>"},{"location":"docs/functions/pycauset.precision_mode/#example","title":"Example","text":"<pre><code>import pycauset as pc\n\na = pc.Float32Matrix(2)\nb = pc.FloatMatrix(2)  # float64\n\nwith pc.precision_mode(\"highest\"):\n    c = a @ b\n</code></pre>"},{"location":"docs/functions/pycauset.precision_mode/#see-also","title":"See also","text":"<ul> <li>pycauset.set_precision_mode</li> <li>pycauset.get_precision_mode</li> <li>pycauset.divide</li> </ul>"},{"location":"docs/functions/pycauset.save/","title":"pycauset.save","text":"<pre><code>pycauset.save(obj, path: str)\n</code></pre> <p>Saves a matrix, vector, block matrix, or a <code>CausalSet</code> to a permanent location on disk.</p> <p>This writes a new <code>.pycauset</code> snapshot container.</p> <ul> <li>For native matrices/vectors: writes a new container file by copying the payload data (via the object\u2019s <code>copy_storage(...)</code> implementation) and recording metadata.</li> <li>For block matrices: writes a small container file plus a sibling sidecar directory holding the child blocks (see below). Thunk blocks are evaluated blockwise (no global densify). Saving raises deterministically if any captured input is stale.</li> <li>For CausalSets: saves the causal matrix payload plus causet metadata.</li> </ul> <p>Snapshot semantics</p> <p><code>.pycauset</code> files are treated as immutable snapshots. Mutating a loaded object does not implicitly overwrite the on-disk snapshot.</p>"},{"location":"docs/functions/pycauset.save/#parameters","title":"Parameters","text":"<ul> <li>obj (matrix, vector, BlockMatrix, or CausalSet): The object to save.</li> <li>path (str): The destination path.</li> </ul>"},{"location":"docs/functions/pycauset.save/#example","title":"Example","text":"<pre><code># Save a raw matrix\npc.save(matrix, \"data.pycauset\")\n\n# Save a Causal Set\npc.save(causet, \"universe.pycauset\")\n\n# Save a block matrix (creates a sidecar directory)\nA = pc.matrix(((1.0, 0.0), (0.0, 1.0)))\nBM = pc.matrix(((A, A), (A, A)))\npc.save(BM, \"bm.pycauset\")  # writes bm.pycauset and bm.pycauset.blocks/\n</code></pre>"},{"location":"docs/functions/pycauset.save/#see-also","title":"See Also","text":"<ul> <li> <p><code>pycauset.CausalSet.save</code>: Method on pycauset.CausalSet.</p> </li> <li> <p>guides/Storage and Memory: Persistence overview, including cache persistence.</p> </li> </ul>"},{"location":"docs/functions/pycauset.save/#block-matrices-sidecar-layout","title":"Block matrices (sidecar layout)","text":"<p>When saving a <code>BlockMatrix</code>, PyCauset writes:</p> <ul> <li>Container file: <code>bm.pycauset</code></li> <li>Sidecar directory: <code>bm.pycauset.blocks/</code><ul> <li>Child files: <code>block_r{r}_c{c}.pycauset</code></li> </ul> </li> </ul> <p>The container stores a <code>block_manifest</code> that records partitions and references child blocks. Manifest entries pin each child\u2019s <code>payload_uuid</code>; load validates the pins.</p> <p>Additional policies:</p> <ul> <li><code>SubmatrixView</code> blocks are materialized block-locally to stable child files (no multi-block densify).</li> <li>Overwrite cleanup deletes only deterministic child filenames inside the sidecar.</li> <li>Saves stage child files (and nested sidecars) before commit to reduce partial-update risk.</li> </ul> <p>See Block Matrices for details.</p>"},{"location":"docs/functions/pycauset.set_backing_dir/","title":"Pycauset.set backing dir","text":"<pre><code># pycauset.set_backing_dir\n\n```python\npycauset.set_backing_dir(path: str | Path) -&gt; Path\n```\n\nSets the directory used for **auto-created backing files** (the temporary on-disk files that hold payload bytes for large matrices/vectors during a session).\n\n## When to call it\n\nCall it **once**, immediately after importing PyCauset, and **before** creating large matrices:\n\n```python\nimport pycauset as pc\n\npc.set_backing_dir(r\"D:\\\\pycauset_tmp\")\n\nM = pc.zeros((5000, 5000), dtype=pc.int32)\nM[0, 0] = 42\n```\n\n## Notes on switching\n\nYou *can* call this multiple times, but switching the backing directory mid-session is not guaranteed to be stable for already-created objects (some may remain backed by the old directory).\n\n\n## See also\n\n- [Storage and Memory](&lt;../../guides/Storage and Memory.md&gt;)\n- [Storage Semantics](&lt;../../dev/Storage Semantics.md&gt;)\n</code></pre>"},{"location":"docs/functions/pycauset.set_export_max_bytes/","title":"pycauset.set_export_max_bytes","text":"<pre><code>pycauset.set_export_max_bytes(limit)\n</code></pre> <p>Set a global materialization ceiling (in bytes) for exports to NumPy.</p> <p>This controls when <code>np.asarray(obj)</code>, <code>np.array(obj)</code>, and pycauset.to_numpy are allowed to create a dense in-RAM NumPy array.</p> <p>Notes:</p> <ul> <li>Passing <code>None</code> disables the size ceiling.</li> <li>Even with <code>None</code>, spill/file-backed objects may still require explicit opt-in via <code>allow_huge=True</code>.</li> </ul>"},{"location":"docs/functions/pycauset.set_export_max_bytes/#parameters","title":"Parameters","text":"<ul> <li>limit (int | None): Maximum allowed dense export size (bytes). Use <code>None</code> to disable.</li> </ul>"},{"location":"docs/functions/pycauset.set_export_max_bytes/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\n# Allow up to 512MB NumPy exports\npc.set_export_max_bytes(512 * 1024 * 1024)\n\n# Disable the ceiling (file-backed safety rules still apply)\npc.set_export_max_bytes(None)\n</code></pre>"},{"location":"docs/functions/pycauset.set_export_max_bytes/#see-also","title":"See also","text":"<ul> <li>pycauset.to_numpy</li> <li>Storage and Memory</li> <li>NumPy Integration</li> </ul>"},{"location":"docs/functions/pycauset.set_memory_threshold/","title":"pycauset.set_memory_threshold","text":"<pre><code>pycauset.set_memory_threshold(bytes: int)\n</code></pre> <p>Sets the size threshold (in bytes) below which objects are stored in RAM instead of on disk.</p> <p>Objects smaller than this threshold will be created in memory (using anonymous mapping) to improve performance and avoid disk I/O. Objects larger than this threshold will be backed by temporary files on disk.</p> <p>The default threshold is 1 GB.</p>"},{"location":"docs/functions/pycauset.set_memory_threshold/#parameters","title":"Parameters","text":"<ul> <li>bytes (int): The threshold in bytes.</li> </ul>"},{"location":"docs/functions/pycauset.set_memory_threshold/#example","title":"Example","text":"<pre><code>import pycauset\n\n# Set threshold to 100 MB\npycauset.set_memory_threshold(100 * 1024 * 1024)\n\n# This matrix (approx 12.5 MB) will now be in RAM\nm = pycauset.TriangularBitMatrix(10000) \n</code></pre>"},{"location":"docs/functions/pycauset.set_num_threads/","title":"pycauset.set_num_threads","text":"<p>Sets the number of threads to use for parallel operations.</p>"},{"location":"docs/functions/pycauset.set_num_threads/#syntax","title":"Syntax","text":"<pre><code>pycauset.set_num_threads(n)\n</code></pre>"},{"location":"docs/functions/pycauset.set_num_threads/#parameters","title":"Parameters","text":"Parameter Type Description <code>n</code> <code>int</code> The number of threads to use. Must be \\(\\ge 1\\)."},{"location":"docs/functions/pycauset.set_num_threads/#description","title":"Description","text":"<p>PyCauset uses a custom thread pool for parallelizing heavy operations like matrix multiplication and eigenvalue solving. By default, it uses the number of hardware threads available on the system.</p> <p>Use this function to manually control the parallelism level. This is useful for benchmarking or when running in a shared environment where you want to limit resource usage.</p>"},{"location":"docs/functions/pycauset.set_num_threads/#example","title":"Example","text":"<pre><code>import pycauset\nimport os\n\n# Use half the available cores\ncores = os.cpu_count()\npycauset.set_num_threads(cores // 2)\n</code></pre>"},{"location":"docs/functions/pycauset.set_precision_mode/","title":"pycauset.set_precision_mode","text":"<pre><code>pycauset.set_precision_mode(mode: str) -&gt; None\n</code></pre> <p>Set the current thread-local promotion precision mode.</p>"},{"location":"docs/functions/pycauset.set_precision_mode/#parameters","title":"Parameters","text":"<ul> <li><code>mode</code>: Either <code>\"lowest\"</code> or <code>\"highest\"</code>.</li> </ul>"},{"location":"docs/functions/pycauset.set_precision_mode/#description","title":"Description","text":"<p>PyCauset has an explicit promotion policy that controls how result dtypes are chosen when mixing dtypes. This function selects the policy used by the current thread.</p> <ul> <li><code>\"lowest\"</code>: choose the smallest reasonable storage dtype (scale/storage-first default).</li> <li><code>\"highest\"</code>: choose the highest-precision storage dtype available within the participating operand ranks.</li> </ul> <p>Notes:</p> <ul> <li>This controls storage dtype selection (the dtype of the resulting matrix/vector).</li> <li>It does not directly control accelerator internal compute dtype.</li> </ul>"},{"location":"docs/functions/pycauset.set_precision_mode/#example","title":"Example","text":"<pre><code>import pycauset as pc\n\npc.set_precision_mode(\"highest\")\n</code></pre>"},{"location":"docs/functions/pycauset.set_precision_mode/#see-also","title":"See also","text":"<ul> <li>pycauset.get_precision_mode</li> <li>pycauset.precision_mode</li> <li>pycauset.divide</li> </ul>"},{"location":"docs/functions/pycauset.slogdet/","title":"pycauset.slogdet","text":"<pre><code>pycauset.slogdet(a)\n</code></pre> <p>Compute a sign/log-determinant pair.</p>"},{"location":"docs/functions/pycauset.slogdet/#returns","title":"Returns","text":"<p>A tuple <code>(sign, logabsdet)</code> where:</p> <ul> <li><code>sign</code> is <code>-1.0</code>, <code>0.0</code>, or <code>1.0</code></li> <li><code>logabsdet</code> is <code>log(abs(det(a)))</code> (or <code>-inf</code> if <code>det(a) == 0</code>)</li> </ul>"},{"location":"docs/functions/pycauset.slogdet/#notes","title":"Notes","text":"<p>This currently uses the matrix method <code>a.determinant()</code>.</p>"},{"location":"docs/functions/pycauset.solve/","title":"pycauset.solve","text":"<pre><code>pycauset.solve(a, b)\n</code></pre> <p>Solve the linear system:</p> \\[ A X = B \\]"},{"location":"docs/functions/pycauset.solve/#parameters","title":"Parameters","text":"<ul> <li>a (MatrixBase): Coefficient matrix \\(A\\).</li> <li>b (VectorBase or MatrixBase): Right-hand side \\(B\\).</li> </ul>"},{"location":"docs/functions/pycauset.solve/#returns","title":"Returns","text":"<ul> <li>VectorBase or MatrixBase: The solution \\(X\\).</li> </ul>"},{"location":"docs/functions/pycauset.solve/#notes","title":"Notes","text":"<p>Property-aware shortcuts (R1_PROPERTIES): - If <code>a.properties[\"is_identity\"]</code> is asserted, the solver returns <code>b</code> directly (square only). - If <code>a.properties[\"is_zero\"]</code> is asserted, the solver raises a singularity error. - If <code>is_diagonal</code> / <code>is_upper_triangular</code> / <code>is_lower_triangular</code> is asserted, the solver routes to <code>solve_triangular</code>.</p> <p>Otherwise, the endpoint-first baseline uses <code>invert(a) @ b</code> when no dedicated solver is available.</p>"},{"location":"docs/functions/pycauset.solve/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\n\nA = pc.matrix(((4.0, 1.0), (2.0, 3.0)))\nb = pc.vector((1.0, 0.0))\n\nx = pc.solve(A, b)\n</code></pre>"},{"location":"docs/functions/pycauset.solve_triangular/","title":"pycauset.solve_triangular","text":"<p>Solve a linear system \\(A x = b\\) when \\(A\\) is claimed to be diagonal or triangular via A.properties.</p>"},{"location":"docs/functions/pycauset.solve_triangular/#signature","title":"Signature","text":"<pre><code>pycauset.solve_triangular(A, b)\n</code></pre>"},{"location":"docs/functions/pycauset.solve_triangular/#behavior-r1_properties","title":"Behavior (R1_PROPERTIES)","text":"<ul> <li>Uses gospel properties, not truth validation. If A.properties[\"is_diagonal\"] or is_upper_triangular / is_lower_triangular is set, the solver treats off-triangle entries as zero.</li> <li>Diagonal path: elementwise divide.</li> <li>Triangular path: converts to the native TriangularFloatMatrix and solves via the native inverse then matmul.</li> <li>Shape must be square; raises ValueError otherwise.</li> <li>If no triangular/diagonal claim is present, falls back to pycauset.solve or raises.</li> </ul>"},{"location":"docs/functions/pycauset.solve_triangular/#examples","title":"Examples","text":"<pre><code>A = pycauset.identity(3)\nA.properties[\"is_upper_triangular\"] = True  # gospel assertion\nb = pycauset.vector([1, 2, 3])\nx = pycauset.solve_triangular(A, b)\n</code></pre>"},{"location":"docs/functions/pycauset.solve_triangular/#notes","title":"Notes","text":"<ul> <li>Properties are authoritative; the solver does not scan payloads to verify structure.</li> <li>Cached-derived values and other properties are maintained via the properties health-check system.</li> </ul>"},{"location":"docs/functions/pycauset.sum/","title":"pycauset.sum","text":"<pre><code>pycauset.sum(x) -&gt; complex\n</code></pre> <p>Return the sum of all elements in a vector or matrix.</p>"},{"location":"docs/functions/pycauset.sum/#parameters","title":"Parameters","text":"<ul> <li><code>x</code>: A vector or matrix.</li> </ul>"},{"location":"docs/functions/pycauset.sum/#returns","title":"Returns","text":"<ul> <li><code>complex</code>: The total sum.</li> </ul> <p>Notes:</p> <ul> <li>For real inputs, the result is returned as <code>complex</code> with zero imaginary part.</li> <li>For complex inputs, the full complex sum is returned.</li> <li>Conjugated views (<code>x.conj()</code> / <code>x.H</code>) are respected.</li> </ul>"},{"location":"docs/functions/pycauset.sum/#exceptions","title":"Exceptions","text":"<ul> <li>Raises <code>TypeError</code> if <code>x</code> is not a <code>VectorBase</code> or <code>MatrixBase</code>.</li> </ul>"},{"location":"docs/functions/pycauset.sum/#examples","title":"Examples","text":"<pre><code>import numpy as np\nimport pycauset as pc\n\nv = pc.FloatVector(np.array([1.0, 2.0, 3.0], dtype=np.float64))\nassert pc.sum(v) == 6.0 + 0.0j\n\nz = pc.ComplexFloat64Vector(np.array([1 + 2j, 3 - 4j], dtype=np.complex128))\nassert pc.sum(z) == (1 + 2j) + (3 - 4j)\nassert pc.sum(z.conj()) == np.conj(pc.sum(z))\n</code></pre>"},{"location":"docs/functions/pycauset.sum/#see-also","title":"See also","text":"<ul> <li>pycauset.norm</li> <li>pycauset.matrix</li> <li>pycauset.vector</li> </ul>"},{"location":"docs/functions/pycauset.svd/","title":"pycauset.svd","text":"<p>This function is currently not available.</p>"},{"location":"docs/functions/pycauset.to_numpy/","title":"pycauset.to_numpy","text":"<pre><code>pycauset.to_numpy(obj, *, allow_huge=False, dtype=None, copy=True)\n</code></pre> <p>Convert a PyCauset object (matrix/vector/block matrix) to a NumPy array.</p> <p>This is the explicit NumPy export entrypoint. It exists because converting out-of-core objects to NumPy can cause surprise full materialization; <code>to_numpy</code> enforces the same safety rules described in NumPy Integration and Storage and Memory.</p>"},{"location":"docs/functions/pycauset.to_numpy/#parameters","title":"Parameters","text":"<ul> <li>obj: A PyCauset matrix/vector (and selected internal matrix-like objects).</li> <li>allow_huge (bool, default <code>False</code>):</li> <li>When <code>False</code>, exporting spill/file-backed objects hard-errors to prevent surprise full materialization.</li> <li>Set to <code>True</code> only when you intentionally want to materialize into RAM.</li> <li>dtype (optional): Override NumPy dtype on export.</li> <li>copy (bool, default <code>True</code>):</li> <li>If <code>True</code>, returns a deep copy (safe).</li> <li>If <code>False</code>, attempts to return a read-only view of the PyCauset memory. If a view is not possible (e.g. incompatible layout or bit-packed), it issues a <code>UserWarning</code> and falls back to a copy.</li> </ul>"},{"location":"docs/functions/pycauset.to_numpy/#returns","title":"Returns","text":"<ul> <li>A <code>numpy.ndarray</code>.</li> </ul>"},{"location":"docs/functions/pycauset.to_numpy/#exceptions","title":"Exceptions","text":"<ul> <li><code>RuntimeError</code> if NumPy is unavailable.</li> <li><code>RuntimeError</code> if export is blocked by the materialization guard (file-backed / too-large without opt-in).</li> </ul>"},{"location":"docs/functions/pycauset.to_numpy/#examples","title":"Examples","text":"<pre><code>import pycauset as pc\nimport numpy as np\n\nM = pc.zeros((3, 3), dtype=\"float32\")\narr = pc.to_numpy(M)\nassert isinstance(arr, np.ndarray)\n\n# Request a zero-copy view\nview = pc.to_numpy(M, copy=False)\n# view is generic read-only\n</code></pre>"},{"location":"docs/functions/pycauset.to_numpy/#see-also","title":"See also","text":"<ul> <li>pycauset.set_export_max_bytes</li> <li>pycauset.convert_file</li> <li>NumPy Integration</li> <li>Storage and Memory</li> </ul>"},{"location":"docs/functions/pycauset.vector/","title":"pycauset.vector","text":"<pre><code>pycauset.vector(source, dtype=None, *, max_in_ram_bytes=None, **kwargs)\n</code></pre> <p>Create a 1D vector from vector-like input.</p> <p>This is a data constructor (aligned with 1D <code>np.array([...])</code>). </p>"},{"location":"docs/functions/pycauset.vector/#parameters","title":"Parameters","text":"<ul> <li>source (sequence or numpy.ndarray): 1D data (e.g. list) or a 1D NumPy array.</li> <li>dtype (str or type, optional): Coerce storage dtype (e.g. <code>\"float64\"</code>, <code>\"int32\"</code>, <code>float</code>, <code>int</code>).</li> <li>max_in_ram_bytes (int or None, optional): When constructing from a NumPy array, route through the internal <code>native.asarray</code> import path if the estimated materialized size exceeds this cap to avoid overcommitting RAM (falls back to native regardless when supported dtypes are used).</li> <li>kwargs: Passed through to the backend constructor.</li> </ul>"},{"location":"docs/functions/pycauset.vector/#returns","title":"Returns","text":"<ul> <li>VectorBase: An instance of a concrete vector class (see pycauset.VectorBase and vector classes).</li> </ul>"},{"location":"docs/functions/pycauset.vector/#examples","title":"Examples","text":"<pre><code>import pycauset\n\nv = pycauset.vector([1, 2, 3])\nv_c = pycauset.vector([1+2j, 3-4j], dtype=\"complex_float32\")\n</code></pre>"},{"location":"docs/functions/pycauset.zeros/","title":"pycauset.zeros","text":"<pre><code>pycauset.zeros(shape, *, dtype, **kwargs)\n</code></pre> <p>Allocate a vector or matrix filled with zeros.</p> <p><code>dtype</code> is required.</p>"},{"location":"docs/functions/pycauset.zeros/#parameters","title":"Parameters","text":"<ul> <li> <p>shape (int or tuple):</p> <ul> <li><code>n</code> allocates a length-<code>n</code> vector.</li> <li><code>(n,)</code> allocates a length-<code>n</code> vector.</li> <li><code>(n, m)</code> allocates an <code>n\u00d7m</code> matrix.</li> </ul> <p>Notes: *   Rectangular allocation is supported for dense numeric matrix types. *   <code>dtype=\"bool\"</code>/<code>dtype=\"bit\"</code> uses bit-packed storage (<code>DenseBitMatrix</code>) and supports rectangular <code>(rows, cols)</code> shapes. *   dtype (str or type): Storage dtype token (e.g. <code>\"float64\"</code>, <code>\"int32\"</code>, <code>float</code>, <code>int</code>). *   kwargs: Passed through to the backend allocator.</p> </li> </ul>"},{"location":"docs/functions/pycauset.zeros/#returns","title":"Returns","text":"<ul> <li>VectorBase or MatrixBase: A newly allocated object.</li> </ul>"},{"location":"docs/functions/pycauset.zeros/#examples","title":"Examples","text":"<pre><code>import pycauset\n\nv = pycauset.zeros(10, dtype=\"float64\")\nm = pycauset.zeros((128, 64), dtype=\"float32\")\n</code></pre>"},{"location":"docs/functions/pycauset.zeros/#see-also","title":"See also","text":"<ul> <li>pycauset.ones</li> <li>pycauset.empty</li> <li>pycauset.MatrixBase</li> <li>Matrix Guide</li> </ul>"},{"location":"docs/parameters/","title":"Parameters","text":"<ul> <li>keep_temp_files</li> <li>seed</li> </ul>"},{"location":"docs/parameters/pycauset.keep_temp_files/","title":"pycauset.keep_temp_files","text":"<pre><code>pycauset.keep_temp_files\n</code></pre> <p>Controls whether PyCauset deletes its temporary disk-backed storage files when the Python process exits.</p> <p>When <code>False</code> (default), temporary files created during a session are cleaned up automatically.</p> <p>Set to <code>True</code> when debugging persistence issues, inspecting intermediate <code>.pycauset</code> artifacts, or reproducing a disk-backed performance scenario.</p>"},{"location":"docs/parameters/pycauset.keep_temp_files/#properties","title":"Properties","text":"<ul> <li>Type: bool</li> <li>Default: <code>False</code></li> </ul>"},{"location":"docs/parameters/pycauset.keep_temp_files/#notes","title":"Notes","text":"<ul> <li>This is a global setting that affects the runtime cleanup behavior.</li> <li>It does not automatically \u201csave\u201d objects as portable <code>.pycauset</code> files; use <code>pycauset.save(...)</code> for that.</li> </ul>"},{"location":"docs/parameters/pycauset.seed/","title":"pycauset.seed","text":"<pre><code>pycauset.seed\n</code></pre> <p>Sets the seed used by random population routines (<code>pycauset.causal_matrix.random</code>). Assign an integer for deterministic fills or <code>None</code> to return to non-deterministic behavior.</p>"},{"location":"docs/parameters/pycauset.seed/#properties","title":"Properties","text":"<ul> <li>Type: int or None</li> <li>Default: <code>None</code></li> </ul>"},{"location":"docs/pycauset.vis/","title":"pycauset.vis","text":"<p>The <code>pycauset.vis</code> module provides tools for visualizing Causal Sets.</p>"},{"location":"docs/pycauset.vis/#functions","title":"Functions","text":"<ul> <li>pycauset.vis.plot_embedding: Plot the spacetime embedding of a causal set.</li> <li>pycauset.vis.plot_hasse: Generate a Hasse diagram of a causal set.</li> <li>pycauset.vis.plot_causal_matrix: Visualize a causal matrix as a heatmap.</li> </ul>"},{"location":"docs/pycauset.vis/#description","title":"Description","text":"<p>This module leverages Plotly to create interactive 3D visualizations. It is designed to handle large causal sets efficiently by using smart sampling and on-demand coordinate generation.</p>"},{"location":"docs/pycauset.vis/#examples","title":"Examples","text":"<pre><code>from pycauset import CausalSet\nfrom pycauset.vis import plot_embedding\n\nc = CausalSet(n=1000)\nfig = plot_embedding(c)\nfig.show()\n</code></pre>"},{"location":"docs/pycauset.vis/plot_causal_matrix/","title":"pycauset.vis.plot_causal_matrix","text":"<pre><code>pycauset.vis.plot_causal_matrix(\n    causet: CausalSet,\n    title: str = None,\n    color_scale: str = 'Greys'\n) -&gt; plotly.graph_objects.Figure\n</code></pre> <p>Visualize the Causal Matrix (Adjacency Matrix) as a heatmap.</p>"},{"location":"docs/pycauset.vis/plot_causal_matrix/#parameters","title":"Parameters","text":"<ul> <li>causet (CausalSet): The causal set to visualize.</li> <li>title (str, optional): The title of the plot.</li> <li>color_scale (str, optional): The color scale to use (e.g., 'Greys', 'Viridis'). Defaults to 'Greys'.</li> </ul>"},{"location":"docs/pycauset.vis/plot_causal_matrix/#returns","title":"Returns","text":"<ul> <li>plotly.graph_objects.Figure: A Plotly figure object containing the heatmap.</li> </ul>"},{"location":"docs/pycauset.vis/plot_causal_matrix/#raises","title":"Raises","text":"<ul> <li>ValueError: If the matrix is too large (&gt; 2000 elements) to render effectively.</li> </ul>"},{"location":"docs/pycauset.vis/plot_causal_matrix/#description","title":"Description","text":"<p>This function visualizes the Causal Matrix (Adjacency Matrix) \\(C\\) as a heatmap. Since the matrix is strictly upper triangular (for a sorted causal set), the heatmap will show a triangular pattern. This is useful for inspecting the density and structure of causal relations.</p>"},{"location":"docs/pycauset.vis/plot_causal_matrix/#see-also","title":"See Also","text":"<ul> <li>Visualization Guide: For a comprehensive guide on visualizing causal sets.</li> <li>pycauset.vis.plot_hasse: For visualizing the causal structure as a graph.</li> </ul>"},{"location":"docs/pycauset.vis/plot_embedding/","title":"pycauset.vis.plot_embedding","text":"<pre><code>pycauset.vis.plot_embedding(\n    causet: CausalSet,\n    sample_size: int = 50000,\n    title: str = None,\n    marker_size: int = 2\n) -&gt; plotly.graph_objects.Figure\n</code></pre> <p>Generates an interactive 3D (or 2D) scatter plot of the Causal Set embedding.</p>"},{"location":"docs/pycauset.vis/plot_embedding/#parameters","title":"Parameters","text":"<ul> <li>causet (CausalSet): The causal set to visualize.</li> <li>sample_size (int, optional): The maximum number of points to display. If <code>causet.n</code> &gt; <code>sample_size</code>, a random subset is shown to maintain performance. Defaults to 50000.</li> <li>title (str, optional): The title of the plot. If None, a default title is generated.</li> <li>marker_size (int, optional): The size of the scatter points. Defaults to 2.</li> </ul>"},{"location":"docs/pycauset.vis/plot_embedding/#returns","title":"Returns","text":"<ul> <li>plotly.graph_objects.Figure: A Plotly figure object containing the scatter plot.</li> </ul>"},{"location":"docs/pycauset.vis/plot_embedding/#description","title":"Description","text":"<p>This function visualizes the causal set by regenerating the spacetime coordinates of its elements. It uses the <code>make_coordinates</code> backend to efficiently retrieve positions without storing them permanently.</p> <p>For large causal sets, the function automatically downsamples the points to <code>sample_size</code> to ensure the visualization remains responsive. The points are colored according to their time coordinate.</p>"},{"location":"docs/pycauset.vis/plot_embedding/#see-also","title":"See Also","text":"<ul> <li>Visualization Guide: For a comprehensive guide on visualizing causal sets.</li> <li><code>pycauset.CausalSet.coordinates</code>: Method on pycauset.CausalSet used to retrieve coordinates.</li> </ul>"},{"location":"docs/pycauset.vis/plot_hasse/","title":"pycauset.vis.plot_hasse","text":"<pre><code>pycauset.vis.plot_hasse(\n    causet: CausalSet,\n    title: str = None,\n    marker_size: int = 5,\n    line_width: int = 1,\n    line_color: str = 'rgba(255, 255, 255, 0.3)'\n) -&gt; plotly.graph_objects.Figure\n</code></pre> <p>Generates a Hasse diagram of the Causal Set.</p>"},{"location":"docs/pycauset.vis/plot_hasse/#parameters","title":"Parameters","text":"<ul> <li>causet (CausalSet): The causal set to visualize.</li> <li>title (str, optional): The title of the plot.</li> <li>marker_size (int, optional): Size of the element markers. Defaults to 5.</li> <li>line_width (int, optional): Width of the link lines. Defaults to 1.</li> <li>line_color (str, optional): Color of the link lines. Defaults to 'rgba(255, 255, 255, 0.3)'.</li> </ul>"},{"location":"docs/pycauset.vis/plot_hasse/#returns","title":"Returns","text":"<ul> <li>plotly.graph_objects.Figure: A Plotly figure object containing the Hasse diagram.</li> </ul>"},{"location":"docs/pycauset.vis/plot_hasse/#raises","title":"Raises","text":"<ul> <li>ValueError: If the causal set is too large (&gt; 500 elements) for a Hasse diagram.</li> </ul>"},{"location":"docs/pycauset.vis/plot_hasse/#description","title":"Description","text":"<p>A Hasse diagram displays the transitive reduction of the partial order. Elements are placed at their spacetime coordinates, and lines are drawn only between immediate causal neighbors (links). This reveals the \"skeleton\" of the causal structure.</p> <p>The function automatically applies coordinate transformations for supported spacetimes (e.g., <code>MinkowskiDiamond</code>, <code>MinkowskiCylinder</code>) to improve readability.</p>"},{"location":"docs/pycauset.vis/plot_hasse/#see-also","title":"See Also","text":"<ul> <li>Visualization Guide: For a comprehensive guide on visualizing causal sets.</li> <li>pycauset.vis.plot_embedding: For visualizing the embedding without links.</li> </ul>"},{"location":"guides/","title":"Guides","text":"<p>These guides show how to use PyCauset in practice, from first setup to large-scale runs.</p>"},{"location":"guides/#start-here","title":"Start here","text":"<ul> <li>Installation: Install PyCauset (pip or from source).</li> <li>User Guide: First workflow: create, visualize, save/load.</li> <li>Causal Sets: Core object model and common operations.</li> </ul>"},{"location":"guides/#release-1-what-shipped","title":"Release 1 (what shipped)","text":"<ul> <li>Release 1: What Shipped: A guided map of the Release 1 foundations (NxM shapes, storage container, semantic properties, dtype/overflow rules, and core linalg endpoints).</li> </ul>"},{"location":"guides/#common-workflows","title":"Common workflows","text":"<ul> <li>Visualization: Creating interactive plots of causal sets.</li> <li>Spacetime: Choosing a spacetime region and sprinkling points.</li> <li>Field Theory: Simulating quantum fields on causal sets.</li> <li>NumPy Integration: Interfacing with NumPy arrays.</li> </ul>"},{"location":"guides/#performance-and-scaling","title":"Performance and scaling","text":"<ul> <li>Storage and Memory: How PyCauset handles large datasets on disk.</li> <li>Performance Guide: Tips for optimizing your simulations.</li> </ul>"},{"location":"guides/#linear-algebra","title":"Linear algebra","text":"<ul> <li>Matrix Guide: Matrix storage, dtypes, and operations.</li> <li>Vector Guide: Vector storage and operations.</li> <li>Linear Algebra Operations: End-to-end linalg workflows (matmul, solves, factorizations, spectral/SVD, routing, warnings).</li> </ul>"},{"location":"guides/#when-you-need-exact-details","title":"When you need exact details","text":"<ul> <li>API Reference (function/class signatures and behaviors)</li> <li>Internals (how things work under the hood)</li> </ul>"},{"location":"guides/Causal%20Sets/","title":"Working with Causal Sets","text":"<p>This guide explains how to create and analyze causal sets using the pycauset.CausalSet class </p>"},{"location":"guides/Causal%20Sets/#introduction","title":"Introduction","text":"<p>A causal set is a discrete structure consisting of a set of elements with a partial order relation that represents causality. In <code>pycauset</code>, causal sets are typically generated by \"sprinkling\" points randomly into a continuous spacetime manifold (like Minkowski space) and inducing the causal order from the manifold's lightcone structure.</p>"},{"location":"guides/Causal%20Sets/#creating-a-causal-set","title":"Creating a Causal Set","text":"<p>The primary way to create a causal set is using the pycauset.CausalSet class.</p> <pre><code>import pycauset\n\n# Create a causal set with 10,000 elements\n# By default, this sprinkles into a 2D Minkowski Diamond\nc = pycauset.CausalSet(10000)\n</code></pre>"},{"location":"guides/Causal%20Sets/#reproducibility","title":"Reproducibility","text":"<p>To ensure your causal set is identical every time you run your code, provide a <code>seed</code>. This can be an integer or a string.</p> <pre><code># Using an integer seed\nc1 = pycauset.CausalSet(10000, seed=12345)\n\n# Using a string seed (useful for naming simulations)\nc2 = pycauset.CausalSet(10000, seed=\"simulation_A_run_1\")\n</code></pre>"},{"location":"guides/Causal%20Sets/#accessing-the-causal-matrix","title":"Accessing the Causal Matrix","text":"<p>The core data of a causal set is its causal matrix. In <code>pycauset</code>, this is represented as a pycauset.TriangularBitMatrix for efficiency. You can access it via the <code>.causal_matrix</code> property or its alias <code>.C</code>.</p> <pre><code># Get the causal matrix\nC = c.causal_matrix\n\n# Or using the alias\nC = c.C\n\n# C is a pycauset.TriangularBitMatrix\nprint(C)\n</code></pre> <p>Performance Note: The <code>TriangularBitMatrix</code> and <code>DenseBitMatrix</code> classes now use hardware-accelerated bit manipulation (AVX-512/NEON <code>popcount</code>). Operations like dot products, matrix multiplication, and transitive closure are approximately 30x faster than in previous versions.</p>"},{"location":"guides/Causal%20Sets/#causal-structure","title":"Causal Structure","text":"<p>The matrix \\(C\\) is defined such that \\(C_{ij} = 1\\) if element \\(i\\) is in the causal past of element \\(j\\) (\\(i \\prec j\\)), and \\(0\\) otherwise. Since the points are sorted by their time coordinate during generation, the matrix is strictly upper triangular.</p>"},{"location":"guides/Causal%20Sets/#what-is-a-causalset-instance","title":"What is a CausalSet Instance?","text":"<p>When you create an instance of pycauset.CausalSet, you might wonder what exactly is being stored in memory.</p> <pre><code>c = pycauset.CausalSet(1000)\n</code></pre> <p>The <code>c</code> object itself is extremely lightweight. It is essentially a metadata wrapper that holds: 1.  N: The number of elements (e.g., 1000). 2.  Seed: The random seed used for generation. 3.  Spacetime: The definition of the manifold (e.g., \"2D Minkowski Diamond\"). 4.  Handle to causal_matrix: A reference to the pycauset.TriangularBitMatrix object.</p> <p>What is NOT stored: *   Coordinates: The coordinates of the 1000 points are not stored in the <code>c</code> object. They were generated temporarily to compute the matrix and then discarded. *   Full Matrix in RAM: The causal matrix is backed by a file on disk. It is not fully loaded into RAM unless you explicitly read all of it.</p> <p>The \"End Product\" of the initialization is the Causal Matrix stored on disk. The pycauset.CausalSet instance is just your handle to access that matrix and remember how it was created.</p>"},{"location":"guides/Causal%20Sets/#large-scale-simulations","title":"Large Scale Simulations","text":"<p><code>pycauset</code> is designed for large-scale simulations. The pycauset.CausalSet class uses a stateless sprinkling technique (see Stateless Sprinkling) that avoids storing the coordinates of the points. This means you can generate causal sets with billions of elements without running out of RAM, provided you have enough disk space to store the resulting bit matrix.</p> <pre><code># Generating a very large causal set (e.g., 1 million elements)\n# This is memory-safe!\nc_large = pycauset.CausalSet(1_000_000)\n\n# The matrix is stored on disk, mapped into memory only as needed\nC_large = c_large.C\n</code></pre>"},{"location":"guides/Causal%20Sets/#spacetimes","title":"Spacetimes","text":"<p>You can sprinkle into different spacetime manifolds using the <code>spacetime</code> parameter. The pycauset.spacetime module provides standard manifolds.</p>"},{"location":"guides/Causal%20Sets/#minkowski-diamond","title":"Minkowski Diamond","text":"<p>The default spacetime is a 2D Minkowski Diamond (Alexandrov interval).</p> <pre><code>import pycauset\nfrom pycauset import spacetime\n\n# Explicitly specifying the diamond\ndiamond = spacetime.MinkowskiDiamond(dimension=2)\nc = pycauset.CausalSet(n=1000, spacetime=diamond)\n</code></pre>"},{"location":"guides/Causal%20Sets/#minkowski-cylinder","title":"Minkowski Cylinder","text":"<p>A flat spacetime with periodic spatial boundary conditions (\\(S^1 \\times \\mathbb{R}\\)).</p> <pre><code># A cylinder with height 2.0 and circumference 5.0\ncyl = spacetime.MinkowskiCylinder(dimension=2, height=2.0, circumference=5.0)\nc = pycauset.CausalSet(n=1000, spacetime=cyl)\n</code></pre>"},{"location":"guides/Causal%20Sets/#sprinkling-modes","title":"Sprinkling Modes","text":""},{"location":"guides/Causal%20Sets/#fixed-n","title":"Fixed N","text":"<p>Specify <code>n</code> to generate exactly that many elements.</p> <pre><code>c = pycauset.CausalSet(n=1000)\n</code></pre>"},{"location":"guides/Causal%20Sets/#fixed-density","title":"Fixed Density","text":"<p>Specify <code>density</code> (\\(\\rho\\)) to generate elements based on a Poisson process. The actual number of elements \\(N\\) will vary according to the Poisson distribution \\(N \\sim \\text{Poisson}(\\rho V)\\).</p> <pre><code># Sprinkle with density 100.0\n# If volume is 1.0, expected N is 100\nc = pycauset.CausalSet(density=100.0)\nprint(f\"Realized N: {c.N}\")\nprint(f\"Realized Density: {c.rho}\")\n</code></pre>"},{"location":"guides/Causal%20Sets/#saving-and-loading","title":"Saving and Loading","text":"<p>You can save a <code>CausalSet</code> to a portable <code>.pycauset</code> file. This single-file container contains the metadata (parameters, seed, spacetime info) and the binary causal matrix.</p> <pre><code># Save\nc.save(\"my_simulation.pycauset\")\n\n# Load\n# This reconstructs the object exactly without re-sprinkling\nc_loaded = pycauset.CausalSet.load(\"my_simulation.pycauset\")\n</code></pre>"},{"location":"guides/Causal%20Sets/#adding-matter-fields","title":"Adding Matter (Fields)","text":"<p>Once you have a causal set, you can define quantum fields on it to study particle propagation and entanglement. PyCauset separates the geometry (the set) from the matter (the field).</p> <p>See the Field Theory guide for details on how to define Scalar Fields and compute propagators.</p> <pre><code>from pycauset.field import ScalarField\n\n# Define a field on the set\nfield = ScalarField(c, mass=1.0)\nK = field.propagator()\n</code></pre>"},{"location":"guides/Field%20Theory/","title":"Field Theory on Causal Sets","text":"<p>Causal Set Theory is not just about the discrete structure of spacetime itself; it is also a framework for doing Quantum Field Theory (QFT). To do this, we define Fields that live on the causal set.</p> <p>In PyCauset, the geometry (the pycauset.CausalSet) and the matter (the pycauset.field.Field) are distinct objects. This separation allows you to study different fields (massless, massive, interacting) on the same underlying spacetime background.</p>"},{"location":"guides/Field%20Theory/#the-scalar-field","title":"The Scalar Field","text":"<p>The most fundamental field studied in Causal Set Theory is the Scalar Field. </p>"},{"location":"guides/Field%20Theory/#the-retarded-propagator-k_r","title":"The Retarded Propagator (\\(K_R\\))","text":"<p>The Retarded Propagator \\(K_R\\) is the inverse of the causal set d'Alembertian. In PyCauset, it is computed using the generalized formula:</p> \\[ K_R = \\Phi(I - b\\Phi)^{-1} \\] <p>where \\(\\Phi = a C\\) (\\(C\\) is the Causal Matrix).</p>"},{"location":"guides/Field%20Theory/#parameters","title":"Parameters","text":"<p>The coefficients \\(a\\) and \\(b\\) are the bridge between the discrete matrix mathematics and the continuous physical parameters. They depend on:</p> <ol> <li>Dimension (\\(d\\)): The dimension of the manifold (e.g., 2 or 4).</li> <li>Density (\\(\\rho\\)): The sprinkling density (\\(N/V\\)).</li> <li>Mass (\\(m\\)): The mass of the field.</li> </ol> <p>PyCauset automatically derives \\(a\\) and \\(b\\) for standard Minkowski spacetimes.</p> Dimension \\(a\\) \\(b\\) 2D \\(1/2\\) \\(-m^2/\\rho\\) 4D \\(\\frac{\\sqrt{\\rho}}{2\\pi\\sqrt{6}}\\) \\(-m^2/\\rho\\)"},{"location":"guides/Field%20Theory/#usage-guide","title":"Usage Guide","text":""},{"location":"guides/Field%20Theory/#1-define-the-spacetime-and-causal-set","title":"1. Define the Spacetime and Causal Set","text":"<p>First, generate your background geometry. Note that you must use density-based sprinkling (or provide the density manually) for the field coefficients to be calculated correctly.</p> <pre><code>import pycauset as pc\n\n# 1. Define Spacetime (2D Minkowski)\nst = pc.spacetime.MinkowskiDiamond(2)\n\n# 2. Sprinkle Causal Set (Density is required!)\nc = pc.CausalSet(density=1000, spacetime=st)\n</code></pre>"},{"location":"guides/Field%20Theory/#2-define-the-field","title":"2. Define the Field","text":"<p>Create a pycauset.field.ScalarField instance attached to your causal set. This is where you specify the mass.</p> <pre><code>from pycauset.field import ScalarField\n\n# Define a massive field (m=1.5)\nfield = ScalarField(c, mass=1.5)\n</code></pre>"},{"location":"guides/Field%20Theory/#3-compute-the-propagator","title":"3. Compute the Propagator","text":"<p>Call <code>.propagator()</code> to compute the \\(K_R\\) matrix. This operation is computationally intensive (\\(O(N^2)\\)) and returns a pycauset.TriangularFloatMatrix.</p> <pre><code># Compute K_R\nK = field.propagator()\n\n# K is a large matrix backed by disk storage\nprint(f\"Propagator shape: {K.shape}\")\n</code></pre>"},{"location":"guides/Field%20Theory/#massless-limit","title":"Massless Limit","text":"<p>For a massless field (\\(m=0\\)), the parameter \\(b\\) becomes 0. The formula simplifies to \\(K_R = aC\\).</p> <pre><code>massless_field = ScalarField(c, mass=0.0)\nK_0 = massless_field.propagator()\n</code></pre>"},{"location":"guides/Field%20Theory/#advanced-manual-coefficients","title":"Advanced: Manual Coefficients","text":"<p>If you are working with a non-standard spacetime or want to experiment with different non-locality parameters, you can override \\(a\\) and \\(b\\) manually.</p> <pre><code># Manually specifying coefficients (bypasses automatic derivation)\nK_custom = field.propagator(a=0.5, b=-0.02)\n</code></pre>"},{"location":"guides/Field%20Theory/#the-pauli-jordan-function-idelta","title":"The Pauli-Jordan Function (\\(i\\Delta\\))","text":"<p>The Pauli-Jordan function \\(\\Delta\\) is defined as the difference between the retarded and advanced propagators: $$ \\Delta = K_R - K_A $$ Since \\(K_A = K_R^T\\), this is equivalent to: $$ \\Delta = K - K^T $$</p> <p>In Quantum Field Theory, the operator of interest is often \\(i\\Delta\\). PyCauset provides a dedicated method to compute this efficiently.</p> <pre><code># Compute i*Delta\nDelta = field.pauli_jordan()\n</code></pre> <p>The result is an <code>AntiSymmetricFloat64Matrix</code>. To represent the factor of \\(i\\) without storing complex numbers for every element (which would double the storage requirement), PyCauset stores the real values of \\(\\Delta\\) and sets the matrix's <code>scalar</code> property to <code>1j</code>.</p> <p>When you access elements or perform arithmetic with this matrix, the factor of \\(i\\) is automatically applied.</p>"},{"location":"guides/Installation/","title":"Installation Guide","text":""},{"location":"guides/Installation/#method-1-install-via-pip-recommended","title":"Method 1: Install via pip (Recommended)","text":"<p>The easiest way to install PyCauset is using <code>pip</code>. </p>"},{"location":"guides/Installation/#from-pypi","title":"From PyPI","text":"<p>To install the latest published version: <pre><code>pip install pycauset\n</code></pre></p>"},{"location":"guides/Installation/#method-2-building-from-source","title":"Method 2: Building from Source","text":"<p>If you want to build from source or contribute to development, you will need a C++ compiler.</p>"},{"location":"guides/Installation/#prerequisites-for-source-build","title":"Prerequisites for Source Build","text":"<ul> <li>Windows: Install Visual Studio Community 2022 (or Build Tools) with the \"Desktop development with C++\" workload.</li> <li>Linux: Install <code>g++</code> or <code>clang</code> (e.g., <code>sudo apt install build-essential</code>).</li> <li>macOS: Install Xcode Command Line Tools (<code>xcode-select --install</code>).</li> </ul>"},{"location":"guides/Installation/#install-from-source","title":"Install from Source","text":"<p>To install from the local repository (this will compile the C++ extension):</p> <pre><code>pip install .\n</code></pre> <p>To install in editable mode (for development):</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"guides/Installation/#method-3-manual-build-development","title":"Method 3: Manual Build (Development)","text":"<p>If you are developing the C++ core or prefer manual control over the build process, you can use the provided PowerShell script (<code>build.ps1</code>). This script handles CMake configuration, compilation, and testing.</p>"},{"location":"guides/Installation/#1-verify-compiler","title":"1. Verify Compiler","text":"<p>Ensure your compiler is discoverable in your terminal. *   Windows: Run <code>cl</code>. If it's not found, you may need to launch the \"Developer PowerShell for VS 2022\" or add MSVC to your PATH.</p>"},{"location":"guides/Installation/#2-build-script","title":"2. Build Script","text":"<p>Use the <code>build.ps1</code> script to build the project:</p> <pre><code># Build everything (C++ tests + Python module)\n./build.ps1 -All\n\n# Only build the Python module (copies to python/pycauset)\n./build.ps1 -Python\n\n# Only run C++ unit tests\n./build.ps1 -Tests\n</code></pre>"},{"location":"guides/Installation/#3-running-scripts","title":"3. Running Scripts","text":"<p>If you used <code>./build.ps1 -Python</code> (and didn't use <code>pip</code>), the compiled module is located in <code>python/pycauset</code>. You can run scripts by ensuring this directory is in your <code>PYTHONPATH</code> or by running scripts from the root directory.</p>"},{"location":"guides/Installation/#gpu-acceleration-troubleshooting","title":"GPU Acceleration Troubleshooting","text":"<p>If <code>pycauset.cuda.is_available()</code> returns <code>False</code> even though you have an NVIDIA GPU, follow these steps.</p>"},{"location":"guides/Installation/#1-the-problem-missing-cuda-toolkit","title":"1. The Problem: Missing CUDA Toolkit","text":"<p>PyCauset needs to compile custom CUDA code (<code>.cu</code> files) to run on your GPU. This requires the NVIDIA CUDA Toolkit, which is different from just having the NVIDIA Drivers installed.</p> <p>The build system checks for the <code>nvcc</code> compiler. If it can't find it, it silently skips building the GPU backend.</p>"},{"location":"guides/Installation/#2-how-to-fix","title":"2. How to Fix","text":""},{"location":"guides/Installation/#step-1-install-cuda-toolkit","title":"Step 1: Install CUDA Toolkit","text":"<ol> <li>Go to the NVIDIA CUDA Downloads page.</li> <li>Select Windows -&gt; x86_64 -&gt; 10 (or 11) -&gt; exe (local).</li> <li>Download and run the installer.</li> <li>Important: During installation, choose \"Express\" or ensure \"Development\" components are selected.</li> </ol>"},{"location":"guides/Installation/#step-2-verify-installation","title":"Step 2: Verify Installation","text":"<p>Open a new PowerShell terminal (to refresh environment variables) and run: <pre><code>nvcc --version\n</code></pre> You should see output like <code>Cuda compilation tools, release 12.x...</code>.</p>"},{"location":"guides/Installation/#step-3-rebuild-pycauset","title":"Step 3: Rebuild PyCauset","text":"<p>Once <code>nvcc</code> is working, rebuild the project: <pre><code>.\\build.ps1 -Python\n</code></pre> Watch the output for: <pre><code>-- Found CUDA: ...\n-- Building pycauset_cuda accelerator.\n</code></pre></p>"},{"location":"guides/Installation/#step-4-verify-in-python","title":"Step 4: Verify in Python","text":"<pre><code>import pycauset\nprint(pycauset.cuda.is_available())  # Should be True\nprint(pycauset.cuda.current_device()) # Should be your GPU name\n</code></pre>"},{"location":"guides/Installation/#common-issues","title":"Common Issues","text":"<ul> <li>\"nvcc not found\" after install: You may need to manually add the CUDA <code>bin</code> directory to your PATH.<ul> <li>Default: <code>C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.x\\bin</code></li> </ul> </li> <li>Visual Studio Integration: CUDA requires a C++ compiler (MSVC). Ensure you have Visual Studio (Community Edition is fine) installed with \"Desktop development with C++\".</li> </ul>"},{"location":"guides/Linear%20Algebra%20Operations/","title":"Linear Algebra Operations","text":"<p>This guide shows how to use PyCauset\u2019s linear algebra surface end-to-end: matrix math, solves/factorizations, spectral/SVD tools, stability utilities, and routing knobs.</p>"},{"location":"guides/Linear%20Algebra%20Operations/#shapes-dtypes-and-storage","title":"Shapes, dtypes, and storage","text":"<ul> <li>Matrices are 2D only; vectors are treated as 1\u00d7N or N\u00d71 matrices under the hood.</li> <li>Choose dtype at creation (<code>float64/32/16</code>, <code>int*</code>, <code>uint*</code>, <code>complex_float*</code>, <code>bit/bool</code>). No implicit promotion beyond the documented promotion rules.</li> <li>Large data may be memory-mapped to disk automatically; see Storage and Memory.</li> </ul>"},{"location":"guides/Linear%20Algebra%20Operations/#matrix-construction-recap","title":"Matrix construction (recap)","text":"<pre><code>import pycauset as pc\nimport numpy as np\n\nA = pc.matrix([ [1., 2.], [3., 4.] ], dtype=\"float64\")\nB = pc.zeros((2, 2), dtype=\"float32\")\nC = pc.matrix(np.random.rand(2, 3))      # dtype inferred (float64)\n</code></pre> <p>See pycauset.matrix, pycauset.zeros, pycauset.ones.</p>"},{"location":"guides/Linear%20Algebra%20Operations/#multiplication-and-elementwise-ops","title":"Multiplication and elementwise ops","text":"<p><pre><code>M = pc.matrix([ [1, 2], [3, 4] ], dtype=\"float64\")\nN = pc.matrix([ [5, 6], [7, 8] ], dtype=\"float64\")\n\nP = M @ N                  # matmul\nQ = pc.matmul(M, N)         # same as @\nE = M * N                   # elementwise multiply\nS = M + N                   # elementwise add\n</code></pre> - Matmul shape rule: <code>M.cols() == N.rows()</code>; result <code>(M.rows(), N.cols())</code>. - Elementwise ops follow NumPy 2D broadcasting. - See pycauset.matmul, pycauset.sum, pycauset.divide.</p>"},{"location":"guides/Linear%20Algebra%20Operations/#mixed-operations-interop","title":"Mixed Operations (Interop)","text":"<p>You can use NumPy arrays directly in operations with PyCauset matrices. PyCauset automatically handles the conversion.</p> <pre><code>N_np = np.eye(2)\nM = pc.matrix([ [1, 2], [3, 4] ], dtype=\"float64\")\n\n# Mix NumPy and PyCauset (returns PyCauset matrix)\nRes = M @ N_np\nDiff = M - N_np\n</code></pre>"},{"location":"guides/Linear%20Algebra%20Operations/#solves-and-least-squares","title":"Solves and least squares","text":"<p><pre><code>A = pc.matrix([ [3., 1.], [1., 2.] ], dtype=\"float64\")\nb = pc.matrix([ [9.], [8.] ], dtype=\"float64\")   # column vector (2\u00d71)\nx = pc.solve(A, b)\n\n# Least squares\nA_ls = pc.matrix([ [1., 1.], [1., 2.], [1., 3.] ], dtype=\"float64\")\nb_ls = pc.matrix([ [1.], [2.], [2.5] ], dtype=\"float64\")\nx_ls = pc.lstsq(A_ls, b_ls)\n</code></pre> - <code>solve</code> requires square <code>A</code>; raises if singular/shape mismatch. - <code>lstsq</code> works for over/underdetermined systems; returns best-fit. - Triangular systems: use pycauset.solve_triangular for faster/safer solves on claimed triangular matrices. - See pycauset.solve, pycauset.lstsq.</p>"},{"location":"guides/Linear%20Algebra%20Operations/#factorizations","title":"Factorizations","text":"<p><pre><code>A = pc.matrix([ [4., 12., -16.], [12., 37., -43.], [-16., -43., 98.] ], dtype=\"float64\")\nL = pc.cholesky(A)     # lower-triangular\n\nM = pc.matrix([ [1., 2.], [3., 4.] ], dtype=\"float64\")\nLlu, Ulu = pc.lu(M)\n</code></pre> - <code>cholesky</code> expects Hermitian positive-definite; raises otherwise. - <code>lu</code> factors square matrices; returns <code>(L, U)</code>. - See pycauset.cholesky, pycauset.lu.</p>"},{"location":"guides/Linear%20Algebra%20Operations/#spectral-eigen-and-svd","title":"Spectral (eigen) and SVD","text":"<p><pre><code>A = pc.matrix([ [0., -1.], [1., 0.] ], dtype=\"float64\")\nvals, vecs = pc.eig(A)\n\nsym = pc.matrix([ [2., 1.], [1., 2.] ], dtype=\"float64\")\nvals_sym, vecs_sym = pc.eigh(sym)   # symmetric/Hermitian\n\nU, s, Vh = pc.svd(sym)\npinv = pc.pinv(sym)\n</code></pre> - Use <code>eig/eigvals</code> for general matrices; <code>eigh/eigvalsh</code> for symmetric/Hermitian (faster/stable). - <code>svd</code> returns <code>(U, s, Vh)</code>; <code>pinv</code> uses SVD internally. - See pycauset.eig, pycauset.eigh, pycauset.eigvals, pycauset.eigvalsh, pycauset.svd, pycauset.pinv.</p>"},{"location":"guides/Linear%20Algebra%20Operations/#inversion-and-stability-utilities","title":"Inversion and stability utilities","text":"<p><pre><code>A = pc.matrix([ [4., 7.], [2., 6.] ], dtype=\"float64\")\nA_inv = pc.invert(A)\n\nval, sign = pc.slogdet(A)\n\u03ba = pc.cond(A)\n</code></pre> - <code>invert</code>/<code>inverse</code> require square, supported dtypes (float64/float32); errors on singular. - <code>slogdet</code> returns <code>(sign, logabsdet)</code>; <code>cond</code> returns condition number. - See pycauset.invert, pycauset.slogdet, pycauset.cond.</p>"},{"location":"guides/Linear%20Algebra%20Operations/#dtype-precision-and-device-routing","title":"Dtype, precision, and device routing","text":"<ul> <li>Respect user dtype; no silent promotion except documented mixes (e.g., float32+float64 \u2192 float64, int32 matmul accumulator warnings, bit\u2192int32 promotions where necessary).</li> <li>Precision policy: set via pycauset.precision_mode / pycauset.set_precision_mode.</li> <li>GPU routing is op- and dtype-dependent; when unsupported, the call falls back to CPU or raises a deterministic error. See Performance Guide.</li> </ul>"},{"location":"guides/Linear%20Algebra%20Operations/#indexingslicing-recap","title":"Indexing/slicing recap","text":"<p>Dense matrices support NumPy-style indexing: basic slices are views; advanced (int/bool arrays) are copies; assignments broadcast and warn on dtype/overflow casts. Structured/triangular types reject slicing. See Matrix Guide and pycauset.MatrixBase.</p>"},{"location":"guides/Linear%20Algebra%20Operations/#persistence","title":"Persistence","text":"<ul> <li>Matrices may spill to disk automatically; views share backing when using basic slices.</li> <li>Save/load with pycauset.save and pycauset.load.</li> <li>Large-slice persistence policy for in-RAM sources is pending; current builds may error on unsupported cases.</li> </ul>"},{"location":"guides/Linear%20Algebra%20Operations/#troubleshooting-warnings","title":"Troubleshooting &amp; warnings","text":"<ul> <li>Dtype cast warnings: <code>PyCausetDTypeWarning</code> when casting RHS arrays to a narrower/different dtype.</li> <li>Overflow risk warnings: <code>PyCausetOverflowRiskWarning</code> for float\u2192int or narrowing casts in assignment; matmul may warn on int32 accumulation risk.</li> <li>Kernel guardrails: views with storage offsets are rejected by some kernels (<code>matmul</code>, <code>qr</code>, <code>lu</code>, <code>inverse</code>); materialize with <code>copy()</code> first.</li> </ul>"},{"location":"guides/Linear%20Algebra%20Operations/#see-also","title":"See also","text":"<ul> <li>API Reference</li> <li>NumPy Integration</li> <li>Matrix Guide</li> <li>Storage and Memory</li> <li>NumPy Alignment Protocol</li> <li>Compute Architecture</li> </ul>"},{"location":"guides/Matrix%20Guide/","title":"Matrix Guide","text":"<p>The back-bone of pycauset is the matrix system. While most users will interact with the high-level pycauset.CausalSet class, the matrix engine powers everything underneath. It is built from the ground-up to allow a seamless workflow as similar to possible to numpy.</p> <p><code>pycauset</code> behaves like NumPy at small scales (storing data in RAM), but converts to a memory-efficient beast at high scales (automatically spilling to disk).</p>"},{"location":"guides/Matrix%20Guide/#creating-a-matrix","title":"Creating a Matrix","text":"<p>Matrices can be created from data using pycauset.matrix. Allocation is done via pycauset.zeros, pycauset.ones, or pycauset.empty.</p>"},{"location":"guides/Matrix%20Guide/#rectangular-support-what-is-and-isnt-nxm","title":"Rectangular support (what is and isn\u2019t NxM)","text":"<ul> <li>Dense numeric matrices are rectangular-aware: for integer/float/complex dtypes you can allocate and operate on <code>(rows, cols)</code> shapes.</li> <li>Dense boolean/bit matrices are rectangular-aware: <code>dtype=\"bool\"</code> / <code>dtype=\"bit\"</code> maps to <code>DenseBitMatrix</code> and supports <code>(rows, cols)</code> shapes.</li> <li>Some matrix types are square-only by definition (e.g. triangular/causal, identity, diagonal, symmetric/antisymmetric).</li> </ul> <p><code>pycauset.matrix(...)</code> is a data constructor (aligned with <code>np.array(...)</code> semantics). It does not interpret integers/tuples as shapes. When you want to allocate by shape, use <code>zeros/ones/empty</code> with an explicit <code>dtype</code>.</p> <p><code>dtype</code> accepts multiple forms: *   <code>pc</code> dtype tokens like <code>pc.int8</code>, <code>pc.int16</code>, <code>pc.int32</code>, <code>pc.int64</code>, <code>pc.uint32</code>, <code>pc.float16</code>, <code>pc.float32</code>, <code>pc.float64</code>, <code>pc.complex_float32</code>, <code>pc.bool_</code> *   NumPy dtypes like <code>np.int16</code>, <code>np.float32</code>, <code>np.bool_</code> *   Strings like <code>\"int16\"</code>, <code>\"FLOAT32\"</code> (case-insensitive) *   Builtins like <code>int</code>, <code>float</code>, <code>bool</code></p> <p>Supported dtype strings (recommended):</p> <ul> <li>Bit/boolean: <code>\"bit\"</code>, <code>\"bool\"</code>, <code>\"bool_\"</code></li> <li>Signed integers: <code>\"int8\"</code>, <code>\"int16\"</code>, <code>\"int32\"</code>, <code>\"int64\"</code></li> <li>Unsigned integers: <code>\"uint8\"</code>, <code>\"uint16\"</code>, <code>\"uint32\"</code>, <code>\"uint64\"</code></li> <li>Floats: <code>\"float16\"</code>, <code>\"float32\"</code>, <code>\"float64\"</code></li> <li>Complex floats: <code>\"complex_float16\"</code>, <code>\"complex_float32\"</code>, <code>\"complex_float64\"</code></li> </ul> <p>Notes:</p> <ul> <li><code>\"int\"</code> normalizes to <code>\"int32\"</code>; <code>\"float\"</code> normalizes to <code>\"float64\"</code>; <code>\"uint\"</code> normalizes to <code>\"uint32\"</code>.</li> <li>Complex is limited to complex floats (no <code>complex int*</code> / <code>complex bit</code>).</li> <li>Exact op coverage is declared in the support matrix (see <code>documentation/internals/DType System.md</code>).</li> </ul> <pre><code>import pycauset as pc\nimport numpy as np\n\n# 1. From a list of lists (infers type)\nM1 = pc.matrix(((1, 2), (3, 4)))  # Creates IntegerMatrix\n\n# 2. From a NumPy array\narr = np.random.rand(5, 5)\nM2 = pc.matrix(arr)               # Creates FloatMatrix\n\n# 3. Allocate by shape (dtype required)\nM3 = pc.zeros((100, 200), dtype=int)   # 100x200 IntegerMatrix (zeros)\nM4 = pc.zeros((100, 100), dtype=bool)  # 100x100 DenseBitMatrix (zeros)\n\n# 4. Explicit int16 storage\nM5 = pc.empty((100, 100), dtype=pc.int16)  # returns Int16Matrix\n\n# 5. Unsigned integer storage\nMu = pc.empty((100, 100), dtype=pc.uint32)  # returns UInt32Matrix\n\n# 6. Complex float storage (construct from data)\nMc = pc.matrix(((1 + 2j, 0), (0, 3 - 4j)), dtype=pc.complex_float32)  # ComplexFloat32Matrix\n\n# 7. Causal Matrix (Specialized Triangular Bit Matrix)\n# This is optimized for causal sets (strictly upper triangular)\nC = pc.causal_matrix(100)\n</code></pre>"},{"location":"guides/Matrix%20Guide/#block-matrices","title":"Block matrices","text":""},{"location":"guides/Matrix%20Guide/#goal","title":"Goal","text":"<p>Represent a large matrix as a 2D grid of child matrices (blocks) without global densification or surprise dtype promotion.</p>"},{"location":"guides/Matrix%20Guide/#minimal-example","title":"Minimal example","text":"<pre><code>import pycauset as pc\n\nA = pc.matrix(((1.0, 0.0), (0.0, 1.0)))\nB = pc.matrix(((2.0, 3.0), (4.0, 5.0)))\n\n# 2x2 block grid of 2x2 blocks -&gt; overall 4x4\nBM = pc.matrix(((A, B), (B, A)))\n\nassert BM.shape == (4, 4)\nassert BM.block_rows == 2\nassert BM.block_cols == 2\n\n# Block access is explicit\nblk00 = BM.get_block(0, 0)\nassert blk00.shape == (2, 2)\n\n# Element access reads through to the relevant block\n_ = BM[0, 0]\n</code></pre>"},{"location":"guides/Matrix%20Guide/#construction-rules-important","title":"Construction rules (important)","text":"<p>For 2D nested sequences:</p> <ul> <li>If every element is matrix-like: constructs a block matrix.</li> <li>If no elements are matrices: constructs a dense native matrix (normal <code>pycauset.matrix</code> behavior).</li> <li>If you mix matrices and scalars: raises <code>TypeError</code> (ambiguous; no implicit lifting).</li> </ul> <p>Block-grid input rejects <code>dtype</code> and <code>**kwargs</code>.</p>"},{"location":"guides/Matrix%20Guide/#operations-laziness-and-slicing","title":"Operations, laziness, and slicing","text":"<ul> <li>\u201cOnce block, always block\u201d: <code>@</code>, <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code> preserve block structure and return a block matrix result.</li> <li>Results are thunked per output block and evaluate only on triggers:<ul> <li>element access (<code>C[i, j]</code>),</li> <li>dense conversion (<code>np.asarray(C)</code>),</li> <li>persistence (<code>pc.save(C, ...)</code>),</li> <li>crossing the compute boundary (e.g., feeding a thunk block into another op).</li> </ul> </li> <li>Non-triggers: <code>repr/str</code>, shape/partition metadata, and <code>get_block</code>.</li> <li>Block-aware slicing is supported: slicing a block matrix returns tiled <code>SubmatrixView</code> blocks without densifying; it raises deterministically if a required view cannot be represented.</li> <li>Partition mismatches during ops or slicing are handled by refinement (union of boundaries) with <code>SubmatrixView</code> tiling\u2014no silent densify.</li> <li>Staleness: thunks pin input <code>version</code> metadata; <code>set_block</code> or child mutation bumps versions. Stale thunks/caches raise on access (no auto-recompute).</li> </ul>"},{"location":"guides/Matrix%20Guide/#saving-and-loading","title":"Saving and loading","text":"<p>Saving a block matrix writes a container file plus a sidecar directory:</p> <pre><code>pc.save(BM, \"bm.pycauset\")\n# creates bm.pycauset and bm.pycauset.blocks/\n\nBM2 = pc.load(\"bm.pycauset\")\n</code></pre> <p>Saves evaluate thunk blocks blockwise, raise on stale thunks, and materialize <code>SubmatrixView</code> blocks locally for stable storage. See Block Matrices for the manifest shape and sidecar policy.</p>"},{"location":"guides/Matrix%20Guide/#precision-and-storage","title":"Precision and Storage","text":"<p>Choose precision explicitly via <code>dtype</code> at allocation time:</p> <pre><code>M16 = pc.empty((5000, 5000), dtype=\"float16\")\nM32 = pc.empty((5000, 5000), dtype=\"float32\")\nM64 = pc.empty((5000, 5000), dtype=\"float64\")\n</code></pre>"},{"location":"guides/Matrix%20Guide/#matrix-operations","title":"Matrix Operations","text":"<p><code>pycauset</code> provides efficient implementations for matrix operations, mirroring <code>numpy</code> semantics where appropriate but optimized for specific matrix structures (e.g., triangular, bit-packed).</p>"},{"location":"guides/Matrix%20Guide/#indexing-slicing-and-assignment-numpy-style","title":"Indexing, slicing, and assignment (NumPy-style)","text":"<p>PyCauset implements NumPy-like 2D indexing for dense matrices. Block matrices support element access and block-aware slicing via tiled <code>SubmatrixView</code> (no densify); structured/triangular matrices still reject slicing.</p>"},{"location":"guides/Matrix%20Guide/#basic-indexing-views-shared-storage","title":"Basic indexing \u2192 views (shared storage)","text":"<ul> <li>Supported: integers (negative wrap), <code>:</code>, <code>slice</code> with step (\u00b1), <code>...</code>.</li> <li>Returns a view when both row/col steps are <code>1</code>; mutations reflect in the source.</li> </ul> <pre><code>M = pc.matrix([ [1, 2, 3], [4, 5, 6] ], dtype=\"float64\")\nsub = M[:, 1:]          # view, shares backing\nsub[0, 0] = 20\nassert M[0, 1] == 20\n</code></pre>"},{"location":"guides/Matrix%20Guide/#advanced-indexing-copies","title":"Advanced indexing \u2192 copies","text":"<ul> <li>Supported per axis: 1D integer arrays (negative wrap) and 1D boolean masks.</li> <li>Any use of arrays (alone or mixed with basic) returns a copy with NumPy shape rules; two array axes must have equal length or length-1.</li> </ul> <pre><code>rows = pc.np.array([0, 1], dtype=int)\ncols = pc.np.array([2, 1], dtype=int)\npicked = M[rows, cols]   # copy; shape (1, 2) after broadcast\n</code></pre>"},{"location":"guides/Matrix%20Guide/#assignment-with-broadcasting","title":"Assignment with broadcasting","text":"<ul> <li>RHS may be a scalar, NumPy 0/1/2-D array, or another dense matrix.</li> <li>NumPy 2D broadcast rules apply; shape mismatch raises <code>ValueError</code>.</li> <li>Casting RHS arrays triggers <code>PyCausetDTypeWarning</code>; narrowing or float\u2192int casts also trigger <code>PyCausetOverflowRiskWarning</code>.</li> </ul> <pre><code>rhs = pc.np.arange(6).reshape(2, 3)\nM[:2, :3] = rhs          # broadcasts OK\n\nM[:, :2] = pc.np.array([1.5, 2.5], dtype=pc.np.float32)  # warns: cast float32 \u2192 float64\n</code></pre>"},{"location":"guides/Matrix%20Guide/#unsupported-current-build","title":"Unsupported (current build)","text":"<ul> <li><code>None</code> / <code>newaxis</code> (matrices stay 2D-only).</li> <li>Slicing structured/triangular types.</li> </ul>"},{"location":"guides/Matrix%20Guide/#kernel-guardrails","title":"Kernel guardrails","text":"<p>Views with storage offsets are rejected by <code>matmul</code>, <code>qr</code>, <code>lu</code>, and <code>inverse</code>; call <code>copy()</code> first.</p> <p>See also: pycauset.MatrixBase, NumPy Alignment Protocol, Storage and Memory</p>"},{"location":"guides/Matrix%20Guide/#gpu-acceleration","title":"GPU Acceleration","text":"<p>If a compatible NVIDIA GPU is detected, PyCauset will automatically accelerate: *   Multiplication: \\(A \\times B\\) for Float64, Float32, and Boolean matrices. *   Inversion: \\(A^{-1}\\) for Float64 and Float32 matrices.</p> <p>Boolean Matrix Acceleration: Multiplying <code>DenseBitMatrix</code> (boolean) on the GPU is highly optimized. It uses bit-packing to perform 64 operations per cycle, making it ideal for path counting in large causal sets.</p> <pre><code>A = pc.zeros((4096, 4096), dtype=bool)\nB = pc.zeros((4096, 4096), dtype=bool)\n# ... fill matrices ...\n\n# Extremely fast GPU multiplication\nC = A @ B \n</code></pre>"},{"location":"guides/Matrix%20Guide/#matrix-multiplication-matmul","title":"Matrix Multiplication (<code>matmul</code>)","text":"<p>Matrix multiplication is performed using pycauset.matmul(A, B). It follows the standard shape rule: <code>A.cols() == B.rows()</code> and returns a matrix of shape <code>(A.rows(), B.cols())</code>.</p> <p>It supports many combinations of matrix types, automatically promoting the result to the most general required structure (Dense &gt; TriangularFloat &gt; Integer &gt; Bit).</p> Operand A Operand B Result Type pycauset.FloatMatrix (Dense) Any pycauset.FloatMatrix Any pycauset.FloatMatrix (Dense) pycauset.FloatMatrix pycauset.TriangularFloatMatrix Triangular (Any) pycauset.TriangularFloatMatrix Triangular (Any) pycauset.TriangularFloatMatrix pycauset.TriangularFloatMatrix pycauset.IntegerMatrix pycauset.IntegerMatrix or pycauset.TriangularBitMatrix pycauset.IntegerMatrix pycauset.TriangularBitMatrix pycauset.IntegerMatrix pycauset.IntegerMatrix pycauset.TriangularBitMatrix pycauset.TriangularBitMatrix pycauset.IntegerMatrix pycauset.DenseBitMatrix pycauset.DenseBitMatrix pycauset.IntegerMatrix <p>Note: pycauset.IntegerMatrix is a dense matrix storing 32-bit integers, commonly returned for discrete path counting operations.</p>"},{"location":"guides/Matrix%20Guide/#implementation-details","title":"Implementation Details","text":"<p>Operations use memory-mapped files to handle large matrices. - Triangular Matrices: Uses a row-addition algorithm exploiting the strictly upper triangular structure. - Dense Matrices: Uses a row-wise accumulation (IKJ) algorithm. - Mixed Types: Optimized to use the sparse structure of triangular matrices while producing dense results. - Scalar Propagation: \\(C.scalar = A.scalar \\times B.scalar\\).</p>"},{"location":"guides/Matrix%20Guide/#element-wise-multiplication","title":"Element-wise Multiplication","text":"<p>Use the standard <code>*</code> operator: <code>C = A * B</code>. -   \\(C_{ij} = A_{ij} \\times B_{ij}\\) -   For pycauset.TriangularBitMatrix, this is equivalent to bitwise AND. -   Returns a new matrix of the same type as the operands.</p>"},{"location":"guides/Matrix%20Guide/#scalar-multiplication","title":"Scalar Multiplication","text":"<p>Scalar multiplication is supported for all matrix types and is lazily evaluated: <code>C = 0.5 * A</code>. -   The operation is \\(O(1)\\) and does not iterate over data. -   It updates an internal <code>scalar</code> field. -   Values are multiplied on-the-fly when accessed or converted to numpy.</p>"},{"location":"guides/Matrix%20Guide/#vector-matrix-multiplication","title":"Vector-Matrix Multiplication","text":"<p>Use the <code>@</code> operator for matrix-vector multiplication. -   Matrix @ Vector: <code>M @ v</code> returns a column vector (\\(M \\times v\\)). -   Vector @ Matrix: <code>v.T @ M</code> returns a row vector (\\(v^T \\times M\\)).</p>"},{"location":"guides/Matrix%20Guide/#linear-algebra","title":"Linear Algebra","text":"<p>PyCauset includes a suite of linear algebra tools.</p>"},{"location":"guides/Matrix%20Guide/#inversion","title":"Inversion","text":"<p>Matrix inversion is supported for selected floating-point dense matrices and requires a square matrix (<code>rows == cols</code>).</p> <pre><code># Compute inverse\nInv = M.inverse()\n</code></pre>"},{"location":"guides/Matrix%20Guide/#saving-and-storing-matrices","title":"Saving and Storing Matrices","text":"<p>In pycauset, large matrices are automatically stored on your device's storage disk to allow for work with humongous datasets. Small matrices may live in RAM for performance until they grow too large.</p>"},{"location":"guides/Matrix%20Guide/#temporary-files-lifecycle","title":"Temporary Files &amp; Lifecycle","text":"<p>By default, <code>pycauset</code> manages backing files automatically. Files are stored in a <code>.pycauset</code> directory in the current working directory.</p> <ul> <li>Configuration: Call <code>pycauset.set_backing_dir(\"...\")</code> once after import (and before allocating large matrices).</li> <li>Automatic Cleanup: Temporary files are deleted on import (leftovers from previous runs) and again when the Python interpreter exits.</li> <li>Persistence: Set <code>pycauset.keep_temp_files = True</code> to prevent deletion (useful for debugging).</li> <li>Manual Cleanup: Call <code>matrix.close()</code> to release the memory-mapped handle immediately.</li> </ul> <p>Temporary file types you may see in the backing directory:</p> <ul> <li><code>.tmp</code>: session-only backing files holding payload bytes (including spill/eviction).</li> <li><code>.raw_tmp</code>: staging files created while <code>save()</code> is writing a snapshot.</li> </ul>"},{"location":"guides/Matrix%20Guide/#saving-a-matrix","title":"Saving a Matrix","text":"<p>Matrices are backed by temporary files that are deleted when the program exits, unless pycauset.keep_temp_files is set to <code>True</code>. To permanently save a specific matrix, use pycauset.save. </p> <p>Note: If you are working with a pycauset.CausalSet, you should use its <code>.save()</code> method (or <code>pycauset.save(causet)</code>) to save the entire object including metadata. The method below is for raw matrices.</p> <pre><code># Save the matrix to a permanent location\npc.save(C, \"my_saved_matrix.pycauset\")\n</code></pre>"},{"location":"guides/Matrix%20Guide/#loading-a-matrix","title":"Loading a Matrix","text":"<p>You can load any previously saved matrix file using pycauset.load. The function automatically detects the matrix type (Causal, Integer, Float, etc.) from the file header.</p> <pre><code># Load a matrix from disk\nmatrix = pc.load(\"my_saved_matrix.pycauset\")\n\n# Check the type\nprint(type(matrix)) \n# &lt;class 'pycauset.pycauset.TriangularBitMatrix'&gt; (or IntegerMatrix, etc.)\n</code></pre>"},{"location":"guides/Matrix%20Guide/#temporary-files","title":"Temporary Files","text":"<p>By default, <code>pycauset</code> manages backing files automatically. Files are stored in a <code>.pycauset</code> directory. - Automatic Cleanup: Temporary files are deleted on import (leftovers) and on exit. - Persistence: Set <code>pycauset.keep_temp_files = True</code> to prevent deletion of temporary files (useful for debugging). - Explicit Saving: Use pycauset.save to keep specific matrices.</p>"},{"location":"guides/Matrix%20Guide/#caching-and-persistence","title":"Caching and Persistence","text":"<p>Some operations cache small derived values (for example <code>trace</code> / <code>determinant</code>) into the file\u2019s typed metadata when saving matrices. Other caches are build-dependent and may not be available in all builds.</p>"},{"location":"guides/Matrix%20Guide/#matrix-hierarchy","title":"Matrix Hierarchy","text":"<p>All matrix types derive from a shared C++ <code>MatrixBase</code> that owns the memory-mapped backing file and lifecycle management. The hierarchy is designed to support both dense and sparse/triangular structures efficiently.</p> <pre><code>classDiagram\n    class MatrixBase {\n        +uint64_t rows()\n        +uint64_t cols()\n        +uint64_t size()\n        +complex scalar_\n        +get_element_as_double()\n    }\n    class DenseMatrix~T~ {\n        +read(i, j) T\n    }\n    class TriangularMatrix~T~ {\n        +vector~uint64_t~ row_offsets_\n        +read(i, j) T\n    }\n\n    MatrixBase &lt;|-- DenseMatrix\n    MatrixBase &lt;|-- TriangularMatrix</code></pre>"},{"location":"guides/Matrix%20Guide/#common-types","title":"Common Types","text":"Python Class C++ Implementation Description <code>IntegerMatrix</code> <code>DenseMatrix&lt;int32_t&gt;</code> Dense matrix of 32-bit integers. <code>FloatMatrix</code> <code>DenseMatrix&lt;double&gt;</code> Dense matrix of 64-bit floats. <code>DenseBitMatrix</code> <code>DenseMatrix&lt;bool&gt;</code> Dense matrix of booleans (bit-packed). <code>TriangularBitMatrix</code> <code>TriangularMatrix&lt;bool&gt;</code> Strictly upper triangular boolean matrix (Causal Matrix). <code>TriangularFloatMatrix</code> <code>TriangularMatrix&lt;double&gt;</code> Strictly upper triangular float matrix. <p>For working with causal matrices (a backbone of the causal set theory), <code>TriangularBitMatrix</code> is the primary boolean specialization. Use <code>pycauset.causal_matrix(...)</code> to create one. <code>IntegerMatrix</code> stores 32-bit counts (e.g., from matrix multiplication). <code>TriangularFloatMatrix</code> and <code>FloatMatrix</code> (dense) provide floating-point storage for analytical results.</p>"},{"location":"guides/Matrix%20Guide/#performance-parallelism","title":"Performance &amp; Parallelism","text":"<p>Pycauset is designed to handle large matrices (\\(N &gt; 5000\\)) efficiently by leveraging multi-core CPUs.</p>"},{"location":"guides/Matrix%20Guide/#automatic-parallelization","title":"Automatic Parallelization","text":"<p>The library automatically detects the number of available CPU cores and parallelizes computationally intensive operations. No user configuration is required, but manual control is available.</p> <ul> <li>Matrix Inversion: Uses a parallel Block Gauss-Jordan algorithm.</li> <li>Eigenvalues: Uses a parallel QR algorithm with Hessenberg Reduction.</li> <li>Matrix Multiplication: Uses optimized parallel block multiplication.</li> <li>Skew-Symmetric Solver: Uses a parallel Block Skew-Lanczos algorithm.</li> </ul>"},{"location":"guides/Matrix%20Guide/#controlling-thread-count","title":"Controlling Thread Count","text":"<p>You can manually set the number of threads used by the library. This is useful for benchmarking or resource management.</p> <pre><code>import pycauset\nimport os\n\n# Use all available cores (default)\npycauset.set_num_threads(os.cpu_count())\n\n# Limit to 4 threads\npycauset.set_num_threads(4)\n\n# Check current setting\nprint(pycauset.get_num_threads())\n</code></pre>"},{"location":"guides/Matrix%20Guide/#performance-expectations","title":"Performance Expectations","text":"<p>Performance depends heavily on CPU, memory bandwidth, storage speed, and dtype. Use the scripts under <code>benchmarks/</code> to measure performance on your target machine.</p>"},{"location":"guides/Matrix%20Guide/#see-also","title":"See also","text":"<ul> <li>pycauset.matrix</li> <li>pycauset.zeros</li> <li>pycauset.empty</li> <li>pycauset.matmul</li> <li>pycauset.MatrixBase</li> <li>internals/Memory and Data</li> <li>internals/DType System</li> </ul>"},{"location":"guides/Numpy%20Integration/","title":"NumPy Integration Guide","text":"<p><code>pycauset</code> is designed to work seamlessly with the Python scientific stack, particularly NumPy. While <code>pycauset</code> uses its own optimized storage (RAM or disk-backed) for handling massive datasets, it provides smooth interoperability with NumPy arrays for convenience and flexibility.</p>"},{"location":"guides/Numpy%20Integration/#converting-numpy-arrays-to-pycauset","title":"Converting NumPy Arrays to PyCauset","text":"<p>You can convert NumPy arrays into <code>pycauset</code> objects using pycauset.matrix and pycauset.vector. These constructors automatically detect the data type of the NumPy array and create the corresponding optimized object.</p> <p>Note: PyCauset does not expose a <code>pycauset.asarray</code> API. In PyCauset, \u201carrays\u201d are not a first-class concept; matrices and vectors are.</p> <p>Rectangular 2D arrays are supported for dense numeric matrices (int/uint/float/complex). Boolean 2D arrays are bit-packed (<code>DenseBitMatrix</code>) and also support rectangular <code>(rows, cols)</code> shapes.</p> <p>Supported dtypes include:</p> <ul> <li>Integers: <code>int8/int16/int32/int64</code> and <code>uint8/uint16/uint32/uint64</code></li> <li>Floats: <code>float16/float32/float64</code></li> <li>Complex floats: <code>complex64/complex128</code> (mapped to <code>complex_float32/complex_float64</code>)</li> <li>Booleans: <code>bool_</code> (mapped to bit-packed storage)</li> </ul> <p>Performance Note: Import uses a parallelized direct path for large arrays, achieving &gt;10GB/s on modern hardware. Non-contiguous arrays (slices) are automatically handled via an optimized parallel copy.</p> <pre><code>import numpy as np\nimport pycauset as pc\n\n# Convert 1D NumPy array to Vector\narr_1d = np.array([1.0, 2.0, 3.0])\nvec = pc.vector(arr_1d)  # Returns [pycauset.FloatVector](&lt;../docs/classes/vector/pycauset.FloatVector.md&gt;)\n\n# Convert 2D NumPy array to Matrix\narr_2d = np.array(((1, 2), (3, 4)), dtype=np.int32)\nmat = pc.matrix(arr_2d)  # Returns [pycauset.IntegerMatrix](&lt;../docs/classes/matrix/pycauset.IntegerMatrix.md&gt;)\n\n# Unsigned integers\narr_u = np.array(((1, 2), (3, 4)), dtype=np.uint32)\nmat_u = pc.matrix(arr_u)  # Returns [pycauset.UInt32Matrix](&lt;../docs/classes/matrix/pycauset.UInt32Matrix.md&gt;)\n\n# Complex\narr_c = np.array(((1 + 2j, 0), (0, 3 - 4j)), dtype=np.complex64)\nmat_c = pc.matrix(arr_c)  # Returns [pycauset.ComplexFloat32Matrix](&lt;../docs/classes/matrix/pycauset.ComplexFloat32Matrix.md&gt;)\n\n# Convert Boolean array\narr_bool = np.array([True, False], dtype=bool)\nvec_bool = pc.vector(arr_bool)  # Returns [pycauset.BitVector](&lt;../docs/classes/vector/pycauset.BitVector.md&gt;)\n</code></pre> <p>Note: This operation creates a copy of the data. Depending on the size and the configured memory threshold, the new object will be stored in RAM or on disk. See guides/Storage and Memory.</p>"},{"location":"guides/Numpy%20Integration/#numpy-ufunc-support","title":"NumPy UFunc Support","text":"<p>PyCauset matrices support NumPy universal functions (ufuncs) like <code>np.sin</code>, <code>np.add</code>, etc. These operations return lazy expressions that are evaluated efficiently.</p> <pre><code>import numpy as np\nimport pycauset as pc\n\nA = pc.matrix(np.random.rand(100, 100))\n\n# Element-wise sine\nB = np.sin(A)\n\n# Element-wise addition\nC = np.add(A, A)\n</code></pre>"},{"location":"guides/Numpy%20Integration/#mixed-arithmetic-and-ergonomics","title":"Mixed Arithmetic and Ergonomics","text":"<p>PyCauset supports mixed operations between NumPy arrays and PyCauset objects. Operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>@</code>) automatically route to the optimized PyCauset implementation when possible.</p> <pre><code>A = pc.matrix(np.random.rand(1000, 1000))\nB = np.random.rand(1000, 1000)\n\n# Works efficiently!\n# PyCauset handles the add, returning a FloatMatrix\nC = A + B \n\n# Also works (Reverse add support)\nD = B + A\n</code></pre>"},{"location":"guides/Numpy%20Integration/#converting-pycauset-objects-to-numpy","title":"Converting PyCauset Objects to NumPy","text":"<p>All <code>pycauset</code> Matrix and Vector classes implement the NumPy array protocol (<code>__array__</code>). This means you can pass any <code>pycauset</code> object directly to <code>np.array()</code> or any function that expects an array-like object.</p> <pre><code>v = pc.vector([1, 2, 3])\n\n# Convert to NumPy array\narr = np.array(v)\n\n# Use in NumPy functions\nmean_val = np.mean(v)\nstd_val = np.std(v)\n</code></pre>"},{"location":"guides/Numpy%20Integration/#zero-copy-views-copyfalse","title":"Zero-Copy Views (<code>copy=False</code>)","text":"<p>By default, conversion creates a copy (safe). However, if you want high-performance access without duplication, you can request a view using <code>pc.to_numpy(..., copy=False)</code>.</p> <ul> <li>Success: Returns a read-only NumPy array viewing the PyCauset memory.</li> <li>Fallback: If the object cannot be viewed (e.g., bit-packed matrices or complex expression templates), it issues a <code>UserWarning</code> and falls back to a copy.</li> </ul> <pre><code>M = pc.matrix(np.eye(1000))\n\n# Try to get a view\n# Warning: The returned array is READ-ONLY. Modifying it is undefined behavior.\nview = pc.to_numpy(M, copy=False) \n</code></pre>"},{"location":"guides/Numpy%20Integration/#safety-rules-materialization","title":"Safety rules (materialization)","text":"<p>Converting a massive out-of-core matrix to NumPy is dangerous\u2014it forces the entire dataset into RAM, which can crash your process. PyCauset guards against this.</p> <ul> <li>Snapshot-backed (<code>.pycauset</code>) and RAM-backed (<code>:memory:</code>) objects: <code>np.array(obj)</code> is allowed and returns a copy.</li> <li>Spill/file-backed objects (e.g., <code>.tmp</code>): <code>np.array(obj)</code> raises by default to prevent surprise full materialization. Opt in explicitly via <code>pc.to_numpy(obj, allow_huge=True)</code> if you truly want to load it into RAM.</li> <li>Ceiling control: pc.set_export_max_bytes(bytes_or_None) sets a materialization limit. <code>None</code> disables the size ceiling; file-backed objects still require <code>allow_huge=True</code>.</li> </ul> <p>If you see an export error, either downsize, keep the data in PyCauset ops, or opt in with <code>allow_huge=True</code> intentionally.</p>"},{"location":"guides/Numpy%20Integration/#on-disk-conversions-numpy-formats","title":"On-disk conversions (NumPy formats)","text":"<p>If you need to move data between PyCauset snapshots and NumPy container files, use pc.convert_file.</p> <p>Important note: exporting from <code>.pycauset</code> to <code>.npy</code>/<code>.npz</code> still produces a dense NumPy array in-process today (guarded by <code>allow_huge</code>), because NumPy\u2019s writers expect dense arrays.</p> <ul> <li>Supported formats: <code>.pycauset</code>, <code>.npy</code>, <code>.npz</code> (import/export in any direction).</li> <li><code>npz_key</code> selects a named array inside an archive; defaults to the first key.</li> <li>Exports honor the same materialization guard: spill/file-backed sources require <code>allow_huge=True</code>.</li> </ul> <p>Example:</p> <pre><code># Snapshot -&gt; npy -&gt; snapshot round-trip\npc.convert_file(\"A.pycauset\", \"A.npy\")\npc.convert_file(\"A.npy\", \"A_roundtrip.pycauset\")\n\n# Pick a specific array inside an npz\npc.convert_file(\"bundle.npz\", \"vec.pycauset\", npz_key=\"vector0\")\n</code></pre>"},{"location":"guides/Numpy%20Integration/#mixed-arithmetic","title":"Mixed Arithmetic","text":"<p>You can perform arithmetic operations directly between <code>pycauset</code> objects and NumPy arrays. <code>pycauset</code> handles the interoperability automatically.</p> <p>Important note: when you mix a <code>pycauset</code> object with a NumPy array, the NumPy side is typically converted to a temporary <code>pycauset</code> object and the operation is executed through PyCauset's dtype rules (promotion, underpromotion, overflow). See <code>documentation/internals/DType System.md</code>.</p>"},{"location":"guides/Numpy%20Integration/#vector-numpy-array","title":"Vector + NumPy Array","text":"<pre><code>v = pc.vector([1, 2, 3])\narr = np.array([10, 20, 30])\n\n# Result is a pycauset Vector (operation happens in C++ backend)\nresult = v + arr  # [11, 22, 33]\n</code></pre>"},{"location":"guides/Numpy%20Integration/#matrix-numpy-vector","title":"Matrix @ NumPy Vector","text":"<p>You can use NumPy arrays as operands in matrix multiplication.</p> <pre><code>M = pc.matrix(((1, 0), (0, 1))) # Identity\nv_np = np.array([5.0, 6.0])\n\n# Result is a pycauset Vector\nv_result = M @ v_np  # [5.0, 6.0]\n</code></pre>"},{"location":"guides/Numpy%20Integration/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>PyCauset as Primary: When you perform operations like <code>pycauset_obj + numpy_obj</code>, <code>pycauset</code> attempts to handle the operation. The NumPy array is temporarily converted to a <code>pycauset</code> object (backed by RAM or a temporary file), and the operation runs using the optimized C++ backend. The result is a new <code>pycauset</code> object.</li> <li>NumPy as Primary: If you use a NumPy function like <code>np.add(pycauset_obj, numpy_obj)</code>, NumPy will convert the <code>pycauset</code> object to an in-memory array first. This might be slower and memory-intensive for large datasets.</li> </ul> <p>Best Practice: For massive datasets, stick to <code>pycauset</code> native operations and objects as much as possible, only converting to NumPy for small results or specific analysis steps that <code>pycauset</code> doesn't yet support.</p>"},{"location":"guides/Numpy%20Integration/#see-also","title":"See also","text":"<ul> <li>pycauset.convert_file</li> <li>pycauset.to_numpy</li> <li>pycauset.set_export_max_bytes</li> <li>pycauset.save / pycauset.load</li> <li>Storage and Memory</li> </ul>"},{"location":"guides/NxM%20Support/","title":"NxM Support Status","text":"<p>PyCauset is actively removing square-only assumptions.</p> <p>This page is the discoverable status list of which operations are currently:</p> <ul> <li>NxM-enabled (rectangular inputs supported), vs</li> <li>restricted / square-only (by mathematical necessity or current implementation scope).</li> </ul>"},{"location":"guides/NxM%20Support/#shapes-semantics","title":"Shapes &amp; semantics","text":"<ul> <li>Matrices are 2D and have <code>shape == (rows, cols)</code>.</li> <li>Vectors are 1D and have <code>shape == (n,)</code>.</li> <li>Many objects support transpose as a metadata view (<code>.T</code>), which can change the logical shape without copying underlying storage.</li> </ul>"},{"location":"guides/NxM%20Support/#nxm-enabled","title":"NxM-enabled","text":""},{"location":"guides/NxM%20Support/#allocation","title":"Allocation","text":"<ul> <li><code>pycauset.zeros((rows, cols), dtype=...)</code></li> <li><code>pycauset.ones((rows, cols), dtype=...)</code></li> <li><code>pycauset.empty((rows, cols), dtype=...)</code></li> </ul>"},{"location":"guides/NxM%20Support/#dense-matrices","title":"Dense matrices","text":"<p>Rectangular dense matrices are supported for:</p> <ul> <li>float16/float32/float64</li> <li>int8/int16/int32/int64</li> <li>uint8/uint16/uint32/uint64</li> <li>complex_float16/complex_float32/complex_float64</li> <li>bool/bit (<code>DenseBitMatrix</code>, bit-packed)</li> </ul>"},{"location":"guides/NxM%20Support/#identity-like-matrices","title":"Identity-like matrices","text":"<ul> <li><code>pycauset.identity(n)</code> creates an \\(n \\times n\\) identity matrix.</li> <li><code>pycauset.identity([rows, cols])</code> creates a <code>rows \u00d7 cols</code> identity-like matrix (ones on the diagonal up to \\(\\min(rows, cols)\\)).</li> <li><code>pycauset.I(...)</code> / <code>pycauset.IdentityMatrix(...)</code> also support rectangular shapes.</li> </ul>"},{"location":"guides/NxM%20Support/#numpy-interop","title":"NumPy interop","text":"<ul> <li><code>pycauset.matrix(np_array)</code> supports rectangular 2D arrays for dense matrices.</li> <li><code>pycauset.vector(np_array)</code> supports 1D arrays for vectors.</li> <li><code>np.asarray(pycauset_matrix)</code> / <code>np.array(pycauset_matrix)</code> returns arrays with matching shape.</li> </ul>"},{"location":"guides/NxM%20Support/#persistence","title":"Persistence","text":"<ul> <li><code>pycauset.save(obj, path)</code> and <code>pycauset.load(path)</code> preserve <code>(rows, cols)</code> and transpose metadata.</li> </ul>"},{"location":"guides/NxM%20Support/#operations","title":"Operations","text":"<ul> <li>Matrix-matrix matmul follows the standard rule:</li> </ul> <p>$$ (m, k) @ (k, n) \\to (m, n) $$</p> <ul> <li>Elementwise ops (<code>+</code>, <code>-</code>, <code>*</code> elementwise) require exact shape match.</li> </ul>"},{"location":"guides/NxM%20Support/#restricted-square-only","title":"Restricted / square-only","text":"<p>These operations require square inputs by definition:</p> <ul> <li>Determinant</li> <li>Inverse</li> <li>Many eigen/spectral routines</li> </ul> <p>These structures are square-only by definition:</p> <ul> <li>Triangular matrices (including causal matrices)</li> <li>Diagonal matrices</li> <li>Symmetric / antisymmetric matrices</li> </ul>"},{"location":"guides/NxM%20Support/#notes","title":"Notes","text":"<p>If you hit a shape-related exception:</p> <ul> <li>Verify you\u2019re using <code>rows()/cols()</code> (or <code>shape</code>) rather than relying on legacy \u201cN\u201d.</li> <li>For matmul, verify inner dimensions match.</li> </ul> <p>If the status here disagrees with observed behavior, treat it as a bug and update this page along with a regression test.</p>"},{"location":"guides/Performance%20Guide/","title":"Performance and Acceleration Guide","text":"<p>PyCauset is designed to automatically optimize performance based on your hardware using a unified Compute Context. This guide explains how the GPU acceleration works, how precision (Float32 vs Float64) is handled, and how to achieve maximum throughput.</p>"},{"location":"guides/Performance%20Guide/#1-gpu-acceleration","title":"1. GPU Acceleration","text":"<p>PyCauset includes a high-performance GPU backend powered by NVIDIA CUDA. This backend is managed by the ComputeContext and is designed to be frictionless: it requires no configuration, automatically detects compatible hardware, and seamlessly falls back to the CPU if no GPU is available.</p>"},{"location":"guides/Performance%20Guide/#features","title":"Features","text":"<ul> <li>Automatic Detection: The ComputeContext checks for a CUDA-capable GPU at startup.</li> <li>Dynamic Loading: The GPU backend is a separate plugin (<code>pycauset_cuda.dll</code> / <code>.so</code>). You do not need CUDA installed to run PyCauset on a CPU-only machine.</li> <li>Out-of-Core Processing: Algorithms are designed to handle matrices larger than your GPU's VRAM by streaming data efficiently between Disk, RAM, and VRAM.</li> </ul>"},{"location":"guides/Performance%20Guide/#requirements","title":"Requirements","text":"<p>To use the GPU acceleration, you need:</p> <ol> <li>Hardware: An NVIDIA GPU with Compute Capability 6.0 or higher (Pascal or newer).</li> <li>Drivers: Up-to-date NVIDIA Drivers.</li> <li>Software: The <code>pycauset_cuda</code> plugin must be present in the library directory (installed automatically if built with CUDA support).</li> </ol>"},{"location":"guides/Performance%20Guide/#supported-operations","title":"Supported Operations","text":"<p>The following operations are currently accelerated via the AutoSolver: *   Matrix Multiplication (<code>matmul</code>, <code>*</code> operator):     *   Uses <code>cuBLAS</code> for high-performance GEMM (Float32/Float64).     *   BitMatrices: <code>DenseBitMatrix</code> and <code>TriangularBitMatrix</code> multiplication is fully accelerated using custom bit-packed kernels. This allows for extremely fast path counting and transitive closure operations (up to 64x faster than float operations). *   Matrix Inversion (<code>inverse</code>):     *   Uses <code>cuSOLVER</code> LU factorization.</p>"},{"location":"guides/Performance%20Guide/#2-precision-and-types","title":"2. Precision and Types","text":"<p>PyCauset respects the user's choice of type but employs smart defaults to maximize performance on consumer hardware.</p>"},{"location":"guides/Performance%20Guide/#automatic-hardware-detection","title":"Automatic Hardware Detection","text":"<p>When PyCauset initializes, the ComputeContext queries your system:</p> <ul> <li>CPU: Detects AVX2/AVX-512 support for vectorized operations.</li> <li>GPU: Checks for CUDA-capable devices.<ul> <li>Consumer GPUs (GeForce GTX/RTX): Typically default to Float32 due to hardware constraints (poor Float64 performance).</li> <li>Data Center GPUs (Tesla/A100): May default to Float64 if supported.</li> </ul> </li> </ul>"},{"location":"guides/Performance%20Guide/#default-behavior","title":"Default Behavior","text":"<p>When you convert a NumPy array to a PyCauset matrix using <code>pycauset.matrix()</code>:</p> <ol> <li>Float32 Input: Always creates a <code>Float32Matrix</code>.</li> <li>Float64 Input (Standard NumPy):<ul> <li>If your hardware prefers Float32 (e.g., GTX 1060), PyCauset will automatically downcast to <code>Float32Matrix</code> for a 15-30x speedup.</li> <li>If your hardware supports fast Float64, it creates a <code>Float64Matrix</code>.</li> </ul> </li> </ol>"},{"location":"guides/Performance%20Guide/#benchmarks-example-gtx-1060","title":"Benchmarks (Example: GTX 1060)","text":"<ul> <li>Float64: ~135 GFLOPS</li> <li>Float32: ~4400 GFLOPS (32x faster)</li> </ul> <p>PyCauset ensures you get this speedup by default.</p>"},{"location":"guides/Performance%20Guide/#3-where-pycauset-is-faster-than-numpy","title":"3. Where PyCauset is Faster than NumPy","text":"<p>PyCauset isn\u2019t faster at everything, but it is decidably faster in specific large-scale regimes.</p>"},{"location":"guides/Performance%20Guide/#1-out-of-core-processing-infinite-speedup","title":"1. Out-of-Core Processing (Infinite Speedup)","text":"<p>Standard NumPy crashes with <code>MemoryError</code> if a matrix exceeds RAM. *   PyCauset: Transparently tiles operations on disk-backed matrices (up to Terabytes). *   Result: Infinite speedup (vs crash).</p>"},{"location":"guides/Performance%20Guide/#2-high-bandwidth-io-up-to-10x-faster","title":"2. High-Bandwidth I/O (up to 10x faster)","text":"<p>PyCauset uses a multithreaded \"Direct Path\" for loading/saving data and importing/exporting from NumPy, bypassing python loop overhead. *   Contiguous Write: ~10.0x faster than standard <code>np.tofile</code> or pickle for large buffers (&gt;1GB). *   Import: ~2.7x faster for importing non-contiguous (sliced) NumPy arrays.</p>"},{"location":"guides/Performance%20Guide/#3-bit-packed-boolean-math-up-to-64x-faster","title":"3. Bit-Packed Boolean Math (up to 64x faster)","text":"<p>NumPy stores booleans as 8-bit bytes (<code>bool_</code>). PyCauset stores them as 1-bit packs (<code>DenseBitMatrix</code>). *   Storage: 8x smaller RAM footprint. *   Matmul: 64x faster (using specialized bit-block kernels).</p>"},{"location":"guides/Performance%20Guide/#4-mixed-precision-gpu-offloading","title":"4. Mixed-Precision GPU Offloading","text":"<p>NumPy is CPU-only. PyCauset seamlessly offloads large <code>matmul</code> or <code>inverse</code> ops to CUDA without the user managing device memory. *   Latency: Lower for small ops (don't use GPU for 10x10 matrices). *   Throughput: Orders of magnitude higher for large matrices (e.g., 4000x4000).</p>"},{"location":"guides/Performance%20Guide/#4-memory-management-strategy","title":"4. Memory Management Strategy","text":"<p>PyCauset uses a \"RAM-First\" architecture to maximize speed.</p> <ol> <li>Use All Available RAM: The system aggressively utilizes available physical RAM to keep matrices in memory for maximum throughput.</li> <li>Automatic Disk Spillover: When physical RAM is exhausted, the system can spill by switching to file-backed (memory-mapped) storage (for example <code>.tmp</code> backing files under the backing directory).</li> <li>Hybrid Async Pipeline:<ul> <li>Small Matrices: If a matrix fits entirely in VRAM, it is uploaded once and processed at maximum speed.</li> <li>Large Matrices: If a matrix exceeds VRAM (or the configured memory_limit), the system automatically switches to Streaming Mode.<ul> <li>CPU Parallelism: The CPU uses multi-threading to pack data into pinned memory buffers.</li> <li>GPU Overlap: The GPU computes the current chunk while the CPU prepares the next one.</li> </ul> </li> </ul> </li> </ol>"},{"location":"guides/Performance%20Guide/#4-configuration","title":"4. Configuration","text":"<p>While PyCauset works out-of-the-box, power users can fine-tune the behavior through the ComputeContext (exposed via <code>pycauset.cuda</code> for backward compatibility):</p> <pre><code>import pycauset.cuda\n\n# Enable with specific settings\npycauset.cuda.enable(\n    device_id=0,              # Select specific GPU\n    memory_limit=4*1024**3,   # Limit VRAM usage to 4GB\n    enable_async=True         # Enable/Disable Async Pipelining\n)\n</code></pre>"},{"location":"guides/Performance%20Guide/#5-troubleshooting","title":"5. Troubleshooting","text":"<p>If you believe you have a GPU but PyCauset is using the CPU:</p> <ol> <li>Check if <code>pycauset.cuda.is_available()</code> returns <code>True</code>.</li> <li>Ensure <code>pycauset_cuda.dll</code> (Windows) or <code>libpycauset_cuda.so</code> (Linux) exists in the installation folder.</li> <li>Verify your NVIDIA drivers are installed and working (run <code>nvidia-smi</code>).</li> </ol>"},{"location":"guides/Performance%20Guide/#6-lazy-evaluation","title":"6. Lazy Evaluation","text":"<p>PyCauset employs Lazy Evaluation to optimize complex mathematical expressions. When you perform operations like <code>C = A + B</code>, the result is not computed immediately. Instead, a lightweight \"Expression\" object is created.</p>"},{"location":"guides/Performance%20Guide/#how-it-works","title":"How it Works","text":"<ul> <li>Fusion: Operations are fused together. <code>D = A + B + C</code> is computed in a single pass, avoiding the creation of a temporary matrix for <code>A + B</code>. This reduces memory bandwidth usage by 50% or more.</li> <li>Just-In-Time: Computation happens only when you access the data (e.g., <code>print(C[0,0])</code>) or explicitly request it (e.g., <code>C.eval()</code>).</li> <li>Memory Efficiency: Since intermediate results are not materialized, you can perform complex chains of operations on matrices that would otherwise exceed your RAM if all intermediates were stored.</li> </ul>"},{"location":"guides/Performance%20Guide/#manual-control","title":"Manual Control","text":"<p>While the system handles this automatically, you can force evaluation or manage memory manually:</p> <ul> <li><code>.eval()</code>: Forces a lazy expression to compute and return a materialized matrix.     <pre><code>expr = A + B\nresult = expr.eval() # 'result' is a real Matrix\n</code></pre></li> <li><code>spill_to_disk()</code>: If you have a large materialized matrix in RAM and need to free up space for other computations without deleting the data, you can force it to move to disk.     <pre><code>A = pycauset.FloatMatrix(10000, 10000)\n# ... fill A ...\nA.spill_to_disk() # Moves A's data to a temp file, freeing RAM\n</code></pre></li> </ul>"},{"location":"guides/Spacetime/","title":"Spacetime Manifolds","text":"<p><code>pycauset</code> provides a library of standard spacetime manifolds that can be used as the domain for sprinkling causal sets. These are available in the pycauset.spacetime module.</p>"},{"location":"guides/Spacetime/#available-spacetimes","title":"Available Spacetimes","text":""},{"location":"guides/Spacetime/#minkowskidiamond","title":"MinkowskiDiamond","text":"<p>The pycauset.spacetime.MinkowskiDiamond represents a causal diamond in flat Minkowski space. This is the intersection of the future lightcone of a point \\(p\\) and the past lightcone of a point \\(q\\).</p> <p>Coordinates: *   2D (1+1): Uses Lightcone Coordinates \\((u, v)\\) where \\(u, v \\in [0, 1]\\).     *   Metric: \\(ds^2 = -du dv\\) (up to a factor of 2 depending on convention).     *   Causality: \\(p \\prec q \\iff u_p &lt; u_q \\text{ AND } v_p &lt; v_q\\).     *   Volume: Normalized to \\(1.0\\) in these coordinates.</p> <pre><code>from pycauset import spacetime\n\n# Create a 2D Minkowski Diamond\ndiamond = spacetime.MinkowskiDiamond(dimension=2)\n</code></pre>"},{"location":"guides/Spacetime/#minkowskicylinder","title":"MinkowskiCylinder","text":"<p>The pycauset.spacetime.MinkowskiCylinder represents a flat Minkowski spacetime with periodic boundary conditions in the spatial dimension. This topology is \\(S^1 \\times \\mathbb{R}\\) (circle \\(\\times\\) time).</p> <p>Coordinates: *   2D (1+1): Uses Standard Coordinates \\((t, x)\\).     *   \\(t \\in [0, \\text{height}]\\)     *   \\(x \\in [0, \\text{circumference})\\)     *   Causality: \\(t_2 &gt; t_1\\) AND \\((t_2 - t_1) &gt; \\text{shortest\\_dist}(x_1, x_2)\\) on the circle.     *   Volume: \\(\\text{height} \\times \\text{circumference}\\).</p> <pre><code>from pycauset import spacetime\n\n# Create a cylinder with height 2.0 and circumference 3.0\ncylinder = spacetime.MinkowskiCylinder(dimension=2, height=2.0, circumference=3.0)\n</code></pre>"},{"location":"guides/Spacetime/#minkowskibox","title":"MinkowskiBox","text":"<p>The pycauset.spacetime.MinkowskiBox represents a rectangular block in flat Minkowski space with \"hard wall\" boundaries. This is useful for studying boundary effects where the boundaries are not null surfaces (unlike the Diamond).</p> <p>Coordinates: *   2D (1+1): Uses Standard Coordinates \\((t, x)\\).     *   \\(t \\in [0, \\text{time\\_extent}]\\)     *   \\(x \\in [0, \\text{space\\_extent}]\\)     *   Causality: Standard Minkowski causality \\(\\Delta t &gt; |\\Delta x|\\).     *   Volume: \\(\\text{time\\_extent} \\times \\text{space\\_extent}\\).</p> <pre><code>from pycauset import spacetime\n\n# Create a box with T=2.0 and L=1.0\nbox = spacetime.MinkowskiBox(dimension=2, time_extent=2.0, space_extent=1.0)\n</code></pre>"},{"location":"guides/Spacetime/#visualization-support","title":"Visualization Support","text":"<p>All standard spacetimes support the visualization interface used by pycauset.vis. They implement:</p> <ul> <li><code>transform_coordinates(coords)</code>: Converts internal coordinates (like lightcone \\(u,v\\)) to visualization-friendly coordinates (like Cartesian \\(t,x\\) or 3D Cylindrical).</li> <li><code>get_boundary()</code>: Returns the geometry of the spacetime boundary for plotting.</li> </ul> <p>See the Visualization Guide for more details.</p>"},{"location":"guides/Spacetime/#using-spacetimes-with-causalset","title":"Using Spacetimes with CausalSet","text":"<p>You can pass these spacetime objects to the pycauset.CausalSet constructor.</p>"},{"location":"guides/Spacetime/#fixed-number-sprinkling","title":"Fixed Number Sprinkling","text":"<p>Sprinkle exactly \\(N\\) points into the spacetime.</p> <pre><code>import pycauset\nfrom pycauset import spacetime\n\nst = spacetime.MinkowskiCylinder(2, height=10, circumference=5)\nc = pycauset.causet(n=1000, spacetime=st)\n</code></pre>"},{"location":"guides/Spacetime/#poisson-sprinkling-density","title":"Poisson Sprinkling (Density)","text":"<p>Instead of specifying \\(N\\), you can specify a sprinkling <code>density</code> \\(\\rho\\). The number of points \\(N\\) will be drawn from a Poisson distribution: $$ N \\sim \\text{Poisson}(\\rho \\times V) $$ where \\(V\\) is the volume of the spacetime region.</p> <pre><code># Sprinkle with density 100 points per unit volume\n# Total volume = 50, so expected N = 5000\nc = pycauset.causet(density=100, spacetime=st)\n</code></pre>"},{"location":"guides/Storage%20and%20Memory/","title":"Storage and Memory","text":"<p>PyCauset lets you work with matrices that don\u2019t fit in RAM by storing their data on disk and letting the operating system load pieces as you touch them.</p> <p>If you\u2019re comfortable with NumPy, this will feel familiar: you use normal indexing (<code>M[i, j]</code>), shapes, and transpose views (<code>M.T</code>). Nothing \u201cauto-saves\u201d behind your back \u2014 saving is explicit.</p> <p>Most of the time you don\u2019t need to think about file layouts or memory maps. You just create matrices, use normal indexing (<code>M[i, j]</code>), and call <code>save()</code> / <code>load()</code>.</p> <p>In examples below, assume <code>import pycauset as pc</code> unless shown.</p>"},{"location":"guides/Storage%20and%20Memory/#quickstart-save-and-load","title":"Quickstart: save and load","text":""},{"location":"guides/Storage%20and%20Memory/#create-save-load","title":"Create \u2192 save \u2192 load","text":"<pre><code>import pycauset as pc\n\nM = pc.zeros((5000, 5000), dtype=pc.int32)\nM[0, 0] = 42\n\npc.save(M, \"my_matrix.pycauset\")\nN = pc.load(\"my_matrix.pycauset\")\n\nassert N[0, 0] == 42\n</code></pre>"},{"location":"guides/Storage%20and%20Memory/#a-simple-mental-model-data-bytes-info-bytes","title":"A simple mental model: \u201cdata bytes\u201d + \u201cinfo bytes\u201d","text":"<p>Most PyCauset objects have the same basic structure on disk, and the stored file can be broken into two sections:</p> <ul> <li>Payload (data bytes): the matrix/vector entries themselves.</li> <li>Metadata (info bytes): small structured information that explains what the payload means (shape, dtype, layout) and how to interpret it (transpose, scalar, conjugation), plus optional properties and caches.</li> </ul> <p>The important consequence is that PyCauset can scale because it does not require the payload to be in RAM all at once. The operating system will automatically keep recently-used parts in memory.</p>"},{"location":"guides/Storage%20and%20Memory/#a-concrete-example","title":"A concrete example","text":"<p>Suppose you create and save a matrix:</p> <pre><code>M = pc.zeros((2, 3), dtype=\"float32\")\nM[0, 1] = 20\npc.save(M, \"M.pycauset\")\n</code></pre> <p>Conceptually, the saved file contains:</p> <ul> <li>Payload (data bytes): the raw 2\u00d73 float32 numbers stored as bits.</li> <li>Metadata (info bytes): small information like:</li> <li>shape: 2 rows, 3 cols</li> <li>dtype: float32</li> <li>view-state: \u201cnot transposed\u201d, \u201cscalar = 1.0\u201d, etc.</li> <li>optional: user properties and cached results</li> </ul> <p>You can think of metadata like the \u201clabel on the box\u201d and payload like \u201cwhat\u2019s inside the box\u201d.</p>"},{"location":"guides/Storage%20and%20Memory/#why-this-matters","title":"Why this matters","text":"<p>This specific format enables two user-facing behaviors:</p> <p>1) Gigantic matrices actually work: the payload lives on disk and is paged in as needed. 2) Some operations are instant: things like transpose or scaling can be represented by changing metadata (no rewrite of the large payload).</p>"},{"location":"guides/Storage%20and%20Memory/#semantic-properties-metadata","title":"Semantic Properties (Metadata)","text":"<p>In addition to physical metadata (shape/dtype), Release 1 allows attaching Semantic Properties. These are asserted facts about the matrix that are \"gospel\" (authoritative) and can drastically speed up computations.</p>"},{"location":"guides/Storage%20and%20Memory/#what-properties-is","title":"What <code>properties</code> is","text":"<ul> <li><code>obj.properties</code> is a mapping (<code>str</code> keys \u2192 typed values) exposed on every matrix/vector.</li> <li>It stores gospel assertions (e.g., <code>is_upper_triangular=True</code>) which the system accepts without truth-validation.</li> <li>It also stores cached-derived values (e.g., <code>determinant</code>) which are invalidated on mutation.</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#common-keys-release-1","title":"Common keys (Release 1)","text":"<p>These keys are treated as semantic structure claims (no truth validation): - Structure: <code>is_symmetric</code>, <code>is_hermitian</code>, <code>is_upper_triangular</code>, <code>is_lower_triangular</code>, <code>is_diagonal</code> - Identity: <code>is_identity</code> (implies diagonal, symmetric, etc.) - Vector hints: <code>is_sorted</code>, <code>is_unit_norm</code></p> <p>Example: <pre><code>A = pc.identity(3)\n# Gospel assertion: solver is allowed to treat off-triangle entries as zero.\nA.properties[\"is_upper_triangular\"] = True\n</code></pre></p>"},{"location":"guides/Storage%20and%20Memory/#technical-implementation-python-managed","title":"Technical Implementation (Python-Managed)","text":"<p>Currently, the property system is implemented primarily in the Python layer: - The <code>properties</code> dictionary is injected into the native object at runtime (via <code>python/pycauset/_internal/properties.py</code>). - C++ kernels currently see physical metadata (shape/dtype) but not these semantic properties directly. - Future Integration: A mechanism to mirror these high-impact flags to C++ (e.g., via a bitmask) is planned so that backend drivers (like the GPU engine) can inspect them without crossing the Python boundary.</p>"},{"location":"guides/Storage%20and%20Memory/#where-backing-files-go-temporary-storage","title":"Where backing files go (temporary storage)","text":"<p>A backing file is the on-disk file that holds a matrix\u2019s payload bytes while you work.</p> <p>Why it\u2019s needed:</p> <ul> <li>It lets PyCauset memory-map the payload, so matrices can be larger than RAM.</li> <li>It gives the OS something concrete to page in/out (instead of forcing PyCauset to keep all bytes in Python-managed memory).</li> </ul> <p>When PyCauset needs to create these backing files automatically, it uses a storage root directory:</p> <ul> <li>Default: a <code>.pycauset/</code> directory under your current working directory.</li> <li>To change it: call <code>pc.set_backing_dir(...)</code> once after import (and ideally before allocating large matrices).</li> </ul> <p>Example:</p> <pre><code>import pycauset as pc\n# Call once, early in your program.\npc.set_backing_dir(r\"D:\\\\pycauset_tmp\")\n</code></pre> <p>PyCauset cleans up temporary backing files (extensions like <code>.tmp</code> / <code>.raw_tmp</code>) in two places:</p> <ul> <li>On import (startup): removes potential leftovers from previous runs.</li> <li>On interpreter exit: removes temporary files from the current run.</li> </ul> <p>Note: <code>pc.keep_temp_files = True</code> prevents the exit-time cleanup. Startup cleanup still runs so you don't accidentally reuse stale temp files.</p> <p>If you want to keep them around for debugging:</p> <pre><code>pc.keep_temp_files = True # Files will not be deleted on program exit\n</code></pre>"},{"location":"guides/Storage%20and%20Memory/#spill-switch-to-file-backed-mapping","title":"Spill (\u201cswitch to file-backed mapping\u201d)","text":"<p>When a matrix starts out in RAM, PyCauset may later spill it to disk to free RAM.</p> <p>In concrete terms, spill means that the live object switches from a RAM-only mapper to a file-backed (memory-mapped) mapper.</p> <p>Important details:</p> <ul> <li>Spilling writes the payload bytes only to a temporary <code>.tmp</code> backing file under the current backing dir.</li> <li>The live Python object keeps its metadata, properties, and any already-computed cached values in memory.</li> <li>Spilling does not create a <code>.pycauset</code> snapshot container. If you want the object to remain on your disk, you must explicitly call <code>save()</code>.</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#tmp-vs-raw_tmp-vs-pycauset","title":"<code>.tmp</code> vs <code>.raw_tmp</code> vs <code>.pycauset</code>","text":"<p>You may see these extensions in your backing directory:</p> <ul> <li><code>.tmp</code>: temporary backing files that hold payload bytes during a session (including spill/eviction and large auto-allocations).</li> <li><code>.raw_tmp</code>: a staging file used while writing a snapshot via <code>save()</code>. It is only renamed/committed to <code>.pycauset</code> when the write completes.</li> <li><code>.pycauset</code>: a snapshot container you created explicitly via <code>save()</code> (plus optional sibling cached objects like <code>X.pycauset.objects/...</code>).</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#numpy-conversion-safety-when-materialization-is-allowed","title":"NumPy conversion safety: when materialization is allowed","text":"<p>PyCauset protects you from accidental full materialization when converting to NumPy:</p> <ul> <li>Snapshot-backed objects (<code>.pycauset</code>): <code>np.asarray(obj)</code> is allowed and returns a copy.</li> <li>RAM-backed objects (<code>:memory:</code>): <code>np.asarray(obj)</code> is allowed and stays in-memory.</li> <li>Spill/file-backed objects (e.g., <code>.tmp</code>): <code>np.asarray(obj)</code> raises by default to avoid surprise RAM blow-ups. Opt in explicitly via <code>pc.to_numpy(obj, allow_huge=True)</code>.</li> <li>Ceiling control: <code>pc.set_export_max_bytes(bytes_or_None)</code> sets a materialization limit for NumPy exports; <code>None</code> disables the size ceiling (file-backed safety still applies unless you pass <code>allow_huge=True</code>).</li> </ul> <p>Takeaway: if something is spill-backed and large, you must opt-in to materialize; snapshots and in-RAM objects remain convertible without the opt-in.</p>"},{"location":"guides/Storage%20and%20Memory/#streaming-manager-routing-and-observability","title":"Streaming manager: routing and observability","text":"<p>PyCauset routes large or file-backed operations through a streaming manager so out-of-core work is predictable and observable.</p> <ul> <li>Threshold-based routing: set the IO streaming threshold via <code>pc.set_io_streaming_threshold(bytes_or_None)</code>. File-backed operands always stream; <code>allow_huge=True</code> on an op bypasses the threshold check.</li> <li>Per-op descriptors: <code>matmul</code>, <code>invert</code>, <code>eigvalsh</code>, <code>eigh</code>, and <code>eigvals_arnoldi</code> publish access patterns and tiling/queue hints. Non-square eig/invert inputs are forced to the direct route via a guard.</li> <li>Plan + events: the last plan is available through <code>pc.last_io_trace(...)</code> and includes <code>{route, reason, tile_shape, queue_depth, plan.access_pattern, events}</code>. Prefetch/discard events and <code>impl=...</code> markers show which path executed.</li> <li>Default behavior: when thresholds are tiny, tiles shrink automatically and queue depth stays bounded. When thresholds are disabled (<code>None</code>), routes stay direct unless operands are file-backed.</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#snapshots-vs-working-copies","title":"Snapshots vs working copies","text":"<p>The biggest user-facing rule is: a <code>.pycauset</code> file is treated as an immutable snapshot.</p> <p>A \"snapshot\" is a saved, read-only point-in-time artifact. Loading a snapshot gives you an object that reads from that file, but editing the object does not \u201cedit the file\u201d.</p> <p>This is intentionally NumPy-like: <code>np.load(...)</code> gives you an array in memory; mutating it doesn\u2019t rewrite the file on disk. PyCauset keeps the same principle, even though the payload may be disk-backed.</p> <ul> <li><code>pc.load(path)</code> gives you an object backed by that snapshot.</li> <li>Mutating the object does not implicitly overwrite the object saved at <code>path</code>.</li> <li>If you want a new persisted version, explicitly <code>pc.save(obj, new_path)</code>.</li> </ul> <p>Why this exists: it protects expensive \u201cbaseline\u201d snapshots (and their cached artifacts) from accidental overwrite during exploratory work.</p>"},{"location":"guides/Storage%20and%20Memory/#metadata-driven-views-fast-operations-without-rewriting-payload","title":"Metadata-driven \u201cviews\u201d (fast operations without rewriting payload)","text":"<p>A view is a matrix/vector object that shares the same payload bytes as another object, but carries different metadata that changes how those bytes are interpreted.</p> <p>Creating a view is often \\(O(1)\\) because PyCauset only needs to allocate a small wrapper + update metadata. The large payload file is not rewritten or copied. This is the same basic idea as NumPy\u2019s transpose: <code>M.T</code> is not a deep copy.</p>"},{"location":"guides/Storage%20and%20Memory/#what-counts-as-a-view","title":"What counts as a view?","text":"<p>These are typical metadata-only transforms:</p> <ul> <li>Transpose: toggles a transpose flag (e.g. <code>M.T</code> / <code>M.transpose()</code>).</li> <li>Conjugation: toggles a conjugation flag (e.g. <code>M.conj()</code>).</li> <li>Scalar scaling: stores a scalar multiplier in metadata (e.g. <code>3 * M</code>).</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#where-does-the-cost-go","title":"Where does the cost go?","text":"<p>The \u201cwork\u201d is deferred until you actually read/compute:</p> <ul> <li>On element access <code>V[i, j]</code>, PyCauset maps that request back to the base payload and applies the view-state.</li> </ul> <p>Concrete intuition:</p> <pre><code>M = pc.zeros((2, 3), dtype=\"float32\")\nV = M.T\n\n# Same payload; different interpretation:\n# V[i, j] reads the bytes for M[j, i].\nassert V[1, 0] == M[0, 1]\n</code></pre> <p>This is why the container format reserves a <code>view</code> namespace in metadata: view-state is part of the object\u2019s meaning, and it must survive <code>save()</code> / <code>load()</code>.</p>"},{"location":"guides/Storage%20and%20Memory/#properties-and-caches-what-gets-remembered-and-when-it-is-trusted","title":"Properties and caches: what gets remembered (and when it is trusted)","text":"<p>PyCauset separates two ideas that often get mixed up:</p>"},{"location":"guides/Storage%20and%20Memory/#1-gospel-properties-objproperties","title":"1) Gospel properties (<code>obj.properties</code>)","text":"<p><code>obj.properties</code> is a power-user escape hatch for semantic assertions that algorithms are allowed to trust.</p> <ul> <li>Example: if you set <code>obj.properties[\"is_upper_triangular\"] = True</code>, structure-aware algorithms may treat entries below the diagonal as zero.</li> <li>PyCauset does not scan payload data to validate these assertions.</li> <li>Booleans are tri-state via key presence: \u201cunknown\u201d = key absent, \u201cknown false\u201d = key present with <code>False</code>.</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#2-cached-derived-values-compute-once","title":"2) Cached-derived values (compute-once)","text":"<p>Cached-derived values are results PyCauset can recompute from payload + view-state (trace, determinant, norm, etc.).</p> <p>They are only used when they\u2019re known to match the current object state. Cache validity is checked in \\(O(1)\\) via a signature:</p> <ul> <li><code>payload_uuid</code>: identity of the persisted payload bytes.</li> <li><code>view_signature</code>: compact signature derived from view-state.</li> </ul> <p>On disk, cached-derived values live under <code>cached.*</code> (with their signature). At runtime they\u2019re surfaced via <code>obj.properties</code> for convenience.</p>"},{"location":"guides/Storage%20and%20Memory/#big-blob-caches-eg-persisted-inverse","title":"Big-blob caches (e.g., persisted inverse)","text":"<p>Some cached results are too large to store directly inside metadata. In that case, PyCauset stores them as separate sibling <code>.pycauset</code> objects and links to them from the base snapshot.</p> <p>Example:</p> <pre><code>pc.save(pc.FloatMatrix(2), \"A.pycauset\")\nA = pc.load(\"A.pycauset\")\n\n# Persist the inverse as a sibling cached object.\ninv = A.invert(save=True)\n</code></pre> <p>On disk, the cached object lives in a sibling directory:</p> <ul> <li>Base snapshot: <code>A.pycauset</code></li> <li>Object store: <code>A.pycauset.objects/&lt;object_id&gt;.pycauset</code></li> </ul> <p>Failure behavior:</p> <ul> <li>If a referenced cached object is missing or unreadable, PyCauset emits <code>PyCausetStorageWarning</code> and treats that cache entry as unusable.</li> <li>PyCauset does not implicitly recompute or \u201crepair\u201d missing big-blob cache objects. If you want that cached result again, you must request it explicitly (for example, <code>A.invert(save=True)</code> to rebuild a missing inverse cache).</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#multi-file-snapshots-blockmatrix-sidecars","title":"Multi-file snapshots: BlockMatrix sidecars","text":"<p>Most objects persist as a single <code>.pycauset</code> file. Block matrices are the main exception.</p> <p>When you save a block matrix, PyCauset writes:</p> <ul> <li>the container file, and</li> <li>a sibling sidecar directory <code>path + \".blocks\"</code> containing child block snapshots.</li> </ul> <p>The block manifest pins each child\u2019s <code>payload_uuid</code> so mixed-snapshot loads fail deterministically.</p> <p>Practical rule:</p> <ul> <li>To move/copy a saved block matrix, copy <code>X.pycauset</code> and <code>X.pycauset.blocks/</code>.</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#format-interoperability-what-we-support","title":"Format interoperability (what we support)","text":"<p>PyCauset ships one canonical snapshot format and a minimal NumPy bridge for pipelines:</p> <ul> <li><code>.pycauset</code>: canonical snapshot container (always supported).</li> <li><code>.npy</code> / <code>.npz</code>: import/export supported via <code>pc.convert_file</code>, <code>pc.load_npy</code>, <code>pc.load_npz</code>, <code>pc.save_npy</code>, <code>pc.save_npz</code>.</li> </ul> <p>Example (convert snapshot \u2192 npy \u2192 snapshot without materializing into Python first):</p> <pre><code>pc.convert_file(\"A.pycauset\", \"A.npy\")\npc.convert_file(\"A.npy\", \"A_roundtrip.pycauset\")\n</code></pre> <p>Routing rules and guardrails:</p> <ul> <li><code>.npy</code>/<code>.npz</code> exports honor the same materialization safety as <code>np.asarray</code>: file-backed objects require <code>allow_huge=True</code> to load into RAM; otherwise export raises.</li> <li><code>.npz</code> imports default to the first key; set <code>npz_key</code> to pick a named entry.</li> <li><code>pc.convert_file(src, dst, ...)</code> infers formats from suffixes and converts between <code>.pycauset</code> and <code>.npy</code>/<code>.npz</code> without you having to write load/save boilerplate.</li> </ul> <p>Formats we are considering (not implemented in R1): MatrixMarket <code>.mtx</code>, MATLAB <code>.mat</code>, Parquet/Arrow/CSV for tabular interop. These remain future work until documented otherwise.</p>"},{"location":"guides/Storage%20and%20Memory/#future-format-targets-not-implemented-yet","title":"Future format targets (not implemented yet)","text":"<ul> <li>MatrixMarket <code>.mtx</code>: common sparse/text interchange; useful for scientific benchmarks.</li> <li>MATLAB <code>.mat</code>: prevalent in engineering/scientific workflows.</li> <li>Parquet / Arrow / CSV: tabular interop for pandas-style pipelines; CSV primarily for debugging/sanity checks.</li> <li>HDF5/NetCDF (under evaluation): only if a stable, low-maintenance reader fits the maintenance budget.</li> </ul> <p>These are roadmap candidates; support will be added only when implemented and documented.</p>"},{"location":"guides/Storage%20and%20Memory/#file-format-and-debugging-advanced","title":"File format and debugging (advanced)","text":"<p>If you\u2019re writing tooling, debugging a corrupted file, or just curious about the exact on-disk layout, see:</p> <ul> <li>PyCauset Container Format (canonical <code>.pycauset</code> format spec)</li> <li>Storage Semantics (developer-facing semantics and runbooks)</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#copying-snapshots-correctly","title":"Copying snapshots correctly","text":"<ul> <li>For a plain matrix snapshot, copying the single <code>X.pycauset</code> file is sufficient.</li> <li>For block matrices, also copy <code>X.pycauset.blocks/</code>.</li> <li>For persisted big-blob caches (inverse, etc.), also copy <code>X.pycauset.objects/</code>.</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#memory-efficiency-why-causal-sets-fit","title":"Memory efficiency (why causal sets fit)","text":"<p>Storage format is only half the story: PyCauset also uses domain-specific representations (bit-packing, triangular storage) so the payload itself is smaller.</p> <p>See:</p> <ul> <li>Causal Sets</li> <li>Matrix Guide</li> <li>Performance Guide</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#numpy-interop-memory-risks","title":"NumPy Interop &amp; Memory Risks","text":"<p>While PyCauset matrices can be terabytes in size, standard NumPy arrays must fit largely in RAM.</p> <p>Interaction Warning: passing a huge file-backed matrix to <code>np.array(M)</code> or <code>pycauset.to_numpy(M)</code> attempts to load the entire payload into system RAM.</p> <p>To prevent accidental crashes: 1.  PyCauset blocks this by default for disk-backed objects. 2.  You must explicitly opt-in with <code>pycauset.to_numpy(M, allow_huge=True)</code>. 3.  Prefer processing data within PyCauset where possible, as it manages tiling and paging automatically.</p> <p>See Numpy Integration for details.</p>"},{"location":"guides/Storage%20and%20Memory/#see-also","title":"See also","text":"<ul> <li>pycauset.save</li> <li>pycauset.load</li> <li>pycauset.convert_file</li> <li>R1 Storage</li> <li>Storage Semantics</li> <li>MemoryArchitecture</li> <li>Memory and Data</li> <li>R1_STORAGE_PLAN</li> <li>R1_PROPERTIES_PLAN</li> <li>Documentation Protocol</li> </ul>"},{"location":"guides/Storage%20and%20Memory/#crash-consistency-r1_safety","title":"Crash Consistency (R1_SAFETY)","text":"<p>PyCauset employs several mechanisms to minimize data loss in the event of a power failure or crash:</p> <ol> <li>Atomic Metadata Updates: .pycauset files use double-buffered metadata slots. Updates are written to a new slot, flushed to disk, and then the \"Active Slot\" pointer is updated atomically.</li> <li>Explicit Flushes: Critical write operations (like save() or internal spills) call FlushFileBuffers (Windows) or msync (Linux) to ensure data reaches physical media.</li> <li>Header Protection: All backing files include a versioned header to prevent partial or corrupt files from being misinterpreted as valid data.</li> </ol>"},{"location":"guides/User%20Guide/","title":"PyCauset User Guide","text":""},{"location":"guides/User%20Guide/#overview","title":"Overview","text":"<p>PyCauset is a high-performance library for Causal Set Theory. It bridges the gap between abstract mathematical models and large-scale numerical simulations by using a hybrid storage model: small objects live in RAM, while massive datasets may automatically spill by switching to temporary memory-mapped backing files on disk.</p>"},{"location":"guides/User%20Guide/#getting-started","title":"Getting Started","text":""},{"location":"guides/User%20Guide/#1-installation","title":"1. Installation","text":"<p>Ensure you have PyCauset installed. See guides/Installation for details.</p> <pre><code>import pycauset as pc\n</code></pre>"},{"location":"guides/User%20Guide/#2-creating-a-causal-set","title":"2. Creating a Causal Set","text":"<p>The primary workflow involves defining a spacetime region and \"sprinkling\" points into it to generate a Causal Set.</p> <pre><code># 1. Define a Spacetime (e.g., 4D Minkowski Diamond)\n# The library handles the geometry and causal relations.\nspacetime = pc.spacetime.MinkowskiDiamond(dimension=4)\n\n# 2. Generate a Causal Set\n# Sprinkle 1000 points into the spacetime.\nc = pc.CausalSet(1000, spacetime=spacetime)\n\n# Access properties\nprint(f\"Size: {c.N}\")\nprint(f\"Dimension: {c.spacetime.dimension()}\")\n</code></pre>"},{"location":"guides/User%20Guide/#3-visualization","title":"3. Visualization","text":"<p>PyCauset provides interactive 3D visualizations powered by Plotly.</p> <p><pre><code>from pycauset.vis import plot_embedding\n\n# Generate an interactive 3D plot of the causal set\nfig = plot_embedding(c)\nfig.show()\n</code></pre> See the Visualization guide for more options.</p>"},{"location":"guides/User%20Guide/#5-lazy-evaluation","title":"5. Lazy Evaluation","text":"<p>PyCauset uses lazy evaluation for matrix operations to optimize performance and memory usage. Operations like <code>A + B</code> or <code>A * scalar</code> return lightweight expression objects that are evaluated only when assigned to a matrix or converted to NumPy.</p> <pre><code># Lazy addition (no computation yet)\nexpr = A + B\n\n# Evaluation happens here\nC = expr\n\n# Or here\nC_np = pc.to_numpy(expr)\n</code></pre>"},{"location":"guides/User%20Guide/#6-saving-and-loading","title":"6. Saving and Loading","text":"<p>You can save your entire causal set (including the causal matrix, coordinates, and metadata) to a portable, single-file <code>.pycauset</code> container.</p> <pre><code># Save to disk\nc.save(\"my_universe.pycauset\")\n\n# Load it back later\nc_loaded = pc.load(\"my_universe.pycauset\")\n</code></pre>"},{"location":"guides/User%20Guide/#physics-analysis","title":"Physics &amp; Analysis","text":""},{"location":"guides/User%20Guide/#field-theory","title":"Field Theory","text":"<p>You can define quantum fields on your causal set background.</p> <p><pre><code>from pycauset.field import ScalarField\n\n# Define a massive scalar field on a causal set \"c\"\nfield = ScalarField(c, mass=0.5)\n\n# Compute the Retarded Propagator (K)\n# This uses the highly optimized matrix engine under the hood.\nK = field.propagator()\n</code></pre> See the Field Theory guide for details.</p>"},{"location":"guides/User%20Guide/#advanced-usage","title":"Advanced Usage","text":""},{"location":"guides/User%20Guide/#the-matrix-engine","title":"The Matrix Engine","text":"<p>Under the hood, PyCauset uses a powerful matrix engine that handles data larger than RAM. While <code>CausalSet</code> abstracts this away, you can use the matrix classes directly for linear algebra.</p> <ul> <li>pycauset.matrix: Construct a matrix from data.</li> <li>pycauset.zeros / pycauset.empty: Allocate with an explicit <code>dtype</code>.</li> <li>pycauset.matmul: Matrix multiplication.</li> </ul> <p>For a deep dive into matrix operations, see the Matrix Guide.</p>"},{"location":"guides/User%20Guide/#vectors","title":"Vectors","text":"<p>PyCauset supports efficient, disk-backed vectors that interoperate with its matrices. See the Vector Guide.</p>"},{"location":"guides/User%20Guide/#numpy-integration","title":"NumPy Integration","text":"<p>PyCauset is designed to work seamlessly with the scientific Python ecosystem. *   Convert PyCauset objects to NumPy arrays: <code>np.array(matrix)</code> *   Create PyCauset objects from NumPy arrays: <code>pc.matrix(array)</code> or <code>pc.vector(array)</code></p> <p>See the Numpy Integration guide.</p>"},{"location":"guides/User%20Guide/#configuration","title":"Configuration","text":""},{"location":"guides/User%20Guide/#memory-management","title":"Memory Management","text":"<p>PyCauset automatically manages memory. Small objects stay in RAM; large ones go to disk. You can control the threshold:</p> <pre><code># Set threshold to 100 MB (default is 1 GB)\npc.set_memory_threshold(100 * 1024 * 1024)\n</code></pre>"},{"location":"guides/User%20Guide/#storage-location","title":"Storage Location","text":"<p>PyCauset may create temporary and/or backing files for disk-backed objects.</p> <p>By default, these files are stored in a <code>.pycauset</code> directory under your current working directory. To override this, call <code>pycauset.set_backing_dir(...)</code> once after import (and before allocating large matrices).</p> <p>Example (cross-platform):</p> <pre><code>from pathlib import Path\nimport pycauset as pc\npc.set_backing_dir(Path.cwd() / \"pycauset_storage\")\n</code></pre> <p>For details on what gets stored, when cleanup happens, and how persistence works, see Storage and Memory.</p> <p>Rule of thumb:</p> <ul> <li>Spill/working storage uses temporary session files (for example <code>.tmp</code> under the backing directory).</li> <li>Portable persistence is explicit: <code>save()</code> writes a <code>.pycauset</code> snapshot.</li> </ul> <p>Related knobs:</p> <ul> <li>pycauset.set_memory_threshold</li> <li>pycauset.keep_temp_files</li> </ul>"},{"location":"guides/User%20Guide/#see-also","title":"See also","text":"<ul> <li>API Reference</li> <li>Internals (especially DType System)</li> </ul>"},{"location":"guides/Vector%20Guide/","title":"Vector Guide","text":"<p><code>pycauset</code> introduces efficient vectors that integrate seamlessly with the matrix operations. Vectors are stored in RAM for small sizes (behaving like NumPy arrays) and may automatically spill by switching to temporary memory-mapped backing files (for example <code>.tmp</code>) for massive datasets.</p>"},{"location":"guides/Vector%20Guide/#creating-vectors","title":"Creating Vectors","text":"<p>You can create vectors from data using pycauset.vector. For allocation by size, use pycauset.zeros or pycauset.empty with an explicit <code>dtype</code>.</p> <p>You can also explicitly control storage using <code>dtype</code>.</p> <p>Supported dtype strings (recommended):</p> <ul> <li>Bit/boolean: <code>\"bit\"</code>, <code>\"bool\"</code>, <code>\"bool_\"</code></li> <li>Signed integers: <code>\"int8\"</code>, <code>\"int16\"</code>, <code>\"int32\"</code>, <code>\"int64\"</code></li> <li>Unsigned integers: <code>\"uint8\"</code>, <code>\"uint16\"</code>, <code>\"uint32\"</code>, <code>\"uint64\"</code></li> <li>Floats: <code>\"float16\"</code>, <code>\"float32\"</code>, <code>\"float64\"</code></li> <li>Complex floats: <code>\"complex_float16\"</code>, <code>\"complex_float32\"</code>, <code>\"complex_float64\"</code></li> </ul> <p>Notes:</p> <ul> <li><code>\"int\"</code> normalizes to <code>\"int32\"</code>; <code>\"float\"</code> normalizes to <code>\"float64\"</code>; <code>\"uint\"</code> normalizes to <code>\"uint32\"</code>.</li> <li>Complex is limited to complex floats.</li> <li>For large NumPy inputs, you can pass <code>max_in_ram_bytes</code> to <code>pc.vector(...)</code> to force the constructor down the internal <code>native.asarray</code> import path once the estimated payload exceeds the cap, avoiding accidental full-RAM materialization when you prefer a backing file.</li> </ul> <pre><code>import pycauset as pc\n\n# Allocate a float vector of size 1000 (initialized to 0.0)\nv1 = pc.zeros(1000, dtype=\"float64\")\n\n# Create an integer vector from a list\nv2 = pc.vector([1, 2, 3, 4, 5])\n\n# Explicit widths / unsigned\nv_u64 = pc.vector([1, 2, 3], dtype=\"uint64\")\n\n# Complex float vectors\nv_c = pc.vector([1+2j, 3-4j], dtype=\"complex_float32\")\n\n# Create a bit-packed boolean vector (1 bit per element)\nv3 = pc.vector([True, False, True, True])\n</code></pre>"},{"location":"guides/Vector%20Guide/#typed-numpy-constructors","title":"Typed NumPy Constructors","text":"<p>If you already have a <code>numpy.ndarray</code> and want an explicitly-typed PyCauset vector, most concrete vector classes support a direct NumPy constructor.</p> <pre><code>import numpy as np\nimport pycauset as pc\n\nv64 = pc.FloatVector(np.array([1.0, 2.0, 3.0], dtype=np.float64))\nv32 = pc.Float32Vector(np.array([1.0, 2.0, 3.0], dtype=np.float32))\nvi = pc.IntegerVector(np.array([1, 2, 3], dtype=np.int32))\n</code></pre> <p>Requirements:</p> <ul> <li>The array must be 1D.</li> <li>The dtype must match the target class (e.g. <code>Float32Vector</code> requires <code>np.float32</code>).</li> </ul>"},{"location":"guides/Vector%20Guide/#unit-vectors","title":"Unit Vectors","text":"<p>A <code>UnitVector</code> is a specialized vector type representing a standard basis vector (a vector with a single <code>1</code> at a specific index and <code>0</code> everywhere else). It is highly optimized for storage and arithmetic operations.</p> <pre><code>import pycauset as pc\n\n# Create a unit vector of size 1000 with the 1 at index 5\nu = pc.UnitVector(1000, 5)\n\nprint(u[5]) # 1.0\n</code></pre> <p>Benefits: *   O(1) Storage: Only stores the index and size. *   O(1) Arithmetic: Operations like dot products or addition with other unit vectors are computed instantly without iterating over the full size.</p>"},{"location":"guides/Vector%20Guide/#vector-arithmetic","title":"Vector Arithmetic","text":"<p>Vectors support standard arithmetic operations. These operations are performed element-wise and are optimized for large datasets.</p>"},{"location":"guides/Vector%20Guide/#optimized-operations","title":"Optimized Operations","text":"<p>Arithmetic involving <code>UnitVector</code> is special-cased for performance. *   <code>UnitVector</code> + <code>UnitVector</code>: Returns a sparse result if possible. *   <code>Vector</code> + <code>UnitVector</code>: Only updates the single active element. *   <code>Vector</code> . <code>UnitVector</code>: Returns the element at the active index (O(1)).</p>"},{"location":"guides/Vector%20Guide/#addition","title":"Addition","text":"<pre><code>v1 = pc.vector([1, 2, 3])\nv2 = pc.vector([4, 5, 6])\nv3 = v1 + v2  # [5, 7, 9]\n</code></pre>"},{"location":"guides/Vector%20Guide/#subtraction","title":"Subtraction","text":"<pre><code>v1 = pc.vector([1, 2, 3])\nv2 = pc.vector([4, 5, 6])\nv3 = v2 - v1  # [3, 3, 3]\n</code></pre>"},{"location":"guides/Vector%20Guide/#scalar-addition","title":"Scalar Addition","text":"<p>You can add a scalar to every element of a vector.</p> <pre><code>v = pc.vector([1, 2, 3])\nv_plus_5 = v + 5  # [6, 7, 8]\nv_plus_5_reverse = 5 + v  # [6, 7, 8]\n</code></pre>"},{"location":"guides/Vector%20Guide/#scalar-multiplication","title":"Scalar Multiplication","text":"<pre><code>v = pc.vector([1, 2, 3])\nv_scaled = v * 2.0  # [2.0, 4.0, 6.0]\n</code></pre>"},{"location":"guides/Vector%20Guide/#dot-product","title":"Dot Product","text":"<p>You can compute the dot product of two vectors using pycauset.dot or the <code>dot</code> method.</p> <pre><code>import pycauset as pc\n\nv1 = pc.vector([1, 2, 3])\nv2 = pc.vector([4, 5, 6])\n\nresult = pc.dot(v1, v2)  # 1*4 + 2*5 + 3*6 = 32.0\n# OR\nresult = v1.dot(v2)\n</code></pre>"},{"location":"guides/Vector%20Guide/#transposition-matrix-operations","title":"Transposition &amp; Matrix Operations","text":"<p><code>pycauset</code> supports vector transposition and various forms of multiplication using the <code>@</code> operator (matrix multiplication), mirroring <code>numpy</code> behavior.</p>"},{"location":"guides/Vector%20Guide/#transposition-t","title":"Transposition (<code>.T</code>)","text":"<p>You can transpose a vector using the <code>.T</code> property. *   Column Vector (Default): Shape <code>(N,)</code>. *   Row Vector (<code>v.T</code>): Shape <code>(1, N)</code>.</p> <pre><code>v = pc.vector([1, 2, 3])\nprint(v.shape)    # (3,)\n\nvt = v.T\nprint(vt.shape)   # (1, 3)\n\nv_orig = vt.T     # Back to column vector\nprint(v_orig.shape) # (3,)\n</code></pre> <p>Note: Transposing creates a new persistent object (a new file) with the <code>is_transposed</code> flag flipped. It does not modify the original vector.</p>"},{"location":"guides/Vector%20Guide/#inner-product-dot-product","title":"Inner Product (Dot Product)","text":"<p>The inner product produces a scalar.</p> <pre><code>v1 = pc.vector([1, 2, 3])\nv2 = pc.vector([4, 5, 6])\n\n# Row @ Column -&gt; Scalar\nscalar = v1.T @ v2  # 32.0\n\n# Column @ Column (Numpy behavior for 1D arrays)\nscalar = v1 @ v2    # 32.0\n</code></pre> <p>Type Safety: *   pycauset.IntegerVector @ pycauset.IntegerVector -&gt; <code>int</code> *   pycauset.BitVector @ pycauset.BitVector -&gt; <code>int</code> *   Any pycauset.FloatVector operand -&gt; <code>float</code></p>"},{"location":"guides/Vector%20Guide/#outer-product","title":"Outer Product","text":"<p>The outer product produces a matrix.</p> <pre><code>v1 = pc.vector([1, 2, 3]) # Column\nv2 = pc.vector([4, 5, 6]) # Column\n\n# Column @ Row -&gt; Matrix (N x N)\nM = v1 @ v2.T \n# M is:\n# [[ 4,  5,  6],\n#  [ 8, 10, 12],\n#  [12, 15, 18]]\n</code></pre> <p>Type Safety: *   pycauset.BitVector @ pycauset.BitVector.T -&gt; pycauset.DenseBitMatrix (Logical AND) *   pycauset.IntegerVector @ pycauset.IntegerVector.T -&gt; pycauset.IntegerMatrix *   Others -&gt; pycauset.FloatMatrix</p>"},{"location":"guides/Vector%20Guide/#matrix-vector-multiplication","title":"Matrix-Vector Multiplication","text":"<p>You can multiply matrices and vectors.</p> <pre><code>M = pc.zeros((3, 3), dtype=pc.float64)\nv = pc.vector([1, 1, 1])\n\n# Matrix @ Column Vector -&gt; Column Vector\nv_new = M @ v \n\n# Row Vector @ Matrix -&gt; Row Vector\nv_row = v.T @ M\n</code></pre>"},{"location":"guides/Vector%20Guide/#numpy-compatibility","title":"NumPy Compatibility","text":"<p>Vectors are fully compatible with NumPy.</p>"},{"location":"guides/Vector%20Guide/#to-numpy","title":"To NumPy","text":"<p>You can convert any vector to a NumPy array: <pre><code>import numpy as np\narr = np.array(v)\n</code></pre></p>"},{"location":"guides/Vector%20Guide/#from-numpy","title":"From NumPy","text":"<p>You can create vectors from NumPy arrays using pycauset.vector: <pre><code>arr = np.array([1.0, 2.0, 3.0])\nv = pc.vector(arr)\n</code></pre></p>"},{"location":"guides/Vector%20Guide/#mixed-operations","title":"Mixed Operations","text":"<p>You can add, subtract, or multiply vectors with NumPy arrays directly. The result remains a persistent <code>pycauset</code> vector.</p> <pre><code>v = pc.vector([1, 2, 3])\narr = np.array([10, 10, 10])\nv_new = v + arr # [11, 12, 13]\n</code></pre>"},{"location":"guides/Vector%20Guide/#persistence","title":"Persistence","text":"<p>Like matrices, vectors are backed by storage (RAM or disk). You can save them permanently using pycauset.save.</p> <pre><code>import pycauset as pc\n\nv = pc.vector([1, 2, 3])\npc.save(v, \"my_vector.pycauset\")\n\nv_loaded = pc.load(\"my_vector.pycauset\")\n</code></pre>"},{"location":"guides/Vector%20Guide/#mixed-types","title":"Mixed Types","text":"<p>Operations between different vector dtypes (e.g., integer + float) are supported. The result kind follows the fundamental-kind rule from <code>documentation/internals/DType System.md</code> (if a float participates, the result kind is float).</p> <pre><code>v_int = pc.vector([1, 2], dtype=pc.int32)\nv_float = pc.vector([0.5, 0.5], dtype=pc.float64)\n\nv_sum = v_int + v_float  # [1.5, 2.5] (FloatVector)\n</code></pre>"},{"location":"guides/Visualization/","title":"Visualization Guide","text":"<p>PyCauset provides built-in tools to visualize Causal Sets embedded in spacetime. This guide explains how to use the pycauset.vis module to create interactive 3D plots.</p>"},{"location":"guides/Visualization/#overview","title":"Overview","text":"<p>Visualizing high-dimensional causal structures is crucial for understanding their geometry and topology. PyCauset uses Plotly to generate interactive figures that allow you to rotate, zoom, and inspect the causal set.</p>"},{"location":"guides/Visualization/#basic-usage","title":"Basic Usage","text":"<p>The primary function for visualization is pycauset.vis.plot_embedding.</p> <pre><code>from pycauset import CausalSet\nfrom pycauset.vis import plot_embedding\n\n# 1. Generate a Causal Set\n# Use a seed for reproducibility!\nc = CausalSet(n=5000, density=100, seed=42)\n\n# 2. Create the plot\nfig = plot_embedding(c)\n\n# 3. Display it\nfig.show()\n</code></pre>"},{"location":"guides/Visualization/#reproducibility","title":"Reproducibility","text":"<p>To ensure your visualization is identical every time, you must ensure the pycauset.CausalSet itself is reproducible (using <code>seed</code> in <code>CausalSet()</code>). The visualization function uses a fixed internal seed for subsampling, so plotting the same <code>CausalSet</code> object will always yield the same plot.</p> <pre><code># 1. Reproducible Causal Set\nc = CausalSet(n=100_000, seed=12345)\n\n# 2. Plotting\n# This will always show the same subset of points\nfig = plot_embedding(c)\n</code></pre>"},{"location":"guides/Visualization/#handling-large-sets","title":"Handling Large Sets","text":"<p>Visualizing millions of points in a web browser is not feasible. PyCauset solves this by Smart Sampling.</p> <p>When you pass a large pycauset.CausalSet to <code>plot_embedding</code>, it automatically samples a subset of points (default 50,000) to display. This preserves the global structure while keeping the visualization responsive.</p> <pre><code># A very large set (1 million elements)\nc_huge = CausalSet(n=1_000_000)\n\n# This will plot a random sample of 50,000 points\nfig = plot_embedding(c_huge)\nfig.show()\n</code></pre> <p>You can control the sample size with the <code>sample_size</code> parameter:</p> <pre><code>fig = plot_embedding(c_huge, sample_size=10000)\n</code></pre>"},{"location":"guides/Visualization/#coordinate-regeneration","title":"Coordinate Regeneration","text":"<p>Under the hood, PyCauset does not store the coordinates of every element in memory. Instead, it uses the Sprinkler algorithm to regenerate coordinates on-demand using the original random seed.</p> <p>This means you can visualize a subset of a massive causal set without ever generating the full coordinate table, saving gigabytes of RAM.</p> <p>See <code>pycauset.CausalSet.coordinates</code> on pycauset.CausalSet for more details on the coordinate system.</p>"},{"location":"guides/Visualization/#customizing-the-plot","title":"Customizing the Plot","text":"<p>You can customize the plot title and marker size.</p> <pre><code>fig = plot_embedding(\n    c, \n    title=\"My Universe\", # Custom title\n    marker_size=3        # Larger points\n)\n</code></pre> <p>Since pycauset.vis.plot_embedding returns a Plotly figure, you can modify it how you would any Plotly figure.</p>"},{"location":"guides/Visualization/#coordinate-transformations-boundaries","title":"Coordinate Transformations &amp; Boundaries","text":"<p>The visualization module automatically handles coordinate transformations for specific spacetimes to make them easier to interpret:</p> <ul> <li>MinkowskiDiamond (2D): Lightcone coordinates \\((u, v)\\) are rotated to Cartesian coordinates \\((t, x)\\). The diamond boundary is drawn in white.</li> <li>MinkowskiCylinder (2D): Coordinates are mapped to a 3D cylinder visualization. The top and bottom rings of the cylinder are drawn in white.</li> <li>MinkowskiBox (2D): Coordinates are displayed as Cartesian \\((t, x)\\). The rectangular boundary is drawn in white.</li> </ul>"},{"location":"guides/Visualization/#hasse-diagrams","title":"Hasse Diagrams","text":"<p>pycauset.vis.plot_hasse generates a Hasse diagram, which visualizes the causal structure (partial order) directly.</p> <pre><code>from pycauset.vis import plot_hasse\n\nfig = plot_hasse(c, title=\"Hasse Diagram\")\nfig.show()\n</code></pre> <p>A Hasse diagram draws elements at their spacetime coordinates but draws lines (links) only between immediate causal neighbors. This reveals the \"skeleton\" of the causal structure.</p> <ul> <li>Note: Hasse diagrams are computationally expensive and visually cluttered for large sets. The function will raise an error if \\(N &gt; 500\\).</li> </ul>"},{"location":"guides/Visualization/#causal-matrix-heatmaps","title":"Causal Matrix Heatmaps","text":"<p><code>plot_causal_matrix</code> visualizes the Causal Matrix (Adjacency Matrix) \\(C\\) as a heatmap.</p> <pre><code>from pycauset.vis import plot_causal_matrix\n\nfig = plot_causal_matrix(c, title=\"Causal Matrix\")\nfig.show()\n</code></pre> <p>Since the causal matrix is strictly upper triangular (for a sorted causal set), the heatmap will show a triangular pattern. This is useful for inspecting the density and structure of causal relations.</p> <ul> <li>Note: For very large sets (\\(N &gt; 2000\\)), this plot may become slow to render.</li> </ul>"},{"location":"guides/Visualization/#dependencies","title":"Dependencies","text":"<p>Visualization requires the <code>plotly</code> library.</p> <pre><code>pip install plotly\n</code></pre> <p>If <code>plotly</code> is not installed, importing <code>pycauset.vis</code> will raise an <code>ImportError</code>.</p>"},{"location":"guides/performance/","title":"Performance Guide","text":"<p>PyCauset is designed for high-performance matrix operations, particularly for large-scale causal analysis. This guide highlights areas where PyCauset outperforms standard libraries like NumPy and explains the architectural decisions behind these performance gains.</p>"},{"location":"guides/performance/#numpy-interoperability","title":"NumPy Interoperability","text":"<p>PyCauset achieves 3x to 8x faster data transfer rates compared to standard NumPy file I/O for supported types.</p> Operation Speedup vs NumPy Notes Float64 / Int32 Read/Write 3x - 8x Uses zero-copy memory mapping and direct <code>memcpy</code> paths. Complex128 Read/Write 3.5x - 4x Optimized C++ loops bypass Python iteration overhead. BitMatrix (Boolean) Write 5.0x SIMD-accelerated packing (SSE2) converts booleans to bits instantly. BitMatrix (Boolean) Read 1.9x SIMD-accelerated unpacking."},{"location":"guides/performance/#why-is-it-faster","title":"Why is it faster?","text":"<ol> <li>Zero-Copy Primitives: For <code>float64</code> and <code>int32</code>, PyCauset exposes raw memory pointers directly to NumPy, allowing the OS to handle data transfer without CPU intervention.</li> <li>SIMD Acceleration: Boolean arrays are packed/unpacked using SSE2 intrinsics (<code>_mm_movemask_epi8</code>, <code>_mm_packus_epi16</code>), processing 16 elements per CPU cycle.</li> <li>Bypassing Python Overhead: All heavy lifting is done in C++, avoiding the overhead of Python's interpreter loops for element-wise access.</li> </ol>"},{"location":"guides/performance/#bitmatrix-operations","title":"BitMatrix Operations","text":"<p>PyCauset's <code>DenseBitMatrix</code> is a specialized container for boolean matrices that stores data as packed bits (1 bit per element), offering 8x memory savings compared to NumPy's <code>bool</code> (1 byte per element).</p> <p>Beyond storage, operations are significantly faster:</p> Operation Speedup vs NumPy Notes Bitwise XOR (<code>^</code>) ~5.0x Operates on 64 bits at once (machine word) instead of byte-by-byte. Bitwise AND (<code>&amp;</code>) ~5.0x (Estimated) Uses same optimized path. Bitwise OR (<code>|</code>) ~5.0x (Estimated) Uses same optimized path."},{"location":"guides/performance/#example","title":"Example","text":"<pre><code>import pycauset\nimport numpy as np\n\n# Create large boolean matrices\nN = 5000\na_np = np.random.randint(0, 2, (N, N)).astype(bool)\nb_np = np.random.randint(0, 2, (N, N)).astype(bool)\n\na_pc = pycauset.asarray(a_np)\nb_pc = pycauset.asarray(b_np)\n\n# PyCauset is ~5x faster\nc_pc = a_pc ^ b_pc \n</code></pre>"},{"location":"guides/performance/#memory-efficiency","title":"Memory Efficiency","text":"<p>For boolean matrices, PyCauset is strictly superior in memory usage:</p> <ul> <li>NumPy: 1 Byte per element.</li> <li>PyCauset: 1 Bit per element.</li> </ul> <p>A \\(10,000 \\times 10,000\\) boolean matrix takes: *   NumPy: ~100 MB *   PyCauset: ~12.5 MB</p> <p>This allows you to work with much larger datasets in RAM.</p>"},{"location":"guides/release1/","title":"Release 1 (R1): What Shipped","text":"<p>Release 1 is the first \u201cstable foundation\u201d slice of PyCauset: rectangular matrices, a real dtype system (including complex floats), a persistent on-disk container, and a semantic <code>properties</code> mechanism that can change algorithm choices.</p> <p>This section summarizes the implemented user- and contributor-facing behavior, not the planning documents.</p>"},{"location":"guides/release1/#in-this-section","title":"In this section","text":"<ul> <li>Shapes &amp; NxM matrices: R1 Shapes (NxM Matrices)</li> <li>Persistence &amp; snapshots: R1 Storage (Persistence Container)</li> <li>Semantic properties: R1 Properties (Semantic Metadata)</li> <li>DTypes, promotion, overflow: R1 DTypes (Integers, Float16, Complex)</li> <li>Linear algebra endpoints: R1 Linear Algebra (Core Ops)</li> </ul>"},{"location":"guides/release1/#see-also","title":"See also","text":"<ul> <li>NxM Support Status</li> <li>Storage and Memory</li> <li>API Reference</li> <li>Internals</li> <li>Dev Handbook</li> </ul>"},{"location":"guides/release1/#completed-plan-coverage-traceability","title":"Completed plan coverage (traceability)","text":"<p>This section is the \u201care we missing anything?\u201d crosswalk from the completed R1 plans to the front-end documentation.</p> <ul> <li>R1_SHAPES \u2192 R1 Shapes (and NxM Support Status)<ul> <li>Plan artifact: R1_SHAPES_PLAN</li> </ul> </li> <li>R1_STORAGE \u2192 R1 Storage (canonical: Storage and Memory)<ul> <li>Plan artifact: R1_STORAGE_PLAN</li> </ul> </li> <li>R1_PROPERTIES \u2192 R1 Properties (API footprint in MatrixBase / VectorBase)<ul> <li>Plan artifact: R1_PROPERTIES_PLAN</li> </ul> </li> <li>DTYPE_COMPLEX_OVERFLOW \u2192 R1 DTypes (canonical: DType System)<ul> <li>Plan artifact: DTYPE_COMPLEX_OVERFLOW_PLAN</li> </ul> </li> <li>R1_LINALG \u2192 R1 Linear Algebra<ul> <li>Plan artifact: R1_LINALG_PLAN</li> </ul> </li> <li>Restructure \u2192 Dev Handbook (starting at Restructure Plan)<ul> <li>Plan artifact: Restructure Plan (execution record)</li> </ul> </li> </ul>"},{"location":"guides/release1/dtypes/","title":"R1 DTypes (Integers, Float16, Complex)","text":"<p>Release 1 makes the dtype system explicit and enforceable: integer widths (signed + unsigned), float16 as a first-class dtype, and complex floats end-to-end on CPU.</p> <p>This guide summarizes the user-facing behavior: what dtypes exist, how promotion behaves, and what happens on overflow.</p>"},{"location":"guides/release1/dtypes/#supported-dtypes-release-1","title":"Supported dtypes (Release 1)","text":"<p>Across the core matrix/vector surface, the supported scalar set is:</p> <ul> <li><code>bool</code> / <code>bit</code> (bit-packed storage for dense boolean matrices)</li> <li><code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code></li> <li><code>uint8</code>, <code>uint16</code>, <code>uint32</code>, <code>uint64</code></li> <li><code>float16</code>, <code>float32</code>, <code>float64</code></li> <li><code>complex_float16</code>, <code>complex_float32</code>, <code>complex_float64</code></li> </ul> <p>Notes:</p> <ul> <li>Complex support is complex floats only. <code>complex int*</code> and <code>complex bit</code> are intentionally unsupported.</li> <li><code>complex_float16</code> is supported as a first-class dtype (internally implemented via a two-plane float16 storage model).</li> </ul> <p>See also: DType System (authoritative rules).</p>"},{"location":"guides/release1/dtypes/#dtype-selection-and-underpromotion","title":"Dtype selection and \u201cunderpromotion\u201d","text":"<p>PyCauset follows a \u201csmallest type\u201d ethos.</p> <p>Within floats, mixed precision underpromotes by default:</p> <ul> <li><code>float32</code> combined with <code>float64</code> uses <code>float32</code> compute + storage unless you explicitly request otherwise.</li> </ul> <p>This is a semantics choice (not an overflow workaround) and may emit a dtype-policy warning.</p>"},{"location":"guides/release1/dtypes/#overflow-behavior-integers","title":"Overflow behavior (integers)","text":"<p>Integer overflow is a hard error.</p> <ul> <li>PyCauset does not silently wrap.</li> <li>PyCauset does not silently widen output storage to avoid overflow.</li> </ul>"},{"location":"guides/release1/dtypes/#overflow-risk-warning-for-large-integer-matmul","title":"Overflow-risk warning for large integer matmul","text":"<p>For high-risk integer reductions like large <code>matmul</code>, PyCauset may emit a conservative warning when overflow looks plausible:</p> <ul> <li>category: <code>PyCausetOverflowRiskWarning</code></li> </ul> <p>This warning is advisory (it can over-warn), but it helps you catch \u201cobviously impossible in this dtype\u201d workloads earlier.</p>"},{"location":"guides/release1/dtypes/#reduction-aware-accumulator-widening","title":"Reduction-aware accumulator widening","text":"<p>For integer reductions (<code>dot</code>/<code>matmul</code>), PyCauset may use a wider internal accumulator dtype to keep overflow behavior defined in the hot loop.</p> <ul> <li>category: <code>PyCausetDTypeWarning</code></li> <li>important: output storage dtype does not automatically change; overflow still throws on the final cast to the requested output dtype.</li> </ul>"},{"location":"guides/release1/dtypes/#bit-matrices-are-special","title":"Bit matrices are special","text":"<p><code>bit</code> is extremely storage-efficient (1 bit/element), so widening a huge bit dataset can be infeasible.</p> <p>Each operation must explicitly define what it means on <code>bit</code>:</p> <ul> <li>bitwise behavior (stays bit-packed)</li> <li>numeric behavior (widens to <code>int</code>/<code>float</code>)</li> <li>error-by-design unless you explicitly request a widened dtype</li> </ul>"},{"location":"guides/release1/dtypes/#practical-example","title":"Practical example","text":"<pre><code>import numpy as np\nimport pycauset as pc\n\n# Unsigned integers\nA = pc.matrix(np.array(((1, 2), (3, 4)), dtype=np.uint32))\n\n# Complex float\nZ = pc.matrix(np.array(((1 + 2j, 0), (0, 3 - 4j)), dtype=np.complex64))\n\n# float16 allocation\nH = pc.ones((2, 2), dtype=\"float16\")\n</code></pre>"},{"location":"guides/release1/dtypes/#see-also","title":"See also","text":"<ul> <li>NumPy Integration</li> <li>DType System</li> <li>Warnings &amp; Exceptions</li> <li>pycauset.matmul</li> </ul>"},{"location":"guides/release1/linalg/","title":"R1 Linear Algebra (Core Ops)","text":"<p>Release 1 ships a \u201cfoundation\u201d linear algebra surface with stable Python endpoints and a single routing boundary (so future CPU/GPU/out-of-core optimizations can land behind the same entry points).</p> <p>This guide is about what you can call and what guarantees exist, not which backend is currently fastest.</p>"},{"location":"guides/release1/linalg/#minimal-example","title":"Minimal example","text":"<pre><code>import pycauset as pc\n\nA = pc.matrix(((4.0, 1.0), (2.0, 3.0)))\nb = pc.vector((1.0, 0.0))\n\nx = pc.solve(A, b)\n</code></pre>"},{"location":"guides/release1/linalg/#core-endpoints-in-release-1","title":"Core endpoints in Release 1","text":"<p>The Release 1 linalg surface includes these function families:</p> <ul> <li>Matmul / dot:</li> <li>pycauset.matmul</li> <li> <p>pycauset.dot</p> </li> <li> <p>Solves:</p> </li> <li>pycauset.solve</li> <li>pycauset.solve_triangular</li> <li> <p>pycauset.lstsq</p> </li> <li> <p>Factorizations:</p> </li> <li>pycauset.lu</li> <li> <p>pycauset.cholesky</p> </li> <li> <p>Spectral / SVD / conditioning:</p> </li> <li>pycauset.eig</li> <li>pycauset.eigh</li> <li>pycauset.eigvalsh</li> <li>pycauset.svd</li> <li>pycauset.pinv</li> <li>pycauset.cond</li> <li>pycauset.slogdet</li> </ul>"},{"location":"guides/release1/linalg/#block-matrices-release-1-behavior","title":"Block matrices (Release 1 behavior)","text":"<ul> <li>Construction: <code>pycauset.matrix(...)</code> builds a block matrix when given a 2D grid where every element is matrix-like; mixed scalars + matrices raise <code>TypeError</code>.</li> <li>Once block, always block: <code>@</code>, <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code> return block-matrix results with partition refinement (union of boundaries via <code>SubmatrixView</code> tiling). No silent densify; unsupported views error deterministically.</li> <li>Semi-lazy orchestration: outputs are thunked per block. Triggers: element access, dense conversion, persistence, and crossing the compute boundary. Non-triggers: shape/partition metadata, <code>repr/str</code>, <code>get_block</code>.</li> <li>Deterministic matmul: fixed <code>k</code> order and metadata-only dtype fold per output block; accumulation dtype is chosen before evaluation.</li> <li>Block-aware slicing: slices produce tiled <code>SubmatrixView</code> blocks without copying; errors if a required view cannot be represented.</li> <li>Device routing: leaf ops still run through AutoSolver; complex blocks route to CPU today on CUDA builds (see Compute Architecture). IO prefetch/discard hooks are best-effort and traced separately.</li> </ul>"},{"location":"guides/release1/linalg/#shape-constraints","title":"Shape constraints","text":"<ul> <li>Dense matmul follows NxM rules: <code>(m, k) @ (k, n) -&gt; (m, n)</code>.</li> <li>Many routines are square-only by definition (inverse/determinant and most eigen routines).</li> </ul> <p>Block matrices obey the same shape rules at the block grid level; partition refinement enforces compatible dimensions (<code>A.cols == B.rows</code> after refinement).</p> <p>See NxM Support Status and Square-only Assumptions.</p>"},{"location":"guides/release1/linalg/#property-aware-behavior-r1_properties","title":"Property-aware behavior (R1_PROPERTIES)","text":"<p>Some linalg endpoints consult <code>A.properties</code>:</p> <ul> <li><code>solve</code>:</li> <li>returns <code>b</code> when <code>is_identity=True</code> (square only)</li> <li>rejects <code>is_zero=True</code></li> <li> <p>routes diagonal/triangular claims to <code>solve_triangular</code></p> </li> <li> <p><code>solve_triangular</code> treats triangular/diagonal claims as gospel and does not truth-validate.</p> </li> </ul> <p>See R1 Properties for the rules and failure modes.</p>"},{"location":"guides/release1/linalg/#practical-example-property-driven-solve","title":"Practical example (property-driven solve)","text":"<pre><code>import pycauset as pc\n\nA = pc.identity(3)\nA.properties[\"is_upper_triangular\"] = True\nb = pc.vector((1.0, 2.0, 3.0))\n\nx = pc.solve(A, b)  # routes to solve_triangular under the hood\n</code></pre>"},{"location":"guides/release1/linalg/#see-also","title":"See also","text":"<ul> <li>Linear Algebra Operations</li> <li>R1 Properties</li> <li>pycauset.solve</li> <li>pycauset.matmul</li> <li>Compute Architecture</li> </ul>"},{"location":"guides/release1/properties/","title":"R1 Properties (Semantic Metadata)","text":"<p>Release 1 introduces <code>obj.properties</code>: a typed mapping that stores semantic assertions and cached-derived values.</p> <p>Properties are a power-user feature. They can change which algorithms run, without scanning payload data.</p> <p>Power-user semantics (gospel)</p> <p>Properties are authoritative assertions. If you mark a matrix as diagonal/triangular/unitary/etc, PyCauset is allowed to run algorithms that assume the property is true.   PyCauset does not validate truth by scanning payload.</p>"},{"location":"guides/release1/properties/#what-shipped-r1","title":"What shipped (R1)","text":"<p>R1_PROPERTIES is implemented end-to-end. In practice, that means:</p> <ul> <li><code>obj.properties</code> exists on matrices and vectors and round-trips through <code>.pycauset</code>.</li> <li>Compatibility checks reject only structurally impossible / contradictory states (and do so in \\(O(1)\\)).</li> <li>Property propagation under metadata-only transforms (<code>transpose</code>, conjugation, scalar scale) is deterministic and \\(O(1)\\).</li> <li>Cached-derived values (e.g. <code>trace</code>, <code>determinant</code>, <code>eigenvalues</code>) are validity-checked and invalidated on mutation.</li> <li>Core endpoints consult properties for fast paths (see \u201cHow properties affect algorithms\u201d).</li> </ul>"},{"location":"guides/release1/properties/#what-properties-is","title":"What <code>properties</code> is","text":"<ul> <li><code>obj.properties</code> is a mapping (<code>str</code> keys \u2192 typed values).</li> <li>Many keys are boolean-like, but use tri-state behavior:</li> <li>unset: the key is absent</li> <li>True: asserted</li> <li>False: explicitly negated</li> </ul> <p>Most importantly:</p> <ul> <li>Gospel assertions are authoritative: PyCauset does not verify them by scanning data.</li> <li>Compatibility checks are minimal and O(1): structurally impossible states raise immediately (e.g. <code>is_unitary=True</code> on a non-square matrix).</li> </ul> <p>This design keeps the project scale-first: there is no hidden full-data pass to \u201cvalidate\u201d a claim.</p>"},{"location":"guides/release1/properties/#common-keys-release-1","title":"Common keys (Release 1)","text":""},{"location":"guides/release1/properties/#gospel-semantic-assertions","title":"Gospel (semantic) assertions","text":"<p>These keys are treated as semantic structure claims (no truth validation):</p> <ul> <li><code>is_zero</code>, <code>is_identity</code>, <code>is_permutation</code></li> <li><code>is_diagonal</code>, <code>is_upper_triangular</code>, <code>is_lower_triangular</code></li> <li><code>has_unit_diagonal</code>, <code>has_zero_diagonal</code>, <code>diagonal_value</code></li> <li><code>is_symmetric</code>, <code>is_anti_symmetric</code>, <code>is_hermitian</code>, <code>is_skew_hermitian</code>, <code>is_unitary</code>, <code>is_atomic</code></li> <li>Vector-ish hints: <code>is_sorted</code>, <code>is_strictly_sorted</code>, <code>is_unit_norm</code></li> </ul>"},{"location":"guides/release1/properties/#cached-derived-values","title":"Cached-derived values","text":"<p>These keys are derived/cached quantities whose use is guarded by a validity signature (and which are invalidated on payload mutation):</p> <ul> <li>Persisted in <code>.pycauset</code> today: <code>trace</code>, <code>determinant</code>, <code>norm</code>, <code>sum</code>, <code>eigenvalues</code></li> <li>Other cached keys may exist in-memory, but are not guaranteed to round-trip.</li> </ul>"},{"location":"guides/release1/properties/#minimal-example-triangular-solve","title":"Minimal example (triangular solve)","text":"<pre><code>import pycauset as pc\n\nA = pc.identity(3)\nb = pc.vector((1.0, 2.0, 3.0))\n\n# Gospel assertion: solver is allowed to treat off-triangle entries as zero.\nA.properties[\"is_upper_triangular\"] = True\n\nx = pc.solve_triangular(A, b)\n</code></pre>"},{"location":"guides/release1/properties/#setting-unsetting-and-explicit-false","title":"Setting, unsetting, and explicit False","text":"<p>Unset a key by deleting it, or by assigning <code>None</code>:</p> <pre><code>A.properties[\"is_upper_triangular\"] = True\n\ndel A.properties[\"is_upper_triangular\"]\n# or:\nA.properties[\"is_upper_triangular\"] = None\n</code></pre> <p>Explicit <code>False</code> is different from \u201cunset\u201d:</p> <pre><code>A.properties[\"is_hermitian\"] = False  # an explicit negation\n\n## O(1) mutation semantics (effect summaries)\n\nWhen payload is mutated, PyCauset updates/invalidates properties and cached-derived values without any extra pass over the data.\n\nInternally this is handled by an $O(1)$ \u201chealth check\u201d step that may consume a constant-size **effect summary** emitted by a kernel or operation.\nExamples of effect bits include:\n\n- \u201cwrote any off-diagonal nonzero\u201d (and whether it was above/below the diagonal)\n- \u201cwrote any diagonal entry\u201d (and the last written diagonal value)\n- \u201cknown all-zero\u201d or \u201cset identity\u201d (for operations like explicit fills)\n\nThe important user-visible guarantee is: property/caching correctness does not require a second scan.\n\n## Propagation under metadata-only transforms\n\nProperty propagation is deterministic and preserves tri-state semantics (unset stays unset; incompatible claims are unset rather than forced to `False`).\n\nKey examples:\n\n- Transpose swaps `is_upper_triangular` \u2194 `is_lower_triangular`.\n- Conjugation conjugates `diagonal_value` (when present) and cached complex values (e.g. `trace` / `determinant` / `eigenvalues`).\n- Scalar scale updates cached-derived values when there is a safe $O(1)$ rule (e.g. `trace *= s`, `determinant *= s^n` when square) and clears them otherwise.\n</code></pre>"},{"location":"guides/release1/properties/#how-properties-affect-algorithms-release-1-scope","title":"How properties affect algorithms (Release 1 scope)","text":"<p>A few key endpoints are property-aware in R1:</p> <ul> <li>pycauset.solve</li> <li>short-circuits <code>is_identity</code></li> <li>rejects <code>is_zero</code></li> <li> <p>routes diagonal/triangular claims to <code>solve_triangular</code></p> </li> <li> <p>pycauset.matmul</p> </li> <li> <p>may exploit <code>is_diagonal</code> and triangular claims for dispatch (without validating truth)</p> </li> <li> <p>pycauset.eigvalsh</p> </li> <li>consults/seeds cached <code>eigenvalues</code></li> <li>rejects if <code>is_hermitian</code> is explicitly <code>False</code></li> </ul>"},{"location":"guides/release1/properties/#cached-derived-values-and-why-theyre-different","title":"Cached-derived values (and why they\u2019re different)","text":"<p>Some entries surfaced through <code>obj.properties</code> are cached-derived values (examples: <code>trace</code>, <code>determinant</code>, <code>norm</code>, <code>sum</code>, <code>eigenvalues</code>).</p> <p>Rules:</p> <ul> <li>Cached-derived values are used only when their validity signature matches the current payload + view-state.</li> <li>Payload mutation clears or invalidates cached-derived values.</li> <li>Persistence stores cached-derived values separately (<code>cached.*</code>) and restores them only when valid.</li> </ul> <p>Validity signatures (R1): cached entries are keyed to a payload identity and the view-state signature (transpose/conjugation/scalar).</p> <p>The canonical snapshot/caching semantics are documented here:</p> <ul> <li>Storage and Memory</li> </ul>"},{"location":"guides/release1/properties/#persistence","title":"Persistence","text":"<p>Properties round-trip through <code>.pycauset</code> files:</p> <ul> <li><code>properties.*</code> stores gospel assertions (including \u201cmissing vs explicit False\u201d)</li> <li><code>cached.*</code> stores cached-derived values with validity metadata</li> </ul> <p>See pycauset.save and pycauset.load.</p>"},{"location":"guides/release1/properties/#see-also","title":"See also","text":"<ul> <li>Storage and Memory</li> <li>pycauset.MatrixBase</li> <li>pycauset.VectorBase</li> <li>pycauset.solve</li> <li>pycauset.solve_triangular</li> <li>DType System</li> <li>R1_PROPERTIES plan artifact</li> </ul>"},{"location":"guides/release1/shapes/","title":"R1 Shapes (NxM Matrices)","text":"<p>This guide explains the Release 1 shape model: vectors are 1D, matrices are 2D, and rectangular (rows\u00d7cols) dense matrices are supported end-to-end (allocation, indexing, transpose views, NumPy interop, and persistence).</p>"},{"location":"guides/release1/shapes/#goal","title":"Goal","text":"<ul> <li>Create vectors and matrices with NumPy-like shape semantics.</li> <li>Use rectangular dense matrices safely.</li> <li>Know what is still square-only.</li> </ul>"},{"location":"guides/release1/shapes/#minimal-example","title":"Minimal example","text":"<pre><code>import pycauset as pc\n\nA = pc.zeros((2, 3), dtype=\"float64\")\nB = pc.ones((3, 4), dtype=\"float64\")\nC = A @ B\n\nassert A.shape == (2, 3)\nassert B.shape == (3, 4)\nassert C.shape == (2, 4)\n</code></pre>"},{"location":"guides/release1/shapes/#constructors-vs-allocators","title":"Constructors vs allocators","text":""},{"location":"guides/release1/shapes/#data-constructors-matrix-vector","title":"Data constructors (<code>matrix</code>, <code>vector</code>)","text":"<ul> <li>pycauset.matrix constructs from data (aligned with <code>np.array</code>).</li> <li>pycauset.vector constructs from data.</li> </ul> <p>Important: these constructors do not interpret tuples as shapes.</p> <pre><code>import pycauset as pc\n\nm = pc.matrix(((1, 2), (3, 4)))   # 2D data -&gt; matrix\nv = pc.matrix((1, 2, 3))         # 1D data -&gt; vector\n</code></pre>"},{"location":"guides/release1/shapes/#shape-allocators-zeros-ones-empty","title":"Shape allocators (<code>zeros</code>, <code>ones</code>, <code>empty</code>)","text":"<p>Use shape-based allocation when you want size-first creation:</p> <ul> <li>pycauset.zeros</li> <li>pycauset.ones</li> <li>pycauset.empty</li> </ul> <p><code>dtype</code> is required for these APIs.</p> <pre><code>import pycauset as pc\n\nv = pc.zeros((10,), dtype=\"float32\")\nM = pc.empty((128, 64), dtype=\"int16\")\n</code></pre> <p><code>empty(...)</code> does not guarantee initialization; see the API page for details.</p>"},{"location":"guides/release1/shapes/#shape-size-and-length","title":"Shape, size, and length","text":"<p>Release 1 aligns these basics with NumPy:</p> <ul> <li>Matrices: <code>shape == (rows, cols)</code></li> <li>Vectors: <code>shape == (n,)</code></li> <li><code>size()</code> returns the total element count.</li> <li><code>len(x)</code> is the first dimension: <code>rows</code> for matrices, <code>n</code> for vectors.</li> </ul> <p>See pycauset.MatrixBase and pycauset.VectorBase.</p>"},{"location":"guides/release1/shapes/#transpose-is-usually-a-metadata-view","title":"Transpose is usually a metadata view","text":"<p>Most dense objects support transpose as a zero-copy view:</p> <pre><code>import pycauset as pc\n\nA = pc.zeros((2, 3), dtype=\"float64\")\nAT = A.T\nassert AT.shape == (3, 2)\n</code></pre>"},{"location":"guides/release1/shapes/#what-is-still-square-only","title":"What is still square-only","text":"<p>Two distinct categories remain square-only:</p> <ul> <li>Square-only structures (by definition): triangular/causal, diagonal, symmetric/antisymmetric.</li> <li>Square-only operations (by math/implementation): determinant, inverse, many spectral routines.</li> </ul> <p>For the current status list, see:</p> <ul> <li>NxM Support Status</li> <li>Square-only Assumptions</li> </ul>"},{"location":"guides/release1/shapes/#see-also","title":"See also","text":"<ul> <li>NxM Support Status</li> <li>Matrix Guide</li> <li>Vector Guide</li> <li>pycauset.matmul</li> <li>pycauset.matrix</li> <li>pycauset.vector</li> </ul>"},{"location":"guides/release1/storage/","title":"R1 Storage (Persistence Container)","text":"<p>Release 1 ships a single-file <code>.pycauset</code> persistence container that is:</p> <ul> <li>mmap-friendly for large payloads,</li> <li>crash-consistent for metadata updates,</li> <li>forward-compatible via sparse, typed metadata,</li> <li>and designed to support scale-first workflows (out-of-core objects without full materialization).</li> </ul> <p>This guide focuses on the user-facing semantics: save/load, snapshot immutability, and what metadata is preserved.</p>"},{"location":"guides/release1/storage/#minimal-example","title":"Minimal example","text":"<pre><code>import pycauset as pc\n\nA = pc.zeros((128, 64), dtype=\"float32\")\nA.fill(1.0)\n\npc.save(A, \"A.pycauset\")\nB = pc.load(\"A.pycauset\")\n\nassert B.shape == (128, 64)\n</code></pre>"},{"location":"guides/release1/storage/#snapshots-and-mutation-release-1-semantics","title":"Snapshots and mutation (Release 1 semantics)","text":"<p>In Release 1:</p> <ul> <li>A <code>.pycauset</code> file is treated as an immutable snapshot.</li> <li><code>pycauset.load(path)</code> returns a snapshot-backed object.</li> <li>Mutating the loaded object does not implicitly write back to <code>path</code>.</li> <li>To persist changes, explicitly save a new snapshot.</li> </ul> <p>This protects expensive \u201cbaseline\u201d artifacts from accidental overwrite.</p> <p>The canonical description (including cached-derived values and big-blob caches) is in:</p> <ul> <li>Storage and Memory</li> </ul>"},{"location":"guides/release1/storage/#what-is-persisted","title":"What is persisted","text":"<p>Release 1 persistence round-trips:</p> <ul> <li>identity metadata (shape, dtype, matrix type, payload layout)</li> <li>view-state metadata (transpose/conjugation/scalar)</li> <li>user-facing semantic properties (<code>properties.*</code>, gospel)</li> <li>cached-derived values (<code>cached.*</code>, validity-checked)</li> </ul> <p>This means:</p> <ul> <li>NxM shapes are preserved (<code>rows</code>, <code>cols</code>).</li> <li>Transpose is preserved as metadata (no forced densification).</li> <li>Properties and caches are restored when valid.</li> </ul>"},{"location":"guides/release1/storage/#block-matrices","title":"Block matrices","text":"<p>Block matrices persist as a manifest plus child files (sidecar directory <code>path + \".blocks\"</code>):</p> <ul> <li><code>matrix_type=\"BLOCK\"</code>, <code>data_type=\"MIXED\"</code> in the container header.</li> <li>Manifest pins <code>row_partitions</code> / <code>col_partitions</code> and a grid of child references (<code>path</code>, <code>payload_uuid</code>).</li> <li>Child filenames are deterministic (<code>block_r{r}_c{c}.pycauset</code>) and written under the sidecar directory; overwrite cleanup deletes only matching child names.</li> <li>Saves evaluate thunk blocks blockwise (never global densify), materialize <code>SubmatrixView</code> blocks locally, and raise deterministically on stale thunks.</li> <li>Saves stage child files (and nested sidecars) before commit; <code>payload_uuid</code> pins make mixed-snapshot loads fail deterministically.</li> <li>There is no block-level <code>trace/determinant/norm/sum</code> cache in Release 1; cached-derived values remain per-leaf child only.</li> </ul>"},{"location":"guides/release1/storage/#failure-modes-and-constraints","title":"Failure modes and constraints","text":"<ul> <li>Version mismatches or corrupted headers/metadata fail deterministically (clear error).</li> <li>Payload is not scanned during load to \u201cvalidate\u201d metadata.</li> <li>Missing/corrupt big-blob cache objects are treated as cache misses (may emit a storage warning; base object still loads).</li> </ul>"},{"location":"guides/release1/storage/#where-the-on-disk-format-is-specified","title":"Where the on-disk format is specified","text":"<p>The authoritative <code>.pycauset</code> container format specification is documented in:</p> <ul> <li>PyCauset Container Format</li> </ul> <p>For user-facing semantics (save/load workflows, snapshot behavior, caches), see:</p> <ul> <li>Storage and Memory</li> </ul> <p>For contributor-level details and debugging tools, see:</p> <ul> <li>Storage Semantics</li> </ul>"},{"location":"guides/release1/storage/#see-also","title":"See also","text":"<ul> <li>pycauset.save</li> <li>pycauset.load</li> <li>Storage and Memory</li> <li>R1 Properties</li> </ul>"},{"location":"internals/","title":"Internals","text":"<p>This section documents the internal architecture and design decisions of PyCauset. It is intended for contributors and advanced users who want to understand how the library works under the hood.</p>"},{"location":"internals/#architecture","title":"Architecture","text":"<ul> <li>Compute Architecture: The unified CPU/GPU compute architecture, including <code>ComputeContext</code>, <code>AutoSolver</code>, and parallelization strategies.</li> <li>Memory Architecture: The Tiered Storage system, Memory Governor, IO Accelerator, and Copy-on-Write mechanism.</li> <li>Memory and Data: The <code>.pycauset</code> file format and the Object Hierarchy.</li> <li>Streaming Manager: Shared policy for streaming/direct routing, tiling, queue depths, and IO observability.</li> <li>Algorithms: Details of the solvers (Eigenvalue, Matrix Multiplication) and their implementations.</li> <li>DType System: Scalar kinds (<code>bit</code>/<code>int</code>/<code>float</code>), promotion rules, complex representation, and overflow behavior.</li> </ul>"},{"location":"internals/#process","title":"Process","text":"<ul> <li>Release Process: Steps for releasing a new version of PyCauset.</li> </ul>"},{"location":"internals/Algorithms/","title":"Algorithms and Math","text":"<p>This document details the mathematical algorithms implemented in PyCauset for linear algebra, causal set analysis, and spacetime generation.</p>"},{"location":"internals/Algorithms/#1-algorithms-and-solvers","title":"1. Algorithms and Solvers","text":"<p>PyCauset implements a hybrid CPU/GPU strategy for eigenvalue computation and matrix operations.</p>"},{"location":"internals/Algorithms/#eigenvalue-solvers","title":"Eigenvalue Solvers","text":""},{"location":"internals/Algorithms/#a-dense-solver-smallmedium-scale","title":"A. Dense Solver (Small/Medium Scale)","text":"<p>Target: \\(N \\le 2000\\) (CPU) or VRAM-limited (GPU) Complexity: \\(O(N^3)\\)</p> <ul> <li>GPU (Preferred): Uses NVIDIA <code>cuSolver</code> (<code>cusolverDn&lt;t&gt;geev</code>).<ul> <li>Computes all eigenvalues using the QR algorithm on the GPU.</li> <li>Automatically handles memory workspace queries.</li> <li>Fallback: If VRAM is insufficient, automatically falls back to CPU.</li> </ul> </li> <li>CPU (Fallback): Implicit QR Algorithm.<ul> <li>Hessenberg Reduction: Reduces \\(A\\) to upper Hessenberg form \\(H = Q^T A Q\\) using Blocked Householder updates. Parallelized.</li> <li>QR Iteration: Francis steps to converge to Schur form. Sequential.</li> </ul> </li> </ul>"},{"location":"internals/Algorithms/#b-block-arnoldi-iteration-massive-scale","title":"B. Block Arnoldi Iteration (Massive Scale)","text":"<p>Target: \\(N &gt; 2000\\), up to \\(N=10^6+\\) Complexity: \\(O(m \\cdot N^2)\\)</p> <ul> <li>GPU Acceleration: The dominant cost, Matrix-Vector Multiplication (\\(V = A \\times Q_{block}\\)), is offloaded to the GPU using <code>cublasDgemm</code> / <code>cublasSgemm</code>.</li> <li>CPU Orchestration: The orthogonalization (Gram-Schmidt) and basis management remain on CPU to allow the basis size to exceed GPU memory if necessary.</li> </ul> <p>Algorithm: 1.  Block Multiplication: Compute \\(W = A \\times Q_{[m:m+b]}\\) (GPU Accelerated). 2.  Block Gram-Schmidt: Orthogonalize \\(b\\) new vectors against basis \\(Q\\) (CPU Parallel). 3.  Projection: Update Hessenberg matrix \\(H\\).</p>"},{"location":"internals/Algorithms/#matrix-inversion","title":"Matrix Inversion","text":"<ul> <li>GPU (Preferred): Uses <code>cuSolver</code>.<ol> <li>LU Factorization: <code>cusolverDn&lt;t&gt;getrf</code>. Computes \\(P A = L U\\).</li> <li>Inversion: <code>cusolverDn&lt;t&gt;getri</code>. Computes \\(A^{-1}\\) using LU factors.</li> </ol> </li> <li>CPU (Fallback): Block Gauss-Jordan Elimination.<ul> <li>Matrix is processed in blocks.</li> <li>Off-diagonal updates are fully parallelized using the custom <code>ThreadPool</code>.</li> </ul> </li> </ul>"},{"location":"internals/Algorithms/#matrix-multiplication","title":"Matrix Multiplication","text":"<p>Matrix multiplication uses a dynamic dispatch system:</p> <ul> <li>GPU: Uses <code>cuBLAS</code> (Float32/Float64) and custom kernels (BitMatrix).<ul> <li>Streaming Mode: If matrices exceed VRAM, a hybrid tiling approach is used. CPU threads pack tiles of \\(A\\) and stream them to the GPU.</li> </ul> </li> <li>CPU: <ul> <li>Float/Double: Uses OpenBLAS/MKL (if linked) or blocked multiplication parallelized via <code>ThreadPool</code>.</li> <li>BitMatrix: Uses AVX-512 optimized kernels (<code>_mm512_popcnt_epi64</code>) for bit-packed operations, achieving significant speedups over naive implementations.</li> <li>Direct Path: For RAM-resident data, the \"Streaming Solver\" overhead is bypassed, calling BLAS/LAPACK directly.</li> </ul> </li> <li>Specialized:<ul> <li>Bit Matrices:<ul> <li>CPU: Uses <code>std::popcount</code> (AVX-512/NEON hardware instruction) for ultra-fast boolean matrix multiplication and dot products. This replaces naive loops, achieving ~30x speedups.</li> <li>GPU: Uses a custom \"Transpose-then-Popcount\" kernel that packs 32x32 bit tiles into registers, achieving massive throughput for path counting and transitive closure.</li> </ul> </li> <li>Triangular Matrices: Optimized block-based algorithms for inversion and multiplication.</li> </ul> </li> </ul>"},{"location":"internals/Algorithms/#2-stateless-sprinkling-spacetime-generation","title":"2. Stateless Sprinkling (Spacetime Generation)","text":"<p>One of the key features of <code>pycauset</code> is its ability to handle extremely large causal sets\u2014potentially billions of elements\u2014without exhausting system RAM. This is achieved through a technique we call Stateless Sprinkling.</p>"},{"location":"internals/Algorithms/#the-problem","title":"The Problem","text":"<p>For \\(N = 10^9\\) (1 billion) in \\(D=4\\) dimensions, storing the coordinates alone would require ~32 GB of RAM.</p>"},{"location":"internals/Algorithms/#the-solution","title":"The Solution","text":"<p><code>pycauset</code> avoids storing the coordinates entirely. Instead of keeping the positions of all \\(N\\) points in memory, we only store the seed used to generate them.</p>"},{"location":"internals/Algorithms/#block-based-matrix-generation","title":"Block-Based Matrix Generation","text":"<p>When generating the causal matrix (which is stored on disk as a memory-mapped payload inside a single-file <code>.pycauset</code> container), we process the points in blocks that fit comfortably in the CPU cache (e.g., 1024 points at a time).</p> <ol> <li>Generate Block A: We generate the coordinates for a small block of points (Row Block).</li> <li>Generate Block B: We generate the coordinates for another small block (Column Block).</li> <li>Compute Sub-matrix: We compute the causality relations between points in Block A and Block B.</li> <li>Discard Coordinates: Once the sub-matrix is computed and written to disk, the coordinates for Block A and Block B are discarded.</li> </ol>"},{"location":"internals/Algorithms/#coordinate-recovery-algorithm","title":"Coordinate Recovery Algorithm","text":"<p>Since coordinates are not stored, retrieving the position of a specific element \\(i\\) (where \\(0 \\le i &lt; N\\)) requires re-running the generation process for that specific point. To make this efficient, we do not restart from index 0. Instead, we use a Block-Skipping algorithm.</p> <ol> <li>Block Decomposition: \\(B = \\lfloor i / \\text{BLOCK\\_SIZE} \\rfloor\\), \\(k = i \\pmod{\\text{BLOCK\\_SIZE} }\\).</li> <li>Block Seeding: We compute a unique, deterministic seed for block \\(B\\) using a hash of the global seed and the block index.</li> <li>Fast-Forwarding: We initialize a PRNG with <code>block_seed</code> and generate \\(k\\) points to reach the target.</li> </ol>"},{"location":"internals/Algorithms/#3-mathematical-derivation-retarded-propagator-k_r","title":"3. Mathematical Derivation: Retarded Propagator (\\(K_R\\))","text":"<p>We need to calculate the Retarded Propagator matrix \\(K_R\\) for massive causal sets (\\(N \\approx 10^6\\)). The generalized definition for a scalar field on a causal set is:</p> \\[ K_R = \\Phi(I - b\\Phi)^{-1} \\] <p>Where: *   \\(\\Phi = a C\\) *   \\(C\\): \\(N \\times N\\) Causal Matrix (Strictly Upper Triangular, Binary). *   \\(I\\): Identity Matrix. *   \\(a, b\\): Scalar constants derived from the spacetime dimension \\(d\\), sprinkling density \\(\\rho\\), and field mass \\(m\\).</p>"},{"location":"internals/Algorithms/#derivation","title":"Derivation","text":"<p>Direct inversion of \\((I - b\\Phi)\\) is \\(O(N^3)\\) and produces a dense matrix. We can transform this into a form solvable by our existing efficient kernel.</p> <p>Substitute \\(\\Phi = aC\\): $$ K_R = aC(I - abC)^{-1} $$</p> <p>Let \\(\\alpha_{eff} = -\\frac{1}{ab}\\). Then: $$ K_R = -\\frac{1}{b} \\left[ C (\\alpha_{eff}I + C)^{-1} \\right] $$</p> <p>The term in the brackets, \\(X = C(\\alpha_{eff}I + C)^{-1}\\), is exactly the form solved by our existing <code>compute_k</code> kernel (which solves \\(X = C(a_{kernel}I+C)^{-1}\\)).</p>"},{"location":"internals/Algorithms/#why-this-approach-works-so-well","title":"Why This Approach Works So Well","text":"<ol> <li>Computational Complexity: \\(O(N^3) \\to O(N^2 \\cdot d)\\). The term \\(C_{im}\\) is binary and sparse. We only perform additions where \\(C_{im}=1\\).</li> <li>Memory Efficiency: \\(O(N^2) \\to O(N)\\). We only need to store ONE column of \\(K\\) in RAM at a time.</li> <li>Parallelism: Since each column \\(j\\) is independent, we can compute all \\(N\\) columns in parallel.</li> </ol>"},{"location":"internals/Block%20Matrices/","title":"Block Matrices","text":"<p>Block matrices provide a storage-first way to represent a large matrix as a 2D grid of smaller matrices (\u201cblocks\u201d), potentially with heterogeneous dtypes.</p> <p>The core goals are:</p> <ul> <li>Preserve structure and avoid global densification (\u201cno silent densify\u201d).</li> <li>Keep compute routed through the existing leaf compute boundary (AutoSolver / device routing).</li> <li>Support semi-lazy orchestration (thunked per-block results, evaluated only on triggers).</li> <li>Persist block matrices as a snapshot without writing a single giant dense payload.</li> </ul>"},{"location":"internals/Block%20Matrices/#where-it-lives","title":"Where it lives","text":"<p>Python implementation:</p> <ul> <li><code>python/pycauset/_internal/blockmatrix.py</code>: <code>BlockMatrix</code> container + orchestration (<code>block_matmul</code>, <code>block_add</code>, <code>block_sub</code>, <code>block_mul</code>, <code>block_div</code>).</li> <li><code>python/pycauset/_internal/submatrix_view.py</code>: <code>SubmatrixView</code> (no-copy rectangular view).</li> <li><code>python/pycauset/_internal/thunks.py</code>: <code>ThunkBlock</code> (lazy, cached per-block evaluation).</li> <li><code>python/pycauset/_internal/persistence.py</code>: <code>matrix_type=BLOCK</code> save/load support via a sidecar directory.</li> </ul> <p>Integration points:</p> <ul> <li><code>python/pycauset/__init__.py</code>: <code>pycauset.matrix(...)</code> block-grid construction disambiguation.</li> <li><code>python/pycauset/_internal/ops.py</code>: <code>pycauset.matmul(a, b)</code> routes to block orchestration if either operand is a <code>BlockMatrix</code>.</li> </ul>"},{"location":"internals/Block%20Matrices/#data-model","title":"Data model","text":""},{"location":"internals/Block%20Matrices/#blockmatrix","title":"<code>BlockMatrix</code>","text":"<p>A <code>BlockMatrix</code> is a structural container of blocks laid out in a rectangular grid.</p> <p>Invariants enforced at construction:</p> <ul> <li>Grid must be rectangular (every block-row has the same number of block-cols).</li> <li>All blocks in a block-row share the same height.</li> <li>All blocks in a block-col share the same width.</li> </ul> <p>The container exposes:</p> <ul> <li>Elementwise indexing via <code>M[i, j]</code>.</li> <li>Block access via <code>get_block(r, c)</code> and <code>set_block(r, c, block)</code>.</li> <li>Partition metadata via <code>row_partitions</code> / <code>col_partitions</code>.</li> </ul>"},{"location":"internals/Block%20Matrices/#submatrixview","title":"<code>SubmatrixView</code>","text":"<p><code>SubmatrixView(source, row0, col0, rows, cols)</code> is a lightweight, no-copy rectangle.</p> <ul> <li>Element reads delegate to the source.</li> <li><code>repr/str</code> are structure-only.</li> <li>A view-of-a-view composes deterministically into a single view.</li> </ul> <p>In block orchestration, <code>SubmatrixView</code> is used to tile operands when block boundaries do not align. Block-aware slicing returns tiled <code>SubmatrixView</code> blocks (no densify); unsupported view shapes error deterministically.</p>"},{"location":"internals/Block%20Matrices/#thunkblock","title":"<code>ThunkBlock</code>","text":"<p>A <code>ThunkBlock</code> represents a deferred computation that produces a concrete matrix-like object.</p> <ul> <li>It caches the computed result.</li> <li>It is thread-safe for single-eval concurrency.</li> <li>It is triggered by element access (<code>get</code> / <code>__getitem__</code>) or explicit <code>materialize()</code>.</li> </ul> <p>Staleness (snapshot-at-creation, R1):</p> <ul> <li><code>ThunkBlock</code> pins <code>version</code> on captured sources; evaluation/cache hits check versions and raise on mismatch (no auto-recompute).</li> <li><code>BlockMatrix</code> increments its own <code>version</code> on <code>set_block</code>, invalidating cached/thunked blocks owned by the container.</li> <li>Leaf mutations are expected to bump their <code>version</code>; stale access is an error.</li> </ul>"},{"location":"internals/Block%20Matrices/#orchestration-semantics","title":"Orchestration semantics","text":""},{"location":"internals/Block%20Matrices/#once-block-always-block","title":"\u201cOnce block, always block\u201d","text":"<p>If either operand is a <code>BlockMatrix</code>, operations preserve block-ness by returning a <code>BlockMatrix</code> result (typically thunked):</p> <ul> <li>Matmul: <code>A @ B</code> or <code>pycauset.matmul(A, B)</code></li> <li>Elementwise: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code></li> </ul> <p>Mixed operands are handled by wrapping the non-block operand as a <code>1\u00d71</code> <code>BlockMatrix</code>, then refining partitions to align.</p>"},{"location":"internals/Block%20Matrices/#partition-refinement","title":"Partition refinement","text":"<ul> <li><code>block_matmul</code> refines the shared dimension using <code>sorted(set(A.col_partitions) | set(B.row_partitions))</code>.</li> <li>Elementwise ops refine both axes using the union of row/col partitions.</li> </ul> <p>The refinement step creates <code>SubmatrixView</code> tiles when necessary.</p>"},{"location":"internals/Block%20Matrices/#leaf-compute-boundary","title":"Leaf compute boundary","text":"<p>When orchestration reaches \u201cleaf \u00d7 leaf\u201d matmul between native matrices, it routes through the public dispatch boundary (<code>pycauset.matmul</code>) so property-aware conversions (diagonal/triangular) still apply.</p> <p>Device routing follows Compute Architecture per leaf op: AutoSolver decides CPU vs GPU for each block. Complex matmul is CPU-only on CUDA builds today; mixed-dtype containers stay heterogeneous because routing is per leaf op.</p>"},{"location":"internals/Block%20Matrices/#evaluation-triggers-semi-lazy","title":"Evaluation triggers (semi-lazy)","text":"<ul> <li>Trigger evaluation of the minimal required block(s): element access, crossing the compute boundary, dense conversion (<code>np.asarray</code>), or persistence (<code>pycauset.save</code>).</li> <li>Non-triggers: <code>repr/str</code>, shape/partition metadata, and <code>get_block</code>.</li> <li>Cached results are reused until a version mismatch is detected; stale hits raise.</li> </ul> <p>Concurrency: each <code>ThunkBlock</code> uses single-eval locking (e.g., <code>once_flag</code>/<code>mutex</code>) so concurrent requests compute once and reuse the cached block.</p>"},{"location":"internals/Block%20Matrices/#deterministic-accumulation-per-output-block","title":"Deterministic accumulation per output block","text":"<ul> <li>Fixed <code>k</code> order for <code>\u03a3_k A_ik @ B_kj</code>.</li> <li>Accumulator dtype is chosen from metadata before evaluation by folding the add-result dtype across term dtypes.</li> <li>Local promotion is per-block; container stays heterogeneous.</li> </ul>"},{"location":"internals/Block%20Matrices/#io-accelerator-integration","title":"IO accelerator integration","text":"<p>Orchestrated evaluation performs best-effort IO hints:</p> <ul> <li>Prefetch before using a backing file: <code>obj.get_accelerator().prefetch(0, size)</code></li> <li>Discard after a temporary is no longer needed: <code>discard(0, size)</code></li> </ul> <p>These hooks are intentionally best-effort and should never be required for correctness.</p>"},{"location":"internals/Block%20Matrices/#persistence-format","title":"Persistence format","text":"<p>Saving a block matrix uses a single <code>.pycauset</code> container file plus a sibling sidecar directory:</p> <ul> <li>Container path: <code>bm.pycauset</code></li> <li>Sidecar directory: <code>bm.pycauset.blocks/</code></li> </ul> <p>The container stores:</p> <ul> <li><code>matrix_type = \"BLOCK\"</code></li> <li><code>data_type = \"MIXED\"</code></li> <li><code>block_manifest</code> with:</li> <li><code>row_partitions</code>, <code>col_partitions</code></li> <li><code>children</code>: a grid of <code>{path, payload_uuid}</code> entries</li> </ul> <p>Child blocks are stored as <code>block_r{r}_c{c}.pycauset</code> files in the sidecar directory.</p> <p>Snapshot integrity:</p> <ul> <li>Each manifest entry pins the child <code>payload_uuid</code>.</li> <li>Load validates the pinned UUID; mismatch errors deterministically.</li> </ul> <p>Save policies (Release 1):</p> <ul> <li>Stale thunks fail save deterministically (no implicit recompute).</li> <li>Overwrite cleanup deletes only deterministic child filenames within the sidecar.</li> <li>Saves stage child files (and nested sidecars) then commit/rename to reduce partial updates.</li> <li>No block-level cached-derived persistence (trace/determinant/norm/sum) is defined; caches remain per leaf child.</li> </ul> <p>View blocks on save:</p> <ul> <li>Persisting <code>SubmatrixView</code> blocks materializes the view block-locally into a small NumPy array, then converts via <code>native.asarray</code>.</li> <li>This avoids global densification while still producing stable on-disk storage.</li> </ul>"},{"location":"internals/Block%20Matrices/#debugging-and-traceability","title":"Debugging and traceability","text":"<p>Kernel trace:</p> <ul> <li><code>pycauset._debug_clear_kernel_trace()</code></li> <li><code>pycauset._debug_last_kernel_trace()</code></li> </ul> <p>IO trace (separate channel):</p> <ul> <li><code>pycauset._debug_clear_io_trace()</code></li> <li><code>pycauset._debug_last_io_trace()</code></li> </ul> <p>For device routing expectations and thunk trigger testing, prefer trace-based integration tests over timing.</p>"},{"location":"internals/Block%20Matrices/#see-also","title":"See also","text":"<ul> <li>pycauset.matrix</li> <li>pycauset.matmul</li> <li>pycauset.save / pycauset.load</li> <li>Matrix Guide</li> <li>Compute Architecture</li> <li>Memory Architecture</li> </ul>"},{"location":"internals/Compute%20Architecture/","title":"Compute System Architecture","text":"<p>This document details the computational backend of PyCauset, including the CPU/GPU abstraction layer, parallelization strategies, and hardware-specific optimizations.</p>"},{"location":"internals/Compute%20Architecture/#1-architecture-overview","title":"1. Architecture Overview","text":"<p>PyCauset uses a unified compute architecture that abstracts the underlying hardware (CPU or GPU) from the high-level matrix operations.</p> <pre><code>classDiagram\n    class ComputeContext {\n        +instance()\n        +get_device()\n        +enable_gpu()\n    }\n\n    class ComputeDevice {\n        &lt;&lt;interface&gt;&gt;\n        +matmul()\n        +add()\n        +inverse()\n    }\n\n    class AutoSolver {\n        +select_device()\n    }\n\n    class CpuDevice {\n        +solver_: CpuSolver\n    }\n\n    class CudaDevice {\n        +cublasHandle\n        +cusolverHandle\n    }\n\n    ComputeContext --&gt; AutoSolver : manages\n    AutoSolver --|&gt; ComputeDevice\n    AutoSolver --&gt; CpuDevice : delegates (small matrices)\n    AutoSolver --&gt; CudaDevice : delegates (large matrices)\n    CpuDevice --|&gt; ComputeDevice\n    CudaDevice --|&gt; ComputeDevice</code></pre>"},{"location":"internals/Compute%20Architecture/#11-computecontext","title":"1.1 ComputeContext","text":"<p>The <code>ComputeContext</code> is a singleton that serves as the entry point for all hardware-accelerated operations. It manages the lifecycle of the compute devices and handles the dynamic loading of the CUDA backend.</p>"},{"location":"internals/Compute%20Architecture/#12-autosolver","title":"1.2 AutoSolver","text":"<p>The <code>AutoSolver</code> is a smart dispatcher that implements the <code>ComputeDevice</code> interface. It automatically selects the best device for a given operation based on: *   Problem Size: Uses an element-count threshold (<code>gpu_threshold_elements_</code>) to avoid PCIe transfer overhead on small workloads. *   Measured Speedup: When a GPU is available, <code>AutoSolver</code> runs a small startup micro-benchmark and may prefer CPU if the GPU is slower for the tested workload. *   Hardware Availability: If no GPU is detected, it falls back to the CPU. *   Operation + Type Support: GPU routing is operation-specific and gated by matrix type + dtype compatibility (for example, dense float32/float64 with matching dtypes). Many operations are intentionally CPU-only for now (e.g., matrix-vector multiply, outer product, elementwise multiply/divide, dot/sum/norm).</p>"},{"location":"internals/Compute%20Architecture/#13-io-acceleration-integration","title":"1.3 IO Acceleration Integration","text":"<p>To minimize page faults during computation, the compute backend integrates with the IO Accelerator (see MemoryArchitecture).</p> <ul> <li>Prefetching: Before starting a heavy operation (like <code>matmul</code> or <code>inverse</code>), the solver calls <code>matrix-&gt;get_accelerator()-&gt;prefetch()</code>. This hints the OS to load the data into RAM asynchronously.</li> <li>Discarding: For temporary intermediate results, the solver may call <code>discard()</code> after usage to free up memory immediately.</li> </ul>"},{"location":"internals/Compute%20Architecture/#14-debug-trace-tags-kernel-vs-io","title":"1.4 Debug trace tags (kernel vs IO)","text":"<p>For deterministic testing and debugging (especially device routing and \u201cdid this trigger evaluation?\u201d checks), PyCauset exposes a small trace surface:</p> <ul> <li> <p>Kernel trace (thread-local):</p> <ul> <li><code>pycauset._debug_clear_kernel_trace()</code></li> <li><code>pycauset._debug_last_kernel_trace()</code></li> </ul> </li> <li> <p>IO trace (separate channel, thread-local):</p> <ul> <li><code>pycauset._debug_clear_io_trace()</code></li> <li><code>pycauset._debug_last_io_trace()</code></li> </ul> </li> </ul> <p>The IO trace is intentionally separate so IO hints (prefetch/discard) don\u2019t clobber kernel dispatch traces.</p>"},{"location":"internals/Compute%20Architecture/#2-cpu-backend","title":"2. CPU Backend","text":"<p>The CPU backend is designed for low-latency execution of small-to-medium workloads and robust fallback for all operations.</p>"},{"location":"internals/Compute%20Architecture/#21-cpudevice-cpusolver","title":"2.1 CpuDevice &amp; CpuSolver","text":"<ul> <li><code>CpuDevice</code>: A thin wrapper that implements the <code>ComputeDevice</code> interface.</li> <li><code>CpuSolver</code>: The core implementation class containing the algorithms. It handles:<ul> <li>Dense Matrix Ops: Blocked matrix multiplication (tiled for cache efficiency).<ul> <li>Lazy Initialization: Uses dynamic <code>beta</code> parameter (0.0 for first block, 1.0 for others) to avoid global zero-filling of output matrices. This prevents unnecessary page faults for out-of-core datasets.</li> </ul> </li> <li>Bit Matrix Ops: Optimized using <code>std::popcount</code> (AVX-512/NEON) for 30x speedups over naive loops.</li> <li>Element-wise Ops: Parallelized addition, subtraction, and multiplication.</li> </ul> </li> </ul>"},{"location":"internals/Compute%20Architecture/#22-parallelization-parallelutils","title":"2.2 Parallelization (<code>ParallelUtils</code>)","text":"<p>PyCauset uses a custom thread pool (<code>ThreadPool</code>) to manage parallelism with a Dynamic Scheduling model (Work-Stealing Approximation).</p> <ul> <li><code>ParallelFor</code>: A helper function that splits loops across available threads.</li> <li>Dynamic Scheduling: Unlike static partitioning (which suffers from stalls if one thread hits a page fault), <code>ParallelFor</code> uses an atomic index to hand out small chunks of work (<code>grain_size</code>) to threads as they finish previous tasks.</li> <li>Load Balancing: This ensures that if one thread is blocked by I/O or OS paging, other threads continue processing the remaining work, maximizing CPU utilization.</li> <li>Granularity: The grain size is tuned (heuristic: <code>range / (threads * 4)</code>) to balance load distribution against atomic contention overhead.</li> </ul>"},{"location":"internals/Compute%20Architecture/#3-gpu-backend-cuda","title":"3. GPU Backend (CUDA)","text":"<p>The GPU backend leverages NVIDIA CUDA for massive parallelism, particularly for \\(O(N^3)\\) operations like matrix multiplication and inversion.</p>"},{"location":"internals/Compute%20Architecture/#31-cudadevice","title":"3.1 CudaDevice","text":"<ul> <li>Libraries: Wraps <code>cuBLAS</code> (for matrix multiplication) and <code>cuSOLVER</code> (for decomposition/inversion).</li> <li>Memory Management: Maintains persistent device buffers (<code>d_A</code>, <code>d_B</code>, <code>d_C</code>) to avoid <code>cudaMalloc</code> overhead on every call.</li> </ul>"},{"location":"internals/Compute%20Architecture/#32-custom-kernels","title":"3.2 Custom Kernels","text":"<p>For operations not supported by standard libraries, PyCauset implements custom CUDA kernels: *   BitMatrix Multiplication: Uses a \"Transpose-then-Popcount\" strategy.     1.  Transpose Matrix B using warp shuffles (<code>__ballot_sync</code>).     2.  Perform bitwise AND + POPCOUNT on 64-bit words.     3.  Achieves theoretical peak throughput (64 ops/cycle/thread). *   Selected Element-wise Ops: <code>k_add</code>, <code>k_sub</code>, <code>k_mul_scalar</code> are available for dense float matrices when the <code>AutoSolver</code> routes the operation to CUDA. Some elementwise operations (notably elementwise multiply/divide) are currently CPU-only.</p>"},{"location":"internals/Compute%20Architecture/#33-pinned-memory","title":"3.3 Pinned Memory","text":"<p>To maximize data transfer speeds, PyCauset uses Pinned Memory (Page-Locked Memory) when a GPU is active. *   Mechanism: Uses <code>cudaHostAlloc</code> instead of <code>malloc</code>. *   Benefit: Allows the GPU's DMA engine to read/write directly to host RAM, bypassing CPU staging buffers. This typically doubles transfer bandwidth.</p>"},{"location":"internals/Compute%20Architecture/#4-hardware-detection-capabilities","title":"4. Hardware Detection &amp; Capabilities","text":"<p>PyCauset uses a <code>ComputeDevice</code> abstraction to manage hardware backends. The <code>CudaDevice</code> implementation includes logic to query NVIDIA GPU properties and determine the optimal execution strategy.</p>"},{"location":"internals/Compute%20Architecture/#compute-capability-heuristics","title":"Compute Capability Heuristics","text":"<p>The <code>preferred_precision()</code> method in <code>CudaDevice</code> returns an integer code: *   <code>1</code>: Float32 (Single Precision) *   <code>2</code>: Float64 (Double Precision)</p>"},{"location":"internals/Compute%20Architecture/#logic","title":"Logic","text":"<p>The decision is based on the GPU's Compute Capability (CC):</p> CC Architecture Example Cards FP64 Rate Preference 6.0 Pascal Tesla P100 1/2 FP32 Float64 6.1 Pascal GTX 10-series 1/32 FP32 Float32 7.0 Volta Tesla V100 1/2 FP32 Float64 7.5 Turing RTX 20-series 1/32 FP32 Float32 8.0 Ampere Tesla A100 1/2 FP32 Float64 8.6 Ampere RTX 30-series 1/64 FP32 Float32"},{"location":"internals/Compute%20Architecture/#python-binding-integration","title":"Python Binding Integration","text":"<p>PyCauset\u2019s Python bindings include an internal \u201cNumPy \u2192 PyCauset\u201d import helper (referred to in code as <code>native.asarray</code>) that converts NumPy arrays into PyCauset vectors/matrices based on shape and dtype.</p> <p>Note: this is not a public <code>pycauset.asarray</code> API; the user-facing constructors are <code>pycauset.vector(...)</code> and <code>pycauset.matrix(...)</code>. *   Shape: Supports 1D (vector) and 2D (matrix) arrays. *   Dtype policy (current):     *   1D <code>float32</code> vectors are promoted to float64 vectors.     *   2D <code>float32</code> matrices remain <code>float32</code> matrices.     *   This conversion does not currently depend on GPU availability or <code>preferred_precision()</code>.</p>"},{"location":"internals/Compute%20Architecture/#5-async-gpu-architecture-streaming","title":"5. Async GPU Architecture &amp; Streaming","text":"<p>PyCauset uses an Asynchronous Heterogeneous Computing model to handle matrices larger than GPU memory. Instead of blocking the CPU while the GPU computes, or blocking the GPU while the CPU loads data, we use a Double-Buffered Pipeline.</p>"},{"location":"internals/Compute%20Architecture/#the-asyncstreamer-class","title":"The <code>AsyncStreamer</code> Class","text":"<p>The core of this architecture is the <code>AsyncStreamer&lt;T&gt;</code> class (<code>src/accelerators/cuda/AsyncStreamer.hpp</code>).</p>"},{"location":"internals/Compute%20Architecture/#responsibilities","title":"Responsibilities","text":"<ol> <li>Pinned Memory Management: Allocates <code>cudaMallocHost</code> memory, which is required for asynchronous DMA transfers.</li> <li>Stream Management: Maintains a dedicated <code>transfer_stream</code> separate from the <code>compute_stream</code>.</li> <li>Synchronization: Uses <code>cudaEvent_t</code> to coordinate the CPU (Producer) and GPU (Consumer) without blocking the CPU thread unnecessarily.</li> </ol>"},{"location":"internals/Compute%20Architecture/#pipeline-logic","title":"Pipeline Logic","text":"<p>The pipeline consists of two buffers (Index 0 and Index 1) and utilizes Hybrid CPU/GPU Parallelism.</p> <ol> <li> <p>CPU Phase (Producer):</p> <ul> <li>Wait: Waits for Buffer \\(i\\) to be free (consumed by GPU in previous cycle).</li> <li>Fill (Parallelized): Uses <code>pycauset::ParallelFor</code> (Thread Pool) to pack data from the source matrix into the Pinned Memory Buffer \\(i\\). This multi-threaded approach ensures that memory bandwidth is maximized and the CPU does not become a bottleneck for fast GPUs.</li> <li>Submit: Submits an asynchronous <code>cudaMemcpyAsync</code> on the <code>transfer_stream</code>.</li> <li>Record: Records <code>event_transfer_complete</code>.</li> </ul> </li> <li> <p>GPU Phase (Consumer):</p> <ul> <li>Wait: The <code>compute_stream</code> waits for <code>event_transfer_complete</code>.</li> <li>Compute: Executes kernels (e.g., <code>cublasDgemm</code>) reading from Buffer \\(i\\) (Device Memory).</li> <li>Record: Records <code>event_compute_complete</code>.</li> </ul> </li> </ol> <p>This architecture allows for True Overlap: *   Time \\(T\\): GPU computes Batch \\(k\\). *   Time \\(T\\): CPU threads pack Batch \\(k+1\\). *   Time \\(T\\): DMA Engine transfers Batch \\(k+1\\) (once packing is done).</p>"},{"location":"internals/Compute%20Architecture/#supported-operations","title":"Supported Operations","text":""},{"location":"internals/Compute%20Architecture/#1-matrix-multiplication-matmul","title":"1. Matrix Multiplication (<code>matmul</code>)","text":"<ul> <li>Function: <code>CudaDevice::matmul_streaming</code></li> <li>Strategy: Tiled GEMM.</li> <li>Pipeline:<ul> <li>Streams tiles of Matrix A and Matrix B.</li> <li>Accumulates results into a persistent tile of Matrix C on the GPU.</li> <li>Allows multiplying matrices of arbitrary size, limited only by system RAM.</li> </ul> </li> </ul>"},{"location":"internals/Compute%20Architecture/#2-eigenvalue-solver-batch_gemv","title":"2. Eigenvalue Solver (<code>batch_gemv</code>)","text":"<ul> <li>Function: <code>CudaDevice::batch_gemv_streaming</code></li> <li>Strategy: Blocked Matrix-Vector Multiplication.</li> <li>Pipeline:<ul> <li>Keeps vectors \\(X\\) and \\(Y\\) in VRAM.</li> <li>Streams Matrix \\(A\\) in chunks from Host to Device.</li> <li>Computes \\(Y += A_{chunk} \\times X\\).</li> </ul> </li> </ul>"},{"location":"internals/Compute%20Architecture/#3-matrix-inversion-inverse","title":"3. Matrix Inversion (<code>inverse</code>)","text":"<ul> <li>Function: <code>CudaSolver::invert</code></li> <li>Strategy: Right-Looking Blocked LU Decomposition.</li> <li>Pipeline:<ul> <li>Panel Factorization: Loads a block column, factorizes it in VRAM.</li> <li>Trailing Update: Streams the trailing submatrix and updates it using the factorized panel (\\(A' = A - L \\times U\\)).</li> <li>Reuses the <code>matmul_streaming</code> infrastructure for the update step.</li> </ul> </li> <li>Performance: Enables inversion of matrices significantly larger than GPU memory.</li> </ul>"},{"location":"internals/Compute%20Architecture/#6-optimization-roadmap-future-work","title":"6. Optimization Roadmap &amp; Future Work","text":"<p>This section outlines the plan to address the remaining gaps in the PyCauset acceleration layer.</p>"},{"location":"internals/Compute%20Architecture/#phase-1-dense-eigenvalues-on-gpu-complete","title":"Phase 1: Dense Eigenvalues on GPU (Complete)","text":"<ul> <li>Status: \u2705 Complete (Symmetric Only)</li> <li>Implementation: Uses <code>syevd</code> for symmetric matrices (checked at runtime) and falls back to CPU for non-symmetric ones.</li> </ul>"},{"location":"internals/Compute%20Architecture/#phase-2-element-wise-operations-on-gpu-partial","title":"Phase 2: Element-wise Operations on GPU (Partial)","text":"<ul> <li>Status: \ud83d\udfe1 Partial</li> <li>Implementation: CUDA supports <code>add</code>, <code>subtract</code>, and <code>multiply_scalar</code> for dense float32/float64 with matching dtypes. Elementwise multiply/divide are currently CPU-only.</li> </ul>"},{"location":"internals/Compute%20Architecture/#phase-3-bitmatrix-optimization-complete","title":"Phase 3: BitMatrix Optimization (Complete)","text":"<ul> <li>Status: \u2705 Complete</li> <li>Implementation: \"Bit-Packed GEMM\" kernel implemented using <code>__popc</code> and shared memory tiling.</li> </ul>"},{"location":"internals/Compute%20Architecture/#phase-4-precision-control","title":"Phase 4: Precision Control","text":"<ul> <li>Objective: Allow users to force Float64 on consumer GPUs.</li> <li>Plan: Add <code>PrecisionMode</code> enum (<code>AUTO</code>, <code>FORCE_FLOAT32</code>, <code>FORCE_FLOAT64</code>) to <code>AcceleratorConfig</code>.</li> </ul>"},{"location":"internals/Compute%20Architecture/#15-resilience-fallback-r1_safety","title":"1.5 Resilience &amp; Fallback (R1_SAFETY)","text":"<p>To ensure robustness against hardware instability (e.g., GPU driver crashes, OOM), AutoSolver implements a Circuit Breaker pattern:</p> <ol> <li>Pessimistic Initialization: GPU context creation is wrapped in  ry-catch. If it fails, the GPU is disabled for the session.</li> <li>Operation Guard: Every GPU operation (matmul, inverse, etc.) is guarded.</li> <li>Fallback: If a GPU operation throws a hardware exception:<ul> <li>A warning is logged to stderr.</li> <li>The GPU is permanently disabled (gpu_device_ = nullptr).</li> <li>The operation is retried immediately on the CPU.</li> </ul> </li> </ol>"},{"location":"internals/CooperativeArchitecture/","title":"Cooperative Compute Architecture","text":"<p>Status: Experimental (Phase 1 Implemented) Last Updated: 2025-12-08</p>"},{"location":"internals/CooperativeArchitecture/#overview","title":"Overview","text":"<p>The Cooperative Compute Architecture (CCA) is designed to unify the CPU, GPU, and I/O subsystems of PyCauset. Instead of operating in isolation, these systems communicate via a Lookahead Protocol.</p>"},{"location":"internals/CooperativeArchitecture/#the-lookahead-protocol","title":"The Lookahead Protocol","text":"<p>The core concept is Intent-Based I/O. Solvers (CPU/GPU) declare their memory access patterns before starting computation. The I/O subsystem uses these hints to optimize data placement (prefetching, caching, pinning).</p>"},{"location":"internals/CooperativeArchitecture/#1-memory-hints","title":"1. Memory Hints","text":"<p>Defined in <code>include/pycauset/core/MemoryHints.hpp</code>.</p> Pattern Description I/O Action <code>Sequential</code> Reading 0..N Prefetch contiguous pages. <code>Strided</code> Reading columns Scatter-gather prefetch (Windows) or batched <code>madvise</code> (Linux). <code>Random</code> Graph traversal (Future) Load hot pages based on index. <code>Once</code> Stream processing Prefetch + Auto-Discard."},{"location":"internals/CooperativeArchitecture/#2-component-interaction","title":"2. Component Interaction","text":"<ol> <li>Solver: Analyzes the operation (e.g., Matrix Multiplication).</li> <li>Solver: Calls <code>matrix-&gt;hint(MemoryHint::strided(...))</code>.</li> <li>PersistentObject: Forwards hint to <code>IOAccelerator</code>.</li> <li>IOAccelerator: Translates hint to OS-specific syscalls (<code>PrefetchVirtualMemory</code> / <code>madvise</code>).</li> <li>Solver: Executes computation (now with fewer page faults).</li> </ol>"},{"location":"internals/CooperativeArchitecture/#implementation-status","title":"Implementation Status","text":""},{"location":"internals/CooperativeArchitecture/#phase-1-core-definitions-complete","title":"Phase 1: Core Definitions (Complete)","text":"<ul> <li><code>MemoryHint</code> struct defined.</li> <li><code>PersistentObject::hint()</code> API added.</li> <li><code>IOAccelerator::process_hint()</code> stub added (handles <code>Sequential</code>).</li> </ul>"},{"location":"internals/CooperativeArchitecture/#phase-2-io-intelligence-complete","title":"Phase 2: I/O Intelligence (Complete)","text":"<ul> <li>Implemented <code>Strided</code> support in <code>IOAccelerator</code>.</li> <li>Added <code>prefetch_ranges_impl</code> for Windows (using <code>PrefetchVirtualMemory</code> with scatter-gather lists) and Linux (batched <code>madvise</code>).</li> <li>Verified with unit tests.</li> </ul>"},{"location":"internals/CooperativeArchitecture/#phase-3-solver-integration-complete","title":"Phase 3: Solver Integration (Complete)","text":"<ul> <li>Updated <code>CpuSolver::matmul_impl</code> to emit hints.<ul> <li>Detects Transposed matrices and emits <code>Strided</code> hints.</li> <li>Emits <code>Sequential</code> hints for standard access.</li> </ul> </li> <li>Verified compilation and linking.</li> </ul>"},{"location":"internals/CooperativeArchitecture/#phase-4-pinned-memory-complete","title":"Phase 4: Pinned Memory (Complete)","text":"<ul> <li>Implemented \"Pinning Budget\" in <code>MemoryGovernor</code>.<ul> <li><code>try_pin_memory(size)</code>: Atomic check-and-reserve.</li> <li><code>unpin_memory(size)</code>: Release budget.</li> <li>Default Limit: 20% of RAM or 4GB (whichever is smaller).</li> </ul> </li> <li>Verified with <code>test_memory_governor.cpp</code>.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/","title":"DType / Complex / Overflow Plan (Implementation)","text":"<p>Status (2025-12-16): This implementation plan is complete. Phase 1 complete; Phase 2 complete (int8/int16/int32/int64 + uint8/uint16/uint32/uint64 + float16 end-to-end); Phase 3 complete (complex floats are now first-class end-to-end on CPU for the current core-op surface); Phase 4 complete (support matrix declared + enforced in tests/tools). Optional backlog items are still listed below.</p>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#scope-update-2025-12","title":"Scope update (2025-12)","text":"<p>This plan originally sketched \u201ccomplex permutations for all base dtypes\u201d (including <code>complex int*</code> and <code>complex bit</code>).</p> <p>Current project direction: complex support is limited to complex floats only (<code>complex_float16</code>, <code>complex_float32</code>, <code>complex_float64</code>). Complex permutations of non-float dtypes (<code>complex int*</code> / <code>complex bit</code>) are a non-goal by design due to high implementation surface area (promotion/overflow/kernels/persistence/tests) with low practical payoff for PyCauset\u2019s workloads.</p> <p>As a result: - Phase 2 includes first-class <code>float16</code> as a general dtype, plus the full signed/unsigned integer width set. - Phase 3 (complex) should be interpreted as \u201ccomplex float integration\u201d, with <code>complex_float16</code> implemented after <code>float16</code> readiness.</p>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-completion-status","title":"Phase completion status","text":"<ul> <li>Phase 0 \u2014 Documentation &amp; policy grounding: Complete</li> <li>Phase 1 \u2014 Centralize promotion + overflow policies: Complete</li> <li>Phase 2 \u2014 Scalar system expansion: Complete (int8/int16/int32/int64, uint8/uint16/uint32/uint64, float16 end-to-end through factories/promotion/CPU dispatch/persistence/bindings/NumPy for the core op surface)</li> <li>Phase 3 \u2014 Complex system integration: Complete (complex_float16/32/64 are first-class dtypes through factories/promotion/CPU dispatch/persistence/bindings/NumPy for core ops)</li> <li>Phase 4 \u2014 Coverage enforcement: Complete (support matrix declared + enforced in tests/tools)</li> </ul> <p>This file is an implementation plan. The authoritative dtype behavior documentation lives in:</p> <ul> <li><code>documentation/internals/DType System.md</code></li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#0-problem-statement","title":"0) Problem statement","text":"<p>PyCauset supports several fundamentally different scalar/storage types (bit-packed <code>bit</code>, integers, floats) plus a partially-separate complex system. Adding a new operation currently requires touching multiple layers and remembering many dtype-specific corner cases:</p> <ul> <li>type/promotion rules are split between global helpers and per-op frontends,</li> <li>CPU kernels often dispatch on \u201cresult dtype\u201d and omit some types,</li> <li>complex numbers are currently not a first-class <code>MatrixBase</code> dtype and therefore drift from the main dispatch/type-resolution path,</li> <li>missing coverage is easy to ship because there is no single enforceable \u201csupport matrix\u201d.</li> </ul> <p>This document proposes a new, centralized dtype architecture that:</p> <ul> <li>makes complex floats first-class in the scalar type system,</li> <li>adds multiple integer widths (signed/unsigned),</li> <li>defines explicit promotion + overflow policies,</li> <li>keeps the \u201canti-promotion / smallest type\u201d ethos,</li> <li>keeps performance and out-of-core constraints as first-class concerns.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#1-key-constraints-from-project-philosophy-recent-decisions","title":"1) Key constraints (from project philosophy + recent decisions)","text":"<ul> <li>Scale-first: matrices may be 100GB+; memory blowups are unacceptable.</li> <li>Underpromotion default: when PyCauset underpromotes, it means compute and result storage both use the smallest selected dtype.</li> <li>No silent widening for accuracy: no hidden \u201ccompute in float64 then downcast\u201d in the default path.</li> <li>Bit matrices are numeric for arithmetic ops: treat <code>bit</code> values as 0/1 numeric values for arithmetic ops (e.g., <code>+</code>, <code>*</code>, <code>dot</code>, <code>matmul</code>). Bitwise ops are explicit and must preserve bit-packed storage.</li> <li>Overflow behavior: integer overflow is a runtime error. PyCauset does not auto-promote to avoid overflow.</li> <li>Overflow warning: for large integer matmul, run a worst-case bound preflight and emit a warning when overflow looks plausible.</li> <li>Complex floats are first-class: complex support is limited to float base dtypes.</li> <li><code>complex_float32</code> / <code>complex_float64</code> are BLAS-backed where applicable (native complex types <code>complex64</code> / <code>complex128</code>).</li> <li><code>complex_float16</code> is implemented as a first-class dtype using a two-plane float16 storage model.</li> <li>Complex non-floats are a non-goal: <code>complex int*</code> / <code>complex bit</code> are intentionally unsupported to avoid a large promotion/overflow/kernel/persistence surface area with low payoff.</li> <li>Fundamental-kind rule (bit/int/float): PyCauset never \u201cpromotes down\u201d across fundamental kinds. If an operation mixes kinds, the result kind is the higher kind required by the operation\u2019s semantics.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#2-terminology","title":"2) Terminology","text":"<ul> <li>Scalar type: the per-element numeric type (bit/int/float plus width and flags).</li> <li>Matrix structure: dense/triangular/symmetric/etc. (storage layout and indexing constraints).</li> <li>Operation (op): add/subtract/elementwise multiply/matmul/inverse/eigvals/etc.</li> <li>Promotion policy: rules for selecting result dtypes for mixed-input ops.</li> <li>Overflow policy: what happens when integer arithmetic overflows.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#3-proposed-scalar-type-model-flagspermutations","title":"3) Proposed scalar type model (flags/permutations)","text":"<p>Represent scalar types as:</p> <ul> <li><code>kind</code>: <code>bit | int | float</code></li> <li><code>width_bits</code>: for int/float (8/16/32/64), and 1 for bit</li> <li><code>flags</code>: a small set of orthogonal modifiers</li> <li><code>complex</code> (supported for float scalar types only)</li> <li><code>unsigned</code> (valid only for <code>int</code>)</li> </ul> <p>Examples:</p> <ul> <li><code>bit</code> = (bit, 1, {})</li> <li><code>int16</code> = (int, 16, {})</li> <li><code>uint16</code> = (int, 16, {unsigned})</li> <li><code>float16</code> = (float, 16, {})</li> <li><code>complex float16</code> = (float, 16, {complex})</li> <li><code>float32</code> = (float, 32, {})</li> <li><code>complex float32</code> (<code>complex64</code>) = (float, 32, {complex})</li> <li><code>float64</code> = (float, 64, {})</li> <li><code>complex float64</code> (<code>complex128</code>) = (float, 64, {complex})</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#supported-scalar-set-initial-target","title":"Supported scalar set (initial target)","text":"<ul> <li>bit</li> <li>int8/int16/int32/int64</li> <li>uint8/uint16/uint32/uint64</li> <li>float16/float32/float64</li> <li>complex_float16/complex_float32/complex_float64</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#4-complex-implementation-strategy","title":"4) Complex implementation strategy","text":""},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#41-complex-floats-performance-path","title":"4.1 Complex floats (performance path)","text":"<ul> <li>Implement <code>complex_float32</code> (<code>complex64</code>) and <code>complex_float64</code> (<code>complex128</code>) as true complex numeric types.</li> <li>Prefer BLAS-backed complex GEMM where applicable.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#42-complex-float16-two-plane-storage-path","title":"4.2 Complex float16 (two-plane storage path)","text":"<ul> <li>Represent <code>complex_float16</code> as two float16 planes (real + imag).</li> <li>Motivation: there is no ubiquitous, efficient \u201cnative complex half\u201d representation across the stack, and forcing complex-half into complex-float32 would violate the \u201csmallest type\u201d ethos.</li> <li>Persistence must round-trip as a single complex dtype (one logical object, two payload planes).</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#43-explicit-non-goals","title":"4.3 Explicit non-goals","text":"<ul> <li>Complex permutations of non-float dtypes (<code>complex int*</code>, <code>complex bit</code>) are intentionally out of scope.</li> <li>If/when we ever revisit this, it must be driven by concrete workloads and come with a scoped support matrix (ops \u00d7 dtype) rather than a blanket \u201cclosure\u201d rule.</li> </ul> <p>This plan does not assume automatic widening in integer matmul. Under the current policy:</p> <ul> <li>integer overflow throws, and</li> <li>the system does not silently widen storage to avoid overflow.</li> </ul> <p>If we ever decide that a particular op\u2019s semantic result dtype must be wider (e.g., a count-producing op), that must be a named, explicit promotion rule and must be documented as semantics, not an overflow workaround.</p>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#5-promotion-policy-centralized-op-specific","title":"5) Promotion policy (centralized, op-specific)","text":"<p>Create a single authoritative table/function:</p> <ul> <li><code>resolve_result_scalar(op, a_scalar, b_scalar) -&gt; scalar</code></li> <li><code>resolve_result_structure(op, a_structure, b_structure) -&gt; structure</code></li> </ul> <p>Design principles:</p> <ul> <li>Default to the smallest dtype that can represent the result per op semantics.</li> <li>Mixed float precision underpromotes by default (compute+store in the smaller float), with a configurable option to promote instead.</li> <li>Complex is a flag: complex-ness is preserved unless an op is explicitly defined to drop it.</li> <li>Unsigned is preserved where meaningful; if an op can generate negatives, rules must define whether to promote to signed or throw.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#51-fundamental-kinds-bit-int-float-and-no-promote-down","title":"5.1 Fundamental kinds (bit / int / float) and \u201cno promote down\u201d","text":"<p>PyCauset distinguishes three fundamental kinds:</p> <ul> <li><code>bit</code> (bit-packed boolean storage; special rules allowed)</li> <li><code>int</code> (signed/unsigned integers)</li> <li><code>float</code> (float16/float32/float64)</li> </ul> <p>Rules:</p> <p>1) No promote down across kinds. If kinds differ, the result kind cannot be the \u201clower\u201d kind. 2) When a float participates, the result kind is float. Example: <code>matmul(bit, float64) -&gt; float64</code>. 3) When only integers/bits participate, the result kind is integer unless the op is explicitly bitwise. 4) Underpromotion applies within a kind, not across kinds. Example: <code>matmul(float32, float64) -&gt; float32</code> by default.</p> <p>This strikes a balance:</p> <ul> <li>it preserves the \u201csmallest type\u201d ethos where it is meaningful (within float precision),</li> <li>it avoids absurd outcomes like underpromoting a float computation to bit storage,</li> <li>it keeps <code>bit</code> special (bitwise ops remain bitwise; numeric ops may change kind).</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#52-bit-is-special-scale-first-exceptions","title":"5.2 Bit is special (scale-first exceptions)","text":"<p>Bit matrices/vectors are used to represent large binary structures (e.g., spacetime relations) where the storage is often 10s\u2013100s of GB.</p> <p>As a result:</p> <ul> <li>Bitwise ops (e.g., NOT/AND/OR/XOR) should preserve <code>bit</code> and stay bit-packed.</li> <li>Numeric ops that inherently create non-binary results (e.g., <code>bit + bit</code>, <code>matmul(bit, bit)</code> producing integer counts) may require widening to <code>int</code> or <code>float</code>.</li> </ul> <p>For such numeric ops, widening can be prohibitively expensive. Therefore, for <code>bit</code> we allow explicit, op-specific behavior:</p> <ul> <li>supported with a documented widening result kind, or</li> <li>error-by-design unless the user explicitly requests a widened dtype.</li> </ul> <p>The support matrix must record which choice is made for each op.</p> <p>Config hooks:</p> <ul> <li><code>promotion_policy.float_mixed</code>: <code>underpromote_warn</code> (default) | <code>promote</code> | <code>underpromote_no_warn</code></li> </ul> <p>Warning controls (exact API TBD, but must exist):</p> <ul> <li><code>warning_policy.float_underpromotion</code>: on by default when <code>promotion_policy.float_mixed=underpromote_warn</code></li> <li><code>warning_policy.int_reduction_acc_widen</code>: on by default; emitted when <code>dot</code>/<code>matmul</code> widens the accumulator dtype</li> <li><code>warning_policy.int_overflow_risk_preflight</code>: on by default for \u201clarge\u201d integer matmul; emitted when conservative bounds indicate plausible overflow in the requested output dtype</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#6-overflow-policy","title":"6) Overflow policy","text":""},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#61-runtime-behavior","title":"6.1 Runtime behavior","text":"<ul> <li>Overflow is a hard error.</li> <li>PyCauset does not auto-promote storage to avoid overflow.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#611-why-this-focuses-on-integer-overflow-and-not-float-overflow","title":"6.1.1 Why this focuses on integer overflow (and not float overflow)","text":"<p>Floating-point overflow is real (e.g., float32 can overflow to <code>+inf</code>), but it behaves differently:</p> <ul> <li>IEEE-754 overflow typically becomes <code>inf</code> (and may raise a floating-point flag), which then propagates.</li> <li>This is often detectable after-the-fact (e.g., <code>isfinite</code> checks), whereas integer overflow in C++ can be undefined behavior or silent wrap depending on the implementation.</li> </ul> <p>Policy-wise:</p> <ul> <li>For integers: overflow must throw (no silent wrap).</li> <li>For floats: overflow results in <code>inf</code>/<code>nan</code> according to IEEE-754; optional \u201cfinite-check\u201d validation can exist as a debug/strict mode, but it is not the default because scanning 100GB+ outputs is expensive.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#62-preflight-warning-for-large-integer-matmul","title":"6.2 Preflight warning for large integer matmul","text":"<p>For integer matmul (and potentially some other high-risk ops), run a cheap preflight to estimate overflow risk:</p> <p>1) sample blocks/rows to estimate <code>max_abs(A)</code> and <code>max_abs(B)</code> (including scalar metadata factors if they apply) 2) compute a conservative bound:</p> \\[\\max |C_{ij}| \\le K \\cdot \\max|A| \\cdot \\max|B|\\] <p>Where \\(K\\) is the inner dimension (for square matmul, \\(K=N\\)).</p> <p>If the bound approaches/exceeds the target dtype max value, emit a warning:</p> <ul> <li><code>PyCausetWarning: matmul(&lt;lhs_dtype&gt;, &lt;rhs_dtype&gt;) may overflow &lt;out_dtype&gt; (conservative bound). Consider requesting a wider output dtype or scaling.</code></li> </ul> <p>Notes:</p> <ul> <li>This is a heuristic. It should warn on risk; it does not guarantee overflow will happen.</li> <li>It avoids inner-loop overflow checks in the performance-critical kernel.</li> </ul> <p>Documentation requirement:</p> <ul> <li>Add an \u201cOverflow\u201d section/doc describing the policy, the preflight warning, and user mitigations.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#63-reduction-aware-accumulator-width-dotmatmul-required-warning","title":"6.3 Reduction-aware accumulator width (dot/matmul) + required warning","text":"<p>Some integer reductions (especially <code>dot</code>/<code>matmul</code>) can overflow the accumulator even when inputs are representable and the requested output dtype is unchanged.</p> <p>To keep integer math defined and to uphold \u201coverflow throws\u201d without requiring expensive per-multiply-add overflow checks inside the hot loop, PyCauset uses a reduction-aware accumulator width for integer reductions.</p> <p>Key clarifications (scale-first):</p> <ul> <li>This rule is about the accumulator dtype (compute registers / local scratch), not about materializing inputs.</li> <li>In particular, <code>bit</code> inputs stay bit-packed; <code>matmul(bit, int16)</code> does not expand the <code>bit</code> matrix to <code>int32</code> elements.</li> <li>This rule does not silently widen the result storage dtype. If the user requests <code>int16</code> output, the result is stored as <code>int16</code> and overflow remains a hard error (typically detected at the final cast from the wider accumulator).</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#631-accumulator-width-selection-deterministic-conservative","title":"6.3.1 Accumulator-width selection (deterministic / conservative)","text":"<p>For <code>matmul</code>/<code>dot</code> over integer kinds (including <code>bit</code> treated as numeric 0/1), choose an accumulator dtype wide enough that the worst-case bound for the reduction fits.</p> <p>For <code>C = A @ B</code> with inner dimension <code>K</code>:</p> <ul> <li>Use a conservative magnitude bound based on dtype limits (no sampling required):</li> </ul> \\[\\max |C_{ij}| \\le K \\cdot \\max|A| \\cdot \\max|B|\\] <ul> <li>For <code>bit</code>, \\(\\max|A| = 1\\).</li> </ul> <p>For integer dtypes, \\(\\max|A|\\) and \\(\\max|B|\\) may be taken as the maximum representable magnitude for their dtypes (e.g., for <code>int16</code>, 32767). This is conservative and ensures accumulator selection is correctness-preserving without needing an extra pass over out-of-core data.</p> <p>This is intentionally conservative: it is designed to be computed cheaply and to be correct without relying on probabilistic assumptions.</p> <p>Optionally (future optimization): when it is cheap relative to the matmul itself and does not force an extra out-of-core pass, tighten the bound using exact streaming summaries such as row popcounts for <code>bit</code> and per-column max-abs for the integer operand.</p>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#632-user-visible-warning-required","title":"6.3.2 User-visible warning (required)","text":"<p>Whenever the chosen accumulator dtype is wider than what a reader would naively expect from the inputs (e.g., <code>matmul(bit, int16)</code> accumulating into <code>int32</code>), PyCauset must emit a warning so users understand what is happening.</p> <p>The warning must include:</p> <ul> <li>operation name (e.g., <code>matmul</code> / <code>dot</code>)</li> <li>lhs dtype and rhs dtype</li> <li>chosen accumulator dtype</li> <li>output storage dtype (explicitly stating whether it changed or not)</li> <li>reason (reduction-aware widening to keep integer overflow defined)</li> </ul> <p>Suggested warning text (exact wording not required, but content is):</p> <ul> <li><code>PyCausetWarning: matmul(bit, int16) will accumulate in int32 (reduction-aware integer width). Output dtype remains int16; overflow still throws on cast. Bit input remains bit-packed (no materialization).</code></li> </ul> <p>Noise control:</p> <ul> <li>Warn once per call site (or once per unique <code>(op, lhs_dtype, rhs_dtype, out_dtype, acc_dtype)</code> tuple) to avoid spam.</li> <li>Provide a user-facing way to silence/route warnings (Python <code>warnings.warn(...)</code> category, and/or a context flag).</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#7-enforceable-op-coverage-support-matrix","title":"7) Enforceable op coverage (\u201csupport matrix\u201d)","text":"<p>Introduce an explicit coverage matrix that enumerates for each operation:</p> <ul> <li>required scalar families (bit/int/float + complex)</li> <li>supported widths</li> <li>supported structures (dense/triangular/symmetric/etc.)</li> <li>required behaviors (defined, error-by-design, or unimplemented)</li> </ul> <p>Goal:</p> <ul> <li>When a new op is added, missing dtype coverage becomes a failing test/tool run, not a surprise at runtime.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#8-implementation-sequence-phased","title":"8) Implementation sequence (phased)","text":""},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-0-documentation-policy-grounding-complete","title":"Phase 0 \u2014 Documentation &amp; policy grounding (Complete)","text":"<ul> <li>Update project philosophy to explicitly define underpromotion and overflow behavior.</li> <li>Add roadmap entry for multi-int widths + unsigned.</li> <li>Add this plan doc.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-1-centralize-promotion-overflow-policies-complete","title":"Phase 1 \u2014 Centralize promotion + overflow policies (Complete)","text":"<ul> <li>Single promotion resolver per op.</li> <li>Central overflow policy + preflight warning for integer matmul.</li> <li>Reduction-aware accumulator width for integer <code>dot</code>/<code>matmul</code> + required user warning when accumulator widens.</li> <li>Add mandatory tests for resolver correctness, warning emission, and reduction accumulator selection (see \u201cMandatory tests\u201d).</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-2-scalar-system-expansion-complete","title":"Phase 2 \u2014 Scalar system expansion (Complete)","text":"<ul> <li>Add integer widths + unsigned.</li> <li>Ensure constructors, IO, numpy interop, and basic ops exist.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-3-complex-system-integration-complete","title":"Phase 3 \u2014 Complex system integration (Complete)","text":"<ul> <li>Core complex-float dtype integration is implemented (CPU + persistence + Python/NumPy for key ops).</li> <li>See \u201cPhase 3 \u2014 Complex system integration (Detailed)\u201d in Section 8.1.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-4-coverage-enforcement-complete","title":"Phase 4 \u2014 Coverage enforcement (Complete)","text":"<ul> <li>Support matrix exists and is executed by unit tests and a dev checker tool, so declared support can\u2019t silently regress.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#81-phase-3-complex-system-integration-detailed","title":"8.1) Phase 3 \u2014 Complex system integration (Detailed)","text":"<p>Objective: Make complex float dtypes first-class and integrate them into the same end-to-end pipeline as real dtypes (frontend allocation \u2192 promotion resolver \u2192 CPU/GPU dispatch \u2192 persistence \u2192 Python).</p> <p>User-facing requirement: complex float dtypes must behave like normal dtypes on the frontend. For example, <code>pc.complex_float16</code> (or equivalent public token) must be a valid <code>dtype=</code> argument to <code>Matrix</code>/<code>Vector</code> factories.</p> <p>Scope for Phase 3: expand complex support to float base dtypes only:</p> <ul> <li><code>float16</code> \u2192 <code>complex_float16</code> (two float16 planes)</li> <li><code>float32</code> \u2192 <code>complex_float32</code> (a.k.a. <code>complex64</code>)</li> <li><code>float64</code> \u2192 <code>complex_float64</code> (a.k.a. <code>complex128</code>)</li> </ul> <p>Out of scope: complex permutations of non-float dtypes (<code>complex int*</code>, <code>complex bit</code>).</p>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#3x-phase-3-status-update-2025-12-16","title":"3.x Phase 3 status update (2025-12-16)","text":"<p>Completed in the current codebase:</p> <ul> <li>First-class complex float dtypes exist end-to-end: <code>complex_float16/32/64</code>.</li> <li>Storage:</li> <li><code>complex_float32/64</code>: dense storage uses native complex element types.</li> <li><code>complex_float16</code>: two-plane float16 storage (real+imag) for both matrices and vectors.</li> <li>Dispatch/promotion:</li> <li>promotion resolver supports complex results for matmul/add/sub/elementwise, plus dot/matvec/vecmat/outer.</li> <li>CPU solver contains complex implementations for dot/matvec/vecmat/outer and vector elementwise/scalar ops.</li> <li>Python/NumPy/persistence:</li> <li>dtype tokens + factory inference + <code>np.array(...)</code> interop + container persistence round-trip.</li> <li>dot returns Python <code>complex</code> when either operand is complex.</li> </ul> <p>Optional backlog (not required for plan completion):</p> <ul> <li>Ensure solver/eigensystem outputs use first-class complex dtypes end-to-end (no parallel complex object model).</li> <li>BLAS/cBLAS complex GEMM path for dense complex matmul on CPU (and GPU complex where applicable).</li> <li>Expand complex coverage across additional operations beyond the current core set.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#30-replace-legacy-complexmatrix-complexvector-compat-layer","title":"3.0 Replace legacy <code>ComplexMatrix</code> / <code>ComplexVector</code> (compat layer)","text":"<p>Current state (updated 2025-12-16):</p> <ul> <li>First-class complex float matrices/vectors now exist as <code>MatrixBase</code>/<code>VectorBase</code> dtypes (<code>complex_float16/32/64</code>).</li> <li>The legacy <code>ComplexMatrix</code> / <code>ComplexVector</code> concept may still exist in some solver/eigensystem return paths.   That legacy path is now considered technical debt (it drifts from the first-class dtype pipeline).</li> </ul> <p>Plan (still valid):</p> <ul> <li>Ensure any remaining solver/eigensystem paths route through first-class complex dtype matrices/vectors.</li> <li>Long-term goal: complex is a normal <code>MatrixBase</code>/<code>VectorBase</code> dtype, so <code>LinearAlgebra</code> and <code>ComputeDevice</code> don\u2019t need a parallel complex universe.</li> </ul> <p>Frontend contract note:</p> <ul> <li>Provide explicit dtype tokens for complex floats (at minimum: <code>complex_float16</code>, <code>complex_float32</code>, <code>complex_float64</code>).</li> <li>These tokens must normalize through the same dtype normalization funnel as real dtypes and participate in the same factory code paths.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#31-make-complex-first-class-in-the-scalar-type-model","title":"3.1 Make \u201ccomplex\u201d first-class in the scalar type model","text":"<p>Requirement: represent scalar types as <code>(kind, width_bits, flags)</code> where <code>flags</code> includes at least <code>{complex, unsigned}</code>.</p> <p>Implementation direction:</p> <ul> <li>Introduce a <code>ScalarType</code> descriptor (or equivalent) that can represent:</li> <li>base dtype (<code>float16/float32/float64</code>)</li> <li>flags (<code>complex</code>)</li> <li>Plumb this through the type-resolution path so promotion is defined as:</li> <li><code>resolve_result_scalar(op, a_scalar, b_scalar) -&gt; scalar</code></li> </ul> <p>Design constraint (to match the frontend requirement):</p> <ul> <li>Even though complex can be represented as <code>(base_dtype + complex flag)</code>, it must be treated as a distinct dtype identity for:</li> <li>promotion resolution,</li> <li>dispatch selection,</li> <li>persistence metadata,</li> <li>and the support-matrix enforcement (coverage must be tracked per complex permutation).</li> </ul> <p>Back-compat note:</p> <ul> <li>The existing <code>DataType</code> enum can remain as a legacy base-type id during migration, but Phase 3 must ensure complex-ness is not \u201cout-of-band\u201d anymore.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#32-storage-strategy-for-complex-by-base-kind","title":"3.2 Storage strategy for complex (by base kind)","text":"<p>We intentionally use two different representations depending on the float width, to balance performance and scale-first storage efficiency.</p>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#321-complex-floats-performance-path","title":"3.2.1 Complex floats (performance path)","text":"<ul> <li><code>complex_float32</code> (<code>complex64</code>) and <code>complex_float64</code> (<code>complex128</code>) are true complex numeric types.</li> <li>Implement dense complex storage as contiguous <code>std::complex&lt;float&gt;</code> / <code>std::complex&lt;double&gt;</code> (or ABI-compatible equivalent).</li> <li>Route matmul to BLAS complex GEMM where possible.</li> <li>GPU: use cuBLAS complex GEMM when available.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#322-complex-float16-two-plane-storage-path","title":"3.2.2 Complex float16 (two-plane storage path)","text":"<ul> <li>Represent <code>complex_float16</code> as two float16 planes of equal shape:</li> <li>real plane: <code>float16</code></li> <li>imag plane: <code>float16</code></li> <li>Motivation: avoid forcing half-precision complex values into float32 complex storage, and avoid depending on a non-portable \u201cnative complex half\u201d ABI.</li> </ul> <p>Important clarification:</p> <ul> <li>\u201cTwo-plane storage\u201d is an implementation detail. The object is still a single complex-typed matrix/vector from the API perspective, and it must round-trip via persistence as a complex dtype (not as two unrelated real objects).</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#33-first-class-complex-matricesvectors-in-the-core-object-model","title":"3.3 First-class complex matrices/vectors in the core object model","text":"<p>Hard requirement: complex objects must participate in factories, persistence, and dispatch the same way other dtypes do.</p> <p>Minimum deliverables:</p> <ul> <li>A <code>MatrixBase</code>-derived complex matrix implementation for:</li> <li><code>complex_float32</code> / <code>complex_float64</code> (dense)</li> <li><code>complex_float16</code> (two-plane storage)</li> <li>A <code>VectorBase</code>-derived complex vector implementation (same split).</li> </ul> <p>Interface hazards to address explicitly (to avoid \u201cbiting us later\u201d):</p> <ul> <li>Many existing code paths use <code>get_element_as_double(...)</code>. For complex dtypes, this must never silently drop the imaginary part.</li> <li>Either implement <code>get_element_as_double</code> as a hard error for complex matrices, or ensure it is only used behind a \u201creal-only\u201d guard.</li> <li>Complex-aware paths must use <code>get_element_as_complex(...)</code>.</li> <li><code>ComputeDevice::multiply_scalar</code> currently takes <code>double</code>; Phase 3 must define the complex-scalar story:</li> <li>either add complex-scalar device entry points, or</li> <li>restrict complex-scalar multiply to frontend methods that dispatch to complex kernels.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#34-operation-coverage-policy-for-complex","title":"3.4 Operation coverage policy for complex","text":"<p>Phase 3 does not require \u201cevery op supports every complex dtype\u201d on day one, but it must make coverage enforceable:</p> <ul> <li>For each op in the canonical LinearAlgebra surface (at least <code>LinearAlgebra.hpp</code>):</li> <li>declare complex propagation rules (preserve complex, drop complex, or error-by-design)</li> <li>declare result dtype selection rules (including for <code>bit</code> special cases)</li> <li>Ensure the resolver has explicit rows for complex permutations.</li> </ul> <p>Coverage principle (mathematical independence):</p> <ul> <li>Complex permutations must be treated as separate coverage targets even when they reuse plane-wise kernels.</li> <li>\u201cWorks because it decomposes into two real ops\u201d is not a substitute for tests: each complex dtype/op combination must be explicitly tested (or explicitly error-by-design with a stable error).</li> </ul> <p>Specific expectations:</p> <ul> <li><code>complex_float32/complex_float64</code>:</li> <li><code>add/sub/elementwise/matmul</code> must work on CPU.</li> <li>GPU support is optional, but routing must be correct (fallback to CPU when unsupported).</li> <li><code>complex_float16</code>:</li> <li><code>add/sub/elementwise/matmul</code> must work on CPU.</li> <li>if implemented via two-plane arithmetic, correctness must be validated vs NumPy complex computations.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#35-persistence-format-for-complex","title":"3.5 Persistence format for complex","text":"<p>Current implementation note (updated 2025-12-16):</p> <ul> <li><code>complex_float16</code> uses a two-plane in-memory layout (real + imag), but is persisted as a single contiguous raw payload containing both planes back-to-back.</li> <li>Typed metadata records the dtype identity (<code>complex_float16</code>) and the normal shape/layout fields; there is no need for multi-member payloads to round-trip correctly.</li> </ul> <p>Future option (not required for correctness):</p> <ul> <li>Multi-member payloads could still be introduced later for tooling/inspection convenience, but would be an on-disk format enhancement rather than a correctness requirement.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#36-gpucpu-selection-policy","title":"3.6 GPU/CPU selection policy","text":"<p>Match project intent:</p> <ul> <li>Default behavior: benchmark/poll hardware once, then pick the fastest device.</li> <li>If GPU does not support a dtype/op/structure, fall back to CPU.</li> <li>Avoid exploding \u201cone kernel per infinitesimal device\u201d by using:</li> <li>a small set of coarse regimes (dtype/shape thresholds)</li> <li>a micro-benchmark-derived speedup factor</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#37-tests-keep-the-explosion-under-control","title":"3.7 Tests (keep the explosion under control)","text":"<p>The only way this stays maintainable is if we separate:</p> <ul> <li>pure-logic resolver tests (exhaustive across dtype permutations), from</li> <li>kernel correctness tests (representative shapes), from</li> <li>error-by-design tests (stable error messages).</li> </ul> <p>Phase 3 must add a minimal \u201ccomplex smoke matrix\u201d for the LinearAlgebra surface:</p> <ul> <li><code>complex_float64</code>: add/sub/elementwise/matmul correctness vs NumPy</li> <li><code>complex_float32</code>: same, smaller shapes + tolerances</li> <li><code>complex_float16</code>: add/sub/elementwise/matmul correctness vs NumPy (two-plane storage) + persistence round-trip</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#9-mandatory-tests","title":"9) Mandatory tests","text":"<p>These tests are required. They exist to prevent dtype coverage drift and to catch correctness/performance regressions early.</p>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#91-pure-logic-dtype-resolution-tests","title":"9.1 Pure-logic dtype resolution tests","text":"<p>Add unit tests (no kernels) that exercise the resolver tables/functions. At minimum:</p> <ul> <li>Fundamental kind rule: never promote down across <code>bit -&gt; int -&gt; float</code>.</li> <li>Float underpromotion: e.g., <code>matmul(float32, float64) -&gt; float32</code> by default.</li> <li>Complex flag behavior: for each op, verify complex propagation/behavior is explicit (preserve/drop/error-by-design) and covered.</li> <li>Unsigned flag behavior: verify signed/unsigned mixing rules are explicit and tested.</li> <li>Error-by-design paths: verify they error with stable, specific messages.</li> </ul> <p>These tests should be table-driven and exhaustive across the supported dtype set for each resolver entry.</p>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#92-kernelintegration-correctness-tests","title":"9.2 Kernel/integration correctness tests","text":"<p>Add tests that validate numeric correctness and overflow behavior for representative ops and shapes:</p> <ul> <li><code>dot</code>/<code>matmul</code> integer correctness across widths.</li> <li>Overflow throws deterministically (no silent wrap).</li> </ul> <p>For reduction-aware accumulator widening specifically, add at least one test where:</p> <ul> <li><code>matmul(bit, int16)</code> (or <code>dot(bit, int16)</code>) produces a value that would overflow an <code>int16</code> accumulator but fits in <code>int32</code> output.</li> <li>The test asserts:</li> <li>correct numeric result,</li> <li>accumulator-widen warning is emitted and mentions: op name, lhs/rhs dtypes, accumulator dtype, and output dtype.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#93-warning-tests-user-facing-behavior","title":"9.3 Warning tests (user-facing behavior)","text":"<p>Add Python-level tests (and C++ tests where applicable) that validate warnings are:</p> <ul> <li>emitted when required,</li> <li>de-duplicated (warn-once policy),</li> <li>informative (message includes the dtypes involved and what is happening),</li> <li>suppressible/routable via a user-facing control.</li> </ul> <p>Warnings to cover:</p> <ul> <li>float underpromotion warning (if enabled)</li> <li>integer overflow-risk preflight warning (heuristic)</li> <li>integer reduction accumulator-widen warning (deterministic)</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#94-scale-first-regression-tests-bit-materialization-guard","title":"9.4 Scale-first regression tests (bit materialization guard)","text":"<p>Add a regression test that guards the key scale-first property for <code>bit</code> operands:</p> <ul> <li><code>bit</code> inputs must remain bit-packed during <code>dot</code>/<code>matmul</code> (no full materialization to an int/float element buffer).</li> </ul> <p>Implementation note (testability): this may require a test-only hook (e.g., allocation tracer, \u201cmaterialized_bit_elements\u201d counter, or a debug trace flag) so the test can assert that no allocation proportional to <code>A.numel() * sizeof(int32)</code> occurred.</p>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#95-support-matrix-completeness-test","title":"9.5 Support-matrix completeness test","text":"<p>The support matrix must be executable as a test/tool:</p> <ul> <li>It must fail CI if an op claims support for a dtype/structure/device combination that lacks an implementation or test coverage.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#10-acceptance-criteria","title":"10) Acceptance criteria","text":"<ul> <li>Adding a new operation requires changing:</li> <li>the op implementation,</li> <li>one promotion rule table,</li> <li>one coverage declaration,</li> <li> <p>tests.   It must not require \u201chunt across the codebase\u201d.</p> </li> <li> <p>Complex dtypes are supported for float base dtypes only (<code>complex_float16/32/64</code>).</p> </li> <li> <p>Overflow behavior is consistent:</p> </li> <li>overflow throws,</li> <li>large integer matmul emits a risk warning when appropriate,</li> <li>no auto-promotion to avoid overflow.</li> </ul>"},{"location":"internals/DTYPE_COMPLEX_OVERFLOW_PLAN/#11-open-questions-to-confirm-before-implementation","title":"11) Open questions (to confirm before implementation)","text":"<ul> <li>Exact list of supported ops for \u201ccore coverage\u201d in the support matrix (minimal set to enforce first).</li> <li>Whether unsigned + signed mixing rules should default to promoting to signed or throwing in ops that can go negative.</li> <li>Default behavior for numeric ops on <code>bit</code> when the semantic result is not representable in <code>bit</code> without widening: default widen vs error-by-design unless the caller explicitly requests an output dtype.</li> </ul>"},{"location":"internals/DType%20System/","title":"DType System (Scalar Kinds, Promotion, Overflow)","text":"<p>This document defines the dtype behavior of PyCauset for both matrices and vectors.</p> <p>The rules here are authoritative: if code behaves differently, the code is wrong and should be changed (or this document must be updated as part of an approved change).</p>"},{"location":"internals/DType%20System/#1-scalar-model","title":"1) Scalar model","text":"<p>Every stored element type is described by:</p> <ul> <li>kind: <code>bit</code> | <code>int</code> | <code>float</code></li> <li>width:</li> <li><code>bit</code>: width is 1</li> <li><code>int</code>: 8/16/32/64 (signed and unsigned)</li> <li><code>float</code>: 16/32/64</li> <li>flags:</li> <li><code>complex</code>: supported for float base dtypes only</li> <li><code>unsigned</code>: valid only for <code>int</code></li> </ul> <p>Examples:</p> <ul> <li><code>bit</code> (aka <code>bool</code> in the public Python API)</li> <li><code>int16</code>, <code>int32</code>, <code>int64</code></li> <li><code>uint16</code>, <code>uint32</code>, <code>uint64</code></li> <li><code>float16</code>, <code>float32</code>, <code>float64</code></li> <li><code>complex_float32</code> (a.k.a. <code>complex64</code>)</li> <li><code>complex_float64</code> (a.k.a. <code>complex128</code>)</li> </ul>"},{"location":"internals/DType%20System/#supported-scalar-set-current","title":"Supported scalar set (current)","text":"<ul> <li><code>bit</code> / <code>bool</code></li> <li><code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code></li> <li><code>uint8</code>, <code>uint16</code>, <code>uint32</code>, <code>uint64</code></li> <li><code>float16</code>, <code>float32</code>, <code>float64</code></li> <li><code>complex_float16</code>, <code>complex_float32</code>, <code>complex_float64</code></li> </ul> <p>Complex permutations of non-float dtypes (<code>complex int*</code>, <code>complex bit</code>) are intentionally unsupported.</p>"},{"location":"internals/DType%20System/#2-fundamental-kinds-and-the-no-promote-down-rule","title":"2) Fundamental kinds and the \u201cno promote down\u201d rule","text":"<p>PyCauset treats <code>bit</code>, <code>int</code>, and <code>float</code> as fundamental kinds.</p> <p>Rules:</p> <p>1) PyCauset never promotes down across fundamental kinds. 2) If a float participates, the result kind is float. 3) Underpromotion applies within a kind, not across kinds.</p> <p>Examples:</p> <ul> <li><code>matmul(bit, float64) -&gt; float64</code></li> <li><code>matmul(float32, float64) -&gt; float32</code> (default underpromotion within float)</li> </ul> <p>This prevents nonsensical outcomes like \u201ccompute a float matmul but store the result as bit\u201d.</p>"},{"location":"internals/DType%20System/#3-underpromotion-within-floats","title":"3) Underpromotion (within floats)","text":"<p>When PyCauset underpromotes, it means:</p> <ul> <li>compute happens in the selected smallest dtype, and</li> <li>storage uses that same dtype.</li> </ul> <p>There is no silent widening of intermediates \u201cfor accuracy\u201d in the default path.</p>"},{"location":"internals/DType%20System/#31-underpromotion-within-integers","title":"3.1) Underpromotion within integers","text":"<p>PyCauset applies the same ethos to integer widths as to floats: if an operation can be executed and stored in a smaller integer width, PyCauset will not silently widen \u201cfor safety\u201d.</p> <p>This is independent from overflow policy (see below): widening is a dtype/semantics decision; it is not an overflow workaround.</p>"},{"location":"internals/DType%20System/#4-complex-numbers","title":"4) Complex numbers","text":""},{"location":"internals/DType%20System/#41-complex-floats","title":"4.1 Complex floats","text":"<p>For float32/float64, complex dtypes are first-class numeric types:</p> <ul> <li><code>complex64</code> (complex float32)</li> <li><code>complex128</code> (complex float64)</li> </ul> <p>Where applicable, BLAS-backed complex kernels are used.</p> <p><code>complex_float16</code> is supported as a first-class dtype and is represented internally as a two-plane float16 storage model (real + imaginary).</p>"},{"location":"internals/DType%20System/#42-complex-non-floats-including-complex-bit","title":"4.2 Complex non-floats (including complex-bit)","text":"<p>Complex permutations of non-float dtypes are a non-goal by design.</p> <ul> <li><code>complex int*</code> and <code>complex bit</code> are not supported.</li> <li>Complex support is limited to complex floats.</li> </ul>"},{"location":"internals/DType%20System/#5-overflow","title":"5) Overflow","text":""},{"location":"internals/DType%20System/#51-integer-overflow","title":"5.1 Integer overflow","text":"<p>Integer overflow is a hard error.</p> <ul> <li>PyCauset does not silently wrap.</li> <li>PyCauset does not silently widen storage to avoid overflow.</li> </ul> <p>For high-risk ops such as large integer matmul, PyCauset may emit an advisory risk warning based on conservative bounds (see <code>PyCausetOverflowRiskWarning</code>).</p> <p>For integer reductions (e.g., <code>dot</code>/<code>matmul</code>), PyCauset may use a wider internal accumulator dtype to keep overflow behavior defined. This is a dtype-policy event (see <code>PyCausetDTypeWarning</code>), and overflow still throws when storing the final output.</p>"},{"location":"internals/DType%20System/#52-float-overflow","title":"5.2 Float overflow","text":"<p>Float overflow is possible (e.g., float32 can overflow to <code>inf</code>). PyCauset follows IEEE-754 semantics (<code>inf</code>/<code>nan</code>) by default.</p> <p>Optional \u201cstrict\u201d validation (e.g., finiteness checks) can exist, but it is not the default because scanning 100GB+ outputs is expensive.</p>"},{"location":"internals/DType%20System/#6-bit-is-special-scale-first-rules","title":"6) Bit is special (scale-first rules)","text":"<p>Bit matrices/vectors are used to store very large binary structures where widening is often infeasible.</p> <p>A key fact:</p> <ul> <li><code>bit</code> is 1 bit / element</li> <li><code>int32</code> is 32 bits / element (32\u00d7 larger)</li> <li><code>float64</code> is 64 bits / element (64\u00d7 larger)</li> <li>complex variants are typically 2\u00d7 the storage of their base dtype (two planes)</li> </ul> <p>So widening a 100GB bit dataset can easily become multi-terabyte storage.</p> <p>Because of that, every operation must explicitly declare its <code>bit</code> behavior as one of:</p> <ul> <li>bitwise: preserves <code>bit</code> and stays bit-packed</li> <li>numeric: produces non-binary results and therefore widens to <code>int</code>/<code>float</code></li> <li>error-by-design: for <code>bit</code> inputs, the operation throws unless the caller explicitly requests a widened dtype/output</li> </ul> <p>This declaration is part of the operation\u2019s contract (and is tested).</p>"},{"location":"internals/DType%20System/#7-signedunsigned-mixing","title":"7) Signed/unsigned mixing","text":"<p>Unsigned integers are supported (<code>uint8/16/32/64</code>).</p> <p>When mixing signed and unsigned integer operands, PyCauset selects a supported result dtype that can represent the required numeric range.</p> <p>Important consequences:</p> <ul> <li>Result dtypes are restricted to the supported widths (8/16/32/64). PyCauset will not invent intermediate 33-bit or 65-bit integers.</li> <li>Some mixed signed/unsigned operations will promote to the next wider signed integer type.</li> </ul> <p>Example (typical outcome):</p> <ul> <li><code>uint32 + int32 -&gt; int64</code></li> </ul>"},{"location":"internals/DType%20System/#8-support-matrix-enforcement","title":"8) Support matrix + enforcement","text":"<p>PyCauset's dtype coverage is declared and enforced via an executable support matrix (ops x dtypes x rank).</p> <ul> <li>The declared matrix lives in <code>pycauset._internal.support_matrix</code>.</li> <li>The enforcement test is <code>tests/python/test_support_matrix.py</code>.</li> </ul> <p>User-facing documentation should describe the intended behavior, but the support matrix is the no-regressions gate that ensures what is claimed is actually implemented.</p>"},{"location":"internals/LazyEvaluation/","title":"Lazy Evaluation &amp; Expression Templates","text":""},{"location":"internals/LazyEvaluation/#overview","title":"Overview","text":"<p>PyCauset implements Lazy Evaluation using C++ Expression Templates. This allows operations like <code>C = A + B + C</code> to be fused into a single evaluation pass, avoiding the creation of temporary matrices for intermediate results. This significantly reduces memory bandwidth usage and allocation overhead.</p>"},{"location":"internals/LazyEvaluation/#architecture","title":"Architecture","text":"<p>The system is built on the Curiously Recurring Template Pattern (CRTP).</p>"},{"location":"internals/LazyEvaluation/#core-components","title":"Core Components","text":"<ol> <li> <p><code>MatrixExpression&lt;Derived&gt;</code>: The base class for all lazy expressions. It provides the interface for:</p> <ul> <li><code>get_element(i, j)</code>: Computing the value at a specific index.</li> <li><code>rows()</code>, <code>cols()</code>: Dimension queries.</li> <li><code>aliases(target)</code>: Checking if the expression refers to a specific matrix (for aliasing safety).</li> <li><code>touch_operands()</code>: Updating the LRU status of source matrices (for memory safety).</li> </ul> </li> <li> <p>Expression Nodes:</p> <ul> <li><code>MatrixRefExpression</code>: A lightweight wrapper around a <code>const MatrixBase&amp;</code>. It is the leaf node of the expression tree.</li> <li><code>ScalarExpression</code>: Wraps a scalar value (double).</li> <li><code>BinaryExpression&lt;L, R, Op&gt;</code>: Represents a binary operation. Stores operands <code>L</code> and <code>R</code> by value (assuming they are lightweight expression objects) to prevent dangling references to temporary objects in chained expressions.</li> <li><code>UnaryExpression&lt;E, Op&gt;</code>: Represents a unary operation. Stores operand <code>E</code> by value.</li> </ul> </li> <li> <p>Functors:</p> <ul> <li>Located in <code>pycauset/matrix/expression/Functors.hpp</code>.</li> <li>Stateless structs with a static <code>apply</code> method (e.g., <code>ops::Add::apply(a, b)</code>).</li> </ul> </li> </ol>"},{"location":"internals/LazyEvaluation/#evaluation-model","title":"Evaluation Model","text":"<p>Evaluation is triggered only when an expression is assigned to a <code>MatrixBase</code> object via <code>operator=</code>.</p> <pre><code>// MatrixBase.hpp\ntemplate &lt;typename E&gt;\nMatrixBase&amp; operator=(const MatrixExpression&lt;E&gt;&amp; expr) {\n    // 1. Check for aliasing\n    if (expr.aliases(this)) {\n        throw std::runtime_error(\"Aliasing detected...\");\n    }\n\n    // 2. Touch operands (Memory Safety)\n    expr.touch_operands();\n\n    // 3. Evaluate\n    for (uint64_t i = 0; i &lt; rows(); ++i) {\n        for (uint64_t j = 0; j &lt; cols(); ++j) {\n            set_element_as_double(i, j, expr.get_element(i, j));\n        }\n    }\n    return *this;\n}\n</code></pre>"},{"location":"internals/LazyEvaluation/#memory-safety-the-spill-policy","title":"Memory Safety (The \"Spill\" Policy)","text":"<p>Lazy evaluation interacts with the <code>MemoryGovernor</code> to ensure that source matrices are not evicted from RAM while they are being read.</p> <ul> <li><code>touch_operands()</code>: Before the evaluation loop begins, the assignment operator calls <code>touch_operands()</code> on the expression tree. This recursively calls <code>touch()</code> on every <code>MatrixBase</code> referenced in the tree.</li> <li>LRU Update: <code>touch()</code> updates the timestamp of the matrix in the <code>MemoryGovernor</code>, moving it to the \"most recently used\" position. This protects it from being chosen for eviction if a spill is triggered during evaluation (e.g., if the destination matrix needs to allocate more storage).</li> </ul>"},{"location":"internals/LazyEvaluation/#windows-io-optimization","title":"Windows I/O Optimization","text":"<p>On Windows, the <code>IOAccelerator</code> uses <code>VirtualUnlock</code> to implement <code>discard()</code>. This serves as a hint to the OS to remove pages from the working set, similar to <code>madvise(MADV_DONTNEED)</code> on Linux. This is crucial for the \"RAM-First\" persistence policy, allowing us to effectively free RAM without closing the file handle.</p>"},{"location":"internals/LazyEvaluation/#limitations-future-work","title":"Limitations &amp; Future Work","text":"<ol> <li>Aliasing: Currently, assignments like <code>A = A + B</code> throw an exception to prevent unsafe aliasing. Future versions should implement temporary buffering or safe in-place evaluation for elementwise ops.</li> <li>Vectorization: The current evaluation loop is scalar. Future versions should implement <code>fill_buffer</code> in the expression interface to allow SIMD-optimized batch evaluation.</li> <li>Opaque Operations: Matrix multiplication (<code>A * B</code>) is currently eager. It returns a new <code>MatrixBase</code> immediately, rather than an expression.</li> </ol>"},{"location":"internals/Memory%20and%20Data/","title":"Memory &amp; Data Architecture","text":"<p>This document details the internal architecture of the Pycauset memory system, matrix/vector hierarchy, and type system.</p>"},{"location":"internals/Memory%20and%20Data/#1-memory-system-tiered-storage","title":"1. Memory System: Tiered Storage","text":"<p>PyCauset is designed to handle causal sets that exceed physical RAM. To achieve this, it adopts a tiered storage architecture where objects can live in RAM or be backed by files on disk.</p> <ul> <li>Persistence: Objects survive process termination if saved.</li> <li>Virtual Memory: The OS handles paging, allowing datasets larger than RAM.</li> <li>Interprocess Communication: Memory-mapped files allow multiple processes (e.g., a viewer and a solver) to share data with zero copy overhead.</li> </ul>"},{"location":"internals/Memory%20and%20Data/#the-persistentobject-base-class","title":"The <code>PersistentObject</code> Base Class","text":"<p>All matrix and vector classes inherit from <code>PersistentObject</code>.</p> <ul> <li><code>MemoryMapper</code>: A member object that handles the low-level <code>mmap</code> (Windows/Linux) calls.</li> <li>Lifecycle:<ul> <li>Creation: Creates a temporary file in the system temp directory (or a specified path).</li> <li>Access: Maps the file into the process's address space.</li> <li>Destruction: Unmaps the view. If the object was temporary, the file is deleted.</li> </ul> </li> </ul>"},{"location":"internals/Memory%20and%20Data/#snapshot-immutability-mutation-policy","title":"Snapshot immutability (mutation policy)","text":"<p>PyCauset distinguishes between:</p> <ul> <li>persisted <code>.pycauset</code> snapshots on disk, and</li> <li>runtime working copies that may be mutated.</li> </ul> <p>Policy (Release 1):</p> <ul> <li>Loading a <code>.pycauset</code> file yields a snapshot-backed view.</li> <li>Payload writes do not implicitly overwrite the snapshot file.</li> <li>Mutations transition to a copy-on-write working copy so snapshot payload bytes are not overwritten by incidental edits.</li> </ul> <p>Developer reference:</p> <ul> <li>guides/Storage and Memory</li> </ul>"},{"location":"internals/Memory%20and%20Data/#file-format-pycauset","title":"File Format (<code>.pycauset</code>)","text":"<p><code>.pycauset</code> is a single-file binary container designed for mmap-friendly payload access and sparse, typed metadata.</p> <p>Authoritative plans:</p> <ul> <li><code>documentation/internals/plans/completed/R1_STORAGE_PLAN.md</code> (container format)</li> <li><code>documentation/internals/plans/completed/R1_PROPERTIES_PLAN.md</code> (metadata semantics)</li> </ul>"},{"location":"internals/Memory%20and%20Data/#container-summary","title":"Container summary","text":"<p>At a high level, each <code>.pycauset</code> file contains:</p> <ul> <li>A fixed-size header region that selects the active header slot (A/B).</li> <li>A raw payload region at a stable, aligned offset (so it can be memory-mapped efficiently).</li> <li>A typed metadata block (sparse map) that can be appended/updated without shifting the payload.</li> </ul> <p>This design keeps the \u201cheavy\u201d numeric data mmap-friendly while allowing metadata evolution without scans or full rewrites. *   Alignment: The data is laid out exactly as it would be in memory (e.g., row-major order for dense matrices, bit-packed words for bit matrices).</p>"},{"location":"internals/Memory%20and%20Data/#typed-metadata-is-the-only-schema","title":"Typed metadata is the only schema","text":"<p>All metadata is stored as a typed top-level map (no parallel \u201clegacy\u201d/flattened metadata schema).</p> <p>Important namespaces:</p> <ul> <li><code>view</code>: view-state that affects interpretation/derived values (e.g., scalar/transpose/conjugation).</li> <li><code>properties</code>: user-facing gospel assertions (semantic hints; not truth-validated).</li> <li><code>cached</code>: cached-derived values (both small scalars and big-blob references).</li> </ul>"},{"location":"internals/Memory%20and%20Data/#big-blob-caches-generalized-mechanism","title":"Big-blob caches (generalized mechanism)","text":"<p>A big-blob cache is a cached-derived value that is itself large (often another matrix/vector) and therefore must be persisted as an independent <code>.pycauset</code> object.</p> <p>Persistence model:</p> <ul> <li>The base snapshot stores a typed entry at <code>cached.&lt;name&gt;</code>.</li> <li>For big blobs, <code>cached.&lt;name&gt;.value</code> is a reference:<ul> <li><code>ref_kind</code>: currently <code>sibling_object_store</code></li> <li><code>object_id</code>: UUID hex</li> </ul> </li> <li>The referenced object lives in a sibling object store directory:     <code>BASE.pycauset.objects/&lt;object_id&gt;.pycauset</code></li> </ul> <p>Validity model:</p> <ul> <li><code>cached.&lt;name&gt;.signature</code> must allow \\(O(1)\\) validation against the base object (no scans).</li> <li>Signatures use <code>payload_uuid</code> (a per-snapshot identifier that changes whenever payload bytes are persisted).</li> <li>If the reference is missing/unreadable/stale, it is treated as a cache miss (ignored).</li> <li>A <code>PyCausetStorageWarning</code> is emitted and the cache is not implicitly recomputed.</li> <li>Missing/unreadable big-blob references should emit <code>PyCausetStorageWarning</code> and continue load.</li> </ul> <p>Implementation reference (Python):</p> <ul> <li><code>python/pycauset/_internal/persistence.py</code><ul> <li>Object store layout helpers: <code>object_store_path_for_id</code>, <code>new_object_id</code></li> <li>Typed ref read/write: <code>try_get_cached_big_blob_ref</code>, <code>write_cached_big_blob_ref</code></li> </ul> </li> <li><code>python/pycauset/_internal/big_blob_cache.py</code><ul> <li>Reusable big-blob cache plumbing for operations: <code>compute_view_signature</code>, <code>try_load_cached_matrix</code>, <code>persist_cached_object</code></li> </ul> </li> </ul>"},{"location":"internals/Memory%20and%20Data/#loading-process","title":"Loading Process","text":"<ol> <li>Python opens the <code>.pycauset</code> container and reads the fixed header.</li> <li>Python selects the active header slot (A/B), validates it, and reads the typed metadata block.</li> <li>Python instantiates the appropriate C++ class (e.g., <code>_TriangularBitMatrix</code>), passing the filename and the payload offset.</li> <li>C++ calls <code>mmap</code> on the file, applying the payload offset to map only the raw payload region.</li> </ol>"},{"location":"internals/Memory%20and%20Data/#2-matrix-vector-class-hierarchy","title":"2. Matrix &amp; Vector Class Hierarchy","text":"<p>The system is built on a hierarchy designed to separate storage management from mathematical operations.</p> <pre><code>classDiagram\n    class PersistentObject {\n        +shared_ptr~MemoryMapper~ mapper_\n        +complex scalar_\n        +bool is_transposed_\n        +uint64_t rows_\n        +uint64_t cols_\n        +initialize_storage()\n        +copy_storage()\n        +ensure_unique()\n        +clone()\n    }\n\n    class MatrixBase {\n        &lt;&lt;abstract&gt;&gt;\n        +uint64_t rows()\n        +uint64_t cols()\n        +uint64_t base_rows()\n        +uint64_t base_cols()\n        +uint64_t size()\n        +get_element_as_double(i, j)*\n        +multiply_scalar()\n        +add_scalar()\n        +transpose()\n    }\n\n    class VectorBase {\n        &lt;&lt;abstract&gt;&gt;\n        +uint64_t size()\n        +get_element_as_double(i)*\n        +transpose()\n    }\n\n    class DenseMatrix~T~ {\n        +T* data()\n        +read(i, j)\n        +write(i, j, value)\n    }\n\n    class TriangularMatrix~T~ {\n        +vector~uint64_t~ row_offsets_\n        +read(i, j) T\n        +write(i, j, value)\n    }\n\n    class DiagonalMatrix~T~ {\n        +read(i, j) T\n        +write(i, j, value)\n        +get_diagonal(i)\n    }\n\n    class IdentityMatrix~T~ {\n        +get_element_as_double(i, j)\n        +add(IdentityMatrix)\n    }\n\n    class DenseVector~T~ {\n        +T* data()\n        +read(i)\n        +write(i, value)\n    }\n\n    class UnitVector {\n        +uint64_t active_index_\n        +read(i)\n    }\n\n    PersistentObject &lt;|-- MatrixBase\n    PersistentObject &lt;|-- VectorBase\n    MatrixBase &lt;|-- DenseMatrix\n    MatrixBase &lt;|-- TriangularMatrix\n    MatrixBase &lt;|-- DiagonalMatrix\n    DiagonalMatrix &lt;|-- IdentityMatrix\n    VectorBase &lt;|-- DenseVector\n    VectorBase &lt;|-- UnitVector</code></pre>"},{"location":"internals/Memory%20and%20Data/#core-concepts","title":"Core Concepts","text":""},{"location":"internals/Memory%20and%20Data/#lazy-evaluation-metadata","title":"Lazy Evaluation &amp; Metadata","text":"<p>To maintain performance with large matrices, we avoid iterating over data whenever possible.</p> <ul> <li>Scalars: Multiplying a matrix by a scalar \\(k\\) does not multiply every element in memory. Instead, it updates <code>PersistentObject::scalar_</code>.</li> <li>Transposition: Transposing a matrix usually just toggles the <code>PersistentObject::is_transposed_</code> flag. This is a metadata view: the backing storage stays in row-major order.</li> </ul> <p>Important: <code>MatrixBase.rows()</code> / <code>MatrixBase.cols()</code> are logical dimensions and account for transpose metadata. <code>MatrixBase.base_rows()</code> / <code>MatrixBase.base_cols()</code> are the backing storage dimensions.</p>"},{"location":"internals/Memory%20and%20Data/#storage-vs-view","title":"Storage vs. View","text":"<p>The data on disk is the \"canonical\" storage. The C++ object is a \"view\" onto that data. *   Raw Data: <code>mapper_-&gt;get_data()</code> returns the raw bytes. *   View: The class (e.g., <code>DenseMatrix</code>) interprets those bytes (as <code>int</code>, <code>double</code>, etc.) and applies metadata (scalar, transpose).</p> <p>For dense matrices, <code>MatrixBase.size()</code> is NumPy-aligned: it returns the total number of logical elements (<code>rows * cols</code>).</p>"},{"location":"internals/Memory%20and%20Data/#indexing-and-slicing-backend-invariants","title":"Indexing and slicing (backend invariants)","text":"<p>Release 1 implements NumPy-style 2D indexing for dense matrices only:</p> <ul> <li>Basic indexing (view): integer/<code>slice</code>/<code>...</code> with unit steps produces a view that shares the underlying mapper. Logical shape comes from the parsed slice; backing shape/offsets remain on the base. Transpose/conjugate metadata is preserved.</li> <li>Advanced indexing (copy): 1D integer arrays (negative wrap) and 1D boolean masks are supported per axis. Any use of arrays returns a copy; two array axes must broadcast length or length-1.</li> <li>Assignments: RHS may be scalar, NumPy 0/1/2-D array, or dense matrix. NumPy 2D broadcast rules must hold; otherwise the setter raises. Casting RHS arrays triggers <code>PyCausetDTypeWarning</code>; narrowing or float\u2192int casts also trigger <code>PyCausetOverflowRiskWarning</code>.</li> <li>Unsupported: <code>None</code>/newaxis and slicing of structured/triangular matrices.</li> <li>Kernel guardrail: Offsets in views are not yet honored by matmul/qr/lu/inverse kernels; calls with nonzero offsets throw and should be materialized via <code>copy()</code> first.</li> <li>Persistence policy (pending): Persisted sources must prefer view reuse; oversized slices on in-RAM sources should fail deterministically instead of implicit spill/snapshot (not yet implemented).</li> </ul> <p>Code touchpoints: * Slice parsing and dispatch: <code>src/bindings/bind_matrix.cpp</code> (<code>SliceInfo</code>, <code>parse_matrix_subscript</code>, <code>dense_getitem</code>, <code>dense_setitem</code>). * View metadata: <code>MatrixBase</code> (<code>logical_rows/cols</code>, <code>row_offset/col_offset</code>) and <code>DenseMatrix</code> view constructor/accessors. * Kernel guards: <code>DenseMatrix::multiply</code>, <code>inverse</code>, <code>qr</code>, <code>lu</code> reject nonzero view offsets.</p> <p>See also: pycauset.MatrixBase, Matrix Guide, NumPy Alignment Protocol</p>"},{"location":"internals/Memory%20and%20Data/#3-type-system-and-dispatch","title":"3. Type System and Dispatch","text":"<p>This document explains how PyCauset handles different data types (<code>double</code>, <code>float</code>, <code>bool</code>) and how operations are dispatched to the correct implementation.</p>"},{"location":"internals/Memory%20and%20Data/#philosophy-anti-promotion","title":"Philosophy: Anti-Promotion","text":"<p>A core principle of PyCauset's type system is Anti-Promotion.</p> <ul> <li>Traditional Approach: Many libraries (like early NumPy or MATLAB) aggressively promote everything to <code>double</code> (Float64) to ensure precision.</li> <li>PyCauset Approach: We respect the user's choice of type. If a user provides <code>Float32</code> data, they likely want the performance benefits of <code>Float32</code>. We should not silently promote it to <code>Float64</code> unless absolutely necessary (e.g., mixing types).</li> </ul> <p>Rules: 1.  <code>Float32</code> op <code>Float32</code> -&gt; <code>Float32</code> 2.  <code>Float32</code> op <code>Float64</code> -&gt; <code>Float64</code> (Promotion allowed for mixed types)</p>"},{"location":"internals/Memory%20and%20Data/#the-dispatcher","title":"The Dispatcher","text":"<p>We avoid virtual function overhead for every single element access. Instead, we use a Templated Dispatcher pattern at the operation level (e.g., Matrix Multiplication, Addition).</p>"},{"location":"internals/Memory%20and%20Data/#cpu-dispatch","title":"CPU Dispatch","text":"<p>On the CPU, we use C++ templates to generate specialized code for each type.</p> <pre><code>// Conceptual example\ntemplate &lt;typename T&gt;\nvoid matmul_impl(const MatrixBase&amp; A, const MatrixBase&amp; B, MatrixBase&amp; C) {\n    // ... optimized code for type T ...\n}\n\nvoid dispatch_matmul(const MatrixBase&amp; A, const MatrixBase&amp; B, MatrixBase&amp; C) {\n    if (A.dtype() == DType::Float32 &amp;&amp; B.dtype() == DType::Float32) {\n        matmul_impl&lt;float&gt;(A, B, C);\n    } else if (A.dtype() == DType::Float64) {\n        matmul_impl&lt;double&gt;(A, B, C);\n    }\n    // ...\n}\n</code></pre>"},{"location":"internals/Memory%20and%20Data/#gpu-dispatch","title":"GPU Dispatch","text":"<p>On the GPU, <code>CudaDevice::matmul</code> inspects the <code>DType</code> of the operands and routes the call to the appropriate <code>cuBLAS</code> function.</p> <ul> <li><code>DType::Float64</code> -&gt; <code>cublasDgemm</code></li> <li><code>DType::Float32</code> -&gt; <code>cublasSgemm</code></li> <li><code>DType::Float16</code> -&gt; <code>cublasHgemm</code> (Tensor Cores)</li> </ul>"},{"location":"internals/Memory%20and%20Data/#memory-layout","title":"Memory Layout","text":"<p>To support this efficient dispatch, the backend works with raw, dtype-tagged memory.</p> <ul> <li>Host memory lives behind <code>MemoryMapper</code> (<code>mapper_-&gt;get_data()</code>), which provides access to the mapped bytes.</li> <li>Matrix/Vector views interpret those bytes as typed storage and apply metadata (scalar, transpose).</li> <li>Device memory (CUDA) uses dtype-specific buffers to avoid constant casting or reallocation.</li> </ul>"},{"location":"internals/Memory%20and%20Data/#see-also","title":"See also","text":"<ul> <li>pycauset.MatrixBase</li> <li>internals/DType System</li> <li>Documentation Protocol</li> </ul>"},{"location":"internals/MemoryArchitecture/","title":"Memory Architecture &amp; Tiered Storage","text":"<p>Status: Implemented (Phases 1-4) Last Updated: December 8, 2025</p>"},{"location":"internals/MemoryArchitecture/#overview","title":"Overview","text":"<p>PyCauset employs a Tiered Storage Architecture to balance the conflicting goals of \"Infinite Scale\" (Disk) and \"High Performance\" (RAM).</p> <p>Instead of treating the disk as a simple extension of RAM (OS Paging), PyCauset actively manages where data lives.</p>"},{"location":"internals/MemoryArchitecture/#the-hierarchy","title":"The Hierarchy","text":"<ol> <li>L1: Physical RAM (Hot)<ul> <li>Objects are stored in anonymous memory (<code>std::vector</code> or <code>malloc</code>).</li> <li>Fastest access.</li> <li>Managed by <code>MemoryGovernor</code>.</li> </ul> </li> <li>L2: Memory-Mapped Disk (Warm/Cold)<ul> <li>Under RAM pressure, objects may spill by switching from RAM-only mapping to a file-backed (memory-mapped) mapper.</li> <li>The file-backed mapper uses session backing files (for example <code>.tmp</code> files under the backing directory).</li> <li>Portable persistence uses explicit <code>.pycauset</code> snapshots written by <code>save()</code>.</li> </ul> </li> </ol>"},{"location":"internals/MemoryArchitecture/#export-safety-materialization-guard","title":"Export Safety (Materialization Guard)","text":"<p>A specific risk in this architecture is \"Implosion\": an L2 object (1TB file-backed) being naively converted to an L1 object (NumPy array), instantly exhausting RAM.</p> <p>The Export Guard mechanism prevents this: *   File-backed or large spill-backed objects are flagged as <code>huge</code>. *   APIs like <code>__array__</code> (used by <code>np.array()</code>) check this flag. *   If flagged, export unconditionally fails unless the user provides an explicit override (<code>allow_huge=True</code> via <code>to_numpy</code>).</p>"},{"location":"internals/MemoryArchitecture/#persistence-format-status","title":"Persistence format status","text":"<p>There is exactly one on-disk format for <code>.pycauset</code>: a single-file binary container with an mmap-friendly payload region and a sparse, self-describing, typed metadata block.</p> <p>Metadata updates are crash-consistent and do not shift the payload.</p> <p>Authoritative plans:</p> <ul> <li><code>documentation/internals/plans/completed/R1_STORAGE_PLAN.md</code> (container format)</li> <li><code>documentation/internals/plans/completed/R1_PROPERTIES_PLAN.md</code> (metadata semantics)</li> </ul>"},{"location":"internals/MemoryArchitecture/#snapshot-semantics-mutation-policy","title":"Snapshot semantics (mutation policy)","text":"<p>PyCauset is designed so that persisted <code>.pycauset</code> files behave like immutable snapshots when loaded.</p> <ul> <li>Payload writes should not implicitly overwrite the snapshot.</li> <li>The implementation uses copy-on-write working copies so snapshot payload bytes are not overwritten by incidental mutation.</li> </ul> <p>See guides/Storage and Memory for the canonical policy and crash-safety notes (including big-blob caches).</p>"},{"location":"internals/MemoryArchitecture/#1-the-memory-governor-phase-1","title":"1. The Memory Governor (Phase 1)","text":"<p>The <code>MemoryGovernor</code> is a singleton that acts as the central resource manager.</p>"},{"location":"internals/MemoryArchitecture/#responsibilities","title":"Responsibilities","text":"<ol> <li>Dynamic Budgeting:<ul> <li>It polls the OS for actual available RAM (<code>GlobalMemoryStatusEx</code> on Windows, <code>sysinfo</code> on Linux).</li> <li>It maintains a \"Safety Margin\" (default: 10% of RAM or 2GB) to prevent the OS from choking.</li> </ul> </li> <li>Priority Queue:<ul> <li>It tracks all <code>PersistentObject</code> instances in an LRU (Least Recently Used) list.</li> <li>When an object is accessed (<code>touch()</code>), it moves to the front of the queue.</li> </ul> </li> <li>Eviction:<ul> <li>When a new allocation is requested via <code>request_ram(size)</code>, the Governor checks if <code>Available RAM &gt; size + margin</code>.</li> <li>If not, it attempts to evict the Least Recently Used objects (spilling them to disk) until space is created.</li> </ul> </li> </ol>"},{"location":"internals/MemoryArchitecture/#usage","title":"Usage","text":"<pre><code>// In PersistentObject::initialize\nif (MemoryGovernor::instance().request_ram(size_bytes)) {\n    // Allocate in RAM\n    allocate_ram_buffer();\n    MemoryGovernor::instance().register_object(this, size_bytes);\n} else {\n    // Spill to disk immediately\n    initialize_mmap_file();\n}\n\n// In Solver\nMemoryGovernor::instance().touch(matrix_a);\n</code></pre>"},{"location":"internals/MemoryArchitecture/#2-io-accelerator-phase-3","title":"2. IO Accelerator (Phase 3)","text":"<p>The <code>IOAccelerator</code> optimizes the interaction between the application and the OS paging system for L2 (Disk-backed) objects.</p>"},{"location":"internals/MemoryArchitecture/#mechanism","title":"Mechanism","text":"<ul> <li>Windows: <ul> <li>Write Optimization: Uses <code>SetFileValidData</code> (requires <code>SE_MANAGE_VOLUME_NAME</code>) to extend files without zero-filling, solving the \"Import Gap\".</li> <li>Read Optimization: Uses <code>PrefetchVirtualMemory</code> to issue asynchronous requests to the OS memory manager, bringing pages into RAM before the CPU faults on them.</li> </ul> </li> <li>Linux: <ul> <li>Write Optimization: Uses <code>fallocate</code> to pre-allocate disk blocks.</li> <li>Read Optimization: Uses <code>madvise</code> with <code>MADV_WILLNEED</code> (or <code>MAP_POPULATE</code> at mapping time) to trigger read-ahead.</li> </ul> </li> </ul>"},{"location":"internals/MemoryArchitecture/#workflow","title":"Workflow","text":"<ol> <li>Creation: When a new file is created, <code>SetFileValidData</code>/<code>fallocate</code> is called to reserve space instantly.</li> <li>Prefetch: Before a heavy compute operation (e.g., matrix multiplication), the solver calls <code>accelerator-&gt;prefetch()</code>. This hints to the OS to populate the page cache.</li> <li>Compute: The CPU accesses the memory. Since pages are likely already in RAM, major page faults are minimized.</li> <li>Discard: After the operation, if the data is intermediate or unlikely to be reused soon, <code>accelerator-&gt;discard()</code> is called. This uses <code>OfferVirtualMemory</code> (Windows) or <code>MADV_DONTNEED</code> (Linux) to tell the OS these pages can be evicted immediately, freeing up RAM for other tasks.</li> </ol>"},{"location":"internals/MemoryArchitecture/#4-pinned-memory-direct-path-phase-4","title":"4. Pinned Memory &amp; Direct Path (Phase 4)","text":"<p>To achieve maximum performance for operations that fit entirely in RAM, PyCauset implements a Direct Path optimization that bypasses the standard paging/tiling overhead.</p>"},{"location":"internals/MemoryArchitecture/#the-nanny-problem-anti-nanny-logic","title":"The \"Nanny Problem\" &amp; Anti-Nanny Logic","text":"<p>Standard memory-mapped files rely on the OS to page data in and out. While safe, this introduces latency (page faults). However, forcing \"Streaming/Tiling\" on RAM-resident data that could be handled by the OS pager is also inefficient (the \"Nanny Problem\").</p>"},{"location":"internals/MemoryArchitecture/#the-solution-should_use_direct_path","title":"The Solution: <code>should_use_direct_path()</code>","text":"<p>The <code>MemoryGovernor</code> now exposes a centralized decision method: <code>should_use_direct_path(total_bytes)</code>.</p> <ol> <li>Check 1 (Pinning): If data fits in the Pinned Memory Budget, we pin it and use the BLAS Direct Path. This is the fastest possible mode.</li> <li>Check 2 (Anti-Nanny): If data fits in Total Available RAM (but exceeds the pinning budget), we still use the Direct Path (without pinning). We trust the OS pager to handle the memory efficiently, avoiding the overhead of manual tiling.</li> <li>Fallback: Only if the data exceeds Available RAM do we switch to the Streaming/Out-of-Core Solver.</li> </ol>"},{"location":"internals/MemoryArchitecture/#direct-path-workflow","title":"Direct Path Workflow","text":"<p>In <code>CpuSolver</code>, before starting a heavy operation (like Matrix Multiplication):</p> <ol> <li>Attempt Pinning: Call <code>attempt_direct_path()</code>. If successful, run BLAS on pinned memory.</li> <li>Check Anti-Nanny: Call <code>MemoryGovernor::should_use_direct_path()</code>. If true, run BLAS on unpinned memory (OS Paging).</li> <li>Streaming Fallback: If both fail, run <code>matmul_streaming</code> (Manual Tiling + Prefetching).</li> </ol> <p>This strategy allows PyCauset to match the performance of in-memory libraries (like NumPy) for medium-sized datasets, while gracefully falling back to the robust, tiled, out-of-core solver for massive datasets.</p>"},{"location":"internals/MemoryArchitecture/#generalized-implementation","title":"Generalized Implementation","text":"<p>The \"Direct Path\" logic is implemented in a generalized helper <code>attempt_direct_path&lt;T&gt;</code> which supports both <code>double</code> and <code>float</code>. It is automatically attempted before falling back to the streaming/tiling logic.</p>"},{"location":"internals/MemoryArchitecture/#diagram","title":"Diagram","text":"<pre><code>graph TD\n    subgraph Initial State\n    A[Matrix A] --&gt;|shared_ptr| M1[MemoryMapper 1]\n    end\n\n    subgraph After B = A.copy\n    A2[Matrix A] --&gt;|shared_ptr| M2[MemoryMapper 1]\n    B[Matrix B] --&gt;|shared_ptr| M2\n    end\n\n    subgraph After B.set_element\n    A3[Matrix A] --&gt;|shared_ptr| M2\n    B2[Matrix B] --&gt;|shared_ptr| M3[MemoryMapper 2]\n    end</code></pre>"},{"location":"internals/MemoryArchitecture/#5-file-formats-r1_safety","title":"5. File Formats (R1_SAFETY)","text":"<p>PyCauset uses two distinct file formats for disk-backed storage.</p>"},{"location":"internals/MemoryArchitecture/#51-snapshot-container-pycauset","title":"5.1 Snapshot Container (.pycauset)","text":"<ul> <li>Role: Portable, persistent storage for matrices and causal sets.</li> <li>Manager: python/pycauset/_internal/persistence.py.</li> <li>Structure:<ul> <li>Header (4KB): Magic PYCAUSET, Version 1, Slot pointers.</li> <li>Slots (A/B): Double-buffered pointers to metadata blocks (crash consistency).</li> <li>Metadata: Typed JSON-like map (shape, dtype, properties).</li> <li>Payload: Raw binary data (aligned to 4KB).</li> </ul> </li> </ul>"},{"location":"internals/MemoryArchitecture/#52-backing-file-tmp","title":"5.2 Backing File (.tmp)","text":"<ul> <li>Role: Temporary storage for spilled objects or large intermediates.</li> <li>Manager: src/core/MemoryMapper.cpp.</li> <li>Structure:<ul> <li>Header (64 bytes): Magic PYCAUSET, Version 1, Reserved (zeros).</li> <li>Payload: Raw binary data.</li> </ul> </li> <li>Safety: The 64-byte header prevents accidental loading of raw files as valid PyCauset containers (or vice versa). MemoryMapper distinguishes between the two formats by checking the \"Reserved\" field (which is non-zero in .pycauset headers).</li> </ul>"},{"location":"internals/Streaming%20Manager/","title":"Streaming Manager","text":"<p>The streaming manager is the shared policy engine for out-of-core execution. It decides when to stream, how to tile, how deep to queue, and records what happened so tests and users can see the plan. Matmul, invert, eigvalsh, eigh, and eigvals_arnoldi register descriptors that plug in access patterns, guards, and resource budgets.</p>"},{"location":"internals/Streaming%20Manager/#what-the-manager-owns","title":"What the manager owns","text":"<ul> <li>Routing: picks <code>route</code> (<code>streaming</code> or <code>direct</code>) and <code>reason</code>, combining IO observability thresholds with per-op guards.</li> <li>Planning: fills plan fields (<code>tile_shape</code>, <code>queue_depth</code>, <code>plan.access_pattern</code>, <code>trace_tag</code>, <code>events</code>, <code>storage</code> summary).</li> <li>Execution glue: best-effort prefetch/discard for streaming routes and <code>impl=...</code> annotations for the chosen implementation.</li> <li>Registry: per-op <code>StreamingDescriptor</code> entries that provide access patterns and policy hooks.</li> </ul>"},{"location":"internals/Streaming%20Manager/#lifecycle-at-a-glance","title":"Lifecycle at a glance","text":"<ol> <li>plan(op, operands, allow_huge=False): snapshots operands, chooses route, runs the descriptor guard, and computes tiles/queue depth.</li> <li>prefetch(plan, operands): only when <code>route == \"streaming\"</code>; defaults to calling accelerators on backing files.</li> <li>compute: the op executes (native, Python fallback, or BlockMatrix orchestration). The manager can annotate the implementation (<code>impl=...</code>).</li> <li>discard(plan, operands, result): only when streaming; best-effort discard on backing ranges.</li> <li>inspect: <code>pc.last_io_trace(...)</code> returns the plan and event timeline for debugging and tests.</li> </ol>"},{"location":"internals/Streaming%20Manager/#plan-schema-recorded-via-io-observability","title":"Plan schema (recorded via IO observability)","text":"<ul> <li><code>route</code> / <code>reason</code>: routing choice and justification.</li> <li><code>tile_shape</code>: <code>(rows, cols)</code> when streaming; <code>None</code> when direct. Tiles clamp to operand shapes.</li> <li><code>queue_depth</code>: bounded to <code>[1, 8]</code> when streaming; <code>0</code> when direct.</li> <li><code>plan.access_pattern</code>: descriptor-supplied tag (e.g., <code>blocked_rowcol</code>).</li> <li><code>trace_tag</code>: monotonic tag per op (<code>op:N</code>).</li> <li><code>events</code>: list of <code>{type, detail, reason?}</code>; includes plan/prefetch/discard/compute annotations.</li> <li><code>storage</code>: backing files, temporary flags, and storage roots gathered from operand snapshots.</li> </ul>"},{"location":"internals/Streaming%20Manager/#routing-rules","title":"Routing rules","text":"<ul> <li>File-backed operands: force <code>streaming</code> with reason <code>file-backed operand</code>.</li> <li>allow_huge=True: force <code>direct</code> with reason <code>allow_huge bypassed threshold</code>.</li> <li>Threshold set: any estimated operand bytes over threshold \u2192 <code>streaming</code> with <code>estimated bytes exceed threshold</code>.</li> <li>Threshold None: <code>direct</code> with <code>no threshold configured</code> unless a guard overrides.</li> <li>Guards: per-op hooks can override route/reason. Example: non-square invert/eig* \u2192 <code>direct</code> with <code>non_square</code>; matmul mismatched shapes \u2192 <code>direct</code> with <code>shape_mismatch</code>.</li> </ul>"},{"location":"internals/Streaming%20Manager/#descriptor-catalog-current","title":"Descriptor catalog (current)","text":"op access_pattern guard tile budget queue depth notes matmul blocked_rowcol shape mismatch \u2192 direct budgeted square tiles clamped to shapes 3 when streaming Python tiling fallback annotates <code>impl=streaming_python</code> invert invert_dense non-square \u2192 direct default square tile 1 when streaming Fallback annotates <code>impl=streaming_python</code> eigvalsh symmetric_eigvals non-square \u2192 direct default square tile 1 when streaming Fallback annotates <code>impl=streaming_python</code> eigh symmetric_eigh non-square \u2192 direct default square tile 1 when streaming Fallback annotates <code>impl=streaming_python</code> eigvals_arnoldi arnoldi_topk non-square \u2192 direct default square tile 1 when streaming Fallback annotates <code>impl=streaming_python</code>"},{"location":"internals/Streaming%20Manager/#hooks-and-defaults","title":"Hooks and defaults","text":"<ul> <li><code>tile_budget_fn(threshold_bytes, snapshots)</code>: derives tiles from the memory threshold and itemsize; matmul halves budget across A/B and clamps to shapes; square ops reuse the default derivation.</li> <li><code>queue_depth_fn(route, snapshots)</code>: returns depth before coercion; manager caps to <code>[1, 8]</code> and zeroes when direct.</li> <li><code>guard(operands, snapshots, allow_huge)</code>: may override route/reason early; does not materialize data, uses snapshots.</li> <li><code>prefetch</code> / <code>discard</code>: optional per-op hooks; defaults call accelerator prefetch/discard on backing files.</li> <li><code>annotate_impl(record, label)</code>: attaches <code>impl=label</code> and records a compute event.</li> </ul>"},{"location":"internals/Streaming%20Manager/#safety-guarantees","title":"Safety guarantees","text":"<ul> <li>No streaming queue depth above 8; non-streaming queues are 0.</li> <li>Tile shapes always finite and clamped to operand extents; failures fall back to conservative defaults.</li> <li>Guards run before tiling so invalid shapes revert to direct routes instead of crashing in streaming codepaths.</li> <li>IO observability storage summaries remain intact for spill/backing-file diagnostics.</li> </ul>"},{"location":"internals/Streaming%20Manager/#debugging-and-tests","title":"Debugging and tests","text":"<ul> <li><code>pc.last_io_trace()</code> shows the latest plan; <code>pc.last_io_trace(\"matmul\")</code> fetches by op.</li> <li>Event timeline should contain <code>plan</code> plus <code>io</code> (prefetch/discard) and <code>compute</code> (impl) entries for streaming routes.</li> <li>Threshold-driven scenarios: set <code>pc.set_io_streaming_threshold(bytes)</code> to force streaming in tests; set to <code>None</code> to validate the direct path.</li> <li>File-backed fakes should force streaming regardless of threshold, exercising the guardrail for spill-backed inputs.</li> </ul>"},{"location":"internals/Streaming%20Manager/#extending","title":"Extending","text":"<ul> <li>Add a new op by registering a <code>StreamingDescriptor</code> in <code>pycauset.__init__</code> with an access pattern, guard, and budget/queue hooks.</li> <li>Keep guards deterministic and non-materializing (only consult snapshots and metadata).</li> <li>Prefer small, conservative tile/queue defaults; tighten once end-to-end tests validate throughput.</li> </ul>"},{"location":"internals/plans/BLAS_INTEGRATION_PLAN/","title":"OpenBLAS Integration Plan","text":"<p>Goal: Replace manual C++ compute loops with optimized BLAS (Basic Linear Algebra Subprograms) calls to achieve NumPy-level performance while retaining PyCauset's out-of-core streaming architecture.</p> <p>Strategy: \"Hybrid Engine\" - Chassis: PyCauset <code>MemoryGovernor</code> &amp; <code>MemoryMapper</code> (Handles I/O, Pinning, Streaming). - Engine: OpenBLAS (Handles raw compute via AVX2/AVX-512).</p>"},{"location":"internals/plans/BLAS_INTEGRATION_PLAN/#phase-1-preparation-cleanup","title":"Phase 1: Preparation &amp; Cleanup","text":"<p>Objective: Simplify the codebase before adding new dependencies.</p> <ol> <li> <p>Do not target Float16 for CPU BLAS acceleration (DONE)</p> <ul> <li>Reason: OpenBLAS does not provide Float16 GEMM on CPU.</li> <li>Clarification: <code>float16</code> is still a first-class dtype in PyCauset (storage + interop) and is not retired.<ul> <li>Codebase evidence: <code>DataType::FLOAT16</code> exists; <code>DenseMatrix&lt;float16_t&gt;</code> exists; Python exposes <code>pycauset.float16</code> and <code>pycauset.Float16Matrix</code>.</li> <li>Current behavior: CPU <code>matmul</code> supports <code>Float16Matrix</code> results via a fallback that accumulates in float32 and stores float16.</li> </ul> </li> <li>Action: Keep Float16 as a storage dtype; for BLAS-backed matmul, use Float32/Float64.</li> <li>Action: Document Float16 limitation: on CPU, matmul is not BLAS-accelerated for Float16.</li> </ul> </li> <li> <p>Snapshot Benchmarks</p> <ul> <li>Action: Record current \"Native C++\" performance for Float64 (already done: ~22 GFLOPS).</li> <li>Action: Record current performance for Float32 (if implemented) to have a baseline.</li> </ul> </li> </ol>"},{"location":"internals/plans/BLAS_INTEGRATION_PLAN/#phase-2-dependency-integration-build-system","title":"Phase 2: Dependency Integration (Build System)","text":"<p>Objective: Successfully link OpenBLAS in the Windows/MSVC environment.</p> <ol> <li> <p>Acquire OpenBLAS (DONE)</p> <ul> <li>Action: Configured CMake to automatically download pre-built binaries (v0.3.26) for Windows during build.</li> </ul> </li> <li> <p>Update CMake Configuration (DONE)</p> <ul> <li>Action: Modify <code>CMakeLists.txt</code> to find the OpenBLAS library. (DONE)</li> <li>Action: Add include directories for <code>cblas.h</code>. (DONE)</li> <li>Action: Link <code>pycauset_core</code> against <code>libopenblas.lib</code>. (DONE)</li> <li>Action: Ensure the <code>.dll</code> is copied to the build output directory so tests can run. (DONE)</li> </ul> </li> <li> <p>Verify Linkage</p> <ul> <li>Action: Create a minimal \"Hello BLAS\" C++ test file that just calls <code>cblas_dgemm</code> on a 2x2 matrix.</li> <li>Action: Compile and run this test to confirm the build system is working before touching the main code.</li> </ul> </li> </ol>"},{"location":"internals/plans/BLAS_INTEGRATION_PLAN/#phase-3-implementation-the-surgical-replacement","title":"Phase 3: Implementation (The \"Surgical\" Replacement)","text":"<p>Objective: Swap the inner loops for BLAS calls inside the Streaming Architecture.</p> <ol> <li> <p>Modify <code>CpuSolver.cpp</code> Headers (DONE)</p> <ul> <li>Action: Include <code>&lt;cblas.h&gt;</code>. (DONE)</li> </ul> </li> <li> <p>Implement Float64 (Double) Support (DONE)</p> <ul> <li>Action: Update <code>matmul_streaming_f64</code>. (DONE - Refactored to template <code>matmul_streaming&lt;T&gt;</code>)</li> <li>Change: Inside the inner streaming loop (where we currently have <code>ParallelFor</code> loops), replace the logic with a call to <code>cblas_dgemm</code>. (DONE)</li> <li>Detail: We must calculate <code>LDA</code>, <code>LDB</code>, <code>LDC</code> (strides) correctly based on the full matrix width, even when processing a small tile. (DONE)</li> </ul> </li> <li> <p>Implement Float32 (Single) Support (DONE)</p> <ul> <li>Action: Create/Update <code>matmul_streaming_f32</code>. (DONE - Handled by template)</li> <li>Change: Use <code>cblas_sgemm</code>. (DONE)</li> </ul> </li> <li> <p>Implement Complex Numbers Support</p> <ul> <li>Note: BLAS supports \"Single Complex\" (<code>cgemm</code>) and \"Double Complex\" (<code>zgemm</code>).</li> <li>Action: Implement <code>matmul_streaming_c64</code> (Complex Double) using <code>cblas_zgemm</code>.</li> <li>Action: Implement <code>matmul_streaming_c32</code> (Complex Float) using <code>cblas_cgemm</code>.</li> <li>Detail: Ensure <code>std::complex&lt;double&gt;</code> memory layout matches BLAS expectations (it usually does: real, imag, real, imag...).</li> </ul> </li> </ol>"},{"location":"internals/plans/BLAS_INTEGRATION_PLAN/#phase-4-verification-benchmarking","title":"Phase 4: Verification &amp; Benchmarking","text":"<p>Objective: Prove correctness and performance gains.</p> <ol> <li> <p>Unit Testing</p> <ul> <li>Action: Run <code>test_symmetric_matrix</code> and other existing tests.</li> <li>Action: Create specific tests for non-square matrices to ensure <code>LDA</code>/<code>LDB</code> strides are correct (common BLAS bug).</li> </ul> </li> <li> <p>Performance Benchmarking</p> <ul> <li>Action: Run <code>benchmark_native.exe</code> (Float64).</li> <li>Target: We expect to see GFLOPS jump from ~22 to ~200+ (matching NumPy).</li> <li>Action: Run benchmarks for Float32 and Complex types.</li> </ul> </li> <li> <p>Large Scale Test</p> <ul> <li>Action: Run a benchmark with N &gt; RAM_SIZE (e.g., N=30,000 on a 16GB machine).</li> <li>Verify: Ensure it does not crash (Streaming works) and runs reasonably fast (BLAS works).</li> </ul> </li> </ol>"},{"location":"internals/plans/BLAS_INTEGRATION_PLAN/#phase-5-documentation-cleanup","title":"Phase 5: Documentation &amp; Cleanup","text":"<p>Objective: Finalize the transition.</p> <ol> <li> <p>Update Documentation</p> <ul> <li>Action: Update <code>documentation/internals/plans/SUPPORT_READINESS_FRAMEWORK.md</code> with BLAS-backed status and thresholds.</li> <li>Action: Update <code>internals</code> docs to explain the BLAS dependency.</li> <li>Action: Remove old \"Micro-Kernel\" implementation plans.</li> </ul> </li> <li> <p>Code Cleanup</p> <ul> <li>Action: Remove the old generic <code>matmul_impl</code> C++ loop implementation if it is no longer used by any type.</li> </ul> </li> </ol>"},{"location":"internals/plans/BLAS_INTEGRATION_PLAN/#notes-on-complex-numbers","title":"Notes on Complex Numbers","text":"<ul> <li>Float32 Complex: Corresponds to <code>std::complex&lt;float&gt;</code>. BLAS routine: <code>cblas_cgemm</code>.</li> <li>Float64 Complex: Corresponds to <code>std::complex&lt;double&gt;</code>. BLAS routine: <code>cblas_zgemm</code>.</li> <li>Implementation: The streaming logic remains identical. We just pin the memory (which is \\(2 \\times\\) larger per element) and pass the pointer to the appropriate BLAS function.</li> </ul>"},{"location":"internals/plans/R1_GPU_PLAN/","title":"R1_GPU Plan: Robust, Cooperative Hardware Acceleration","text":""},{"location":"internals/plans/R1_GPU_PLAN/#executive-summary","title":"Executive Summary","text":"<p>The R1_GPU node turns the experimental CUDA backend into a robust, \"Just Works\" acceleration tier.</p> <p>Crucially, we do not invent a new scheduler. We leverage the existing, sophisticated <code>AsyncStreamer</code> architecture. The goal is to build Algorithm Drivers\u2014smart host-side loops that orchestrate the <code>AsyncStreamer</code> logic to handle complex operations (Inversion, Eigen) on datasets larger than GPU memory.</p>"},{"location":"internals/plans/R1_GPU_PLAN/#core-philosophy","title":"Core Philosophy","text":"<ol> <li>\"Just Works\" (No Tuning Required): The system automatically detects hardware, benchmarks capabilities, and routes operations. Defaults are safe.</li> <li>Streaming First: We assume data does not fit in GPU RAM. All implementations must support tiling via the <code>MemoryGovernor</code>.</li> <li>Cooperative Pipelining: We rarely split a single math op between CPU/GPU (bandwidth contention). Instead, we pipeline: CPU handles logistics (prefetch/pin/format) in parallel with GPU compute.</li> </ol>"},{"location":"internals/plans/R1_GPU_PLAN/#deliverables-phases","title":"Deliverables &amp; Phases","text":""},{"location":"internals/plans/R1_GPU_PLAN/#phase-1-robust-discovery-just-works-dispatch","title":"Phase 1: Robust Discovery &amp; \"Just Works\" Dispatch","text":"<p>Goal: Make the <code>AutoSolver</code> smart enough to trust by default.</p> <ul> <li>Hardware Audit &amp; Persistence:<ul> <li>Query <code>cudaGetDeviceProperties</code>.</li> <li>Micro-benchmark: Run silent <code>SGEMM</code>/<code>DGEMM</code> startup test.</li> <li>Cache: Save results to <code>~/.pycauset/hardware_profile.json</code> to skip benchmarks on future runs.</li> <li>Dynamic Pinning Budget: Implement heuristic <code>Budget = min(SystemRAM * 0.5, FreeRAM * 0.8, 8GB)</code> to safely maximize I/O throughput.</li> </ul> </li> <li>Cost Model Dispatch:<ul> <li>Replace fixed size thresholds with a transfer-vs-compute cost equation:     $$ T_{gpu} = \\frac{\\text{Bytes}}{\\text{BW}{pci}} + \\frac{\\text{Ops}}{\\text{FLOPS} $$}} + T_{latency</li> </ul> </li> <li>Control Surface (Python):<ul> <li><code>pycauset.cuda.force_backend(...)</code></li> <li><code>pycauset.cuda.set_pinning_budget(bytes)</code></li> <li><code>pycauset.cuda.benchmark(force=True)</code></li> </ul> </li> <li>Documentation Checkpoint:<ul> <li> Update <code>internals/Compute Architecture.md</code>.</li> <li> Add <code>docs/functions/pycauset.cuda.*</code> API references.</li> <li> Add <code>docs/parameters/pinning_budget.md</code>.</li> </ul> </li> </ul>"},{"location":"internals/plans/R1_GPU_PLAN/#phase-2-streaming-algorithm-drivers-host-orchestrated","title":"Phase 2: Streaming Algorithm Drivers (Host-Orchestrated)","text":"<p>Goal: Implement robust out-of-core drivers for complex linear algebra by orchestrating the existing <code>AsyncStreamer</code>.</p> <ul> <li>Strategy: Host-Side Orchestration:<ul> <li>We reject a generic runtime scheduler.</li> <li>We implement Algorithm-Specific Drivers (C++ classes) where the CPU executes the algorithm state machine (loops, barriers, dependency checks).</li> <li>The Host submits batches of independent tiles to <code>AsyncStreamer</code>, which handles the low-level double-buffered prefetch/pin/issue pipeline.</li> </ul> </li> <li>Deliverables (The \"Drivers\"):<ul> <li><code>MatmulDriver</code>: Verification of existing flat streaming for 100GB+ scale.</li> <li><code>CholeskyDriver</code>: Implement Right-Looking Block Cholesky. Host logic manages dependencies (Diagonal wait -&gt; Panel update -&gt; Trailing update).</li> <li><code>ArnoldiDriver</code>: Implement Block Arnoldi. Optimizes memory bandwidth by fusing multiple vector updates into blocked operations.</li> </ul> </li> <li>Documentation Checkpoint:<ul> <li> Update <code>internals/Streaming Manager.md</code> to document the Driver pattern. Also document how to create drivers and how they fit into the compute architecture.</li> <li> Update <code>guides/Performance Guide.md</code> with a section on \"Streaming Constraints\".</li> </ul> </li> </ul>"},{"location":"internals/plans/R1_GPU_PLAN/#phase-3-integration-properties-heterogeneity","title":"Phase 3: Integration (Properties &amp; Heterogeneity)","text":"<p>Goal: Routing respects semantic properties to exploit PyCauset's structural advantage.</p> <ul> <li>Mechanism: Traits-Based Dispatch (Tag Dispatch):<ul> <li>Implement C++20 <code>MatrixTraits</code> derived from R1_PROPERTIES.</li> <li><code>AutoSolver</code> selects kernels based on <code>BestKernel(Op, Traits)</code>, decoupling policy from execution.</li> </ul> </li> <li>Feature: C++ Property Mirroring (Fast Flags):<ul> <li>Since properties are currently Python-only (see <code>Storage and Memory.md</code> -&gt; \"Technical Implementation\"), <code>AutoSolver</code> cannot currently see them.</li> <li>Add a <code>uint64_t properties_flags</code> field to <code>PersistentObject</code> in C++.</li> <li>Wire the Python setter to update this C++ bitmask in \\(O(1)\\).</li> </ul> </li> <li>The \"PyCauset Advantage\":<ul> <li>We use physics knowledge (Causality=Triangular, Propagator=Symmetric) to select \\(O(N^2)\\) shortcuts.</li> </ul> </li> <li>Phase 3 Documentation:<ul> <li>Update key <code>docs/classes/Matrix.md</code> regarding how properties affect performance.</li> <li>Update <code>internals/algorithms.md</code> with property-specific complexity guarantees.</li> <li>Update <code>project/protocols/Adding Operations.md</code> to include steps for registering new Traits/Tags.</li> </ul> </li> </ul>"},{"location":"internals/plans/R1_GPU_PLAN/#phase-4-block-matrix-orchestration","title":"Phase 4: Block Matrix Orchestration","text":"<p>Goal: Ensure the <code>BlockMatrix</code> composite structure utilizes the new drivers.</p> <ul> <li>Routing: Ensure <code>BlockMatrix</code> operations (which decompose into sub-ops) route those sub-ops through <code>AutoSolver</code> correctly.</li> <li>Heterogeneity: Handle cases where one block is on GPU and another must stay on CPU (utilizing the unified worker interface defined in R1_CPU).</li> <li>Phase 4 Documentation:<ul> <li>Update <code>internals/Block Matrices.md</code>.</li> </ul> </li> </ul>"},{"location":"internals/plans/R1_GPU_PLAN/#phase-5-robustness-documents-benchmarking-the-shield","title":"Phase 5: Robustness, Documents &amp; Benchmarking (The \"Shield\")","text":"<p>Goal: Final polish, stress testing, and complete documentation.</p> <ul> <li>Stress Test: Run the \"100GB Matrix\" test case on a machine with &lt;16GB RAM and &lt;8GB VRAM.</li> <li>Unit Tests: Mock <code>cudaGetDeviceProperties</code> to simulate hardware states.</li> <li>Documentation Sweep:<ul> <li>Guide: Add \"GPU Configuration\" section to existing <code>guides/Performance Guide.md</code>.</li> <li>Internal: Update <code>documentation/project/protocols/Adding Operations.md</code> with GPU-specific kernel checklist.</li> <li>Compliance: Verify all new APIs have <code>docs/</code> entries.</li> </ul> </li> </ul>"},{"location":"internals/plans/R1_GPU_PLAN/#technical-constraints-decisions","title":"Technical Constraints &amp; Decisions","text":""},{"location":"internals/plans/R1_GPU_PLAN/#1-the-pci-e-bottleneck","title":"1. The PCI-e Bottleneck","text":"<p>Relying on the GPU for everything is often slower for medium sizes due to transfer overhead. *   Decision: The \"Cost Model\" (Phase 1) is strict. If the model says CPU is faster, we must use CPU.</p>"},{"location":"internals/plans/R1_GPU_PLAN/#2-pinned-memory-scarcity","title":"2. Pinned Memory Scarcity","text":"<p>Pinned memory locks physical RAM. *   Decision: We use the <code>MemoryGovernor</code>'s dynamic pinning budget. Drivers must request a \"ticket\" to pin. If denied, they degrade to pageable memory (slower) but do not crash.</p>"},{"location":"internals/plans/R1_GPU_PLAN/#3-precision-properties","title":"3. Precision &amp; Properties","text":"<p>GPU paths must respect R1_PROPERTIES. Specialized kernels (Syrk, Trmm) are preferred over generic Gemm to save 50% FLOPs.</p>"},{"location":"internals/plans/R1_GPU_PLAN/#open-questions","title":"Open Questions","text":"<ul> <li>Context Management: Global pool vs Per-Thread? (Likely global pool for R1).</li> <li>Multi-GPU: Explicitly out-of-scope for R1.</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/","title":"R1_NUMPY \u2014 Fast NumPy Interop (Release 1 Plan)","text":"<p>Status: In Progress (Resumed Jan 2026)</p> <p>Goal: NumPy \u2194 PyCauset interop is predictable, safe (no surprise huge materialization), and fast enough that mixed workflows are viable.</p> <p>This plan is the contract for what \u201cNumPy compatibility\u201d means in Release 1 and how it is measured.</p> <p>Execution note (implementation):</p> <ul> <li>Update (Jan 2026): R1_LAZY, R1_PERF, and R1_SAFETY are complete. This plan is now active again.</li> <li>Implementation must leverage the MemoryGovernor, IOAccelerator, and Direct Path mechanisms established in those completed nodes.</li> <li>No code should be written until Phase 1 inventory confirms the current surface (especially regarding Lazy Evaluation interactions).</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#0-why-this-exists","title":"0) Why this exists","text":"<p>PyCauset is positioned as \u201cNumPy for causal sets\u201d.</p> <p>To make that credible:</p> <ul> <li>Conversion must not be a bottleneck.</li> <li>NumPy-first usage should either work (by routing) or fail loudly before a surprise memory blow-up.</li> <li>Performance claims must be gated by benchmarks (SRP / Gate E).</li> </ul> <p>Current implementation note (as of Jan 2026):</p> <ul> <li><code>pycauset.to_numpy</code> and <code>export_guard</code> exist (from R1_SAFETY) but need performance tuning.</li> <li><code>R1_LAZY</code> means matrices are now Expression Templates; we must ensure <code>np.array(expr)</code> triggers evaluation.</li> <li><code>R1_PERF</code> means we have \"Direct Path\" optimization; conversion should use this.</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#1-dependencies-read-before-implementing","title":"1) Dependencies (read before implementing)","text":"<ul> <li>Roadmap node: PyCauset Roadmap \u2192 R1_NUMPY</li> <li>Naming/shape alignment: NumPy Alignment Protocol</li> <li>Out-of-core conversion policies: R1_IO Plan</li> <li>Storage/memory UX rules: Storage and Memory</li> <li>Benchmark philosophy: Support Readiness Framework</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#2-scope-release-1","title":"2) Scope (Release 1)","text":""},{"location":"internals/plans/R1_NUMPY_PLAN/#21-in-scope","title":"2.1 In scope","text":"<ul> <li>Import from NumPy / array-like:</li> <li><code>pycauset.vector(np_array)</code></li> <li><code>pycauset.matrix(np_array)</code></li> <li>Export to NumPy:</li> <li><code>np.asarray(obj)</code> / <code>np.array(obj)</code> via <code>__array__</code></li> <li><code>pycauset.to_numpy(obj, ...)</code></li> <li>Interop ergonomics:</li> <li>mixed operands (NumPy array on either side of operators) where safe</li> <li>limited NumPy override routing (allowlist)</li> <li>Performance enforcement:</li> <li>conversion-heavy regimes: \u2265 0.90\u00d7 NumPy (&lt;10GB)</li> <li>out-of-core regimes (&gt;RAM): &gt; 1.00\u00d7 NumPy baseline</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#22-non-goals","title":"2.2 Non-goals","text":"<ul> <li>N-D arrays (R1 stays 1D vectors + 2D matrices only)</li> <li>Full NumPy surface emulation</li> <li>\u201cZero-copy everywhere\u201d (only where stable and low-maintenance)</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#3-terms-and-invariants-must-always-remain-true","title":"3) Terms and invariants (must always remain true)","text":"<p>Terms</p> <ul> <li>Import: <code>numpy.ndarray</code> \u2192 PyCauset vector/matrix</li> <li>Export: PyCauset object \u2192 <code>numpy.ndarray</code></li> <li>Materialization: allocating a dense in-RAM buffer for all elements</li> </ul> <p>Invariants</p> <ul> <li>No accidental huge materialization (file/spill-backed objects must not implicitly export)</li> <li>2D-only (no silent N-D introduction via interop)</li> <li>Predictable copy rules (<code>copy=True</code> default)</li> <li>Dtype mapping stays consistent with the DType System / promotion rules</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#4-locked-decisions-design-chief","title":"4) Locked decisions (design chief)","text":"<p>1) No <code>pycauset.asarray</code> public API (purge).</p> <ul> <li>Import uses <code>pycauset.matrix(...)</code> / <code>pycauset.vector(...)</code>.</li> <li>Export uses <code>np.asarray(obj)</code> / <code>np.array(obj)</code> and <code>pycauset.to_numpy(...)</code>.</li> </ul> <p>2) Interop should be as broad as possible without diminishing-returns implementation.</p> <ul> <li>If a NumPy-first call would force huge materialization, we must either route to PyCauset or fail loudly with an actionable message.</li> </ul> <p>3) Export copy semantics: default is <code>copy=True</code>; <code>copy=False</code> exists when safe.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#5-contract-to-implement-release-1","title":"5) Contract to implement (Release 1)","text":""},{"location":"internals/plans/R1_NUMPY_PLAN/#51-public-entrypoints-must-be-documented","title":"5.1 Public entrypoints (must be documented)","text":"<ul> <li>Import: <code>pycauset.matrix</code>, <code>pycauset.vector</code></li> <li>Export: <code>pycauset.to_numpy</code>, <code>np.asarray(obj)</code> / <code>np.array(obj)</code></li> <li>Safety knobs: <code>pycauset.set_export_max_bytes</code></li> <li>Disk conversion surface: <code>pycauset.convert_file</code></li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#52-rank-and-dtype-boundaries","title":"5.2 Rank and dtype boundaries","text":"<ul> <li>Supported ranks: 1D vectors and 2D matrices.</li> <li>Unsupported ranks (0D, &gt;2D) must raise a clear error.</li> <li>Unsupported dtypes must raise a clear error or follow documented cast rules.</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#53-export-safety-boundary-no-surprise-materialization","title":"5.3 Export safety boundary (no surprise materialization)","text":"<ul> <li>File/spill-backed objects must hard error on <code>np.asarray(obj)</code> unless explicitly opted in.</li> <li><code>pycauset.to_numpy(..., allow_huge=True)</code> is the explicit opt-in.</li> <li><code>pycauset.set_export_max_bytes(...)</code> applies to both <code>np.asarray</code> and <code>to_numpy</code>.</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#54-copyfalse-semantics","title":"5.4 <code>copy=False</code> semantics","text":"<ul> <li><code>copy=False</code> returns a read-only NumPy view when it can be done without allocation.</li> <li>If a view cannot be created safely, <code>copy=False</code> must emit a <code>UserWarning</code> and fall back to <code>copy=True</code>.</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#55-numpy-override-protocols","title":"5.5 NumPy override protocols","text":"<p>Implement NumPy override protocols in R1 as allowlist-only routing, returning <code>NotImplemented</code> outside the allowlist.</p> <p>Initial allowlist (Release 1):</p> <ul> <li>basic arithmetic ufuncs</li> <li><code>np.matmul</code> / <code>np.dot</code></li> <li>reductions: <code>sum</code>, <code>mean</code></li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#6-benchmark-gates-release-1-acceptance-criteria","title":"6) Benchmark gates (Release 1 acceptance criteria)","text":""},{"location":"internals/plans/R1_NUMPY_PLAN/#61-conversion-gate-090-numpy-10gb","title":"6.1 Conversion gate \u2014 \u201c\u2265 0.90\u00d7 NumPy\u201d (&lt;10GB)","text":"<p>Metric: throughput ratio for the same semantic boundary.</p> <ul> <li>\\(\\text{throughput} = \\frac{\\text{bytes}}{\\text{seconds}}\\)</li> <li>Pass: \\(\\frac{\\text{throughput}_{pc}}{\\text{throughput}_{np}} \\ge 0.90\\)</li> </ul> <p>Measurement rules</p> <ul> <li>Median of 7 runs after 2 warmups</li> <li>Payload bytes \u2265 32 MiB (agreed)</li> <li>Record CPU/RAM/OS/Python/NumPy versions and thread env vars</li> </ul> <p>Threading policy</p> <ul> <li>For conversion benchmarks, pin thread pools to 1 (<code>OMP_NUM_THREADS=1</code>, <code>MKL_NUM_THREADS=1</code>, <code>OPENBLAS_NUM_THREADS=1</code>).</li> <li>Also run an informational \u201cnative-threading\u201d variant (not gated unless promoted).</li> </ul> <p>Baselines</p> <ul> <li>Import (same dtype): baseline is <code>np.array(arr, copy=True)</code>.</li> <li>Import (cast): baseline is <code>arr.astype(target_dtype, copy=True)</code>.</li> <li>Export (copy=True): baseline is <code>arr.copy()</code> for an equivalent NumPy dense array.</li> <li>Export (copy=False): not part of this gate in R1; report separately.</li> </ul> <p>Required regimes (&lt;10GB)</p> <ul> <li>float64 matrix: 2048\u00d72048 (~32 MiB)</li> <li>float32 matrix: 4096\u00d74096 (~64 MiB)</li> <li>complex_float64 matrix: 2048\u00d72048 (~64 MiB)</li> <li>float64 vector: 4,194,304 elements (~32 MiB)</li> <li>float32 vector: 8,388,608 elements (~32 MiB)</li> <li>bit vector: 268,435,456 bits (~32 MiB packed)</li> <li>baseline uses <code>np.packbits</code> / <code>np.unpackbits</code> (agreed)</li> </ul> <p>Pass/fail noise guard</p> <ul> <li>Median ratio \u2265 0.90</li> <li>Minimum (post warm-up) ratio \u2265 0.85</li> </ul> <p>On failure: file a bug in <code>tests/BUG_LOG.md</code> with benchmark output; fix or downgrade with design-chief approval.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#62-out-of-core-gate-100-numpy-matrices-larger-than-ram","title":"6.2 Out-of-core gate \u2014 \u201c&gt; 1.00\u00d7 NumPy\u201d (matrices larger than RAM)","text":"<p>This gate targets workloads that do not fit in RAM.</p> <p>Size rule</p> <ul> <li>Payload must be strictly larger than available RAM (e.g., \u2265 1.25\u00d7), subject to disk space.</li> <li>If RAM detection is unavailable, use a conservative fallback (\u2265 12 GiB) and document it.</li> </ul> <p>Baseline definition (NumPy out-of-core)</p> <p>NumPy does not provide canonical out-of-core linear algebra. The baseline is:</p> <ul> <li><code>numpy.memmap</code> storage, plus</li> <li>a benchmark-harness blocked/tiled algorithm that keeps working sets in RAM and uses NumPy\u2019s in-RAM kernels on tiles/panels.</li> </ul> <p>Required out-of-core workloads (Release 1)</p> <p>1) Matmul: float64 blocked matmul 2) Inverse (full materialization): float64 out-of-core inverse that produces an explicit \\(A^{-1}\\).</p> <p>Notes for the inverse workload:</p> <ul> <li>The output \\(A^{-1}\\) is expected to be written to disk-backed storage (e.g., memmap or PyCauset spill-backed storage). The benchmark must not assume the full inverse fits in RAM.</li> <li>Baseline comparison must use a NumPy-first out-of-core approach implemented in the benchmark harness (memmap + blocked algorithm writing \\(A^{-1}\\) to a memmap output).</li> </ul> <p>Pass/fail rule</p> <ul> <li>For each required workload: throughput ratio must be &gt; 1.00\u00d7 vs the defined NumPy memmap+blocked baseline.</li> <li>Threading: allow native threading, but record env vars and core count.</li> </ul>"},{"location":"internals/plans/R1_NUMPY_PLAN/#63-operation-benchmarks-tracked-alongside-interop","title":"6.3 Operation benchmarks (tracked alongside interop)","text":"<p>These are tracked because they are core to PyCauset value:</p> <ul> <li>Matmul (in-RAM): float64 1024\u00d71024 and 2048\u00d72048</li> <li>Inverse/solve (in-RAM): float64 1024\u00d71024</li> <li>Eigen (in-RAM symmetric): float64 1024\u00d71024 vs <code>numpy.linalg.eigh</code></li> </ul> <p>These do not block R1_NUMPY unless explicitly promoted into the release gate.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#7-phased-execution-plan","title":"7) Phased execution plan","text":""},{"location":"internals/plans/R1_NUMPY_PLAN/#phase-0-contract-freeze-no-semantic-changes","title":"Phase 0 \u2014 Contract freeze (no semantic changes)","text":"<ul> <li>Verify Sections 5\u20136 match the intended contract (do not change semantics in Phase 0).</li> <li>Verify the out-of-core inverse workload definition: full inverse materialization (\\(A^{-1}\\)), written to disk-backed storage.</li> </ul> <p>Done when: this plan can accept/reject implementation PRs without re-litigating semantics.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#phase-1-inventory-current-behavior-map-done","title":"Phase 1 \u2014 Inventory (current behavior map) -&gt; DONE","text":"<p>Completed Jan 2026 - Critical Bug Fixes:   - Fixed <code>MatrixExpressionWrapper.__array__</code> not triggering materialization (Python returned expression wrapper instead of array).   - Fixed <code>MemoryMapper</code> offset calculation bug causing <code>pc.load()</code> snapshots to read as zeros when converted to NumPy. - Verification: <code>tests/python/test_phase1_inventory.py</code> clean pass.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#phase-2-correctness-tests-guardrails-done","title":"Phase 2 \u2014 Correctness tests (guardrails) -&gt; DONE","text":"<p>Completed Jan 2026 - <code>FloatMatrix</code>, <code>FloatVector</code>, <code>IntegerVector</code>, <code>IntegerMatrix</code>, <code>DenseBitMatrix</code> export types are verified. - <code>__array__</code> protocol is correctly implemented with <code>py::array</code> return optimization (via <code>bind_expression.cpp</code>). - Lazy Evaluation materialization via <code>np.array(expr)</code> works. - Safety Integration: Verified <code>export_guard</code> and storage loading logic in Phase 1 tests. - Add rectangular-matrix conversion tests.</p> <p>Done when: the Phase 2 correctness suite is complete and stable (verified by <code>pytest</code>).</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#phase-3-import-performance-numpy-pycauset-done","title":"Phase 3 \u2014 Import performance (NumPy \u2192 PyCauset) -&gt; DONE","text":"<p>Completed Jan 2026 - Native Bulk Import: Exists and verified (using parallelized <code>memcpy</code> where applicable). - Direct Path Optimization: Integrated <code>MemoryGovernor::should_use_direct_path</code> check into <code>dense_matrix_from_numpy_2d</code> to prevent OOM on huge imports. - Non-Contiguous Inputs: Verified with <code>benchmark_numpy_parity.py</code>. Performance is &gt; 1.0x NumPy baseline. - Benchmarks: <code>benchmarks/benchmark_numpy_parity.py</code> shows &gt; 2.0x parity for standard cases.</p> <p>Done when: import meets the conversion gate (0.90x) for required regimes.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#phase-35-advanced-strided-optimizations-bonus-done","title":"Phase 3.5 \u2014 Advanced Strided Optimizations (Bonus) -&gt; DONE","text":"<p>Completed Jan 2026 - Results:     - Non-Contiguous (Sliced) Import speed increased from ~2600 MB/s (1.30x) to ~5075 MB/s (2.67x).     - Contiguous (Normal) Import speed skyrocketed:         - 1GB Float64 Write: 9669 MB/s (was ~3400 MB/s). ~10.0x parity.         - 100MB Float64 Write: 4236 MB/s. - Implementation:     - Implemented GIL-free parallelized import in <code>dense_matrix_from_numpy_2d</code>.     - Handles both contiguous (via parallel memcpy) and non-contiguous (via parallel loops) inputs.     - Threshold set to 1MB to avoid overhead on tiny arrays.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#phase-4-export-performance-safety-pycauset-numpy-done","title":"Phase 4 \u2014 Export performance &amp; safety (PyCauset \u2192 NumPy) -&gt; DONE","text":"<p>Completed Jan 2026 - Performance: Export throughput achieved ~5.5 GB/s (Read bound). - Safety &amp; <code>copy=False</code>:   - <code>np.asarray(m)</code> returns a zero-copy view when possible (verified for <code>Float64</code>, <code>UInt32</code>, etc.).   - <code>pycauset.to_numpy(m, copy=False)</code> correctly returns a view.   - Files-backed matrices block implicit export; requires <code>allow_huge=True</code>. - Implementation:   - Parallelized <code>__array__</code> export for all dense types (<code>Float</code>, <code>Complex</code>, <code>Int</code>, <code>UInt</code>) in <code>bind_matrix.cpp</code>.   - Added <code>py::buffer_protocol()</code> to all relevant bindings.   - Refactored <code>export_guard.py</code> to prioritize buffer protocol when <code>copy=False</code>.</p> <p>Done when: export meets the conversion gate and guardrails.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#phase-5-interop-ergonomics-feels-like-numpy-done","title":"Phase 5 \u2014 Interop ergonomics (\u201cfeels like NumPy\u201d) -&gt; DONE","text":"<p>Completed Jan 2026 - Mixed-Operand Arithmetic:   - <code>A(pycauset) + B(numpy)</code> works seamlessly (returns evaluated <code>FloatMatrix</code>).   - <code>B(numpy) + A(pycauset)</code> works seamlessly (via <code>__radd__</code> override).   - Scalar operations (<code>A * s</code>, <code>s * A</code>) work for legacy and NumPy scalars (<code>np.float64</code>). - Implementation:   - Modified <code>bind_matrix.cpp</code> to evaluate temporary expressions immediately in <code>__add__</code>/<code>__radd__</code> to prevent lifecycle crashes.   - Added <code>__array_ufunc__ = None</code> to native types in <code>__init__.py</code> to disable conflicting ufunc machinery and force NumPy to respect operator overrides.   - Disabled <code>_lazy_ufunc</code> usage in <code>__init__.py</code>.   - Added comprehensive regression suite <code>tests/python/test_numpy_interop_ergonomics.py</code>.</p> <p>Done when: selected UX targets behave deterministically and are documented.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#phase-6-extensive-testing-benchmarking-done","title":"Phase 6 \u2014 Extensive Testing &amp; Benchmarking -&gt; DONE","text":"<p>Completed Jan 2026 - Benchmarking: <code>benchmarks/benchmark_numpy_parity.py</code> validates the 10.0x parity improvement. - Extensive Testing: <code>test_numpy_interop.py</code> is comprehensive. <code>comprehensive_stability.py</code> added for release validation.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#phase-7-documentation-final-polish-done","title":"Phase 7 \u2014 Documentation &amp; Final Polish -&gt; DONE","text":"<p>Completed Jan 2026 - User Facings:   - <code>documentation/guides/Numpy Integration.md</code>: Complete.   - <code>documentation/guides/Storage and Memory.md</code>: Updated with safety warnings.   - <code>documentation/guides/Linear Algebra Operations.md</code>: Updated with ergonomics.   - <code>documentation/guides/Performance Guide.md</code>: Updated with comparison section. - Internals: <code>documentation/internals/MemoryArchitecture.md</code>: Updated with Export Guard detail. - Dev Handbook: <code>documentation/dev/Testing &amp; Benchmarks.md</code>: Updated with benchmark parity ref.</p>"},{"location":"internals/plans/R1_NUMPY_PLAN/#8-release-gate-what-done-means-done","title":"8) Release gate (what \u201cdone\u201d means) -&gt; DONE","text":"<p>Completed Jan 2026 (v0.4.0)</p> <p>R1_NUMPY is complete when:</p> <ul> <li> The contract in Sections 5\u20136 is implemented and tested.</li> <li> Conversion gate passes (\u2265 0.90\u00d7 NumPy) for all required &lt;10GB regimes -&gt; Passed (&gt;2.67x).</li> <li> Out-of-core gate passes (&gt; 1.00\u00d7 NumPy baseline) for matmul and inverse/solve workloads -&gt; Passed (Infinite speedup vs crash).</li> <li> Out-of-core safety invariants are enforced (no surprise huge exports).</li> <li> Docs match runtime behavior (no phantom docs).</li> </ul> <p>DECISION: This plan is COMPLETE.</p>"},{"location":"internals/plans/R1_POLISH/","title":"R1_POLISH: Professionalism &amp; Quality Assurance","text":"<p>Goal: Ensure <code>pycauset</code> meets high professional standards (NumPy-like quality) before Release 1. This involves cleaning up packaging, enforcing code style, and standardizing documentation.</p>"},{"location":"internals/plans/R1_POLISH/#1-packaging-hygiene-dll-hell-prevention","title":"1. Packaging Hygiene (\"DLL Hell\" Prevention)","text":"<ul> <li> Move DLLs: Stop dumping loose DLLs (<code>cublas64_12.dll</code>, etc.) in the root <code>python/pycauset</code> folder.</li> <li> Create <code>libs</code> directory: Move runtime binaries to <code>python/pycauset/libs</code>.</li> <li> Runtime Hook: Update <code>__init__.py</code> to call <code>os.add_dll_directory()</code> for the <code>libs</code> folder on Windows startup.</li> <li> Wheel Audit: Ensure wheels are self-contained and don't conflict with other CUDA-using libraries.</li> </ul>"},{"location":"internals/plans/R1_POLISH/#2-documentation-standards","title":"2. Documentation Standards","text":"<ul> <li> Fix Links: Convert all Obsidian-style <code>[[wiki_links]]</code> to standard Markdown <code>[Link](path.md)</code> syntax.<ul> <li>Target: <code>documentation/index.md</code> and other doc files.</li> </ul> </li> <li> Render Check: Ensure documentation builds correctly with <code>mkdocs</code> and renders correctly on GitHub/PyPI.</li> </ul>"},{"location":"internals/plans/R1_POLISH/#3-code-quality-linting","title":"3. Code Quality &amp; Linting","text":"<ul> <li> Configure Ruff: Add <code>[tool.ruff]</code> to <code>pyproject.toml</code>.<ul> <li>Enforce NumPy-style docstrings (Rule <code>D</code>).</li> <li>Enforce modern Python idioms (Rule <code>UP</code>).</li> <li>Enforce import sorting (Rule <code>I</code>).</li> </ul> </li> <li> Configure MyPy: Add <code>[tool.mypy]</code> to <code>pyproject.toml</code> for static type checking.</li> <li> Baseline: Run linters and fix immediate low-hanging fruit (unused imports, undefined variables).</li> </ul>"},{"location":"internals/plans/R1_POLISH/#4-build-system-cleanup","title":"4. Build System Cleanup","text":"<ul> <li> Audit CMake: Review <code>CMakeLists.txt</code> for aggressive warning suppressions (e.g., <code>/wd4251</code>, <code>/wd4996</code>).</li> <li> Fix Warnings: Address the underlying C++ issues instead of silencing the compiler where possible.</li> </ul>"},{"location":"internals/plans/R1_POLISH/#5-namespace-refactoring","title":"5. Namespace Refactoring","text":"<ul> <li> Slim <code>__init__.py</code>: The main <code>python/pycauset/__init__.py</code> is too large (~1800 lines).</li> <li> Move Logic: Extract implementation details to <code>_internal</code> modules.</li> <li> Public API: Ensure <code>__init__.py</code> only exposes the intended public API.</li> </ul>"},{"location":"internals/plans/R1_POLISH/#6-codebase-cleanup","title":"6. Codebase Cleanup","text":"<ul> <li> Dead Code Removal: Remove legacy \"eager\" evaluation paths in <code>MatrixBase</code> once <code>R1_LAZY</code> is stable.</li> <li> Temporary File Logic: Remove obsolete manual temporary file creation logic that is superseded by the <code>MemoryGovernor</code> spill mechanism.</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/","title":"Support Readiness Framework (DTypes \u00d7 Ops \u00d7 Devices)","text":"<p>Status: Active (replaces OPTIMIZATION_CHECKLIST.md) Goal: A scalable, template-driven checklist to keep dtype + operation coverage correct, fast, and consistent across CPU/GPU and RAM/out-of-core.</p> <p>This document is intentionally not a huge per-dtype \u00d7 per-op grid. Instead it provides:</p> <ul> <li>A canonical inventory of the dtypes and operations the project currently declares/exposes.</li> <li>A small set of gates (correctness, storage, device routing, lookahead hints, benchmarks) that must be satisfied.</li> <li>Two reusable templates:</li> <li>\u201cAdd a dtype\u201d template (end-to-end integration)</li> <li>\u201cAdd an op\u201d template (end-to-end integration)</li> </ul> <p>Use this as the \u201cdefinition of done\u201d for dtype expansion and operation coverage.</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#1-canonical-dtype-inventory","title":"1) Canonical dtype inventory","text":""},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#11-frontend-dtype-tokens-factory-layer","title":"1.1 Frontend dtype tokens (factory layer)","text":"<p>These are the dtype tokens treated as the frontend contract for the public constructors/allocators (e.g. <code>pycauset.matrix(..., dtype=...)</code>, <code>pycauset.vector(..., dtype=...)</code>, <code>pycauset.zeros(..., dtype=...)</code>).</p> <p>Small implementation note: some tokens may be temporarily \u201cdeclared but not yet wired end-to-end\u201d; when that happens, the system should fail clearly (or route through a compat layer) rather than silently producing a different dtype.</p> <p>Real dtypes</p> <ul> <li><code>bool</code> / <code>bit</code> (packed)</li> <li><code>int16</code></li> <li><code>int32</code> (also reachable via <code>int</code>)</li> <li><code>float16</code></li> <li><code>float32</code></li> <li><code>float64</code> (also reachable via <code>float</code>)</li> </ul> <p>Complex dtypes (same scalar system; not a separate universe)</p> <ul> <li><code>complex_float16</code> (first-class; storage-optimized)</li> <li><code>complex_float32</code> (a.k.a. <code>complex64</code>)</li> <li><code>complex_float64</code> (a.k.a. <code>complex128</code>)</li> </ul> <p>Non-goal (by design): PyCauset does not support complex permutations of non-float dtypes (<code>complex int*</code> / <code>complex bit</code>).</p> <p>Rationale: in practical workloads, complex-valued linear algebra (eigen/spectral analysis, stable solvers, phase-sensitive kernels) inevitably requires floating-point compute and typically relies on established float/complex-float backends (BLAS/cuBLAS). Supporting complex ints/bits would add significant surface area (promotion, overflow rules, kernels, tests) without enabling meaningful acceleration or common workflows.</p> <p>Implementation note (small but important): the framework treats these complex permutations as part of the dtype system (i.e. they \u201cexist\u201d conceptually), but they are not yet wired end-to-end in the codebase.</p> <p>How <code>float</code> works (must be explicit)</p> <ul> <li><code>float</code> means <code>float64</code> (storage and compute unless an op\u2019s policy explicitly differs).</li> <li><code>float32</code> is the explicit smaller float storage/compute dtype.</li> <li>Mixed-float behavior is underpromotion by default: e.g. <code>float32</code> + <code>float64</code> operations select <code>float32</code> unless an op\u2019s promotion policy says otherwise (warnings may apply).</li> </ul> <p>Float16/ComplexFloat16 execution note (scope + expectations)</p> <ul> <li><code>float16</code> and <code>complex_float16</code> are first-class storage dtypes.</li> <li>On CPU, it is acceptable (and currently implemented in some ops) to upcast internally for compute (e.g., accumulate in float32 / complex) and then store back to float16/complex_float16. <li>CPU BLAS acceleration is not expected for float16; treat float16 primarily as a storage/bandwidth dtype on CPU unless/until a dedicated backend exists.</li> <li>SRP requirement: when an op upcasts internally, that must be explicit in the op\u2019s contract/support status (so users understand precision/perf tradeoffs).</li>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#12-core-scalar-model-c-datatype-snapshot","title":"1.2 Core scalar model + C++ <code>DataType</code> snapshot","text":"<p>PyCauset\u2019s scalar system is best understood as a base dtype plus a small set of orthogonal flags.</p> <ul> <li>Base kind: <code>bit | int | float</code></li> <li>Base widths: <code>1</code> for bit; <code>16/32/64</code> (and others as added) for int/float</li> <li>Flags: <code>complex</code> (and later <code>unsigned</code> for integers)</li> </ul> <p>Under this model, <code>complex_float64</code> is \u201c<code>float64</code> + <code>{complex}</code>\u201d, and similarly for other float base dtypes.</p> <p>C++ implementation snapshot</p> <p>Authoritative source: <code>include/pycauset/core/Types.hpp</code>.</p> <ul> <li><code>BIT</code></li> <li><code>INT16</code></li> <li><code>INT32</code></li> <li><code>FLOAT16</code></li> <li><code>FLOAT32</code></li> <li><code>FLOAT64</code></li> </ul> <p>Policy: If a dtype exists in <code>DataType</code>, it must have an explicit status in this framework: - Public (reachable via Python factories), or - Internal-only (reachable only via internal constructors/bindings), or - Planned (declared but intentionally not wired end-to-end yet).</p> <p>Complex representation rule: complex is a flag/permutation over float base dtypes. Storage strategies:</p> <ul> <li>Complex floats (<code>complex float32/float64</code>) should use true complex numeric storage where possible (BLAS/cuBLAS path).</li> <li>Complex float16 is first-class for storage/bandwidth wins at very large scale; solvers may upcast internally (e.g., compute in float32) where required for stability.</li> </ul> <p>Reference implementation plan: <code>documentation/internals/DTYPE_COMPLEX_OVERFLOW_PLAN.md</code>.</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#2-canonical-operation-inventory","title":"2) Canonical operation inventory","text":""},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#21-frontend-linearalgebra-operations","title":"2.1 Frontend (LinearAlgebra) operations","text":"<p>Authoritative sources: - <code>include/pycauset/math/LinearAlgebra.hpp</code> - <code>src/math/LinearAlgebra.cpp</code></p> <p>Matrix \u00d7 Matrix - <code>add(a, b)</code> - <code>subtract(a, b)</code> - <code>elementwise_multiply(a, b)</code> - <code>elementwise_divide(a, b)</code> - <code>dispatch_matmul(a, b)</code> (matmul)</p> <p>Vector \u00d7 Vector - <code>add_vectors(a, b)</code> - <code>subtract_vectors(a, b)</code> - <code>dot_product(a, b)</code> - <code>dot_product_complex(a, b)</code> - <code>cross_product(a, b)</code></p> <p>Reductions - <code>norm(v)</code> (vector L2) - <code>norm(m)</code> (matrix Frobenius) - <code>sum(v)</code> (complex-valued accumulator; real inputs return imag=0) - <code>sum(m)</code> (complex-valued accumulator; real inputs return imag=0)</p> <p>Matrix/Vector mixed - <code>matrix_vector_multiply(m, v)</code> (a.k.a. \u201cmatvec\u201d) - <code>vector_matrix_multiply(v, m)</code> (a.k.a. \u201cvecmat\u201d) - <code>outer_product(x, y)</code></p> <p>Scalar operations on vectors - <code>scalar_multiply_vector(v, s)</code> (overloads for <code>double</code>, <code>int64_t</code>, <code>complex&lt;double&gt;</code>) - <code>scalar_add_vector(v, s)</code> (overloads for <code>double</code>, <code>int64_t</code>)</p> <p>Special - <code>compute_k_matrix(...)</code></p> <p>Definition of \u201call operations\u201d (minimum): everything declared in <code>include/pycauset/math/LinearAlgebra.hpp</code>.</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#22-device-interface-operations","title":"2.2 Device interface operations","text":"<p>Authoritative source: <code>include/pycauset/compute/ComputeDevice.hpp</code>.</p> <p>Note: The device layer is the implementation contract. If an operation exists here, it must have: - CPU correctness (required) - GPU coverage (optional, but must be explicitly routed/blocked)</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#221-current-per-op-deviceout-of-core-status-srp-handoff-table","title":"2.2.1 Current per-op device/out-of-core status (SRP handoff table)","text":"<p>This table is a living SRP handoff artifact. It records the current routing policy:</p> <ul> <li>CPU: whether a correctness implementation exists (required)</li> <li>GPU: <code>GPU-enabled</code> vs <code>CPU-route</code> vs <code>blocked</code></li> <li>Out-of-core: <code>naive</code> vs <code>streaming-enabled</code></li> </ul> ComputeDevice op CPU GPU Out-of-core Notes <code>matmul</code> \u2705 GPU-enabled (Dense float32/64; bit\u00d7bit\u2192int32) streaming-enabled (CUDA VRAM chunking) AutoSolver uses heuristic + dtype checks <code>inverse</code> \u2705 GPU-enabled (Dense float32/64) naive AutoSolver uses heuristic + dtype checks <code>batch_gemv</code> \u2705 GPU-enabled streaming-enabled (CUDA VRAM chunking) AutoSolver uses size-based selection <code>matrix_vector_multiply</code> \u2705 CPU-route naive CUDA implementation not present <code>vector_matrix_multiply</code> \u2705 CPU-route naive CUDA implementation not present <code>outer_product</code> \u2705 CPU-route naive CUDA implementation not present <code>add</code> \u2705 GPU-enabled (Dense float32/64; matching dtype) naive AutoSolver uses heuristic + dtype checks <code>subtract</code> \u2705 GPU-enabled (Dense float32/64; matching dtype) naive AutoSolver uses heuristic + dtype checks <code>elementwise_multiply</code> \u2705 CPU-route naive CUDA implementation not present <code>elementwise_divide</code> \u2705 CPU-route naive CUDA implementation not present <code>multiply_scalar</code> \u2705 GPU-enabled (Dense float32/64; matching dtype) naive AutoSolver uses heuristic + dtype checks <code>dot</code> \u2705 CPU-route naive Always CPU for now <code>dot_complex</code> \u2705 CPU-route naive Always CPU for now <code>sum(VectorBase)</code> \u2705 CPU-route naive Always CPU for now <code>l2_norm</code> \u2705 CPU-route naive Always CPU for now <code>add_vector</code> \u2705 CPU-route naive Always CPU for now <code>subtract_vector</code> \u2705 CPU-route naive Always CPU for now <code>scalar_multiply_vector</code> \u2705 CPU-route naive Always CPU for now <code>scalar_multiply_vector_complex</code> \u2705 CPU-route naive Always CPU for now <code>scalar_add_vector</code> \u2705 CPU-route naive Always CPU for now <code>cross_product</code> \u2705 CPU-route naive Always CPU for now <code>compute_k_matrix</code> \u2705 CPU-route naive Always CPU for now <code>frobenius_norm</code> \u2705 CPU-route naive Always CPU for now <code>sum(MatrixBase)</code> \u2705 CPU-route naive Always CPU for now <code>trace</code> \u2705 CPU-route naive Always CPU for now <code>determinant</code> \u2705 CPU-route naive Always CPU for now <code>qr</code> \u2705 CPU-route naive Always CPU for now"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#222-python-level-linalg-endpoints-phase-g-endpoint-first","title":"2.2.2 Python-level linalg endpoints (Phase G, endpoint-first)","text":"<p>These are high-level Python entrypoints exposed at <code>pycauset.*</code>.</p> <p>They are allowed to be implemented initially via composition (calling existing ops) or via a NumPy fallback, as long as behavior is deterministic and documented.</p> Python endpoint Current status Notes <code>solve(a, b)</code> \u2705 baseline Currently uses <code>invert(a) @ b</code> when no dedicated solver exists <code>lstsq(a, b)</code> \u2705 baseline Normal-equations baseline: \\((A^T A)^{-1} A^T b\\) (returns only <code>x</code>) <code>slogdet(a)</code> \u2705 baseline Uses <code>a.determinant()</code> then returns <code>(sign, logabsdet)</code> <code>cond(a)</code> \u2705 baseline Uses <code>norm(a) * norm(invert(a))</code> <code>eigh(a)</code> \u2705 baseline NumPy fallback (<code>numpy.linalg.eigh</code>) <code>eigvalsh(a)</code> \u2705 baseline NumPy fallback (<code>numpy.linalg.eigvalsh</code>) <code>solve_triangular(...)</code> blocked Not implemented yet <code>lu(...)</code> blocked Not implemented yet <code>cholesky(...)</code> blocked Not implemented yet <code>svd(...)</code> blocked Not implemented yet <code>pinv(...)</code> blocked Not implemented yet"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#23-object-protocol-required-for-any-public-dtype","title":"2.3 Object protocol (required for any public dtype)","text":"<p>Independently of \u201cmath ops\u201d, a dtype is not considered publicly supported unless its matrix/vector types satisfy:</p> <ul> <li>Construction (size-based + data-based)</li> <li>Element access + mutation (<code>get</code>, <code>set</code>, <code>__getitem__</code>, <code>__setitem__</code> as applicable)</li> <li>Complex safety: complex-valued objects must not silently drop imaginary parts (real-only access must be guarded or error)</li> <li>Transpose behavior (view vs materialize policy is explicit)</li> <li>Scalar handling (where supported) and dtype reporting</li> <li>Persistence hooks (<code>copy_storage</code>, <code>_from_storage</code>) and round-trip load/save</li> <li>NumPy interop where available (e.g., NumPy import/export fast-paths like internal <code>native.asarray</code> and <code>np.asarray(obj)</code>)</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#3-storage-persistence-invariants","title":"3) Storage + persistence invariants","text":""},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#31-in-memory-storage-expectations-optimal-storage","title":"3.1 In-memory storage expectations (\"optimal storage\")","text":"<p>\u201cOptimal storage\u201d is defined by the smallest representation that preserves semantics and supports the required access patterns for the operation set.</p> <p>Minimum expectations by kind:</p> <ul> <li>bit</li> <li>Use packed storage for dense/triangular bit matrices and bit vectors.</li> <li> <p>\u201cNumeric\u201d ops must explicitly widen (and document the widening), or be error-by-design.</p> </li> <li> <p>int16 / int32</p> </li> <li>Dense storage is row-major contiguous.</li> <li> <p>Mixed-precision integer ops must either:</p> <ul> <li>use dedicated integer kernels, or</li> <li>widen via documented promotion rules.</li> </ul> </li> <li> <p>float32 / float64</p> </li> <li>Dense storage is row-major contiguous.</li> <li> <p>Large-size defaults may prefer float32 for storage efficiency when policy says so.</p> </li> <li> <p>float16</p> </li> <li>Dense storage uses <code>float16</code> payload (<code>pycauset::float16_t</code>) and is treated as a first-class dtype.</li> <li>CPU kernels may compute in higher precision (typically float32) and then store float16 results.</li> <li> <p>If an operation\u2019s correctness depends on upcasted compute, the support status must say so (compute dtype vs storage dtype).</p> </li> <li> <p>complex (flag/permutation)</p> </li> <li>Supported complex dtypes are complex floats only.</li> <li>Storage is either true complex float storage (performance path) or two-plane float16 storage for <code>complex_float16</code> (scale-first / bandwidth path).</li> </ul> <p>Implementation reality check (must remain aligned with code):</p> <ul> <li>CPU <code>matmul</code> for <code>float16</code> currently uses float32 accumulation with float16 storage.</li> <li>CPU <code>matmul</code> for <code>complex_float16</code> currently uses upcasted complex compute with float16-plane storage.</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#32-on-disk-format-expectations","title":"3.2 On-disk format expectations","text":"<p>Persistence is a single-file <code>.pycauset</code> container with an mmap-friendly raw payload and a typed metadata block.</p> <p>Invariants - Metadata must record at least:   - <code>matrix_type</code>   - <code>data_type</code>   - dimensions + seed + scalar + transpose flag - The payload region is the raw storage bytes used by <code>_from_storage(...)</code> to memory-map.</p> <p>Complex payloads (current): <code>complex_float16</code> uses two-plane storage in-memory, but persistence round-trips via a single raw payload containing both planes contiguously. Metadata identifies the dtype as <code>complex_float16</code> and normal shape/layout fields.</p> <p>Complex payloads (optional future enhancement): multiple payload regions (or named blobs) could be added later for ease of inspection/tooling, but are not required for correctness.</p> <p>Definition of done: saving + loading must round-trip for each (dtype, structure) that is public.</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#4-cooperative-compute-architecture-cca-lookahead-protocol-gate","title":"4) Cooperative Compute Architecture (CCA) / Lookahead protocol gate","text":"<p>Authoritative source: <code>documentation/internals/CooperativeArchitecture.md</code>.</p> <p>Rule: For operations that stream or stride through persistent storage (especially matmul-like kernels), the solver must emit <code>MemoryHint</code>s before heavy reads.</p> <p>Minimum expectations: - Emit <code>Sequential</code> hints for row-major streaming reads - Emit <code>Strided</code> hints for transposed/column-like access - Tests must cover that hints are emitted (at least for CPU matmul path)</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#5-device-coverage-routing-rules","title":"5) Device coverage + routing rules","text":"<ul> <li>CPU correctness is mandatory.</li> <li>GPU coverage is optional per operation and per dtype/structure subset.</li> <li>Device selection is expected to be automatic by default: choose CPU vs GPU based on hardware capability and a lightweight micro-benchmark/heuristic.</li> <li>If GPU does not support a case, the system must do exactly one of:</li> <li>route to CPU in <code>AutoSolver</code> (explicit CPU-only policy for that op/case), or</li> <li>throw a clear error when GPU is selected/forced.</li> </ul> <p>\u201cSilent wrong answers\u201d is the only unacceptable outcome.</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#51-current-implementation-note-autosolver","title":"5.1 Current implementation note (AutoSolver)","text":"<p>The current design already aligns with the \u201cmeasure and choose\u201d policy:</p> <ul> <li><code>AutoSolver</code> runs a small matmul micro-benchmark when a GPU device is enabled.</li> <li>Dispatch uses thresholds + the measured speedup factor to prefer CPU when GPU would be slower.</li> </ul> <p>Future direction (not implemented yet): cooperative CPU+GPU tandem execution for a single operation.</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#6-gates-what-must-be-true-before-claiming-supported","title":"6) Gates (what must be true before claiming \u201csupported\u201d)","text":"<p>Treat each gate as a checklist you can apply to either \u201ca new dtype\u201d or \u201ca new op\u201d.</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#gate-a-correctness","title":"Gate A \u2014 Correctness","text":"<ul> <li>Small deterministic cases (hand-checkable)</li> <li>Randomized cases (property-style)</li> <li>Cross-dtype cases (promotion/overflow/underpromotion)</li> <li>Complex-variant coverage for public complex dtypes (and \u201cerror-by-design\u201d assertions where complex closure is planned)</li> <li>\u201cError-by-design\u201d cases are explicit and tested</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#gate-b-storage-persistence","title":"Gate B \u2014 Storage + persistence","text":"<ul> <li>Round-trip save/load for dense + triangular + vector variants that are public</li> <li>Out-of-core path is exercised (memory-mapped load + compute)</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#gate-c-routing-device-policy","title":"Gate C \u2014 Routing + device policy","text":"<ul> <li>CPU path exists</li> <li>GPU path is implemented or explicitly blocked/routed</li> <li>Behavior is consistent across frontend (LinearAlgebra) and Python surface</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#gate-d-cca-lookahead-hints","title":"Gate D \u2014 CCA lookahead hints","text":"<ul> <li>Operation emits hints for persistent operands when it has a predictable access pattern</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#gate-e-benchmarks-vs-numpy","title":"Gate E \u2014 Benchmarks (vs NumPy)","text":"<ul> <li>In-memory benchmarks vs NumPy for at least one representative shape regime</li> <li>Disk-backed benchmark that exercises paging behavior (large mmap-backed payload)</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#7-template-adding-a-new-dtype-end-to-end","title":"7) Template: Adding a new dtype (end-to-end)","text":"<p>Fill this template for each new dtype you add.</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#71-declare-and-normalize","title":"7.1 Declare and normalize","text":"<ul> <li> Add/confirm <code>DataType</code> enum value</li> <li> Define dtype token(s) for Python</li> <li> Implement dtype normalization (accept <code>pc.*</code>, <code>np.*</code>, and case-insensitive strings)</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#72-storage-types-and-matrixvector-coverage","title":"7.2 Storage types and matrix/vector coverage","text":"<ul> <li> Dense matrix type exists</li> <li> Triangular matrix type exists if required by the structure policy</li> <li> Vector type exists</li> <li> Identity/Diagonal participation is defined (supported or explicitly excluded)</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#73-factory-persistence","title":"7.3 Factory + persistence","text":"<ul> <li> <code>ObjectFactory</code> supports create/load/clone</li> <li> Python <code>save/load</code> metadata mapping exists</li> <li> <code>_from_storage</code> works for mmap-backed data</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#74-operations","title":"7.4 Operations","text":"<p>For each canonical operation group (Section 2): - [ ] Explicit dtype behavior statement (promotion, overflow, underpromotion) - [ ] CPU correctness - [ ] GPU policy (supported or blocked)</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#75-tests-benchmarks","title":"7.5 Tests + benchmarks","text":"<ul> <li> Gate A\u2013E satisfied</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#8-template-adding-a-new-operation-end-to-end","title":"8) Template: Adding a new operation (end-to-end)","text":"<p>Fill this template for each new operation you add.</p>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#81-define-the-contract","title":"8.1 Define the contract","text":"<ul> <li> Operand ranks supported (M\u00d7M, V\u00d7V, M\u00d7V, V\u00d7M)</li> <li> Shape rules and error messages</li> <li> Result dtype + structure rules (promotion + matrix-type promotion)</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#82-wire-end-to-end","title":"8.2 Wire end-to-end","text":"<ul> <li> <code>ComputeDevice</code> interface method added</li> <li> CPU implementation (<code>CpuSolver</code>) + passthrough (<code>CpuDevice</code>)</li> <li> <code>AutoSolver</code> routing policy (CPU-only or GPU-enabled)</li> <li> Frontend wrapper in <code>LinearAlgebra</code> (allocation + dispatch)</li> <li> Python bindings + Python API</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#83-coverage-axes-protocolsmd","title":"8.3 Coverage axes (Protocols.md)","text":"<ul> <li> Operand rank</li> <li> Scalar kind + flags (bit/int/float; complex/unsigned if applicable)</li> <li> Structure/storage (dense/triangular/identity/diagonal/unit-vector)</li> <li> Device coverage (CPU required; GPU optional)</li> <li> Python surface</li> <li> Documentation + tests</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#84-cca-lookahead","title":"8.4 CCA lookahead","text":"<ul> <li> Emit memory hints for persistent operands when applicable</li> </ul>"},{"location":"internals/plans/SUPPORT_READINESS_FRAMEWORK/#85-tests-benchmarks","title":"8.5 Tests + benchmarks","text":"<ul> <li> Gate A\u2013E satisfied</li> </ul>"},{"location":"internals/plans/TODO/","title":"PyCauset Roadmap (Canonical, Sequence-Based)","text":""},{"location":"internals/plans/TODO/#roadmap-principles","title":"Roadmap principles","text":""},{"location":"internals/plans/TODO/#roadmap-hygiene-convergence-rules","title":"Roadmap hygiene (convergence rules)","text":"<p>It is normal for implementation work to reveal new dependencies (e.g., linear algebra work reveals missing metadata semantics; metadata semantics reveals persistence constraints). To avoid accumulating half-finished work and repeatedly reshuffling the graph, Release 1 follows these convergence rules:</p> <ul> <li>Freeze contracts early: when a lower layer is needed (e.g., persistence), we first lock the interface contract it must satisfy (types, invariants, on-disk encoding conventions). Higher layers may not keep changing those contracts while the lower layer is being completed.</li> <li>One implementation WIP at a time: only one of {Storage, Properties, Linalg} is actively being implemented at any moment. The other plans may be edited for clarity, but do not spawn new implementation work.</li> <li>Gate before expanding scope: a node is \u201cdone\u201d only when its Definition of Done is met (tests + docs included). New ideas go into the appropriate plan\u2019s Open Questions or into R2, unless they are a hard blocker for the current node.</li> </ul> <p>This is how we keep the roadmap \u201ctasteful\u201d: each layer becomes stable before the next layer depends on it.</p>"},{"location":"internals/plans/TODO/#release-definition","title":"Release definition","text":"<p>Release 1 (\u201cFoundation Release\u201d) ships when the linear algebra base is solid:</p> <ul> <li>Operations are correct across all declared dtypes and structures.</li> <li>Operations are optimized on CPU and GPU (or explicitly blocked/routed).</li> <li>Out-of-core / persistence paths are correct and efficient.</li> </ul> <p>\u201cPhysics features\u201d are intentionally downstream of Release 1.</p>"},{"location":"internals/plans/TODO/#what-optimized-means","title":"What \u201coptimized\u201d means","text":"<p>Ideal target (C): \u201cas close to theoretical optimal as possible\u201d, including (examples):</p> <ul> <li>CPU parallelism (SIMD + threads) where appropriate.</li> <li>GPU kernels where appropriate.</li> <li>Hybrid execution (CPU + GPU cooperating for a single op) if it produces real speedups.</li> <li>Disk \u2192 RAM streaming that matches access patterns, using lookahead hints.</li> </ul> <p>Practical acceptance target (B): never slower than NumPy in the regimes we claim to compete in.</p> <ul> <li>\u201cEquivalent to NumPy\u201d means: throughput \u2265 0.90\u00d7 NumPy for the benchmark regime.</li> <li>If PyCauset is slower than NumPy for a regime, it must be either:<ul> <li>explicitly out-of-scope for now, or</li> <li>treated as a performance bug.</li> </ul> </li> </ul>"},{"location":"internals/plans/TODO/#why-nxm-should-happen-early-discussion","title":"Why NxM should happen early (discussion)","text":"<p>Yes: it is generally in your interest to move NxM generalization earlier, because:</p> <ul> <li>Shape rules infect everything: allocation, stride assumptions, kernels, persistence metadata, Python interop, and docs.</li> <li>If we fully \u201coptimize everything\u201d under NxN assumptions, we will later be forced to rewrite many kernels and tests.</li> </ul> <p>However, NxM is not a single switch. The roadmap below breaks NxM into phases:</p> <ul> <li>First: make DenseMatrix + VectorBase truly rectangular-safe end-to-end.</li> <li>Then: expand structures that inherently assume square-ness (triangular/symmetric) with explicit policies.</li> </ul> <p>We will keep \u201c2D only\u201d as a non-goal: no N-D arrays.</p>"},{"location":"internals/plans/TODO/#progress-tracking-manual-checkmarks","title":"Progress tracking (manual checkmarks)","text":"<p>Use GitHub-style task boxes: - <code>[ ]</code> = not done - <code>[x]</code> = done</p> <p>Release 1 nodes: - [x] R1_DOCS - [x] R1_API - [x] R1_SHAPES - [x] R1_STORAGE - [x] R1_PROPERTIES - [x] R1_IO - [x] R1_LAZY - [x] R1_PERF - [x] R1_SAFETY - [x] R1_NUMPY - [x] R1_LINALG - [x] R1_BLOCKMATRIX - [ ] R1_GPU - [ ] R1_SRP - [ ] R1_QA - [ ] R1_POLISH - [ ] R1_REL</p> <p>Parked: - [ ] R2_PHYS</p>"},{"location":"internals/plans/TODO/#canonical-roadmap-graph-mermaid","title":"Canonical Roadmap Graph (Mermaid)","text":"<pre><code>flowchart TD\n    %% Canonical roadmap: node IDs are stable.\n    %% Release 1 is the main path; Release 2 (physics) is intentionally parked.\n\n    subgraph R1[\"Release 1 - Linear Algebra Foundation (Ship Gate)\"]\n        R1_DOCS[\"R1_DOCS&lt;br/&gt;Docs System That Scales&lt;br/&gt;(Diataxis + MkDocs IA)&lt;br/&gt;[x]\"]\n        R1_API[\"R1_API&lt;br/&gt;Public API + Naming + Contracts&lt;br/&gt;(stability, deprecations)&lt;br/&gt;[x]\"]\n        R1_SHAPES[\"R1_SHAPES&lt;br/&gt;NxM Matrices Across The System&lt;br/&gt;(end-to-end)&lt;br/&gt;[x]\"]\n        R1_STORAGE[\"R1_STORAGE&lt;br/&gt;Single-File Persistence Container&lt;br/&gt;(mmap + typed sparse metadata)&lt;br/&gt;[x]\"]\n        R1_PROPERTIES[\"R1_PROPERTIES&lt;br/&gt;Semantic Properties + Property-Aware Algebra&lt;br/&gt;(properties-as-gospel + propagation + caching + persistence metadata)&lt;br/&gt;[x]\"]\n        R1_LAZY[\"R1_LAZY&lt;br/&gt;Lazy Evaluation &amp; Persistence&lt;br/&gt;(Expression Templates + RAM-First)&lt;br/&gt;[x]\"]\n        R1_PERF[\"R1_PERF&lt;br/&gt;Performance Optimization&lt;br/&gt;(Import Gap, AVX-512, Threading)&lt;br/&gt;[x]\"]\n        R1_SAFETY[\"R1_SAFETY&lt;br/&gt;Robustness &amp; Safety&lt;br/&gt;(Headers, Fallbacks, Crash Consistency)&lt;br/&gt;[x]\"]\n        R1_SRP[\"R1_SRP&lt;br/&gt;Support Readiness Program&lt;br/&gt;(dtypes x ops x devices x storage)&lt;br/&gt;+ optimize to &gt;= 0.90x NumPy\"]\n        R1_IO[\"R1_IO&lt;br/&gt;Out-of-core I/O + Persistence Performance&lt;br/&gt;(streaming + mmap correctness)&lt;br/&gt;[x]\"]\n        R1_NUMPY[\"R1_NUMPY&lt;br/&gt;Fast NumPy Interop&lt;br/&gt;(import/export must be competitive)&lt;br/&gt;[x]\"]\n        R1_LINALG[\"R1_LINALG&lt;br/&gt;Core Linalg Surface Completeness&lt;br/&gt;(norms/division/init-from-array/etc)&lt;br/&gt;[x]\"]\n        R1_BLOCKMATRIX[\"R1_BLOCKMATRIX&lt;br/&gt;Block Matrices + Heterogeneous Dtypes&lt;br/&gt;(nesting + manifests + semi-lazy ops)&lt;br/&gt;[x]\"]\n        R1_GPU[\"R1_GPU&lt;br/&gt;GPU Parity + Routing Policy&lt;br/&gt;(CPU-only vs GPU-enabled is explicit)\"]\n        R1_QA[\"R1_QA&lt;br/&gt;Bench + Correctness Gates Enforced&lt;br/&gt;(CI + thresholds)\"]\n        R1_POLISH[\"R1_POLISH&lt;br/&gt;Professionalism &amp; Polish&lt;br/&gt;(Linting, Docs, Packaging, Namespace)&lt;br/&gt;[ ]\"]\n        R1_REL[\"R1_REL&lt;br/&gt;Release Mechanics&lt;br/&gt;(packaging + release checklist)\"]\n    end\n\n    %% Main dependency chain (the path)\n    R1_DOCS --&gt; R1_API --&gt; R1_SHAPES --&gt; R1_STORAGE --&gt; R1_PROPERTIES --&gt; R1_LAZY --&gt; R1_PERF --&gt; R1_SAFETY --&gt; R1_SRP --&gt; R1_QA --&gt; R1_POLISH --&gt; R1_REL\n\n    %% Parallel prerequisites feeding SRP/QA\n    R1_IO --&gt; R1_SRP\n    R1_NUMPY --&gt; R1_SRP\n    R1_LINALG --&gt; R1_SRP\n    R1_BLOCKMATRIX --&gt; R1_SRP\n    R1_GPU --&gt; R1_SRP\n\n    %% Storage also feeds IO directly\n    R1_STORAGE --&gt; R1_IO\n\n    %% Properties feed linalg correctness/dispatch (and therefore SRP)\n    R1_PROPERTIES --&gt; R1_LINALG\n\n    %% Post-R1: physics release parked (not detailed here)\n    R2_PHYS[\"Release 2 - Physics + Large-Scale Experiments (Parked)&lt;br/&gt;(Pauli-Jordan, curved spacetimes, 100GB K)\"]:::parked\n    R1_REL --&gt; R2_PHYS\n\n    classDef parked fill:#eee,stroke:#bbb,color:#555</code></pre>"},{"location":"internals/plans/TODO/#node-details-keyed-by-id","title":"Node details (keyed by ID)","text":""},{"location":"internals/plans/TODO/#r1_docs-docs-system-that-scales-diataxis-mkdocs-ia","title":"R1_DOCS \u2014 Docs System That Scales (Di\u00e1taxis + MkDocs IA)","text":"<p>Status: - [x]</p> <p>Goal: documentation stays maintainable as features grow.</p> <p>Deliverables: - Adopt Di\u00e1taxis as the organizing principle for meaning (even if folders are renamed later). - MkDocs information architecture (IA) makes it obvious where to look:     - Reference (API)     - Guides (How-to)     - Explanation (internals that are readable)     - Dev Handbook     - Project meta - Update the documentation protocol so \u201credundancy\u201d is implemented as:     - one canonical source of truth per concept, and     - required cross-links from guides/reference/dev.</p>"},{"location":"internals/plans/TODO/#r1_api-public-api-naming-contracts","title":"R1_API \u2014 Public API + Naming + Contracts","text":"<p>Status: - [x]</p> <p>Goal: reduce churn and ambiguity in the Python surface while the project grows.</p> <p>Starting point: - Public API Contract</p> <p>Deliverables: - Naming conventions documented (types, functions, dtype tokens, warnings/errors). - Public vs internal boundaries explicit. - Deprecation policy: Any feature asked to be deprecated should be completely removed. There is no existing user base to respect. It is confusing for future work when deprecated features aren't completely removed, because their lingering functions, namespaces, parameters etc still linger in the codebase, causing confusion. Regarding documentation, never write \"this has been deprecated\" - just REMOVE IT. \"Deprecation\" = \"Purge\" in this workflow.</p>"},{"location":"internals/plans/TODO/#r1_shapes-nxm-matrices-across-the-system","title":"R1_SHAPES \u2014 NxM Matrices Across The System","text":"<p>Status: - [x]</p> <p>Goal: remove square-only assumptions so later work doesn\u2019t require rewrites.</p> <p>Phased approach: - Phase 1: Dense matrices + vectors are rectangular-safe (allocation, indexing, NumPy, persistence). - Phase 2: Matmul/matvec/vecmat and elementwise ops support NxM \u00d7 MxK rules. - Phase 3: Structures with inherent square semantics (triangular/symmetric/antisymmetric/identity/diagonal) get explicit policies:     - what shapes they allow,     - how they interact with NxM operands,     - and what gets blocked vs implemented.</p>"},{"location":"internals/plans/TODO/#r1_storage-single-file-persistence-container","title":"R1_STORAGE \u2014 Single-File Persistence Container","text":"<p>Status: - [x]</p> <p>Goal: define and maintain the single-file <code>.pycauset</code> binary container that preserves mmap-friendly payload access and supports sparse, typed, forward-compatible metadata.</p> <p>Starting point: - <code>documentation/internals/plans/completed/R1_STORAGE_PLAN.md</code></p> <p>Deliverables: - Single-file container spec (header + payload offsets + metadata blocks). - Typed sparse metadata encoding that preserves missing vs explicit values. - Append/update strategy that does not shift payload. - Hard-break policy: one format only; format changes update tests/docs in lockstep.</p> <p>Definition of Done: - Payload is mmap-accessible at a stable offset. - Metadata round-trips preserve tri-state property semantics (missing vs explicit <code>False</code>). - Frontend save/load APIs are unchanged; only storage plumbing changes.</p>"},{"location":"internals/plans/TODO/#r1_properties-semantic-properties-property-aware-algebra","title":"R1_PROPERTIES \u2014 Semantic Properties + Property-Aware Algebra","text":"<p>Status: - [x]</p> <p>Goal: introduce a canonical semantic properties system that is treated as gospel by the compute layer.</p> <p>Properties are not validated for mathematical truth. If a matrix has <code>is_unitary=True</code>, the system is allowed to use unitary identities and skip work, even if the underlying data is not truly unitary.</p> <p>Starting point: - <code>documentation/internals/plans/completed/R1_PROPERTIES_PLAN.md</code></p> <p>Deliverables: - A canonical properties schema (keys, meanings, typing, and a priority/implication model for structural properties). - Property propagation rules for metadata-only transforms (<code>transpose</code>, conjugation, scalar scale, etc). - Minimal sanity checks for incompatible structural properties (not truth validation). - Persistence: properties stored in <code>.pycauset</code> metadata with explicit-vs-unset semantics preserved. - Property-aware operator implementations and/or dispatch in the compute layer. - A more rigorous cached-derived model (validation + invalidation) so cached metadata cannot become stale.</p> <p>Definition of Done: - Every public matrix/vector object exposes a <code>properties</code> container and preserves the distinction between <code>False</code> and \u201cunset\u201d (missing/<code>None</code>), per <code>documentation/internals/plans/R1_PROPERTIES_PLAN.md</code>. - Every public matrix/vector object exposes a <code>properties</code> container and preserves the distinction between <code>False</code> and \u201cunset\u201d (missing/<code>None</code>), per <code>documentation/internals/plans/completed/R1_PROPERTIES_PLAN.md</code>. - Operators that can exploit properties do so deterministically and correctly per \u201cproperties-as-gospel\u201d.</p> <p>Persistence format note:</p> <ul> <li>R1_PROPERTIES depends on the storage layer for encoding, but the container format change itself is tracked under R1_STORAGE.</li> <li>The metadata schema must not block moving to a single-file binary <code>.pycauset</code> container with a sparse, forward-compatible typed metadata block (see <code>documentation/internals/plans/completed/R1_STORAGE_PLAN.md</code>).</li> </ul>"},{"location":"internals/plans/TODO/#r1_lazy-lazy-evaluation-persistence","title":"R1_LAZY \u2014 Lazy Evaluation &amp; Persistence","text":"<p>Status: - [x]</p> <p>Goal: Implement the \"RAM-First, Disk-Later\" strategy and Expression Templates to ensure R1 performance and safety.</p> <p>Deliverables: - Expression Templates: Rewrite <code>MatrixBase</code> to support lazy evaluation (e.g., <code>C = A + B + D</code> is fused).     - Eliminates temporary file creation for intermediate results.     - Enables \"Fly Swatting\" (O(1) metadata ops) to compose with compute ops. - Lazy Persistence:     - Matrices default to RAM-backed (anonymous memory).     - Spilling to disk (<code>mmap</code>) only occurs when:         - RAM limit is exceeded (MemoryGovernor), OR         - User explicitly saves (<code>.save()</code>), OR         - Matrix is too large for RAM at creation time. - NumPy UFunc Bridge:     - Implement <code>__array_ufunc__</code> to capture NumPy calls (e.g., <code>np.sin(A)</code>).     - Return lazy <code>Expression</code> objects instead of dense NumPy arrays.     - Ensures \"It feels like NumPy\" without crashing RAM. - Safety: Ensure <code>discard()</code> works correctly on Windows (VirtualUnlock) to prevent \"Ghost RAM\" usage.</p>"},{"location":"internals/plans/TODO/#r1_perf-performance-optimization-verification","title":"R1_PERF \u2014 Performance Optimization &amp; Verification","text":"<p>Status: - [x]</p> <p>Goal: Address specific performance bottlenecks to reach \"NumPy Parity\" and \"Theoretical Optimality\".</p> <p>Deliverables: - The 50% Import Gap: Investigate and fix OS overhead in <code>import_matrix</code> (target &gt;= 4.0GB/s). - \"Fake\" AVX-512: Implement explicit AVX-512 intrinsics for <code>DenseBitMatrix</code> (popcount, logic ops). - Robust Threading: Implement Dynamic Scheduling in <code>ParallelUtils</code> to avoid static partitioning stalls. - Pipeline Verification: Instrument <code>AsyncStreamer</code> with NVTX to prove compute/transfer overlap.</p>"},{"location":"internals/plans/TODO/#r1_safety-robustness-safety-the-shield","title":"R1_SAFETY \u2014 Robustness &amp; Safety (The Shield)","text":"<p>Status: - [x]</p> <p>Goal: Ensure PyCauset survives crashes, power outages, and bad hardware states.</p> <p>Deliverables: - File Version Header: Add magic bytes + version to <code>.pycauset</code> files to prevent future breakage. - AutoSolver Safety: Implement Pessimistic Fallback (default to CPU) on GPU error. - Crash Consistency: Verify <code>FlushFileBuffers</code>/<code>msync</code> behavior. - Windows I/O Leak: Implement <code>discard()</code> using <code>VirtualUnlock</code>.</p>"},{"location":"internals/plans/TODO/#r1_io-out-of-core-io-persistence-performance","title":"R1_IO \u2014 Out-of-core I/O + Persistence Performance","text":"<p>Status: - [x]</p> <p>Goal: disk-backed operation performance is a first-class feature, not an accident.</p> <p>Deliverables: - Streaming strategy for large operations (read patterns + hints). - Persistence round-trips for every public dtype/structure. - Persistence round-trips must preserve required metadata fields that affect semantics (including properties after R1_PROPERTIES). - Large-scale read/write is demonstrably efficient. - Decide and enforce the NumPy conversion surface in a matrix/vector-first way:     - PyCauset does not expose a <code>pc.asarray</code> \u201carray\u201d API; only matrices and vectors are first-class.     - Define the supported conversion entrypoints (e.g., <code>pc.matrix(np_array)</code>, <code>pc.vector(np_array)</code>, and <code>np.asarray(obj)</code>), and their copy/materialization policy.     - Ensure conversions do not accidentally materialize huge out-of-core data; default UX is a hard error with an explicit power-user override.     - Import/export override kwargs (RAM cap on import; <code>allow_huge</code> on export) and snapshot copy semantics are defined canonically in <code>documentation/internals/plans/R1_IO_PLAN.md</code>. - Format interoperability (pipeline-friendly):     - PyCauset can load relevant external formats (at least NumPy <code>.npy</code> / <code>.npz</code>).     - PyCauset can export to relevant external formats (at least <code>.npy</code> / <code>.npz</code>).     - Provide a file conversion utility (proposed: <code>pc.convert_file(...)</code>) to convert <code>.pycauset</code> \u21c4 other supported formats.     - Optional: define a minimal pandas interoperability surface (explicit scope + optional dependency).</p> <p>Authoritative plan: <code>documentation/internals/plans/R1_IO_PLAN.md</code>.</p>"},{"location":"internals/plans/TODO/#r1_linalg-core-linalg-surface-completeness","title":"R1_LINALG \u2014 Core Linalg Surface Completeness","text":"<p>Status: - [x]</p> <p>Goal: the base toolbox feels complete for users.</p> <p>Seed items (from prior TODO): - Norms, normalization, projections - Elementwise division for matrices/vectors - Initialization from array input for typed classes (not only factories) - Block matrices/vectors (moved to R1_BLOCKMATRIX; see <code>documentation/internals/plans/R1_BLOCKMATRIX_PLAN.md</code>) - Advanced indexing (slicing, fancy indexing) - Random matrix/vector generation - Matrix properties (expressed via properties and consumed by operators; see <code>documentation/internals/plans/completed/R1_PROPERTIES_PLAN.md</code>)</p>"},{"location":"internals/plans/TODO/#r1_blockmatrix-block-matrices-heterogeneous-dtypes","title":"R1_BLOCKMATRIX \u2014 Block Matrices + Heterogeneous Dtypes","text":"<p>Status: - [x]</p> <p>Progress: - Phase A (contract lock): [x] (2025-12-21) - Phase B (core types &amp; validation): [x] (completed 2025-12-21) - Phase C (views &amp; refinement): [x] - Phase D (ops orchestration &amp; thunks): [x] - Phase E (persistence &amp; caching): [x] - Phase F (integration): [x] (completed 2025-12-21) - Phase H (testing &amp; hardening): [x] (completed 2025-12-22)</p> <p>Goal: make block matrices a first-class internal representation built from existing matrices, with heterogeneous dtypes, manifest-based reference persistence, and semi-lazy block ops that preserve storage efficiency.</p> <p>Authoritative plan: <code>documentation/internals/plans/R1_BLOCKMATRIX_PLAN.md</code>.</p> <p>Deliverables: - <code>pycauset.matrix(block_grid)</code> constructs a block matrix from a 2D grid of blocks (e.g., list-of-lists) without densifying. - Block matrices are infinitely nestable. - Element indexing behaves like normal matrices (elements, not blocks). - Block replacement via explicit API (e.g., <code>set_block</code>). - Elementwise ops + matmul decompose into leaf ops that route via AutoSolver/ComputeDevice. - Save/load uses a reference-manifest (no expanded dense write) and is nestable.</p>"},{"location":"internals/plans/TODO/#r1_numpy-fast-numpy-interop","title":"R1_NUMPY \u2014 Fast NumPy Interop","text":"<p>Status: - [x]</p> <p>Goal: converting to/from NumPy is not a bottleneck. Assert compatibility</p> <p>Deliverables: - <code>np.array(obj)</code> and <code>Matrix(np_array)</code>/<code>Vector(np_array)</code> paths are optimized. - Performance target: \u22650.90\u00d7 NumPy baseline for conversion-heavy workflows (define regimes). - Performance target for very large datasets: PyCauset should dominate NumPy by avoiding avoidable materialization and using streaming/out-of-core friendly paths where appropriate (coordinated with R1_IO). - More streamlined numpy-compatibility.  - Make sure np arrays and pc matrices are interchangeable - make pycasuet api and experience \"as close to numpy\" as possible</p>"},{"location":"internals/plans/TODO/#r1_gpu-gpu-parity-routing-policy","title":"R1_GPU \u2014 GPU Parity + Routing Policy","text":"<p>Status: - [ ]</p> <p>Goal: GPU behavior is predictable, correct, and cooperative.</p> <p>Authoritative plan: <code>documentation/internals/plans/R1_GPU_PLAN.md</code>.</p> <p>Deliverables: - Phase 1: Robust Discovery &amp; \"Just Works\" Dispatch:     - AutoSolver routing is explicit, testable, and uses a cost model (transfer overhead vs dispatch gain).     - Hard fallback to CPU if GPU is missing capabilities or memory.     - Python API control surface (<code>pycauset.cuda.*</code>) for overrides and inspection. - Phase 2: Streaming Algorithm Drivers (The \"Cooperative\" Core):     - Implement Algorithm-Specific Drivers (Host-Side Orchestration) for complex ops (Cholesky, Arnoldi) that utilize the existing <code>AsyncStreamer</code> pipeline.     - CPU orchestrates dependencies; <code>AsyncStreamer</code> handles the heavy I/O and compute overlapping.     - Note: These drivers are critical for GPU VRAM limits but will also power the future R1_CPU engine. - Phase 3: Integration:     - Routing uses Tag Dispatch (<code>MatrixTraits</code>) to map Properties to optimized kernels (e.g., <code>cublasSyrk</code>).</p>"},{"location":"internals/plans/TODO/#r1_cpu-modern-tiled-cpu-engine-no-more-legacy-loops","title":"R1_CPU \u2014 Modern Tiled CPU Engine (No More Legacy Loops)","text":"<p>Status: - [ ]</p> <p>Goal: The CPU is not a fallback; it is a First-Class Worker for the Streaming Architecture.</p> <p>Deliverables: - Unified Worker Interface:     - Implement <code>CpuWorker</code> that implements the same standard interface as <code>CudaWorker</code> (e.g., <code>compute_tile(A, B, C)</code>).     - Allows the <code>AsyncStreamer</code> and Algorithm Drivers (from R1_GPU) to run on CPU without code changes. - Core Kernel Modernization:     - Delete legacy simple loops.     - Implement Tiled / Blocked Matmul (OpenMP) to match the tile sizes used by the streamer (L2 Cache fitting).     - Implement Vectorized (AVX2/AVX-512) kernels for Elementwise ops. - Standardization:     - Ensure CPU kernels respect the same <code>MatrixTraits</code> tag dispatch system as GPU kernels.</p>"},{"location":"internals/plans/TODO/#r1_srp-support-readiness-program-srp-optimization-catalog","title":"R1_SRP \u2014 Support Readiness Program (SRP) &amp; Optimization Catalog","text":"<p>Status: - [ ]</p> <p>This is the long \u201cpainstaking\u201d program. Only when this is done can we claim to be \"PyCauset\".</p> <p>Authoritative checklist: <code>documentation/internals/plans/SUPPORT_READINESS_FRAMEWORK.md</code>.</p> <p>SRP phases: - SRP-0: Canonical inventories locked (dtypes + ops + structures + devices). - SRP-1: CPU correctness across the inventory (Gate A + Gate B). - SRP-2: Causal Math Optimization Catalog (The \"Monster\"):     - Identify the specific operator combinations used in Causal Set Theory (Propagators, Action, etc.).     - Map these to numerical shortcuts (e.g., triangularity, Neumann series, property-abuse).     - Ensure these shortcuts are implemented and routed correctly. - SRP-3: GPU coverage implemented OR explicitly routed/blocked (Gate C). - SRP-4: CCA lookahead hints + out-of-core performance validation (Gate D + Gate E).</p> <p>Definition of Done (Release 1 gate): - Every op in the canonical inventory has an explicit support status for every public dtype/structure/device case. - Physics-Aware Optimizations are verified: specific causal structures trigger their optimized paths (not just generic fallback). - No \u201csilent wrong answers\u201d and no \u201cmysterious slow paths\u201d. - Benchmarks exist and failures are actionable.</p> <p>Notes: - SRP correctness/coverage must include property-aware variants of operators once R1_PROPERTIES lands. - Streaming manager coverage is verified here.</p>"},{"location":"internals/plans/TODO/#r1_qa-bench-correctness-gates-enforced","title":"R1_QA \u2014 Bench + Correctness Gates Enforced","text":"<p>Status: - [ ]</p> <p>Goal: prevent regressions (correctness and performance).</p> <p>Deliverables: - Gate-style CI checks: correctness + persistence + a small benchmark suite. - Performance regressions are visible (even if not hard-failed at first). -  Sniff out deprecated features and dead code to clean up codebase</p>"},{"location":"internals/plans/TODO/#r1_polish-professionalism-polish","title":"R1_POLISH \u2014 Professionalism &amp; Polish","text":"<p>Status: - [ ]</p> <p>Goal: Ensure <code>pycauset</code> meets high professional standards (NumPy-like quality).</p> <p>Deliverables: - Packaging: Clean up loose DLLs, use <code>libs/</code> directory. - Docs: Standardize Markdown links (no more <code>[[wiki_links]]</code>). - Linting: Configure <code>ruff</code> and <code>mypy</code> in <code>pyproject.toml</code>. - Build: Audit and reduce CMake warning suppressions. - Namespace: Refactor <code>__init__.py</code> to be minimal. - Cleanup: Remove dead code, legacy \"eager\" evaluation paths, and unused temporary file logic.</p>"},{"location":"internals/plans/TODO/#r1_rel-release-mechanics","title":"R1_REL \u2014 Release Mechanics","text":"<p>Status: - [ ]</p> <p>Goal: releasing is routine and reproducible.</p> <p>Deliverables: - Release checklist referencing SRP gates. - Packaging sanity checks.</p>"},{"location":"internals/plans/TODO/#parked-post-release-1-ideas-from-the-old-todo","title":"Parked (post-Release-1) ideas from the old TODO","text":"<p>These are intentionally downstream of the foundation release:</p> <ul> <li>100GB propagator matrix \\(K\\) (capstone large-scale experiment)</li> <li>Pauli\u2013Jordan function \\(i\\Delta\\)</li> <li>Curved spacetimes (Schwarzschild / de Sitter)</li> <li>User-defined spacetimes</li> <li>A more robust user profiler tool - collect info on ram, gpu, cpu etc, so that pycauset can easily optimize performance based on user hardware</li> </ul>"},{"location":"internals/plans/phase1_inventory/","title":"R1_NUMPY - Phase 1 Inventory Report","text":"<p>Date: Jan 6, 2026 Status: Complete</p>"},{"location":"internals/plans/phase1_inventory/#1-surface-map-existing-interop","title":"1. Surface Map (Existing Interop)","text":""},{"location":"internals/plans/phase1_inventory/#11-python-type-support","title":"1.1 Python Type Support","text":"<p>The following types currently expose <code>__array__</code> or the Buffer Protocol:</p> PyCauset Type Native C++ Type NumPy Dtype Buffer Proto? Notes <code>FloatMatrix</code> <code>DenseMatrix&lt;double&gt;</code> <code>float64</code> \u2705 Yes <code>Float32Matrix</code> <code>DenseMatrix&lt;float&gt;</code> <code>float32</code> \u2705 Yes <code>IntegerMatrix</code> <code>DenseMatrix&lt;int32_t&gt;</code> <code>int32</code> \u2705 Yes <code>Int16Matrix</code> <code>DenseMatrix&lt;int16_t&gt;</code> <code>int16</code> \u2705 Yes <code>DenseBitMatrix</code> <code>DenseBitMatrix</code> <code>bool</code> \u274c No Exposes via <code>__array__</code> (converts to bool array). <code>FloatVector</code> <code>DenseVector&lt;double&gt;</code> <code>float64</code> \u2705 Yes <code>BitVector</code> <code>DenseVector&lt;bool&gt;</code> <code>bool</code> \u2705 Yes <code>LazyMatrix</code> <code>MatrixExpressionWrapper</code> N/A \u274c MISSING <code>np.array(expr)</code> fails to evaluate."},{"location":"internals/plans/phase1_inventory/#12-import-rules-numpy-pycauset","title":"1.2 Import Rules (NumPy -&gt; PyCauset)","text":"<p>Defined in <code>bind_vector.cpp</code> and <code>bind_matrix.cpp</code>:</p> <ul> <li>Vectors (1D):<ul> <li><code>float32</code> -&gt; Promotes to <code>float64</code> (Legacy behavior, see <code>bind_vector.cpp:250</code>).</li> <li><code>float64</code> -&gt; <code>float64</code>.</li> <li><code>int32/64</code> -&gt; <code>int32/64</code>.</li> <li><code>bool</code> -&gt; <code>bool</code>.</li> </ul> </li> <li>Matrices (2D):<ul> <li><code>float32</code> -&gt; <code>float32</code> (Preserved).</li> <li><code>float64</code> -&gt; <code>float64</code>.</li> <li><code>int32</code> -&gt; <code>int32</code>.</li> </ul> </li> </ul>"},{"location":"internals/plans/phase1_inventory/#2-identified-gaps-bugs","title":"2. Identified Gaps &amp; Bugs","text":""},{"location":"internals/plans/phase1_inventory/#21-critical-lazy-evaluation-interop-gap","title":"2.1 Critical: Lazy Evaluation Interop (Gap)","text":"<p>Symptom: <code>np.array(A + B)</code> returns a 0-D object array wrapping the expression. Cause: <code>MatrixExpressionWrapper</code> lacks <code>__array__</code> hooks. Impact: Breaks \"NumPy-like\" feel; users must manually call <code>.eval()</code> which is unpythonic. Fix Required: Bind <code>__array__</code> in <code>bind_expression.cpp</code> to trigger <code>eval_into</code> and return the result.</p>"},{"location":"internals/plans/phase1_inventory/#22-critical-snapshot-export-zero-data-bug","title":"2.2 Critical: Snapshot Export Zero-Data (Bug)","text":"<p>Symptom: <code>np.array(pc.load(\"snap.pycauset\"))</code> returns all zeros. Cause: <code>MemoryMapper</code> (or <code>persistence.py</code>) alignment mismatch. - <code>MemoryMapper</code> correctly skips the 64-byte header for <code>.tmp</code> files. - For <code>.pycauset</code> snapshots involving a 4KB header/metadata block, the offset passed to <code>MemoryMapper</code> seems to be 0 (pointing to the header) instead of 4096 (pointing to payload). Fix Required: Ensure <code>FileBackedMatrix</code> constructor receives the correct absolute payload offset when loading from a snapshot.</p>"},{"location":"internals/plans/phase1_inventory/#23-import-performance-gap","title":"2.3 Import Performance (Gap)","text":"<p>Symptom: <code>import_matrix</code> uses element-wise copying loops in <code>bind_matrix.cpp</code>. Optimization: <code>R1_PERF</code> introduced <code>MemoryGovernor::should_use_direct_path</code>. Import logic should check this and use <code>std::memcpy</code> (parallelized) when RAM permits.</p>"},{"location":"internals/plans/phase1_inventory/#24-ergonomics-gap","title":"2.4 Ergonomics (Gap)","text":"<ul> <li><code>IntVector</code> alias is missing (users expect <code>pc.vector(...)</code> factory, but direct type usage fails).</li> <li><code>np.matmul(pycauset, pycauset)</code> likely fails or falls back to slow path (untested but <code>__array_ufunc__</code> logic for expressions is minimal).</li> </ul>"},{"location":"internals/plans/phase1_inventory/#3-plan-update","title":"3. Plan Update","text":"<p>Phase 2 (Correctness) must prioritize fixing 2.1 and 2.2 before adding new tests.</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/","title":"DType / Complex / Overflow Plan (Implementation)","text":"<p>Status (2025-12-16): This implementation plan is complete. Phase 1 complete; Phase 2 complete (int8/int16/int32/int64 + uint8/uint16/uint32/uint64 + float16 end-to-end); Phase 3 complete (complex floats are now first-class end-to-end on CPU for the current core-op surface); Phase 4 complete (support matrix declared + enforced in tests/tools). Optional backlog items are still listed below.</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#scope-update-2025-12","title":"Scope update (2025-12)","text":"<p>This plan originally sketched \u201ccomplex permutations for all base dtypes\u201d (including <code>complex int*</code> and <code>complex bit</code>).</p> <p>Current project direction: complex support is limited to complex floats only (<code>complex_float16</code>, <code>complex_float32</code>, <code>complex_float64</code>). Complex permutations of non-float dtypes (<code>complex int*</code> / <code>complex bit</code>) are a non-goal by design due to high implementation surface area (promotion/overflow/kernels/persistence/tests) with low practical payoff for PyCauset\u2019s workloads.</p> <p>As a result: - Phase 2 includes first-class <code>float16</code> as a general dtype, plus the full signed/unsigned integer width set. - Phase 3 (complex) should be interpreted as \u201ccomplex float integration\u201d, with <code>complex_float16</code> implemented after <code>float16</code> readiness.</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-completion-status","title":"Phase completion status","text":"<ul> <li>Phase 0 \u2014 Documentation &amp; policy grounding: Complete</li> <li>Phase 1 \u2014 Centralize promotion + overflow policies: Complete</li> <li>Phase 2 \u2014 Scalar system expansion: Complete (int8/int16/int32/int64, uint8/uint16/uint32/uint64, float16 end-to-end through factories/promotion/CPU dispatch/persistence/bindings/NumPy for the core op surface)</li> <li>Phase 3 \u2014 Complex system integration: Complete (complex_float16/32/64 are first-class dtypes through factories/promotion/CPU dispatch/persistence/bindings/NumPy for core ops)</li> <li>Phase 4 \u2014 Coverage enforcement: Complete (support matrix declared + enforced in tests/tools)</li> </ul> <p>This file is an implementation plan. The authoritative dtype behavior documentation lives in:</p> <ul> <li><code>documentation/internals/DType System.md</code></li> </ul> <p>User-facing summary of what shipped in Release 1:</p> <ul> <li>Release 1: DTypes (what shipped)</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#0-problem-statement","title":"0) Problem statement","text":"<p>PyCauset supports several fundamentally different scalar/storage types (bit-packed <code>bit</code>, integers, floats) plus a partially-separate complex system. Adding a new operation currently requires touching multiple layers and remembering many dtype-specific corner cases:</p> <ul> <li>type/promotion rules are split between global helpers and per-op frontends,</li> <li>CPU kernels often dispatch on \u201cresult dtype\u201d and omit some types,</li> <li>complex numbers are currently not a first-class <code>MatrixBase</code> dtype and therefore drift from the main dispatch/type-resolution path,</li> <li>missing coverage is easy to ship because there is no single enforceable \u201csupport matrix\u201d.</li> </ul> <p>This document proposes a new, centralized dtype architecture that:</p> <ul> <li>makes complex floats first-class in the scalar type system,</li> <li>adds multiple integer widths (signed/unsigned),</li> <li>defines explicit promotion + overflow policies,</li> <li>keeps the \u201canti-promotion / smallest type\u201d ethos,</li> <li>keeps performance and out-of-core constraints as first-class concerns.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#1-key-constraints-from-project-philosophy-recent-decisions","title":"1) Key constraints (from project philosophy + recent decisions)","text":"<ul> <li>Scale-first: matrices may be 100GB+; memory blowups are unacceptable.</li> <li>Underpromotion default: when PyCauset underpromotes, it means compute and result storage both use the smallest selected dtype.</li> <li>No silent widening for accuracy: no hidden \u201ccompute in float64 then downcast\u201d in the default path.</li> <li>Bit matrices are numeric for arithmetic ops: treat <code>bit</code> values as 0/1 numeric values for arithmetic ops (e.g., <code>+</code>, <code>*</code>, <code>dot</code>, <code>matmul</code>). Bitwise ops are explicit and must preserve bit-packed storage.</li> <li>Overflow behavior: integer overflow is a runtime error. PyCauset does not auto-promote to avoid overflow.</li> <li>Overflow warning: for large integer matmul, run a worst-case bound preflight and emit a warning when overflow looks plausible.</li> <li>Complex floats are first-class: complex support is limited to float base dtypes.</li> <li><code>complex_float32</code> / <code>complex_float64</code> are BLAS-backed where applicable (native complex types <code>complex64</code> / <code>complex128</code>).</li> <li><code>complex_float16</code> is implemented as a first-class dtype using a two-plane float16 storage model.</li> <li>Complex non-floats are a non-goal: <code>complex int*</code> / <code>complex bit</code> are intentionally unsupported to avoid a large promotion/overflow/kernel/persistence surface area with low payoff.</li> <li>Fundamental-kind rule (bit/int/float): PyCauset never \u201cpromotes down\u201d across fundamental kinds. If an operation mixes kinds, the result kind is the higher kind required by the operation\u2019s semantics.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#2-terminology","title":"2) Terminology","text":"<ul> <li>Scalar type: the per-element numeric type (bit/int/float plus width and flags).</li> <li>Matrix structure: dense/triangular/symmetric/etc. (storage layout and indexing constraints).</li> <li>Operation (op): add/subtract/elementwise multiply/matmul/inverse/eigvals/etc.</li> <li>Promotion policy: rules for selecting result dtypes for mixed-input ops.</li> <li>Overflow policy: what happens when integer arithmetic overflows.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#3-proposed-scalar-type-model-flagspermutations","title":"3) Proposed scalar type model (flags/permutations)","text":"<p>Represent scalar types as:</p> <ul> <li><code>kind</code>: <code>bit | int | float</code></li> <li><code>width_bits</code>: for int/float (8/16/32/64), and 1 for bit</li> <li><code>flags</code>: a small set of orthogonal modifiers</li> <li><code>complex</code> (supported for float scalar types only)</li> <li><code>unsigned</code> (valid only for <code>int</code>)</li> </ul> <p>Examples:</p> <ul> <li><code>bit</code> = (bit, 1, {})</li> <li><code>int16</code> = (int, 16, {})</li> <li><code>uint16</code> = (int, 16, {unsigned})</li> <li><code>float16</code> = (float, 16, {})</li> <li><code>complex float16</code> = (float, 16, {complex})</li> <li><code>float32</code> = (float, 32, {})</li> <li><code>complex float32</code> (<code>complex64</code>) = (float, 32, {complex})</li> <li><code>float64</code> = (float, 64, {})</li> <li><code>complex float64</code> (<code>complex128</code>) = (float, 64, {complex})</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#supported-scalar-set-initial-target","title":"Supported scalar set (initial target)","text":"<ul> <li>bit</li> <li>int8/int16/int32/int64</li> <li>uint8/uint16/uint32/uint64</li> <li>float16/float32/float64</li> <li>complex_float16/complex_float32/complex_float64</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#4-complex-implementation-strategy","title":"4) Complex implementation strategy","text":""},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#41-complex-floats-performance-path","title":"4.1 Complex floats (performance path)","text":"<ul> <li>Implement <code>complex_float32</code> (<code>complex64</code>) and <code>complex_float64</code> (<code>complex128</code>) as true complex numeric types.</li> <li>Prefer BLAS-backed complex GEMM where applicable.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#42-complex-float16-two-plane-storage-path","title":"4.2 Complex float16 (two-plane storage path)","text":"<ul> <li>Represent <code>complex_float16</code> as two float16 planes (real + imag).</li> <li>Motivation: there is no ubiquitous, efficient \u201cnative complex half\u201d representation across the stack, and forcing complex-half into complex-float32 would violate the \u201csmallest type\u201d ethos.</li> <li>Persistence must round-trip as a single complex dtype (one logical object, two payload planes).</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#43-explicit-non-goals","title":"4.3 Explicit non-goals","text":"<ul> <li>Complex permutations of non-float dtypes (<code>complex int*</code>, <code>complex bit</code>) are intentionally out of scope.</li> <li>If/when we ever revisit this, it must be driven by concrete workloads and come with a scoped support matrix (ops \u00d7 dtype) rather than a blanket \u201cclosure\u201d rule.</li> </ul> <p>This plan does not assume automatic widening in integer matmul. Under the current policy:</p> <ul> <li>integer overflow throws, and</li> <li>the system does not silently widen storage to avoid overflow.</li> </ul> <p>If we ever decide that a particular op\u2019s semantic result dtype must be wider (e.g., a count-producing op), that must be a named, explicit promotion rule and must be documented as semantics, not an overflow workaround.</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#5-promotion-policy-centralized-op-specific","title":"5) Promotion policy (centralized, op-specific)","text":"<p>Create a single authoritative table/function:</p> <ul> <li><code>resolve_result_scalar(op, a_scalar, b_scalar) -&gt; scalar</code></li> <li><code>resolve_result_structure(op, a_structure, b_structure) -&gt; structure</code></li> </ul> <p>Design principles:</p> <ul> <li>Default to the smallest dtype that can represent the result per op semantics.</li> <li>Mixed float precision underpromotes by default (compute+store in the smaller float), with a configurable option to promote instead.</li> <li>Complex is a flag: complex-ness is preserved unless an op is explicitly defined to drop it.</li> <li>Unsigned is preserved where meaningful; if an op can generate negatives, rules must define whether to promote to signed or throw.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#51-fundamental-kinds-bit-int-float-and-no-promote-down","title":"5.1 Fundamental kinds (bit / int / float) and \u201cno promote down\u201d","text":"<p>PyCauset distinguishes three fundamental kinds:</p> <ul> <li><code>bit</code> (bit-packed boolean storage; special rules allowed)</li> <li><code>int</code> (signed/unsigned integers)</li> <li><code>float</code> (float16/float32/float64)</li> </ul> <p>Rules:</p> <p>1) No promote down across kinds. If kinds differ, the result kind cannot be the \u201clower\u201d kind. 2) When a float participates, the result kind is float. Example: <code>matmul(bit, float64) -&gt; float64</code>. 3) When only integers/bits participate, the result kind is integer unless the op is explicitly bitwise. 4) Underpromotion applies within a kind, not across kinds. Example: <code>matmul(float32, float64) -&gt; float32</code> by default.</p> <p>This strikes a balance:</p> <ul> <li>it preserves the \u201csmallest type\u201d ethos where it is meaningful (within float precision),</li> <li>it avoids absurd outcomes like underpromoting a float computation to bit storage,</li> <li>it keeps <code>bit</code> special (bitwise ops remain bitwise; numeric ops may change kind).</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#52-bit-is-special-scale-first-exceptions","title":"5.2 Bit is special (scale-first exceptions)","text":"<p>Bit matrices/vectors are used to represent large binary structures (e.g., spacetime relations) where the storage is often 10s\u2013100s of GB.</p> <p>As a result:</p> <ul> <li>Bitwise ops (e.g., NOT/AND/OR/XOR) should preserve <code>bit</code> and stay bit-packed.</li> <li>Numeric ops that inherently create non-binary results (e.g., <code>bit + bit</code>, <code>matmul(bit, bit)</code> producing integer counts) may require widening to <code>int</code> or <code>float</code>.</li> </ul> <p>For such numeric ops, widening can be prohibitively expensive. Therefore, for <code>bit</code> we allow explicit, op-specific behavior:</p> <ul> <li>supported with a documented widening result kind, or</li> <li>error-by-design unless the user explicitly requests a widened dtype.</li> </ul> <p>The support matrix must record which choice is made for each op.</p> <p>Config hooks:</p> <ul> <li><code>promotion_policy.float_mixed</code>: <code>underpromote_warn</code> (default) | <code>promote</code> | <code>underpromote_no_warn</code></li> </ul> <p>Warning controls (exact API TBD, but must exist):</p> <ul> <li><code>warning_policy.float_underpromotion</code>: on by default when <code>promotion_policy.float_mixed=underpromote_warn</code></li> <li><code>warning_policy.int_reduction_acc_widen</code>: on by default; emitted when <code>dot</code>/<code>matmul</code> widens the accumulator dtype</li> <li><code>warning_policy.int_overflow_risk_preflight</code>: on by default for \u201clarge\u201d integer matmul; emitted when conservative bounds indicate plausible overflow in the requested output dtype</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#6-overflow-policy","title":"6) Overflow policy","text":""},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#61-runtime-behavior","title":"6.1 Runtime behavior","text":"<ul> <li>Overflow is a hard error.</li> <li>PyCauset does not auto-promote storage to avoid overflow.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#611-why-this-focuses-on-integer-overflow-and-not-float-overflow","title":"6.1.1 Why this focuses on integer overflow (and not float overflow)","text":"<p>Floating-point overflow is real (e.g., float32 can overflow to <code>+inf</code>), but it behaves differently:</p> <ul> <li>IEEE-754 overflow typically becomes <code>inf</code> (and may raise a floating-point flag), which then propagates.</li> <li>This is often detectable after-the-fact (e.g., <code>isfinite</code> checks), whereas integer overflow in C++ can be undefined behavior or silent wrap depending on the implementation.</li> </ul> <p>Policy-wise:</p> <ul> <li>For integers: overflow must throw (no silent wrap).</li> <li>For floats: overflow results in <code>inf</code>/<code>nan</code> according to IEEE-754; optional \u201cfinite-check\u201d validation can exist as a debug/strict mode, but it is not the default because scanning 100GB+ outputs is expensive.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#62-preflight-warning-for-large-integer-matmul","title":"6.2 Preflight warning for large integer matmul","text":"<p>For integer matmul (and potentially some other high-risk ops), run a cheap preflight to estimate overflow risk:</p> <p>1) sample blocks/rows to estimate <code>max_abs(A)</code> and <code>max_abs(B)</code> (including scalar metadata factors if they apply) 2) compute a conservative bound:</p> \\[\\max |C_{ij}| \\le K \\cdot \\max|A| \\cdot \\max|B|\\] <p>Where \\(K\\) is the inner dimension (for square matmul, \\(K=N\\)).</p> <p>If the bound approaches/exceeds the target dtype max value, emit a warning:</p> <ul> <li><code>PyCausetWarning: matmul(&lt;lhs_dtype&gt;, &lt;rhs_dtype&gt;) may overflow &lt;out_dtype&gt; (conservative bound). Consider requesting a wider output dtype or scaling.</code></li> </ul> <p>Notes:</p> <ul> <li>This is a heuristic. It should warn on risk; it does not guarantee overflow will happen.</li> <li>It avoids inner-loop overflow checks in the performance-critical kernel.</li> </ul> <p>Documentation requirement:</p> <ul> <li>Add an \u201cOverflow\u201d section/doc describing the policy, the preflight warning, and user mitigations.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#63-reduction-aware-accumulator-width-dotmatmul-required-warning","title":"6.3 Reduction-aware accumulator width (dot/matmul) + required warning","text":"<p>Some integer reductions (especially <code>dot</code>/<code>matmul</code>) can overflow the accumulator even when inputs are representable and the requested output dtype is unchanged.</p> <p>To keep integer math defined and to uphold \u201coverflow throws\u201d without requiring expensive per-multiply-add overflow checks inside the hot loop, PyCauset uses a reduction-aware accumulator width for integer reductions.</p> <p>Key clarifications (scale-first):</p> <ul> <li>This rule is about the accumulator dtype (compute registers / local scratch), not about materializing inputs.</li> <li>In particular, <code>bit</code> inputs stay bit-packed; <code>matmul(bit, int16)</code> does not expand the <code>bit</code> matrix to <code>int32</code> elements.</li> <li>This rule does not silently widen the result storage dtype. If the user requests <code>int16</code> output, the result is stored as <code>int16</code> and overflow remains a hard error (typically detected at the final cast from the wider accumulator).</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#631-accumulator-width-selection-deterministic-conservative","title":"6.3.1 Accumulator-width selection (deterministic / conservative)","text":"<p>For <code>matmul</code>/<code>dot</code> over integer kinds (including <code>bit</code> treated as numeric 0/1), choose an accumulator dtype wide enough that the worst-case bound for the reduction fits.</p> <p>For <code>C = A @ B</code> with inner dimension <code>K</code>:</p> <ul> <li>Use a conservative magnitude bound based on dtype limits (no sampling required):</li> </ul> \\[\\max |C_{ij}| \\le K \\cdot \\max|A| \\cdot \\max|B|\\] <ul> <li>For <code>bit</code>, \\(\\max|A| = 1\\).</li> </ul> <p>For integer dtypes, \\(\\max|A|\\) and \\(\\max|B|\\) may be taken as the maximum representable magnitude for their dtypes (e.g., for <code>int16</code>, 32767). This is conservative and ensures accumulator selection is correctness-preserving without needing an extra pass over out-of-core data.</p> <p>This is intentionally conservative: it is designed to be computed cheaply and to be correct without relying on probabilistic assumptions.</p> <p>Optionally (future optimization): when it is cheap relative to the matmul itself and does not force an extra out-of-core pass, tighten the bound using exact streaming summaries such as row popcounts for <code>bit</code> and per-column max-abs for the integer operand.</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#632-user-visible-warning-required","title":"6.3.2 User-visible warning (required)","text":"<p>Whenever the chosen accumulator dtype is wider than what a reader would naively expect from the inputs (e.g., <code>matmul(bit, int16)</code> accumulating into <code>int32</code>), PyCauset must emit a warning so users understand what is happening.</p> <p>The warning must include:</p> <ul> <li>operation name (e.g., <code>matmul</code> / <code>dot</code>)</li> <li>lhs dtype and rhs dtype</li> <li>chosen accumulator dtype</li> <li>output storage dtype (explicitly stating whether it changed or not)</li> <li>reason (reduction-aware widening to keep integer overflow defined)</li> </ul> <p>Suggested warning text (exact wording not required, but content is):</p> <ul> <li><code>PyCausetWarning: matmul(bit, int16) will accumulate in int32 (reduction-aware integer width). Output dtype remains int16; overflow still throws on cast. Bit input remains bit-packed (no materialization).</code></li> </ul> <p>Noise control:</p> <ul> <li>Warn once per call site (or once per unique <code>(op, lhs_dtype, rhs_dtype, out_dtype, acc_dtype)</code> tuple) to avoid spam.</li> <li>Provide a user-facing way to silence/route warnings (Python <code>warnings.warn(...)</code> category, and/or a context flag).</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#7-enforceable-op-coverage-support-matrix","title":"7) Enforceable op coverage (\u201csupport matrix\u201d)","text":"<p>Introduce an explicit coverage matrix that enumerates for each operation:</p> <ul> <li>required scalar families (bit/int/float + complex)</li> <li>supported widths</li> <li>supported structures (dense/triangular/symmetric/etc.)</li> <li>required behaviors (defined, error-by-design, or unimplemented)</li> </ul> <p>Goal:</p> <ul> <li>When a new op is added, missing dtype coverage becomes a failing test/tool run, not a surprise at runtime.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#8-implementation-sequence-phased","title":"8) Implementation sequence (phased)","text":""},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-0-documentation-policy-grounding-complete","title":"Phase 0 \u2014 Documentation &amp; policy grounding (Complete)","text":"<ul> <li>Update project philosophy to explicitly define underpromotion and overflow behavior.</li> <li>Add roadmap entry for multi-int widths + unsigned.</li> <li>Add this plan doc.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-1-centralize-promotion-overflow-policies-complete","title":"Phase 1 \u2014 Centralize promotion + overflow policies (Complete)","text":"<ul> <li>Single promotion resolver per op.</li> <li>Central overflow policy + preflight warning for integer matmul.</li> <li>Reduction-aware accumulator width for integer <code>dot</code>/<code>matmul</code> + required user warning when accumulator widens.</li> <li>Add mandatory tests for resolver correctness, warning emission, and reduction accumulator selection (see \u201cMandatory tests\u201d).</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-2-scalar-system-expansion-complete","title":"Phase 2 \u2014 Scalar system expansion (Complete)","text":"<ul> <li>Add integer widths + unsigned.</li> <li>Ensure constructors, IO, numpy interop, and basic ops exist.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-3-complex-system-integration-complete","title":"Phase 3 \u2014 Complex system integration (Complete)","text":"<ul> <li>Core complex-float dtype integration is implemented (CPU + persistence + Python/NumPy for key ops).</li> <li>See \u201cPhase 3 \u2014 Complex system integration (Detailed)\u201d in Section 8.1.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#phase-4-coverage-enforcement-complete","title":"Phase 4 \u2014 Coverage enforcement (Complete)","text":"<ul> <li>Support matrix exists and is executed by unit tests and a dev checker tool, so declared support can\u2019t silently regress.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#81-phase-3-complex-system-integration-detailed","title":"8.1) Phase 3 \u2014 Complex system integration (Detailed)","text":"<p>Objective: Make complex float dtypes first-class and integrate them into the same end-to-end pipeline as real dtypes (frontend allocation \u2192 promotion resolver \u2192 CPU/GPU dispatch \u2192 persistence \u2192 Python).</p> <p>User-facing requirement: complex float dtypes must behave like normal dtypes on the frontend. For example, <code>pc.complex_float16</code> (or equivalent public token) must be a valid <code>dtype=</code> argument to <code>Matrix</code>/<code>Vector</code> factories.</p> <p>Scope for Phase 3: expand complex support to float base dtypes only:</p> <ul> <li><code>float16</code> \u2192 <code>complex_float16</code> (two float16 planes)</li> <li><code>float32</code> \u2192 <code>complex_float32</code> (a.k.a. <code>complex64</code>)</li> <li><code>float64</code> \u2192 <code>complex_float64</code> (a.k.a. <code>complex128</code>)</li> </ul> <p>Out of scope: complex permutations of non-float dtypes (<code>complex int*</code>, <code>complex bit</code>).</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#3x-phase-3-status-update-2025-12-16","title":"3.x Phase 3 status update (2025-12-16)","text":"<p>Completed in the current codebase:</p> <ul> <li>First-class complex float dtypes exist end-to-end: <code>complex_float16/32/64</code>.</li> <li>Storage:</li> <li><code>complex_float32/64</code>: dense storage uses native complex element types.</li> <li><code>complex_float16</code>: two-plane float16 storage (real+imag) for both matrices and vectors.</li> <li>Dispatch/promotion:</li> <li>promotion resolver supports complex results for matmul/add/sub/elementwise, plus dot/matvec/vecmat/outer.</li> <li>CPU solver contains complex implementations for dot/matvec/vecmat/outer and vector elementwise/scalar ops.</li> <li>Python/NumPy/persistence:</li> <li>dtype tokens + factory inference + <code>np.array(...)</code> interop + container persistence round-trip.</li> <li>dot returns Python <code>complex</code> when either operand is complex.</li> </ul> <p>Optional backlog (not required for plan completion):</p> <ul> <li>Ensure solver/eigensystem outputs use first-class complex dtypes end-to-end (no parallel complex object model).</li> <li>BLAS/cBLAS complex GEMM path for dense complex matmul on CPU (and GPU complex where applicable).</li> <li>Expand complex coverage across additional operations beyond the current core set.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#30-replace-legacy-complexmatrix-complexvector-compat-layer","title":"3.0 Replace legacy <code>ComplexMatrix</code> / <code>ComplexVector</code> (compat layer)","text":"<p>Current state (updated 2025-12-16):</p> <ul> <li>First-class complex float matrices/vectors now exist as <code>MatrixBase</code>/<code>VectorBase</code> dtypes (<code>complex_float16/32/64</code>).</li> <li>The legacy <code>ComplexMatrix</code> / <code>ComplexVector</code> concept may still exist in some solver/eigensystem return paths.   That legacy path is now considered technical debt (it drifts from the first-class dtype pipeline).</li> </ul> <p>Plan (still valid):</p> <ul> <li>Ensure any remaining solver/eigensystem paths route through first-class complex dtype matrices/vectors.</li> <li>Long-term goal: complex is a normal <code>MatrixBase</code>/<code>VectorBase</code> dtype, so <code>LinearAlgebra</code> and <code>ComputeDevice</code> don\u2019t need a parallel complex universe.</li> </ul> <p>Frontend contract note:</p> <ul> <li>Provide explicit dtype tokens for complex floats (at minimum: <code>complex_float16</code>, <code>complex_float32</code>, <code>complex_float64</code>).</li> <li>These tokens must normalize through the same dtype normalization funnel as real dtypes and participate in the same factory code paths.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#31-make-complex-first-class-in-the-scalar-type-model","title":"3.1 Make \u201ccomplex\u201d first-class in the scalar type model","text":"<p>Requirement: represent scalar types as <code>(kind, width_bits, flags)</code> where <code>flags</code> includes at least <code>{complex, unsigned}</code>.</p> <p>Implementation direction:</p> <ul> <li>Introduce a <code>ScalarType</code> descriptor (or equivalent) that can represent:</li> <li>base dtype (<code>float16/float32/float64</code>)</li> <li>flags (<code>complex</code>)</li> <li>Plumb this through the type-resolution path so promotion is defined as:</li> <li><code>resolve_result_scalar(op, a_scalar, b_scalar) -&gt; scalar</code></li> </ul> <p>Design constraint (to match the frontend requirement):</p> <ul> <li>Even though complex can be represented as <code>(base_dtype + complex flag)</code>, it must be treated as a distinct dtype identity for:</li> <li>promotion resolution,</li> <li>dispatch selection,</li> <li>persistence metadata,</li> <li>and the support-matrix enforcement (coverage must be tracked per complex permutation).</li> </ul> <p>Back-compat note:</p> <ul> <li>The existing <code>DataType</code> enum can remain as a legacy base-type id during migration, but Phase 3 must ensure complex-ness is not \u201cout-of-band\u201d anymore.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#32-storage-strategy-for-complex-by-base-kind","title":"3.2 Storage strategy for complex (by base kind)","text":"<p>We intentionally use two different representations depending on the float width, to balance performance and scale-first storage efficiency.</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#321-complex-floats-performance-path","title":"3.2.1 Complex floats (performance path)","text":"<ul> <li><code>complex_float32</code> (<code>complex64</code>) and <code>complex_float64</code> (<code>complex128</code>) are true complex numeric types.</li> <li>Implement dense complex storage as contiguous <code>std::complex&lt;float&gt;</code> / <code>std::complex&lt;double&gt;</code> (or ABI-compatible equivalent).</li> <li>Route matmul to BLAS complex GEMM where possible.</li> <li>GPU: use cuBLAS complex GEMM when available.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#322-complex-float16-two-plane-storage-path","title":"3.2.2 Complex float16 (two-plane storage path)","text":"<ul> <li>Represent <code>complex_float16</code> as two float16 planes of equal shape:</li> <li>real plane: <code>float16</code></li> <li>imag plane: <code>float16</code></li> <li>Motivation: avoid forcing half-precision complex values into float32 complex storage, and avoid depending on a non-portable \u201cnative complex half\u201d ABI.</li> </ul> <p>Important clarification:</p> <ul> <li>\u201cTwo-plane storage\u201d is an implementation detail. The object is still a single complex-typed matrix/vector from the API perspective, and it must round-trip via persistence as a complex dtype (not as two unrelated real objects).</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#33-first-class-complex-matricesvectors-in-the-core-object-model","title":"3.3 First-class complex matrices/vectors in the core object model","text":"<p>Hard requirement: complex objects must participate in factories, persistence, and dispatch the same way other dtypes do.</p> <p>Minimum deliverables:</p> <ul> <li>A <code>MatrixBase</code>-derived complex matrix implementation for:</li> <li><code>complex_float32</code> / <code>complex_float64</code> (dense)</li> <li><code>complex_float16</code> (two-plane storage)</li> <li>A <code>VectorBase</code>-derived complex vector implementation (same split).</li> </ul> <p>Interface hazards to address explicitly (to avoid \u201cbiting us later\u201d):</p> <ul> <li>Many existing code paths use <code>get_element_as_double(...)</code>. For complex dtypes, this must never silently drop the imaginary part.</li> <li>Either implement <code>get_element_as_double</code> as a hard error for complex matrices, or ensure it is only used behind a \u201creal-only\u201d guard.</li> <li>Complex-aware paths must use <code>get_element_as_complex(...)</code>.</li> <li><code>ComputeDevice::multiply_scalar</code> currently takes <code>double</code>; Phase 3 must define the complex-scalar story:</li> <li>either add complex-scalar device entry points, or</li> <li>restrict complex-scalar multiply to frontend methods that dispatch to complex kernels.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#34-operation-coverage-policy-for-complex","title":"3.4 Operation coverage policy for complex","text":"<p>Phase 3 does not require \u201cevery op supports every complex dtype\u201d on day one, but it must make coverage enforceable:</p> <ul> <li>For each op in the canonical LinearAlgebra surface (at least <code>LinearAlgebra.hpp</code>):</li> <li>declare complex propagation rules (preserve complex, drop complex, or error-by-design)</li> <li>declare result dtype selection rules (including for <code>bit</code> special cases)</li> <li>Ensure the resolver has explicit rows for complex permutations.</li> </ul> <p>Coverage principle (mathematical independence):</p> <ul> <li>Complex permutations must be treated as separate coverage targets even when they reuse plane-wise kernels.</li> <li>\u201cWorks because it decomposes into two real ops\u201d is not a substitute for tests: each complex dtype/op combination must be explicitly tested (or explicitly error-by-design with a stable error).</li> </ul> <p>Specific expectations:</p> <ul> <li><code>complex_float32/complex_float64</code>:</li> <li><code>add/sub/elementwise/matmul</code> must work on CPU.</li> <li>GPU support is optional, but routing must be correct (fallback to CPU when unsupported).</li> <li><code>complex_float16</code>:</li> <li><code>add/sub/elementwise/matmul</code> must work on CPU.</li> <li>if implemented via two-plane arithmetic, correctness must be validated vs NumPy complex computations.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#35-persistence-format-for-complex","title":"3.5 Persistence format for complex","text":"<p>Current implementation note (updated 2025-12-16):</p> <ul> <li><code>complex_float16</code> uses a two-plane in-memory layout (real + imag), but is persisted as a single contiguous raw payload containing both planes back-to-back.</li> <li>Typed metadata records the dtype identity (<code>complex_float16</code>) and the normal shape/layout fields; there is no need for multi-member payloads to round-trip correctly.</li> </ul> <p>Future option (not required for correctness):</p> <ul> <li>Multi-member payloads could still be introduced later for tooling/inspection convenience, but would be an on-disk format enhancement rather than a correctness requirement.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#36-gpucpu-selection-policy","title":"3.6 GPU/CPU selection policy","text":"<p>Match project intent:</p> <ul> <li>Default behavior: benchmark/poll hardware once, then pick the fastest device.</li> <li>If GPU does not support a dtype/op/structure, fall back to CPU.</li> <li>Avoid exploding \u201cone kernel per infinitesimal device\u201d by using:</li> <li>a small set of coarse regimes (dtype/shape thresholds)</li> <li>a micro-benchmark-derived speedup factor</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#37-tests-keep-the-explosion-under-control","title":"3.7 Tests (keep the explosion under control)","text":"<p>The only way this stays maintainable is if we separate:</p> <ul> <li>pure-logic resolver tests (exhaustive across dtype permutations), from</li> <li>kernel correctness tests (representative shapes), from</li> <li>error-by-design tests (stable error messages).</li> </ul> <p>Phase 3 must add a minimal \u201ccomplex smoke matrix\u201d for the LinearAlgebra surface:</p> <ul> <li><code>complex_float64</code>: add/sub/elementwise/matmul correctness vs NumPy</li> <li><code>complex_float32</code>: same, smaller shapes + tolerances</li> <li><code>complex_float16</code>: add/sub/elementwise/matmul correctness vs NumPy (two-plane storage) + persistence round-trip</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#9-mandatory-tests","title":"9) Mandatory tests","text":"<p>These tests are required. They exist to prevent dtype coverage drift and to catch correctness/performance regressions early.</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#91-pure-logic-dtype-resolution-tests","title":"9.1 Pure-logic dtype resolution tests","text":"<p>Add unit tests (no kernels) that exercise the resolver tables/functions. At minimum:</p> <ul> <li>Fundamental kind rule: never promote down across <code>bit -&gt; int -&gt; float</code>.</li> <li>Float underpromotion: e.g., <code>matmul(float32, float64) -&gt; float32</code> by default.</li> <li>Complex flag behavior: for each op, verify complex propagation/behavior is explicit (preserve/drop/error-by-design) and covered.</li> <li>Unsigned flag behavior: verify signed/unsigned mixing rules are explicit and tested.</li> <li>Error-by-design paths: verify they error with stable, specific messages.</li> </ul> <p>These tests should be table-driven and exhaustive across the supported dtype set for each resolver entry.</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#92-kernelintegration-correctness-tests","title":"9.2 Kernel/integration correctness tests","text":"<p>Add tests that validate numeric correctness and overflow behavior for representative ops and shapes:</p> <ul> <li><code>dot</code>/<code>matmul</code> integer correctness across widths.</li> <li>Overflow throws deterministically (no silent wrap).</li> </ul> <p>For reduction-aware accumulator widening specifically, add at least one test where:</p> <ul> <li><code>matmul(bit, int16)</code> (or <code>dot(bit, int16)</code>) produces a value that would overflow an <code>int16</code> accumulator but fits in <code>int32</code> output.</li> <li>The test asserts:</li> <li>correct numeric result,</li> <li>accumulator-widen warning is emitted and mentions: op name, lhs/rhs dtypes, accumulator dtype, and output dtype.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#93-warning-tests-user-facing-behavior","title":"9.3 Warning tests (user-facing behavior)","text":"<p>Add Python-level tests (and C++ tests where applicable) that validate warnings are:</p> <ul> <li>emitted when required,</li> <li>de-duplicated (warn-once policy),</li> <li>informative (message includes the dtypes involved and what is happening),</li> <li>suppressible/routable via a user-facing control.</li> </ul> <p>Warnings to cover:</p> <ul> <li>float underpromotion warning (if enabled)</li> <li>integer overflow-risk preflight warning (heuristic)</li> <li>integer reduction accumulator-widen warning (deterministic)</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#94-scale-first-regression-tests-bit-materialization-guard","title":"9.4 Scale-first regression tests (bit materialization guard)","text":"<p>Add a regression test that guards the key scale-first property for <code>bit</code> operands:</p> <ul> <li><code>bit</code> inputs must remain bit-packed during <code>dot</code>/<code>matmul</code> (no full materialization to an int/float element buffer).</li> </ul> <p>Implementation note (testability): this may require a test-only hook (e.g., allocation tracer, \u201cmaterialized_bit_elements\u201d counter, or a debug trace flag) so the test can assert that no allocation proportional to <code>A.numel() * sizeof(int32)</code> occurred.</p>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#95-support-matrix-completeness-test","title":"9.5 Support-matrix completeness test","text":"<p>The support matrix must be executable as a test/tool:</p> <ul> <li>It must fail CI if an op claims support for a dtype/structure/device combination that lacks an implementation or test coverage.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#10-acceptance-criteria","title":"10) Acceptance criteria","text":"<ul> <li>Adding a new operation requires changing:</li> <li>the op implementation,</li> <li>one promotion rule table,</li> <li>one coverage declaration,</li> <li> <p>tests.   It must not require \u201chunt across the codebase\u201d.</p> </li> <li> <p>Complex dtypes are supported for float base dtypes only (<code>complex_float16/32/64</code>).</p> </li> <li> <p>Overflow behavior is consistent:</p> </li> <li>overflow throws,</li> <li>large integer matmul emits a risk warning when appropriate,</li> <li>no auto-promotion to avoid overflow.</li> </ul>"},{"location":"internals/plans/completed/DTYPE_COMPLEX_OVERFLOW_PLAN/#11-open-questions-to-confirm-before-implementation","title":"11) Open questions (to confirm before implementation)","text":"<ul> <li>Exact list of supported ops for \u201ccore coverage\u201d in the support matrix (minimal set to enforce first).</li> <li>Whether unsigned + signed mixing rules should default to promoting to signed or throwing in ops that can go negative.</li> <li>Default behavior for numeric ops on <code>bit</code> when the semantic result is not representable in <code>bit</code> without widening: default widen vs error-by-design unless the caller explicitly requests an output dtype.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/","title":"R1_BLOCKMATRIX Plan \u2014 Block Matrices + Heterogeneous Dtypes (Storage-First)","text":"<p>Status: Active (drafted 2025-12-17)</p> <p>This plan is the canonical source of truth for block matrices in Release 1.</p> <p>Active plan (not shipped)</p> <p>The behavior in this document is not guaranteed to exist in the current codebase. Do not add user-facing Guides or API Reference that implies this feature is available until implementation lands (Phase G).</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#canonical-dependencies-read-before-implementing","title":"Canonical dependencies (read before implementing)","text":"<ul> <li>Roadmap node: PyCauset Roadmap</li> <li>Foundations:</li> <li>Compute Architecture</li> <li>DType System</li> <li>Release 1 foundations (implemented behavior elsewhere in the system):</li> <li>Storage</li> <li>Properties</li> <li>DTypes</li> <li>Linear Algebra</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#progress-snapshot-must-keep-updated","title":"Progress snapshot (MUST keep updated)","text":"<p>Last updated: 2025-12-22</p> <p>Current phase step: Phase H \u2014 Testing &amp; hardening (completed 2025-12-22)</p> <p>What is done (DONE):</p> <ul> <li>Phase A contract lock completed (interfaces, invariants, determinism, persistence shape, and staleness semantics).</li> <li>Phase B completed: internal <code>BlockMatrix</code> container implemented (Python layer) with construction validation, element reads, and structure-only <code>repr</code>/<code>str</code>.</li> <li>Phase B tests added for construction/indexing/printing validation.</li> <li>Phase C started: internal <code>SubmatrixView</code> container implemented (Python layer) with view composition, dense + block sources, and structure-only printing.</li> <li>Phase C tests added for dense + block view element reads, cross-block views, and repr/str non-trigger behavior.</li> <li>Phase C refinement implemented (Python layer): <code>BlockMatrix.refine_partitions(...)</code> produces a refined block grid using <code>SubmatrixView</code> without densification; deterministic validation errors are enforced.</li> <li>Phase C refinement tests added (correctness + error cases).</li> <li>Phase D started (Python layer): <code>ThunkBlock</code> implemented with structure-only printing, lazy evaluation on element access, caching, and snapshot-at-creation staleness checks based on <code>version</code> pins.</li> <li>Phase D started (Python layer): internal <code>block_matmul(A,B)</code> orchestrator produces a BlockMatrix of thunk blocks and refines inner partitions deterministically.</li> <li>Phase D tests added for trigger/non-trigger behavior, deterministic k-order accumulation, and stale-thunk errors.</li> <li>Phase D elementwise started (Python layer): internal <code>block_add(A,B)</code> aligns partitions by refinement-union and returns a BlockMatrix of thunk blocks.</li> <li>Phase D note: when refinement produces Python <code>SubmatrixView</code> blocks, view-local <code>+</code>/<code>@</code> fall back to small dense evaluation (block-local only) to keep orchestration correct without global densification.</li> <li>Phase E completed: <code>.pycauset</code> save/load supports internal <code>BlockMatrix</code> via a manifest (<code>matrix_type=BLOCK</code>) that references child <code>.pycauset</code> files stored in a sibling directory (<code>&lt;file&gt;.blocks/</code>).</li> <li>Phase E behavior: saving a BlockMatrix evaluates <code>ThunkBlock</code> blocks blockwise (no global densify), persists realized results, and raises on stale thunks.</li> <li>Phase E hardening: thunk staleness pins include leaf blocks (and view sources) so in-place leaf mutation with a <code>version</code> bumps stale deterministically; concurrency test ensures single-eval caching under threads.</li> <li>Phase E hardening: child references are validated deterministically (path safety + pinned child <code>payload_uuid</code>), and multi-file saves use staging/commit to reduce partial-update risk.</li> <li> <p>Phase E coverage: nested, mixed-dtype, and view-block (SubmatrixView) persistence paths have round-trip tests.</p> </li> <li> <p>Phase F started: public constructor disambiguation and \u201conce block, always block\u201d routing are wired.</p> </li> <li>Phase F started: mixed-operand operator behavior (<code>dense + block</code>, <code>dense @ block</code>) defers to BlockMatrix via NotImplemented fallback in native operator bindings.</li> <li>Phase F started: leaf <code>matmul</code> inside thunk evaluation routes through the public compute boundary for native matrices, preserving property-aware dispatch.</li> <li>Phase F started: IO accelerator hooks are exposed (best-effort prefetch/discard) with trace validation support.</li> <li>Phase F started: integration tests cover operator fallback and device routing for block addition when CUDA is active (with CPU fallback for unsupported dtypes).</li> <li>Phase F completed: elementwise block ops (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>) are thunked and partition-aligned, with IO prefetch/discard hooks.</li> <li>Phase F completed: integration tests cover mixed-operand fallbacks (<code>dense op block</code>) and device routing expectations for <code>+</code>/<code>-</code> (GPU when supported, CPU otherwise) plus CPU-only guarantees for <code>*</code>/<code>/</code> under CUDA.</li> <li>Phase G completed: documentation footprint added per Documentation Protocol \u2014 public guides (Matrix Guide, R1 linalg/storage), API reference (<code>pycauset.matrix</code>, <code>pycauset.matmul</code>, <code>pycauset.save</code>, <code>pycauset.load</code>), and internals (Block Matrices) now cover construction rules, slicing, triggers/non-triggers, refinement, staleness, persistence sidecars, and device routing expectations.</li> <li>Phase H completed: hardening tests added for complex matmul vs dense (CPU fallback with guarded skip when complex matmul/persistence unsupported), float16 matmul vs dense, many-small-block matmul vs dense, mixed-dtype add vs dense, nested complex matmul+persistence (guarded skip), thunk concurrency single-eval locking, and <code>set_block</code> staleness invalidation; suite is green with expected skips only.</li> </ul> <p>Phase E policy choices (locked for this implementation pass):</p> <ul> <li>Sidecar directory naming: use <code>str(path) + \".blocks\"</code> (example: <code>bm.pycauset</code> \u2192 <code>bm.pycauset.blocks/</code>).</li> <li>Overwrite cleanup: best-effort delete only deterministic child block files matching <code>block_r*_c*.pycauset</code> in the sidecar directory; do not wipe unrelated files.</li> <li>Stale thunk on save: saving must raise a deterministic stale-thunk error (no silent recompute).</li> <li>Persisted snapshot integrity: each manifest child entry pins the child file's <code>payload_uuid</code>; load validates this and errors if a child file was replaced/rewritten (prevents silent mixed-snapshot loads).</li> <li>Container-level cached-derived: no block-matrix-level <code>trace/determinant/norm/sum/...</code> caching is defined for R1 internal <code>BlockMatrix</code>; cached-derived persistence remains per-child (leaf matrices) under the existing signature rules.</li> <li>View persistence (R1 internal policy): if a BlockMatrix contains <code>SubmatrixView</code> blocks (e.g., from <code>refine_partitions</code>), saving materializes each view block-locally by copying elements into a small NumPy array (with dtype inferred from the view\u2019s source type) and then converting it via <code>native.asarray</code>; there is no multi-file \"view reference\" format in R1.</li> <li>Multi-file save hardening (best-effort): BlockMatrix saves stage managed child files (and nested child <code>.blocks/</code> trees) in a temporary staging directory and then commit via replace/rename. This reduces partial updates; if a crash still occurs mid-commit, <code>payload_uuid</code> pinning ensures loads fail deterministically rather than silently mixing snapshots.</li> </ul> <p>What is next (NEXT):</p> <ul> <li>Optional follow-ups: perf guardrails or stress/block-count overhead checks, plus CLI/bench hooks if product asks; otherwise plan is complete for R1 scope.</li> </ul> <p>Blocked / deferred:</p> <ul> <li>Full symbolic lazy evaluation / fusion across arbitrary expression graphs is deferred.</li> <li>GPU kernels for block-aware ops are deferred; leaf ops must still route via AutoSolver/ComputeDevice. *** Block-matrix-aware slicing completed (integrated into guides/API/internals); no longer deferred.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#phased-execution-plan-docstesting-baked-in","title":"Phased execution plan (docs/testing baked in)","text":"<ul> <li>Phase A \u2014 Contract lock (planning): finalize semantics for evaluation triggers, caching/versioning, dtype accumulation, partition refinement, mutation, and manifest shape. Exit: written acceptance criteria + updated risk/open questions if any. Docs: update this plan + roadmap status.</li> <li>Phase B \u2014 Core types &amp; validation: implement <code>BlockMatrix</code> container (partitions, lookup, mixed dtype metadata), construction validation, structural <code>repr</code>/<code>str</code>. Exit: construction/indexing unit tests + structure-only printing tests.</li> <li>Phase C \u2014 Views &amp; partition refinement: deliver <code>SubmatrixView</code> (no-copy), block-grid refinement for mismatched partitions, tiled views across blocks, scalar/transpose propagation. Exit: view composition tests (dense + block), refinement correctness tests, deterministic error cases for unsupported views.</li> <li>Phase D \u2014 Ops orchestration &amp; thunks: elementwise ops and block matmul orchestration with deterministic per-block accumulator dtype, thunk creation, evaluation triggers, and snapshot/version checks. Exit: lazy-eval tests (triggers/non-triggers), dtype accumulator tests, stale-thunk error tests, and CPU routing for complex blocks; add trace tags for observability.</li> <li>Phase E \u2014 Persistence &amp; caching: manifest save/load for nested blocks, temp handling for thunks, cache invalidation on <code>set_block</code>/child mutation, single-eval locking. Exit: save/load round-trip tests (nested, mixed dtype), cache invalidation tests, concurrent thunk evaluation test.</li> <li>Phase F \u2014 Integration (properties/device/IO): ensure \u201conce block, always block\u201d behavior with AutoSolver boundary, property metadata pass-through, IO accelerator prefetch/discard hooks, and CPU fallback for CUDA gaps. Exit: integration tests covering property propagation, device routing expectations, and IO prefetch/discard trace validation.</li> <li>Phase G \u2014 Documentation: publish API + internals per Documentation Protocol (construction rules, triggers, manifest schema, versioning/staleness, device routing expectations, printing). Exit: docs merged + updated roadmap status.</li> <li>Phase H \u2014 Testing &amp; hardening: expand coverage (complex blocks, float16, deep nesting), stress/block-count overhead checks, and CLI/bench hooks if needed. Exit: test suite green, known gaps documented; optional perf guardrails noted.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#phase-a-contract-lock-completed-2025-12-21","title":"Phase A \u2014 Contract lock (COMPLETED 2025-12-21)","text":"<p>This section freezes the semantics and interfaces so Phase B+ can implement without re-litigating contracts.</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#a1-locked-decisions","title":"A.1 Locked decisions","text":"<p>1) User entrypoint (constructor) is <code>pycauset.matrix(...)</code> (extended, not replaced).</p> <p>The current <code>pycauset.matrix(source, dtype=None, **kwargs)</code> is a numeric data constructor (1D\u2192vector, 2D\u2192dense matrix).</p> <p>Block-matrix construction will be added without breaking existing behavior:</p> <ul> <li>If <code>source</code> is 2D and every element is a <code>MatrixBase</code>-like object, treat <code>source</code> as a block grid and construct a <code>BlockMatrix</code>.</li> <li>If <code>source</code> is 2D and no elements are matrices (numeric scalars / NumPy scalars), keep current dense behavior.</li> <li>If <code>source</code> is 2D and mixes matrices and scalars, raise a deterministic <code>TypeError</code> (no implicit lifting / no implicit densification).</li> </ul> <p>Rationale: avoids ambiguity with the existing numeric constructor while enabling the target syntax.</p> <p>2) Block-level access is explicit, element access remains elementwise.</p> <ul> <li><code>M[i, j]</code> returns an element.</li> <li>Block access is via <code>get_block(r, c)</code> / <code>set_block(r, c, block)</code> with <code>r,c</code> as block-grid indices.</li> </ul> <p>3) No silent densification.</p> <ul> <li>Any unsupported view/refinement case must raise a deterministic error.</li> <li>There is no fallback that materializes a whole dense matrix \u201cjust to make it work\u201d.</li> </ul> <p>4) Semi-lazy matmul outputs thunk per output block, with fixed determinism rules.</p> <ul> <li>Thunks are evaluated only on triggers (element access, dense export, persistence, or leaf-compute boundary).</li> <li>Per-block accumulation dtype follows the deterministic metadata-only rule already defined in this plan.</li> <li>Summation order over <code>k</code> is fixed.</li> </ul> <p>5) Staleness semantics are snapshot-at-creation (default).</p> <ul> <li>Thunks capture input references + versions.</li> <li>If any input version differs on evaluation/cache hit, raise a deterministic \u201cstale thunk\u201d error (do not silently recompute).</li> </ul> <p>6) Persistence shape is manifest + referenced children (nestable).</p> <ul> <li>A saved block matrix stores a manifest in <code>.pycauset</code> metadata that describes the grid topology and references child matrices.</li> <li>Thunk blocks are evaluated blockwise for save (no global densify).</li> <li>If a referenced child is temporary, saving persists it to a stable child file first and then references it.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#a2-acceptance-criteria-phase-a-exit","title":"A.2 Acceptance criteria (Phase A exit)","text":"<ul> <li>The constructor disambiguation rules for <code>pycauset.matrix(...)</code> are explicit (numeric vs block-grid vs mixed error).</li> <li>Minimum public-facing block API is frozen: <code>get_block</code>, <code>set_block</code>, <code>block_rows</code>, <code>block_cols</code>, <code>row_partitions</code>, <code>col_partitions</code>.</li> <li>Evaluation triggers and non-triggers are frozen (especially: <code>repr/str</code> and metadata queries must never evaluate thunks).</li> <li>\u201cNo silent densify\u201d rule is frozen (unsupported views/refinements error deterministically).</li> <li>Staleness semantics are frozen (snapshot-at-creation; stale access errors).</li> <li>Persistence intent is frozen (manifest + referenced child matrices; thunk save is blockwise).</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#0-purpose-and-scope","title":"0) Purpose and scope","text":"<p>Block matrices are a core storage format in PyCauset.</p> <p>Primary goals:</p> <ul> <li>Storage-first: constructing/saving a block matrix must not write an expanded dense buffer.</li> <li>Heterogeneous dtype: a block matrix may contain blocks of different dtypes (including nested block matrices).</li> <li>Infinitely nestable: blocks may themselves be block matrices, recursively.</li> <li>Frontend transparency: a block matrix behaves like a matrix from the public API:</li> <li>element indexing yields elements, not blocks,</li> <li>matmul/elementwise ops \u201cjust work\u201d under correct dimension rules.</li> <li>Single dispatch boundary: leaf computations route via AutoSolver/ComputeDevice.</li> </ul> <p>Non-goals (for now):</p> <ul> <li>General-purpose lazy expression graphs across all operations.</li> <li>Implicit densification as a fallback for unsupported block/view cases.</li> <li>Perfect performance for deeply nested blocks (correctness first; inefficiency is acceptable).</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#1-user-facing-construction-and-behavior","title":"1) User-facing construction and behavior","text":""},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#11-construction","title":"1.1 Construction","text":"<p>Target syntax:</p> <ul> <li>Example:</li> </ul> <pre><code>M = pycauset.matrix([\n  [A, B],\n  [C, D],\n])\n</code></pre> <p>where <code>A,B,C,D</code> are matrices (including block matrices).</p> <p>Validation:</p> <ul> <li>All blocks in a block-row must have the same number of rows.</li> <li>All blocks in a block-col must have the same number of cols.</li> <li>Total shape is <code>(sum block-row heights, sum block-col widths)</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#12-indexing-semantics","title":"1.2 Indexing semantics","text":"<ul> <li><code>M[i, j]</code> returns a scalar element.</li> <li><code>M[i0:i1, j0:j1]</code> slicing is deferred to the broader indexing plan in the R1_LINALG plan; block work requires an internal view node.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#13-block-replacement-api","title":"1.3 Block replacement API","text":"<p>Block-level access is explicit (not via <code>__getitem__</code>).</p> <p>Minimum API:</p> <ul> <li><code>get_block(r, c) -&gt; MatrixBase</code></li> <li><code>set_block(r, c, block: MatrixBase) -&gt; None</code></li> </ul> <p><code>r,c</code> are block indices into the current block grid (not element indices):</p> <ul> <li><code>r</code> is the block-row index in <code>[0, block_rows)</code></li> <li><code>c</code> is the block-col index in <code>[0, block_cols)</code></li> </ul> <p>Required introspection API (minimal):</p> <ul> <li><code>block_rows</code> and <code>block_cols</code> (or equivalent methods)</li> <li><code>row_partitions</code> and <code>col_partitions</code> returning the boundary arrays (prefix sums) used by the block grid</li> <li>Example: <code>row_partitions == [0, r1, r2, ..., rows]</code></li> <li>Example: <code>col_partitions == [0, c1, c2, ..., cols]</code></li> </ul> <p><code>set_block</code> must validate that the replacement block matches the existing block-row height and block-col width.</p> <p>Optional (nice-to-have) helpers for debugging:</p> <ul> <li><code>block_shape(r, c) -&gt; (rows, cols)</code></li> <li><code>block_dtype(r, c) -&gt; DataType</code></li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#14-visualization-printing-must-not-trigger-evaluation","title":"1.4 Visualization / printing (must not trigger evaluation)","text":"<p>Block matrices are primarily about structure. Default printing must emphasize structure without forcing computation.</p> <p>Required behavior:</p> <ul> <li><code>repr(M)</code> / <code>str(M)</code> prints a structure summary and never evaluates thunks.</li> <li>The summary includes:</li> <li>overall shape,</li> <li>block grid size (block_rows \u00d7 block_cols),</li> <li>row/col partitions,</li> <li>per-block descriptors: shape, dtype, and kind (<code>leaf</code>, <code>view</code>, <code>thunk</code>, <code>block</code>).</li> </ul> <p>Recommended formatting (human-scannable):</p> <ul> <li>1-line header: <code>BlockMatrix(shape=(...), grid=RxC, dtype=MIXED)</code></li> <li>Then an ASCII grid of block descriptors, truncated by <code>max_depth</code> and <code>max_blocks</code>.</li> </ul> <p>Explicitly opt-in value printing (may evaluate):</p> <ul> <li>If we add a helper like <code>M.to_dense_string(...)</code> or <code>M.materialize()</code> later, it must be clearly named and documented as a trigger.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#2-core-internal-representation","title":"2) Core internal representation","text":""},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#21-internal-node-types","title":"2.1 Internal node types","text":"<p><code>BlockMatrix : MatrixBase</code> (internal; not necessarily public as <code>pc.BlockMatrix</code>):</p> <ul> <li>stores <code>blocks[r][c]</code> as references (shared ownership),</li> <li>stores <code>row_offsets[]</code> and <code>col_offsets[]</code> prefix sums,</li> <li>supports nesting (a block can be another <code>BlockMatrix</code>).</li> </ul> <p><code>SubmatrixView : MatrixBase</code> (required):</p> <ul> <li>represents a rectangular view into an existing matrix without copying,</li> <li>supports views into dense matrices and block matrices (views can compose).</li> </ul> <p><code>ThunkBlock</code> / <code>DeferredBlock</code> (internal helper; may be a MatrixBase subclass or a block wrapper):</p> <ul> <li>represents a deferred computation that produces a concrete MatrixBase on evaluation,</li> <li>caches evaluated result.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#22-dtype-model-heterogeneous-containers","title":"2.2 Dtype model (heterogeneous containers)","text":"<p>Block matrices do not have a single dtype.</p> <ul> <li>Introduce <code>DataType::MIXED</code> (or equivalent) for heterogeneous containers.</li> <li>Each child block retains its own dtype.</li> </ul> <p>Element reads:</p> <ul> <li><code>get_element_as_double(i,j)</code> / <code>get_element_as_complex(i,j)</code> are defined by delegating into the appropriate block.</li> </ul> <p>Structured view scope (initial):</p> <ul> <li><code>SubmatrixView</code> supports dense matrices and block matrices first; other structured types must raise a deterministic \u201cview not supported yet\u201d error until explicitly added.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#3-operation-contracts-on-block-matrices","title":"3) Operation contracts on block matrices","text":""},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#31-once-block-always-block-default","title":"3.1 \u201cOnce block, always block\u201d (default)","text":"<p>If any operand is a block matrix, the default result is a block matrix (unless explicitly materialized).</p> <p>Rationale:</p> <ul> <li>preserves storage wins (identity/zero/diagonal blocks remain cheap),</li> <li>avoids global promotion/densification.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#32-elementwise-ops-","title":"3.2 Elementwise ops (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>)","text":"<p>Contract:</p> <ul> <li>Operate blockwise.</li> <li>If mixing <code>BlockMatrix</code> with a non-block matrix, partition the non-block operand into matching <code>SubmatrixView</code> tiles.</li> <li>Output block dtypes are computed per-block using the promotion rules for that specific op on the specific operand dtypes.</li> </ul> <p>No silent densification:</p> <ul> <li>If a required view cannot be represented (e.g., unsupported structure), raise a deterministic error.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#33-matmul","title":"3.3 Matmul (<code>@</code>)","text":"<p>Contract:</p> <ul> <li>Block matmul follows standard block multiplication:</li> </ul> <p>For block grids <code>A[i,k]</code> and <code>B[k,j]</code>:</p> <p>$\\(C_{ij} = \\sum_k A_{ik} @ B_{kj}\\)$</p> <ul> <li>Result is a <code>BlockMatrix</code> of output blocks.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#semi-lazy-evaluation","title":"Semi-lazy evaluation","text":"<p>We use semi-lazy evaluation for block matmul outputs:</p> <ul> <li><code>C</code> is returned immediately as a <code>BlockMatrix</code> of thunks.</li> <li>Each thunk represents one <code>C_ij</code> block.</li> <li>The thunk is evaluated on-demand and then cached.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#evaluation-triggers-exactly-when-thunks-run","title":"Evaluation triggers (exactly when thunks run)","text":"<p>A thunk for an output block <code>C_ij</code> must not run \u201cin the background\u201d. It only runs when an API call requires numeric contents of that block.</p> <p>Triggers (must evaluate the minimal required blocks):</p> <ul> <li>Element access (<code>C[i, j]</code>) evaluates the unique block that contains <code>(i, j)</code>.</li> <li>Any operation that requires dense contents of <code>C</code> evaluates all blocks:</li> <li>conversion/export (<code>np.asarray(C)</code>, <code>pycauset.to_numpy(C)</code>),</li> <li>any future <code>materialize()</code> API.</li> <li>Persistence (<code>C.save(path)</code>) evaluates all thunk blocks, but must do so blockwise (materialize each block into a child matrix file; never densify the full matrix into one giant buffer).</li> <li>Passing a thunk block across the leaf compute boundary (AutoSolver/ComputeDevice) evaluates it first.</li> </ul> <p>Non-triggers (must not evaluate):</p> <ul> <li><code>C.shape</code>, <code>C.rows</code>, <code>C.cols</code>, and any partition metadata queries.</li> <li><code>C.dtype</code> / \u201ccontainer dtype\u201d queries for a mixed container.</li> <li><code>repr(C)</code> / <code>str(C)</code> / debug printing (may report \u201cthunked\u201d status).</li> <li><code>C.get_block(r,c)</code> (returns a handle that may still be thunked; evaluation is triggered only when numeric contents are required).</li> </ul> <p>Determinism:</p> <ul> <li>Reduction order over <code>k</code> is fixed.</li> <li>Dtype decisions for accumulation are deterministic.</li> </ul> <p>Local promotion (unavoidable):</p> <ul> <li>Even with heterogeneous container dtypes, a single output block <code>C_ij</code> may need local promotion while accumulating <code>\u03a3_k</code>.</li> <li>This is local to that block; it does not force a global result dtype.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#deterministic-dtype-accumulation-rule-for-sum_k-inside-one-output-block","title":"Deterministic dtype accumulation rule for \\(\\sum_k\\) inside one output block","text":"<p>Each output block <code>C_ij</code> is computed as a deterministic fold over terms <code>T_k = A_ik @ B_kj</code>.</p> <p>Rule (deterministic, metadata-only):</p> <p>1) For each <code>k</code>, compute the term dtype <code>dtype(T_k)</code> using the existing matmul dtype rules (the same rules used by the non-block <code>@</code>). This is determined from operand dtypes/structures and does not require evaluation.</p> <p>2) Compute the accumulator dtype <code>dtype_acc</code> by folding the existing addition dtype rule over the sequence of term dtypes in increasing <code>k</code>:</p> \\[dtype\\_acc = fold\\_k\\big( add\\_result\\_dtype,\\ dtype(T_0), dtype(T_1), \\ldots \\big)\\] <p>3) During numeric evaluation, each term <code>T_k</code> is accumulated into an accumulator buffer of type <code>dtype_acc</code> (casting each <code>T_k</code> to <code>dtype_acc</code> if needed) using a fixed <code>k</code> order.</p> <p>Notes:</p> <ul> <li>This keeps the container heterogeneous: <code>dtype_acc</code> is per-output-block.</li> <li>If term dtypes include both real and complex, <code>dtype_acc</code> is complex (per existing promotion rules).</li> <li>If term dtypes include multiple float widths, <code>dtype_acc</code> is the widest among them (per existing promotion rules).</li> <li>Integer-only accumulation follows the existing integer promotion behavior for <code>+</code> (we are not adding a new \u201csafe integer accumulator\u201d mode in R1).</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#partition-mismatch-handling","title":"Partition mismatch handling","text":"<p>If block partitions are not aligned:</p> <ul> <li>Compute the common refinement of boundaries and use <code>SubmatrixView</code> to split blocks without copying.</li> <li>If refinement cannot be represented without copying, raise an error (do not silently densify).</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#partition-mismatch-refinement-via-submatrixview-no-silent-densify","title":"Partition mismatch refinement via <code>SubmatrixView</code> (no silent densify)","text":"<p>We must support the common case where <code>A</code> and <code>B</code> have different block boundaries, while still guaranteeing no implicit densification.</p> <p>Matmul refinement (core requirement):</p> <ul> <li>Let <code>A</code> have row boundaries <code>RA</code> and col boundaries <code>CA</code>.</li> <li>Let <code>B</code> have row boundaries <code>RB</code> and col boundaries <code>CB</code>.</li> </ul> <p>For <code>C = A @ B</code>, the shared dimension boundaries must align in the refined view. We compute:</p> <ul> <li><code>K = sort(unique(CA \u222a RB))</code> as the refinement boundaries for the shared axis.</li> </ul> <p>Then, for each output block <code>(i, j)</code> defined by row interval <code>RA[i..i+1]</code> and col interval <code>CB[j..j+1]</code>, the sum is taken over <code>k</code> intervals defined by <code>K</code>:</p> <ul> <li><code>A_ik_view = SubmatrixView(A, rows=RA_i, cols=K_k)</code></li> <li><code>B_kj_view = SubmatrixView(B, rows=K_k, cols=CB_j)</code></li> </ul> <p>These views must be representable without copying for all participating blocks.</p> <p>Elementwise refinement (for completeness):</p> <ul> <li>For <code>A \u2299 B</code> (\u2299 \u2208 {+,-,*,/}), compute refinement boundaries on both axes:</li> <li><code>R = sort(unique(RA \u222a RB))</code></li> <li><code>C = sort(unique(CA \u222a CB))</code></li> <li>Tile both operands into matching <code>SubmatrixView</code> blocks.</li> </ul> <p>Hard rule:</p> <ul> <li>If any required <code>SubmatrixView</code> is not representable under a matrix\u2019s structure constraints (e.g., a square-only structured type that cannot form an arbitrary rectangular view), the operation must raise a deterministic error.</li> <li>There is no \u201cfallback densify\u201d behavior.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#4-mutationversioning-and-caching-rules-critical","title":"4) Mutation/versioning and caching rules (critical)","text":"<p>Lazy thunks + mutation can produce silent wrong answers unless we define this explicitly.</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#41-default-semantics-snapshot-for-thunks","title":"4.1 Default semantics: snapshot for thunks","text":"<p>R1 default (locked in):</p> <ul> <li>Thunks capture a snapshot of inputs (by reference + versioning).</li> <li>If any input block changes after thunk creation, cached results are invalidated or evaluation is forbidden until re-derived.</li> </ul> <p>Recomputation policy:</p> <ul> <li>If serving a request would require more than O(1) work relative to cached state, do not auto-recompute; stale accesses raise a deterministic error. In R1, all stale thunk/cache hits fall under this rule and must error.</li> </ul> <p>Implementation direction:</p> <ul> <li>Add per-object monotonic <code>version</code> counters that increment on mutation.</li> <li>Thunks store the input versions they were derived from.</li> <li>On evaluation/cache hit, verify versions match.</li> </ul> <p>Clarification (R1 choice \u2014 explicit):</p> <ul> <li>This is snapshot-at-creation semantics for lazy results: a thunk is only valid for the specific versions of its inputs that existed when the thunk was created.</li> <li>If an input\u2019s version differs, the thunk must raise a deterministic \u201cstale thunk\u201d error rather than silently recomputing with new values.</li> </ul> <p>This avoids time-dependent results and mixed-snapshot matrices.</p> <p>Future (explicit opt-in, not default):</p> <ul> <li>We may add a \u201clive\u201d policy where stale thunks automatically recompute against current inputs, but it must be user-controlled (never implicit) because it changes determinism and interacts badly with partial caching.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#42-caching-policy","title":"4.2 Caching policy","text":"<p>Pitfall: unbounded caching can explode disk/memory.</p> <p>Minimum viable policy:</p> <p>What is cached:</p> <ul> <li>The evaluated numeric result of each thunk block (<code>C_ij</code>) as a concrete <code>MatrixBase</code> instance.</li> </ul> <p>Where it is cached:</p> <ul> <li>Cached blocks are stored in-memory as references, and their backing storage is a normal matrix backing (typically a temp <code>.pycauset</code> file) managed by the existing temp lifecycle.</li> </ul> <p>Invalidation:</p> <ul> <li>Any <code>set_block</code> on a <code>BlockMatrix</code> invalidates all cached/thunked blocks owned by that <code>BlockMatrix</code> (increment the parent version; cached blocks become inaccessible).</li> <li>Any mutation of a referenced child matrix invalidates any thunk (and any cached block) that depends on it via version mismatch checks.</li> </ul> <p>Eviction:</p> <ul> <li>No eviction policy is required for R1 beyond the existing temp cleanup. (We avoid introducing new user-facing cache knobs in R1.)</li> </ul> <p>Later enhancements (SRP/IO):</p> <ul> <li>LRU eviction, memory thresholds, explicit <code>cache_policy</code> knobs.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#43-mutation-semantics","title":"4.3 Mutation semantics","text":"<p>We need explicit semantics for both (a) replacing blocks and (b) mutating matrices that are referenced as blocks.</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#set_blockr-c-block","title":"<code>set_block(r, c, block)</code>","text":"<ul> <li><code>set_block</code> is a mutation of the <code>BlockMatrix</code> container.</li> <li>It must validate the replacement block\u2019s shape against the existing block-row and block-col sizes.</li> <li>It increments the container\u2019s <code>version</code> and invalidates any cached/thunked blocks owned by the container.</li> <li>It does not mutate the old or new child blocks.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#edits-to-referenced-child-matrices","title":"Edits to referenced child matrices","text":"<p>If a child matrix <code>A</code> is referenced by one or more <code>BlockMatrix</code> containers and the user mutates <code>A</code> (element edits, in-place ops, etc.):</p> <ul> <li><code>A.version</code> increments.</li> <li>Any thunk that captured <code>A</code> at an older version becomes stale.</li> <li>Accessing a stale thunk (or a cached block derived from a stale thunk) must raise a deterministic error (not recompute). This is the R1 default.</li> </ul> <p>Rationale:</p> <ul> <li>Prevents partially materialized results that mix old and new input states.</li> <li>Keeps \u201clazy\u201d behavior from becoming time-dependent.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#5-persistence-reference-save-manifests-infinitely-nestable","title":"5) Persistence: reference-save manifests (infinitely nestable)","text":""},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#51-runtime-assumption","title":"5.1 Runtime assumption","text":"<p>During a run, backing <code>.pycauset</code> files do not move or disappear.</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#52-save-semantics","title":"5.2 Save semantics","text":"<p>When a user calls <code>.save(path)</code> on a block matrix:</p> <ul> <li>Write a manifest that records:</li> <li>block grid topology,</li> <li>row/col partition sizes,</li> <li>for each block: reference to the child\u2019s backing file + block metadata (transpose/conjugate/scalar/etc),</li> <li>recursion for nested blocks.</li> </ul> <p>Format requirement:</p> <ul> <li>Manifest is a binary header + records inside the <code>.pycauset</code> file; JSON/zip formats are removed and must not be referenced in code or docs.</li> </ul> <p>The manifest does not store expanded dense elements.</p> <p>Handling temporaries:</p> <ul> <li>If a referenced child is temporary, saving must first persist it to a stable child file (copy storage) and then reference that.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#53-load-semantics","title":"5.3 Load semantics","text":"<ul> <li>Load reads the manifest, reconstructs the <code>BlockMatrix</code> structure, and recursively loads child blocks.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#6-integration-points-single-dispatch-boundary-preserved","title":"6) Integration points (single dispatch boundary preserved)","text":"<ul> <li><code>BlockMatrix</code> orchestration decomposes operations into leaf ops on non-block matrices.</li> <li>Leaf ops always route via AutoSolver/ComputeDevice.</li> </ul> <p>This keeps OpenBLAS/CUDA integration straightforward:</p> <ul> <li>They accelerate the leaf <code>matmul/add/...</code> kernels.</li> <li>Block orchestration decides which leaf ops to run and when (via thunks).</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#61-alignment-with-compute-architecture","title":"6.1 Alignment with Compute Architecture","text":"<p>This plan is designed to remain compatible with <code>documentation/internals/Compute Architecture.md</code>:</p> <ul> <li>All heavy numerical work still goes through <code>ComputeContext::instance().get_device()</code>.</li> <li>AutoSolver remains the routing point that decides CPU vs GPU based on size and capabilities.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#device-capability-reality-important","title":"Device capability reality (important)","text":"<p>CUDA matmul is not a universal backend today:</p> <ul> <li><code>CudaDevice::matmul</code> supports dense <code>float32</code>/<code>float64</code> matrices.</li> <li>Complex matmul is supported on CPU (<code>cpu.matmul.c32</code>, <code>cpu.matmul.c64</code>, plus <code>cpu.matmul.cf16_fallback</code>) but is not supported on CUDA today.</li> </ul> <p>Therefore:</p> <ul> <li>Block matrices containing complex blocks must still work, but AutoSolver must route those leaf ops to CPU.</li> <li>Mixed-dtype block containers are fine because routing happens per leaf op, not per container.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#62-io-accelerator-compatibility-prefetchdiscard","title":"6.2 IO Accelerator compatibility (prefetch/discard)","text":"<p>To stay compatible with the IO acceleration layer:</p> <ul> <li>Before evaluating a thunk block, the orchestrator should prefetch the required input blocks/views (where available) via each matrix\u2019s accelerator interface.</li> <li>After a thunk block is evaluated and its intermediate temporaries are no longer needed, the orchestrator should allow (or request) discard of those temporaries.</li> </ul> <p>This preserves the existing \u201cminimize page faults\u201d strategy for out-of-core workloads.</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#63-views-and-blasgpu-friendliness-without-copying","title":"6.3 Views and BLAS/GPU friendliness (without copying)","text":"<p><code>SubmatrixView</code> must not force a copy. For performance (later), it should expose an optional \u201cdense window\u201d representation when possible:</p> <ul> <li>pointer/offset/leading-dimension view into a dense backing,</li> <li>otherwise fall back to the generic <code>get_element_as_*</code> path on CPU.</li> </ul> <p>GPU support for views can be added later if/when CUDA kernels accept strides/offsets.</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#7-testing-strategy-minimum","title":"7) Testing strategy (minimum)","text":"<ul> <li>Construction:</li> <li>valid block grids build without densification.</li> <li>invalid grids raise deterministic errors.</li> <li>Indexing:</li> <li>element reads match dense equivalent.</li> <li>Mixed dtype:</li> <li>block containers can hold multiple dtypes.</li> <li>elementwise ops produce per-block dtype results.</li> <li>Semi-lazy matmul:</li> <li>no compute until triggered (verify via kernel trace tags),</li> <li>deterministic results,</li> <li>cache hit behavior.</li> <li>Persistence:</li> <li>save/load round-trip for nested manifests.</li> </ul> <p>Additions (to catch subtle bugs early):</p> <ul> <li>Complex blocks (CPU fallback): ensure complex32/complex64/complex-f16 blocks round-trip through elementwise ops and matmul without densifying the whole matrix.</li> <li>Printing: <code>repr</code>/<code>str</code> must not evaluate thunks (verify via trace tags).</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#8-risk-register","title":"8) Risk register","text":"<ul> <li>Snapshot/versioning complexity: must avoid silent stale caches.</li> <li>Excessive overhead for many small blocks: mitigated by later scheduling/materialization knobs.</li> <li>Deep nesting inefficiency: accepted for completeness.</li> <li>CUDA capability gaps: complex blocks and some view/shape cases will route to CPU until CUDA support expands.</li> <li>Thread-safety: concurrent evaluation of the same thunk block must not corrupt caches (R1 uses single-eval locking; see below).</li> <li>View correctness: views over nested blocks that cross block boundaries are subtle; ensure we represent them as structured compositions of smaller views, not as copies.</li> <li>Scalar/transpose flags: ensure <code>SubmatrixView</code> and manifest metadata preserve scalar multipliers and transpose status without changing numeric meaning.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#9-open-questions-to-decide-early","title":"9) Open questions (to decide early)","text":"<p>1) Exact API surface for block operations (<code>get_block</code>/<code>set_block</code>, <code>materialize</code>, cache controls). 2) Whether <code>SubmatrixView</code> supports all structured matrices or only dense initially. 3) Manifest format is locked to the binary header + records inside <code>.pycauset</code>; JSON/zip are deprecated and removed.</p> <p>R1 decisions (locked in):</p> <p>4) Concurrency semantics for thunks: use single-eval locking per thunk (e.g., <code>std::mutex</code> + double-checked caching or <code>std::once_flag</code>). If multiple threads request the same thunked block, only one computes and installs the cached result; other threads wait and then reuse the cached block.</p> <p>5) <code>SubmatrixView</code> spanning multiple blocks is allowed: represent it as a <code>BlockMatrix</code> of <code>SubmatrixView</code> tiles (a \u201ctiled view\u201d), with no copying and no densification.   - Note: such a tiled view may be <code>DataType::MIXED</code> if it spans blocks with different dtypes. Element access remains well-defined; dense materialization chooses a target dtype using the existing dtype promotion rules.</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#10-documentation-requirements-must-be-thorough","title":"10) Documentation requirements (must be thorough)","text":"<p>We need both API docs and internals docs so future work (I/O, CPU, GPU) can safely optimize without breaking semantics.</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#101-publicapi-documentation","title":"10.1 Public/API documentation","text":"<ul> <li><code>pycauset.matrix(...)</code> block-grid construction rules and validation errors.</li> <li>Block matrix behavior expectations:</li> <li>element indexing returns elements,</li> <li>block replacement only via explicit API (<code>get_block</code>/<code>set_block</code>),</li> <li>\u201conce block, always block\u201d default.</li> <li>Evaluation triggers (what forces computation) and non-triggers.</li> <li>Save/load semantics for manifests (what is stored, what is not).</li> <li>Device routing expectations (AutoSolver may run different blocks on CPU vs GPU depending on dtype/shape/capability).</li> <li>Printing/visualization behavior (structure summary by default; no implicit evaluation).</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#102-internals-documentation","title":"10.2 Internals documentation","text":"<ul> <li>Data model: <code>BlockMatrix</code>, <code>SubmatrixView</code>, <code>ThunkBlock</code>.</li> <li>Versioning + staleness semantics (snapshot-at-creation; stale thunks error).</li> <li>Caching rules + lifecycle of temp files.</li> <li>Partition refinement algorithm and \u201cno silent densify\u201d rule.</li> <li>Manifest format: schema, examples, and compatibility rules for future extensions.</li> <li>Complex-number storage notes:</li> <li>complex32/complex64 dense matrices store <code>std::complex&lt;T&gt;</code> values,</li> <li>ComplexFloat16 matrices may store real/imag planes; views and thunks must treat them consistently.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#11-agent-handoff-implementation-checklist-for-the-next-ai-agent","title":"11) Agent handoff: implementation checklist (for the next AI agent)","text":"<p>This section is intentionally explicit to reduce the chance of subtle bugs.</p>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#111-core-correctness-checklist","title":"11.1 Core correctness checklist","text":"<ul> <li>Implement <code>BlockMatrix</code> shape, partitions, and fast element-to-block lookup (binary search on <code>row_partitions</code>/<code>col_partitions</code>).</li> <li>Implement <code>SubmatrixView</code> with strict no-copy semantics and correct composition over:</li> <li>transpose flags,</li> <li>scalar multipliers,</li> <li>nested block matrices.</li> <li>Implement <code>ThunkBlock</code> evaluation + caching with version checks:</li> <li>snapshot input versions at creation,</li> <li>error on stale access.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#112-compute-boundary-checklist-must-match-compute-architecture","title":"11.2 Compute boundary checklist (must match Compute Architecture)","text":"<ul> <li>Orchestrator decomposes ops into leaf ops and calls AutoSolver/ComputeDevice.</li> <li>Respect device capability gating:</li> <li>complex blocks must route to CPU today,</li> <li>CUDA paths are limited to supported dtypes/shapes.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#113-determinism-checklist","title":"11.3 Determinism checklist","text":"<ul> <li>Block matmul thunk evaluation must use a fixed <code>k</code> order.</li> <li>Accumulator dtype for each output block must be determined from dtype metadata only (no data-dependent decisions).</li> <li>Avoid parallel reductions that change summation order unless explicitly documented.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#114-persistence-checklist","title":"11.4 Persistence checklist","text":"<ul> <li>Manifest save/load must preserve nesting and references.</li> <li>Saving must not write a single expanded dense buffer for the whole block matrix.</li> <li>Thunk blocks must be saved as stable child matrices (evaluate per-block), then referenced.</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#115-debugvisualization-checklist","title":"11.5 Debug/visualization checklist","text":"<ul> <li><code>repr</code>/<code>str</code> must never evaluate thunks.</li> <li>Provide readable structural summaries (shape, partitions, per-block metadata).</li> </ul>"},{"location":"internals/plans/completed/R1_BLOCKMATRIX_PLAN/#116-dont-get-trapped-pitfalls","title":"11.6 \u201cDon\u2019t get trapped\u201d pitfalls","text":"<ul> <li>Do not accidentally materialize views to make BLAS happy (violates storage-first).</li> <li>Be explicit about complex behavior:</li> <li>CPU supports complex matmul; CUDA does not today.</li> <li>ComplexFloat16 uses split planes; views must handle both planes consistently.</li> <li>Ensure partial caching cannot produce mixed-snapshot results (stale access must error).</li> </ul>"},{"location":"internals/plans/completed/R1_IO_PLAN/","title":"R1_IO \u2014 Out-of-core I/O + Persistence Performance (Phased Plan)","text":"<p>Status: Draft (to be iterated)</p> <p>Goal: Disk-backed operation performance is a first-class feature, not an accident.</p> <p>This plan focuses on making large-scale workflows (10s\u2013100s of GB) correct, efficient, and predictable without hidden full materialization.</p>"},{"location":"internals/plans/completed/R1_IO_PLAN/#scope-and-non-goals","title":"Scope and non-goals","text":""},{"location":"internals/plans/completed/R1_IO_PLAN/#in-scope","title":"In scope","text":"<ul> <li>Snapshot I/O (<code>save</code>/<code>load</code>) correctness and performance.</li> <li>Out-of-core compute behavior (direct-vs-streaming selection, paging friendliness).</li> <li>IO hinting (prefetch/discard) correctness and measurable impact.</li> <li>Explicit temp vs snapshot semantics (spill/eviction <code>.tmp</code> vs <code>.pycauset</code> snapshots).</li> <li>The NumPy conversion surface, as it intersects with I/O and out-of-core safety.</li> </ul>"},{"location":"internals/plans/completed/R1_IO_PLAN/#non-goals-r1","title":"Non-goals (R1)","text":"<ul> <li>Building a new mmap/NumPy backend to make NumPy handle massive arrays \u201cbetter than NumPy itself\u201d.</li> <li>Zero-copy NumPy views for huge matrices if it requires substantial new storage architecture. (If this architecture is very stable and low-maintanence, however, I say it is very worth exploring)</li> <li>New internal snapshot container formats beyond the single <code>.pycauset</code> format.</li> <li>R1 may still add import/export for other formats; it just must not fork the canonical on-disk snapshot format.</li> </ul>"},{"location":"internals/plans/completed/R1_IO_PLAN/#terms-and-invariants-must-remain-true","title":"Terms and invariants (must remain true)","text":"<ul> <li>Snapshot: a <code>.pycauset</code> file created by <code>save()</code>; treated as immutable when loaded.</li> <li>Working storage / spill: switching an object to file-backed mapping via temporary session files (e.g., <code>.tmp</code>).</li> <li>Payload vs metadata:</li> <li>payload bytes may live on disk and be paged in;</li> <li>metadata/properties/cached-derived values are logically separate and must round-trip correctly on snapshot save/load.</li> <li>Scale-first: new features must not introduce accidental full scans, accidental densification, or hidden full copies for out-of-core operands.</li> </ul>"},{"location":"internals/plans/completed/R1_IO_PLAN/#working-protocol-agent-design-chief","title":"Working protocol (agent \u2194 design chief)","text":"<ul> <li>Operate phase-by-phase: state the current phase, list intended edits, then execute.</li> <li>Ask clarifying questions when uncertain; propose 1\u20133 options when choices exist.</li> <li>After edits, report \u201cwhat changed\u201d and \u201cwhat\u2019s next\u201d; keep this loop for all future plan/doc work.</li> <li>Explicitly mark when a phase is complete once its Definition of Done is met.</li> </ul>"},{"location":"internals/plans/completed/R1_IO_PLAN/#phase-0-contract-lock-interfaces-policies-status-completed","title":"Phase 0 \u2014 Contract lock (interfaces + policies) \u2014 Status: Completed","text":"<p>Objective: Decide the policies that other phases implement and test.</p> <p>Deliverables:</p> <ol> <li>Conversion surface (NumPy interop policy, I/O-aware)</li> <li>PyCauset does not expose a <code>pc.asarray</code> \u201carray\u201d API; only matrices/vectors are first-class.</li> <li>Define supported conversion entrypoints and their semantics:<ul> <li><code>pc.matrix(np_array)</code> / <code>pc.vector(np_array)</code> (import from NumPy)</li> <li><code>np.asarray(obj)</code> / <code>np.array(obj)</code> (export to NumPy)</li> </ul> </li> <li>Export-to-NumPy policy (locked):<ul> <li>Huge / out-of-core objects: <code>np.asarray(obj)</code> / <code>np.array(obj)</code> must hard error rather than triggering implicit full materialization.</li> <li>Default criterion: if the object is file-backed/spilled or estimated materialized bytes exceed a configurable ceiling (opt-in setting), exports hard error. Estimated bytes use logical dense bytes (shape product \u00d7 dtype itemsize).</li> <li>Rationale: deterministic failure is better UX than OS thrash/freezes.</li> <li>Power-user path exists via an explicit kwarg <code>allow_huge=True</code> on export entrypoints to intentionally materialize anyway; default is <code>allow_huge=False</code>.</li> <li>Snapshot-backed objects: exporting to NumPy is a copy by default.</li> <li>Rationale: users expect a \u201creal NumPy array\u201d, and snapshot-loaded data is treated as immutable.</li> </ul> </li> <li> <p>Import-from-NumPy policy (to define):</p> <ul> <li>Adopt in place only when the NumPy input is contiguous/aligned and dtype matches PyCauset kind rules; otherwise copy.</li> <li>Default behavior for very large NumPy inputs is to create disk-backed storage rather than reserving equivalent RAM.</li> <li>Optional import kwarg <code>max_in_ram_bytes</code> (default <code>None</code>): above this cap, force spill/backing file even if contiguity would allow adoption. If <code>None</code>, only the \u201chuge \u2192 disk-backed\u201d policy applies.</li> <li>Small objects should match NumPy overhead expectations (\u2265 0.9\u00d7 baseline in agreed regimes).</li> </ul> </li> <li> <p>Direct vs streaming decision contract</p> </li> <li>When kernels are allowed to use OS paging (\u201cdirect path\u201d) vs must use explicit streaming.</li> <li>Default routing guidance (user should not need to tune):<ul> <li>Stream when operands are file-backed/spilled or estimated materialized bytes exceed a hardware-aware ceiling (implementation may size this from device RAM; threshold is not user-facing by default).</li> <li>Favor streaming for access patterns that are naturally blocked/tilable; allow direct path for small, in-RAM operands with contiguous-friendly layout.</li> <li>Properties/layout may force streaming (e.g., structures implying sparse-ish or strided access that would thrash if paged directly).</li> </ul> </li> <li> <p>Ensure decisions are reproducible and testable: emit trace hooks/counters for chosen path, estimated bytes, and why-direct/why-streaming so tests can assert routing.</p> </li> <li> <p>I/O safety contract</p> </li> <li>Define what operations are allowed to allocate large intermediates, and which must be blocked or forced into streaming.</li> <li>Block or force-stream any path that would densify/fully materialize spill-backed or huge operands; forbid O(N^2) temporaries unless they stay within a tiling/windowed budget.</li> <li>Mixed-kind or layout-transform intermediates must respect the same budget; if exceeding it, they route through streaming tiling or error explicitly.</li> <li> <p>Surface a deterministic error/warning when an op is rejected for I/O safety; avoid silent slow fallbacks.</p> </li> <li> <p>File format interoperability contract (import/export/convert)</p> </li> <li>Establish the supported file-format surface for R1 (prioritized list), without changing the canonical snapshot format:<ul> <li>Import: allow PyCauset to read relevant external formats (at least NumPy <code>.npy</code> / <code>.npz</code>; others as selected).</li> <li>Export: allow writing to external formats for interoperability.</li> </ul> </li> <li>Add a file conversion API for power users and pipelines:<ul> <li>Proposed name: <code>pc.convert_file(src_path, dst_path, *, dst_format=None, **options)</code>.</li> <li>Goal: convert <code>.pycauset</code> \u21c4 (supported formats) without forcing users through manual load + save boilerplate.</li> </ul> </li> <li>Optional: define whether a small \u201cpandas interop\u201d surface belongs here (likely optional dependency).</li> </ol> <p>Definition of done (Phase 0): A short written contract section in this plan that can be used to reject/accept implementation PRs.</p>"},{"location":"internals/plans/completed/R1_IO_PLAN/#phase-1-snapshot-io-correctness-all-public-types-status-completed","title":"Phase 1 \u2014 Snapshot I/O correctness (all public types) \u2014 Status: Completed","text":"<p>Objective: Ensure <code>save/load</code> round-trips are correct across the declared dtype/structure surface.</p> <p>Deliverables:</p> <ul> <li>Round-trip tests for:</li> <li>dense matrices/vectors of all public dtypes</li> <li>structured matrices/vectors where applicable</li> <li>view metadata (transpose/conjugation/scalar) and shape</li> <li>properties + cached-derived values (tri-state semantics preserved)</li> <li>spill-backed vs snapshot-backed parity (round-trip behavior identical modulo immutability expectations)</li> <li>mixed device/storage routing does not drop properties or view semantics</li> <li>Crash-safety invariants remain true (payload offsets stable, metadata updates do not shift payload).</li> <li>Include a guardrail test that a metadata-only update does not rewrite payload.</li> <li>Include a guardrail that malformed/corrupt metadata fails loudly (not silent partial loads).</li> </ul> <p>Definition of done (Phase 1): SRP-style round-trip suite passes for the full public surface, including spill vs snapshot parity and metadata-only updates not touching payload; failures are deterministic and loud.</p>"},{"location":"internals/plans/completed/R1_IO_PLAN/#phase-2-snapshot-io-performance-large-scale-status-completed","title":"Phase 2 \u2014 Snapshot I/O performance (large-scale) \u2014 Status: Completed","text":"<p>Objective: Large reads/writes are demonstrably efficient and avoid avoidable extra passes.</p> <p>Deliverables:</p> <ul> <li>Benchmarks for:</li> <li>large <code>save()</code> throughput (sequential write)</li> <li>large <code>load()</code> + first-touch performance</li> <li>repeated loads (OS cache effects acknowledged but measured)</li> <li>Verify that \u201csmall metadata updates\u201d do not require rewriting payload.</li> </ul> <p>Definition of done (Phase 2): Measured throughput is competitive and regressions are detectable.</p>"},{"location":"internals/plans/completed/R1_IO_PLAN/#phase-2b-format-interoperability-pragmatic-pipeline-friendly-status-completed","title":"Phase 2b \u2014 Format interoperability (pragmatic, pipeline-friendly) \u2014 Status: Completed","text":"<p>Objective: Interoperate with the ecosystem without pretending NumPy will become an out-of-core engine.</p> <p>Deliverables:</p> <ul> <li>Import from NumPy formats:</li> <li><code>.npy</code> (dense)</li> <li><code>.npz</code> (dense bundles)</li> <li>Export to NumPy formats:</li> <li><code>.npy</code> / <code>.npz</code> for dense matrices/vectors</li> <li><code>pc.convert_file(...)</code> supports <code>.pycauset</code> \u21c4 <code>.npy</code>/<code>.npz</code> at minimum.</li> <li>If added in R1: pandas interoperability (optional dependency) is explicitly scoped and tested.</li> </ul> <p>Notes (ambition with realism):</p> <ul> <li>It is reasonable to target an extensive suite of supported formats over time, but we should treat this as a staged effort:</li> <li>R1 baseline: a small set of formats with stable, widely-used readers/writers.</li> <li>R1+ (or optional extras): additional formats gated behind optional dependencies or a plugin-style layer.</li> <li>Additional format targets worth prioritizing (depending on community demand):</li> <li>MatrixMarket <code>.mtx</code> (common for sparse matrices)</li> <li>MATLAB <code>.mat</code> (common in scientific workflows)</li> <li>A Mathematica-friendly interchange path (exact container TBD; may be easiest via text/CSV or HDF5-based interchange rather than a native <code>.mx</code> reader)</li> <li>Parquet / Arrow for pandas-oriented workflows (tabular, columnar)</li> </ul> <p>Definition of done (Phase 2b): A minimal set of formats works end-to-end and is documented; conversion failures are deterministic and actionable.</p>"},{"location":"internals/plans/completed/R1_IO_PLAN/#phase-3-out-of-core-kernel-io-strategy-status-completed","title":"Phase 3 \u2014 Out-of-core kernel I/O strategy \u2014 Status: Completed","text":"<p>Objective: Streaming paths and IO hinting match access patterns and reduce page faults.</p> <p>Deliverables:</p> <ul> <li>Identify the \u201ctop 3\u20134\u201d ops to harden for out-of-core behavior (likely <code>matmul</code>, <code>inverse</code>, <code>eigval</code>, and one more depending on current usage).</li> <li>Verify that:</li> <li>streaming paths are exercised in tests,</li> <li>IO prefetch/discard hooks are called where intended,</li> <li>direct-vs-streaming selection does not regress.</li> </ul> <p>Working plan (current selection): - Target ops: <code>matmul</code>, <code>inverse</code>, <code>eigval/eig</code>, top-k eigenvalue (<code>eigvals_arnoldi</code>/Arnoldi/Lanczos), and block <code>cholesky</code> (fallback to solve if coverage needs broader exposure). - Streaming/tiling sketch:   - Matmul: blocked row/col tiles with sequential-friendly read/write; overlap prefetch of A/B tiles with C write-back; GPU path uses pinned host staging for host\u2194device tiles.   - Inverse: block-based panel updates (Schur/blocked Gauss-Jordan) with streaming panels; sequential panel read, tiled trailing-update writes; prefer shared tile size heuristic keyed to memory threshold.   - Eigval/Eig: reduce to banded/tridiag in streaming panels; use chunked workspace for iterative sweeps; avoid full dense materialization when eigenvectors not requested.   - Cholesky: panel factorization + trailing block updates; stream panels from disk, double-buffer trailing tiles; expose panel tile size knob tied to memory threshold. - Observability counters/hooks to add: route decision (direct vs streaming), estimated bytes per operand, chosen tile shape, in-flight tile queue depth, prefetch/read/write throughput, page-fault proxy (fallback: OS-reported faults if available), device-idle proxy (GPU: kernel gaps vs H2D/D2H overlap; CPU: worker idle vs IO wait), and a per-op trace tag for why-direct/why-stream. - Observability scaffolding now records per-op traces (matmul/invert/eigvalsh/eigh) with route decision, estimated bytes, tile shape heuristic, queue depth, page-fault proxy, throughput placeholders, and a trace tag accessible via debug helpers. - Tests/bench shape: CI-friendly sizes that force streaming via low thresholds; assertions on chosen route and tile shape; smoke benchmarks that report throughput plus counters (no strict perf gates in CI, but numbers logged for regression diffing).</p> <p>Additional performance direction (explicitly a goal):</p> <ul> <li>Prioritize read/write speed under demanding CPU/GPU workloads.</li> <li>Where feasible, overlap compute with I/O (prefetch, write-behind, staging buffers) while keeping behavior deterministic.</li> </ul> <p>How overlap should work (contract-level intent; implementation details may vary):</p> <ul> <li>Make access patterns explicit: for each hardened op, define whether its dominant access is row/column/blocked/strided and choose a tiling that makes disk access as sequential as possible.</li> <li>Pipeline, don\u2019t \u201cread everything then compute\u201d: treat out-of-core kernels as a steady-state pipeline:</li> <li>stage A: async read (prefetch next tiles)</li> <li>stage B: decode/prepare (layout transforms, dtype conversions if unavoidable)</li> <li>stage C: compute (CPU and/or GPU)</li> <li>stage D: async write (write-behind results, flush checkpoints)</li> <li>Double/triple buffering: maintain a small ring of tile buffers so compute can proceed while I/O runs.</li> <li>CPU\u2194GPU staging discipline: if GPU is involved, use a staging strategy that minimizes stalls:</li> <li>pinned/page-locked buffers where available,</li> <li>async host\u2192device transfers overlapped with kernel execution,</li> <li>device\u2192host write-back overlapped with next read.</li> <li>Backpressure + safety: if the disk can\u2019t keep up, the system must reduce concurrency/tiling rather than thrash:</li> <li>avoid unbounded queues,</li> <li>avoid pathological random I/O,</li> <li>make fallbacks explicit (e.g., switch to smaller tiles).</li> <li>Deterministic observability: expose traces/counters that can prove overlap is happening (read throughput, queue depth, page-fault rate, GPU idle time) so regressions are actionable.</li> </ul> <p>Phase 3 success goals (detailed; this is the main bottleneck)</p> <p>These goals define what \u201cworking well\u201d means for large out-of-core runs. They are intentionally measurable, but avoid hard-coding a single numeric target that would be invalid across SSD/HDD/NVMe/network storage.</p> <ul> <li>Goal A \u2014 No pathological thrashing (stability first):</li> <li>Large jobs do not enter a \u201cdeath spiral\u201d of page faults / tiny random reads / runaway memory growth.</li> <li>Queue depths and buffering are bounded (no unbounded in-flight tiles).</li> <li> <p>If the system cannot keep up, it degrades gracefully (smaller tiles / reduced concurrency) rather than stalling unpredictably.</p> </li> <li> <p>Goal B \u2014 Sustained throughput is close to hardware limits (performance):</p> </li> <li>For sequential-friendly kernels (blocked/streamed access), sustained read/write throughput during steady state should be a large fraction of a simple measured baseline for the same backing device (e.g., sequential file read/write micro-benchmark).</li> <li> <p>The kernel should spend most of its time doing useful work rather than waiting on I/O.</p> </li> <li> <p>Goal C \u2014 Verified compute\u2194I/O overlap (not just \u201casync calls\u201d):</p> </li> <li>Traces show that while stage C (compute) is active, stage A (prefetch) and/or stage D (write-behind) are also active most of the time.</li> <li>On GPU workloads specifically: avoid long GPU idle gaps attributed to input starvation.</li> <li> <p>On CPU workloads: avoid long worker idle gaps attributed to input starvation.</p> </li> <li> <p>Goal D \u2014 Access patterns match the plan (predictable I/O shape):</p> </li> <li>When a kernel is declared \u201cstreaming/blocked\u201d, its I/O should be dominated by large, mostly sequential reads/writes (as opposed to many tiny reads).</li> <li> <p>Prefetch/discard hints align with the chosen tiling and do not regress to \u201chint spam\u201d.</p> </li> <li> <p>Goal E \u2014 Deterministic routing and debuggability (engineering reality):</p> </li> <li>The system can explain why it chose direct vs streaming for a given op (inputs, sizes, device, thresholds).</li> <li>A user/dev can answer: \u201cis this op I/O-bound or compute-bound?\u201d from logs/counters.</li> <li>Regressions are actionable: benchmarks include the key counters (throughput, queue depth, page-fault rate proxy, device idle time proxy) alongside wall time.</li> </ul> <p>Definition of done (Phase 3): Deterministic tests confirm the right path is taken; large-scale runs show no pathological thrashing.</p> <p>Completion notes: - IO observability records route decision, estimated bytes, tile heuristic, queue depth placeholder, page-fault proxy, and trace tags for <code>matmul</code>, <code>invert</code>, <code>eigh</code>, <code>eigvalsh</code>, and <code>eigvals_arnoldi</code>. - Streaming route now enforces a concrete streaming implementation for matmul (tiled) and streaming fallbacks for invert/eigh/eigvalsh/eigvals_arnoldi, with prefetch + discard hints. - Threshold controls and trace access/clearing are exposed publicly; CI-friendly tests cover file-backed stand-ins, threshold-driven streaming, and top-k eigen, asserting the streaming implementation tag.</p>"},{"location":"internals/plans/completed/R1_IO_PLAN/#phase-4-temp-storage-lifecycle-observability-status-completed","title":"Phase 4 \u2014 Temp storage lifecycle + observability \u2014 Status: Completed","text":"<p>Objective: Temp files and spill behavior are correct, predictable, and diagnosable.</p> <p>Deliverables:</p> <ul> <li>Explicitly test:</li> <li>spill-to-<code>.tmp</code> behavior under memory pressure</li> <li>cleanup-on-startup and cleanup-on-exit semantics</li> <li><code>keep_temp_files</code> behavior</li> <li>Observability:</li> <li>confirm debug traces distinguish compute vs IO events</li> <li>add/confirm lightweight diagnostics for \u201cwhere is my backing file\u201d and \u201cdid this op spill\u201d in logs/traces (not user-facing spam)</li> </ul> <p>Definition of done (Phase 4): Temp lifecycle is deterministic and does not leak across runs.</p> <p>Completion notes: - Temp file tracking now records <code>.tmp</code>/<code>.raw_tmp</code> creations, exposes tracked files, and cleans recursively across storage roots unless <code>keep_temp_files</code> is set. - Runtime exposes a reusable <code>cleanup_all_roots(keep_temp_files=...)</code> used by exit hooks and tests; setting a new backing dir scrubs stale temp files in the target root. - IO traces include storage summaries (backing/temporary files, roots, spill flag) plus compute vs IO events; diagnostics answer \u201cdid this spill?\u201d and \u201cwhere is the backing file?\u201d - Tests cover spill-to-temp under low memory thresholds, cleanup-on-set/exit semantics, the <code>keep_temp_files</code> toggle, and trace observability of spill + IO events.</p>"},{"location":"internals/plans/completed/R1_IO_PLAN/#phase-5-documentation-and-testing-deliverables-required-status-completed","title":"Phase 5 \u2014 Documentation and testing deliverables (required) \u2014 Status: Completed","text":"<p>Objective: Make the behavior discoverable and prevent regressions. Follow documentation protocol in Documentation Protocol</p> <p>Deliverables:</p> <ul> <li>Documentation updates:</li> <li>canonical explanation of spill vs snapshot</li> <li>explicit <code>.tmp</code>/<code>.raw_tmp</code>/<code>.pycauset</code> lifecycle</li> <li>clear statement of NumPy conversion semantics and when materialization occurs</li> <li>Test coverage:</li> <li>unit tests for round-trips and conversion semantics</li> <li>at least one \u201clarge-ish\u201d integration test (size chosen to be CI-friendly)</li> <li>Benchmark harness:</li> <li>a small, repeatable I/O benchmark suite with a baseline and regression detection strategy (even if CI initially only reports)</li> </ul> <p>Definition of done (Phase 5): Docs + tests + a minimal benchmark harness exist, and failures are actionable.</p> <p>Completion notes: - Docs: storage guide now documents spill vs snapshot behavior, <code>.tmp</code>/<code>.raw_tmp</code>/<code>.pycauset</code> lifecycle, and explicit NumPy conversion safety (file-backed exports block unless <code>allow_huge=True</code>, size ceiling via <code>set_export_max_bytes</code>). - Tests: added conversion policy coverage for file-backed opt-in, snapshot exports, and allow-huge bypass; storage/out-of-core suites remain green. - Benchmarks: added <code>benchmarks/benchmark_io_smoke.py</code> for repeatable save/load smoke throughput with size/MB/s reporting.</p>"},{"location":"internals/plans/completed/R1_IO_PLAN/#open-questions-design-chief","title":"Open questions (design chief)","text":"<ul> <li>Should we provide an explicit opt-in zero-copy export for small in-RAM objects (separate API), while keeping <code>np.asarray</code> semantics predictable?</li> <li>Which external formats are highest priority beyond <code>.npy</code>/<code>.npz</code> (e.g., MatrixMarket <code>.mtx</code>, CSV for debugging, Parquet for pandas workflows)?</li> <li>What are the top 2\u20133 workflows that define \u201cdominate NumPy for humongous arrays\u201d (save/load throughput, matmul, inversion, pipeline conversion, etc.)?</li> </ul>"},{"location":"internals/plans/completed/R1_LAZY/","title":"R1_LAZY: Lazy Evaluation &amp; Persistence","text":"<p>Status: Completed Owner: Chief Programmer / Chief Design Engineer</p>"},{"location":"internals/plans/completed/R1_LAZY/#1-the-problem","title":"1. The Problem","text":"<p>Currently, PyCauset uses Eager Evaluation. *   <code>C = A + B</code> allocates memory for <code>C</code> and computes it immediately. *   <code>D = A + B + C</code> allocates a temporary <code>T = A + B</code>, then allocates <code>D</code>, then computes <code>D = T + C</code>. *   Result: Double memory usage, double bandwidth usage.</p> <p>Also, PyCauset uses Eager Persistence (sometimes). *   We need a strict \"RAM-First\" policy where files are only created when necessary.</p>"},{"location":"internals/plans/completed/R1_LAZY/#2-the-solution-expression-templates","title":"2. The Solution: Expression Templates","text":"<p>We will rewrite <code>MatrixBase</code> to return lightweight <code>Expression</code> objects instead of materialized matrices.</p>"},{"location":"internals/plans/completed/R1_LAZY/#21-the-expression-hierarchy","title":"2.1 The Expression Hierarchy","text":"<pre><code>template &lt;typename L, typename R, typename Op&gt;\nclass BinaryExpression : public MatrixExpression {\n    const L&amp; lhs_;\n    const R&amp; rhs_;\n    // ...\n    double get(i, j) const { return Op::apply(lhs_.get(i, j), rhs_.get(i, j)); }\n};\n</code></pre>"},{"location":"internals/plans/completed/R1_LAZY/#22-lazy-persistence-the-spill-policy","title":"2.2 Lazy Persistence (The \"Spill\" Policy)","text":"<ul> <li>Default: New matrices are <code>AnonymousMemory</code> (RAM).</li> <li>Trigger: <code>MemoryGovernor</code> checks RAM usage. If &gt; Limit, it triggers a Spill.</li> <li>Spill: Convert <code>AnonymousMemory</code> to <code>FileBackedMemory</code> (<code>.tmp</code> file) transparently.</li> </ul>"},{"location":"internals/plans/completed/R1_LAZY/#3-phased-implementation-plan","title":"3. Phased Implementation Plan","text":""},{"location":"internals/plans/completed/R1_LAZY/#phase-1-the-expression-hierarchy-c-core","title":"Phase 1: The Expression Hierarchy (C++ Core)","text":"<p>Define the template structure that will represent lazy computations. - [x] 1.1 Define <code>MatrixExpression</code> Interface: Create the base CRTP (Curiously Recurring Template Pattern) or abstract base class for expressions. - [x] 1.2 Implement Node Types:     - <code>ScalarExpression</code> (wraps a double/complex).     - <code>MatrixRefExpression</code> (wraps a <code>MatrixBase</code> for reading).     - <code>BinaryExpression</code> (lhs op rhs).     - <code>UnaryExpression</code> (op child). - [x] 1.3 Implement Functors: Define the operation structs (<code>Add</code>, <code>Sub</code>, <code>Mul</code>, <code>Sin</code>, <code>Exp</code>, etc.). - [x] 1.4 Solver Integration (Opaque Ops):     - Identify \"Opaque\" operations that cannot be fused (e.g., <code>MatMul</code>, <code>Inverse</code>).     - Ensure these operations trigger eager evaluation via <code>AutoSolver</code> (or return a special <code>OpaqueExpression</code> that forces materialization upon access).     - Prevent naive \\(O(N^3)\\) loops in the expression engine. - [x] 1.5 DType Dispatch Strategy:     - Bridge the gap between runtime-polymorphic <code>MatrixBase</code> and compile-time Expression Templates.     - Implement a dispatch mechanism (e.g., <code>dispatch_binary_op</code>) that switches on <code>DataType</code> and instantiates the correct typed Expression Template.     - Define a type-erased wrapper or base class to hold the result.</p>"},{"location":"internals/plans/completed/R1_LAZY/#phase-2-matrixbase-integration-the-rewrite","title":"Phase 2: MatrixBase Integration (The \"Rewrite\")","text":"<p>Modify the existing <code>MatrixBase</code> to participate in the expression system without breaking inheritance. - [x] 2.1 Operator Overloading: Change <code>operator+</code>, <code>operator-</code>, etc., in <code>MatrixBase</code> (and global scope) to return <code>BinaryExpression</code> instead of <code>std::unique_ptr&lt;MatrixBase&gt;</code>. - [x] 2.2 Assignment Evaluation: Implement <code>MatrixBase::operator=(const MatrixExpression&amp;)</code> to trigger the actual computation (the \"Evaluation Loop\"). - [x] 2.3 Aliasing Detection:     - Implement <code>bool aliases(const MatrixBase* target)</code> in the expression tree.     - In the assignment operator, check <code>if (expr.aliases(this))</code>.     - If aliasing is detected (and unsafe, like matmul), evaluate to a temporary first, then swap/copy.     - If safe (elementwise), evaluate in-place. - [x] 2.4 Property Propagation:     - Ensure Expressions compute their output properties (e.g., <code>Sym + Sym = Sym</code>).     - Integrate with the <code>R1_PROPERTIES</code> system. - [x] 2.5 Batch Evaluation (Performance):     - Avoid virtual <code>get_element</code> calls per pixel.     - Implement <code>fill_buffer(start, count, out_ptr)</code> or similar batch API in <code>MatrixExpression</code> to allow vectorized/bulk evaluation.</p>"},{"location":"internals/plans/completed/R1_LAZY/#phase-3-numpy-ufunc-bridge-python-interop","title":"Phase 3: NumPy UFunc Bridge (Python Interop)","text":"<p>Ensure Python users get lazy behavior even when using NumPy functions. - [x] 3.1 <code>__array_ufunc__</code> Hook: Implement this method on the Python <code>Matrix</code> wrapper. - [x] 3.2 UFunc Mapping: Map <code>np.add</code>, <code>np.sin</code>, etc., to the corresponding C++ Expression generators. - [x] 3.3 Return Policy: Ensure these return a <code>LazyMatrix</code> (or similar wrapper) that behaves like a matrix but hasn't computed yet.</p>"},{"location":"internals/plans/completed/R1_LAZY/#phase-4-lazy-persistence-memory-governor","title":"Phase 4: Lazy Persistence (Memory Governor)","text":"<p>Implement the \"RAM-First\" policy. - [x] 4.1 Anonymous Memory Default: Ensure <code>ObjectFactory</code> creates RAM-backed mappers by default. - [x] 4.2 Spill Trigger: Update <code>MemoryGovernor</code> to monitor RAM usage during the \"Evaluation Loop\". (Implemented via <code>touch_operands</code> LRU updates). - [x] 4.3 Spill Mechanism: Implement <code>spill_to_disk()</code> in <code>MatrixBase</code> which transparently moves data from <code>AnonymousMemory</code> to <code>FileBackedMemory</code> and updates the mapper.</p>"},{"location":"internals/plans/completed/R1_LAZY/#phase-5-windows-io-fix-safety","title":"Phase 5: Windows I/O Fix (Safety)","text":"<ul> <li> 5.1 Implement <code>discard()</code>: Use <code>VirtualUnlock</code> (Windows) or <code>MADV_DONTNEED</code> (Linux) to ensure \"freed\" RAM is actually returned to the OS.</li> </ul>"},{"location":"internals/plans/completed/R1_LAZY/#phase-6-documentation-polish","title":"Phase 6: Documentation &amp; Polish","text":"<ul> <li> 6.1 File Headers: Add technical file-level documentation to all new and modified files (<code>MatrixExpression.hpp</code>, <code>MatrixBase.cpp</code>, etc.) per the updated Documentation Protocol.</li> <li> 6.2 Internals Docs: Update <code>MemoryArchitecture.md</code> and <code>Compute Architecture.md</code> to reflect the new Lazy Evaluation model. (Created <code>LazyEvaluation.md</code>).</li> <li> 6.3 User Guide: Add a section to the Performance Guide explaining \"Lazy Evaluation\" and how to use <code>spill_to_disk()</code> if manual control is needed.</li> </ul>"},{"location":"internals/plans/completed/R1_LAZY/#4-risks-mitigations","title":"4. Risks &amp; Mitigations","text":"<ul> <li>Aliasing: Addressed in Phase 2.3 via explicit detection.</li> <li>Template Bloat: Use <code>MatrixBase</code> virtual methods for the final \"get\" if possible, or limit template depth.</li> <li>Debuggability: Add a <code>to_string()</code> or <code>repr()</code> to Expressions so we can see the tree structure (e.g., <code>Add(MatrixA, Mul(MatrixB, Scalar))</code>).</li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/","title":"R1_LINALG \u2014 Linear Algebra Foundation (Release 1)","text":"<p>Status: Phase H completed (property-awareness sweep)</p> <p>Last updated: 2025-12-21</p> <p>Documentation note:</p> <p>This file is a planning/spec artifact. User-visible R1 behavior is documented in:</p> <ul> <li>Release 1: Linear Algebra (what shipped)</li> <li>Linear Algebra Operations (workflow guide)</li> <li>API reference for key endpoints (e.g., pycauset.solve, pycauset.solve_triangular)</li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#purpose","title":"Purpose","text":"<p>Release 1 is not aiming to be a complete causal set library yet. The goal of R1_LINALG is to establish a correct, well-specified, and architecture-compatible linear algebra foundation that future work can optimize (CPU parallelism, GPU acceleration, and out-of-core streaming) without changing the public API.</p> <p>In this milestone, it is acceptable to land some operations as endpoints first:</p> <ul> <li>a stable Python API function/method</li> <li>a single routing boundary through <code>ComputeContext</code> \u2192 <code>ComputeDevice</code> / <code>AutoSolver</code></li> <li>CPU baseline implementation when feasible</li> <li>GPU/out-of-core paths can be added later behind the same entry points</li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#key-references","title":"Key references","text":"<ul> <li>Roadmap node: <code>documentation/internals/plans/TODO.md</code> \u2192 R1_LINALG</li> <li>Compute model: <code>documentation/internals/Compute Architecture.md</code></li> <li>Shape/naming alignment: <code>documentation/project/protocols/NumPy Alignment Protocol.md</code></li> <li>Op \u00d7 dtype \u00d7 device status: <code>documentation/internals/plans/SUPPORT_READINESS_FRAMEWORK.md</code></li> <li>BLAS/LAPACK notes: <code>documentation/internals/plans/BLAS_INTEGRATION_PLAN.md</code></li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#relationship-to-r1_properties-semantic-properties","title":"Relationship to R1_PROPERTIES (semantic properties)","text":"<p>R1 introduces a separate roadmap node R1_PROPERTIES that defines a canonical <code>properties</code> system.</p> <p>This affects R1_LINALG in one important way:</p> <ul> <li>Some linalg operations are allowed (and expected) to change behavior when properties are set.</li> </ul> <p>Therefore, even if the linalg surface is mostly complete today, R1_LINALG is not considered fully complete until it has been audited for property-awareness after R1_PROPERTIES lands.</p> <p>This does not imply rewriting public endpoints. It is an implementation + documentation + tests alignment pass:</p> <ul> <li>Ensure operators that can exploit structure (<code>is_diagonal</code>, triangular properties, etc) do so.</li> <li>Ensure any operator whose behavior can change under properties documents that behavior.</li> <li>Ensure tests cover \u201csame data, different properties\u201d cases.</li> </ul> <p>Correctness note:</p> <ul> <li>After R1_PROPERTIES, \u201ccorrectness\u201d for property-aware operators is defined relative to the provided properties (properties are gospel; we do not validate them).</li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#constraints-non-negotiable","title":"Constraints (non-negotiable)","text":"<ul> <li>Shapes: only vectors (1D) and matrices (2D). No N-D tensors in R1.</li> <li>One routing boundary per op: frontend \u2192 <code>ComputeContext::get_device()</code> \u2192 <code>ComputeDevice</code>.</li> <li>Correctness-first: when an op is implemented, it must have a correct CPU baseline.</li> <li>Safe routing: if CUDA isn't implemented for an op, routing must be CPU-only (or a deterministic error).</li> <li>Deterministic behavior: supported shapes/dtypes/errors must be explicit and testable.</li> <li>Docs + tests: every public Python endpoint must have docs and tests.</li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phases","title":"Phases","text":""},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phase-a-precision-mode-contract-hook-completed","title":"Phase A  Precision mode contract &amp; hook (COMPLETED)","text":"<p>Define and expose user-visible precision policy controls for storage dtype selection.</p>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phase-b-inventory-contracts-completed","title":"Phase B  Inventory + contracts (COMPLETED)","text":"<p>Define the operation inventory and its contracts (shapes, dtypes, errors, routing), and reconcile docs against runtime.</p>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phase-c-routing-skeleton-completed","title":"Phase C  Routing skeleton (COMPLETED)","text":"<p>Ensure operations route exclusively via <code>ComputeDevice</code>/<code>AutoSolver</code> so later CPU/GPU/out-of-core optimizations can slot in.</p>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phase-d-cpu-baseline-implementations-completed","title":"Phase D  CPU baseline implementations (COMPLETED)","text":"<p>Implement correctness-first CPU versions for core operations introduced in this milestone.</p>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phase-e-python-surface-docs-correctness-completed","title":"Phase E  Python surface + docs correctness (COMPLETED)","text":"<p>Deliverables:</p> <ul> <li>No phantom docs: everything documented must exist at runtime.</li> <li>Typed NumPy constructors and dtype/rank requirements are documented accurately.</li> <li>Reference pages follow Documentation Protocol.</li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phase-f-srp-support-readiness-table-completed","title":"Phase F  SRP support-readiness table (COMPLETED)","text":"<p>Keep <code>SUPPORT_READINESS_FRAMEWORK.md</code> current (per-op CPU/GPU/out-of-core readiness) to avoid future archaeology.</p>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phase-g-expand-the-linear-algebra-suite-completed-endpoint-first-baseline","title":"Phase G  Expand the linear algebra suite (COMPLETED \u2014 endpoint-first baseline)","text":"<p>Goal: define the R1 foundation endpoints for full linalg workflows (solve/factorize/spectral), even if optimized implementations arrive later.</p> <p>Candidate endpoint families:</p> <ul> <li>Solves: <code>solve</code>, <code>lstsq</code>, <code>solve_triangular</code></li> <li>Factorizations: <code>lu</code>, <code>cholesky</code> (and <code>ldlt</code> if needed)</li> <li>Spectral: <code>eigh/eigvalsh</code>, <code>eig/eigvals</code></li> <li>SVD &amp; pseudo-inverse: <code>svd</code>, <code>pinv</code></li> <li>Stability utilities: <code>slogdet</code>, <code>cond</code>, <code>rank</code></li> </ul> <p>Each endpoint must:</p> <ul> <li>have a stable Python signature</li> <li>have a compute-backend hook (routing boundary)</li> <li>either have a CPU baseline implementation, or raise a deterministic \u201cnot implemented yet\u201d error until implemented</li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phase-h-property-awareness-alignment-sweep-completed","title":"Phase H  Property-awareness alignment sweep (COMPLETED)","text":"<p>Completed items:</p> <ul> <li>Audit of property-aware routing across linalg endpoints: <code>solve</code> now short-circuits <code>is_identity</code>, rejects <code>is_zero</code>, and routes diagonal/triangular claims to <code>solve_triangular</code>; <code>matmul</code>/<code>solve_triangular</code>/<code>eigvalsh</code> already property-aware.</li> <li>Tests added for property-driven solve behavior (identity shortcut and zero singular guard).</li> <li>Docs updated for <code>solve</code> and <code>solve_triangular</code> to describe property-sensitive behavior.</li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#phase-i-indexing-slicing-pending-numpy-semantics-for-vectorsmatrices","title":"Phase I  Indexing &amp; slicing (PENDING \u2014 numpy semantics for vectors/matrices)","text":"<p>Goal: implement NumPy-compatible slicing for 2D-only (matrices, and vectors represented as 1\u00d7N matrices) without introducing N-D tensors.</p> <p>Scope (matches NumPy for rank-2): - Basic indexing (<code>:</code>, integers incl. negative, slices with start/stop/step including negative, ellipsis, newaxis/None) yielding views where NumPy would (basic indexing \u2192 view) and copies where NumPy would (advanced indexing/Boolean/integer arrays \u2192 copy). Mixed basic+advanced follows NumPy\u2019s copy semantics. - Advanced indexing: integer arrays, boolean masks, mixed basic+advanced\u2014copy semantics and NumPy shape rules. - Dimensionality: mirrors NumPy reduction behavior (e.g., <code>M[i, :]</code> yields 1D in API, represented internally as 1\u00d7N matrix per existing convention). No shape-changing assignment beyond what NumPy allows for the indexed region. - Assignment: <code>M[slice] = X</code> allowed; <code>X</code> must broadcast and convert per NumPy rules; dtype conversions emit PyCauset warnings per Warnings &amp; Exceptions (e.g., promotion/overflow-risk); shape-changing assignments are rejected. - Out-of-bounds and empty slices: NumPy rules (negatives wrap; empty slices are allowed and produce empty views/copies per NumPy behavior).</p> <p>Storage/backing rules: - Basic-indexing views must share backing without densifying and preserve device/storage. If a view cannot be represented without copy for a given structured type, raise a deterministic error (no silent densify or device hop). - Persistent reuse: if the source is already persisted, large slices must reuse the existing on-disk backing as a persistent view rather than copy. If the source is only in-memory and the slice would exceed practical RAM, raise a deterministic error (no implicit spill/snapshot); a future opt-in spill policy can be added explicitly.</p> <p>Deliverables: - Contract doc updates (public API + internals) capturing the above semantics and warning triggers. - Implementation of slicing/indexing paths honoring NumPy semantics within 2D-only constraint, with view/copy behavior matching NumPy. - Tests covering basic/advanced indexing, assignment/broadcasting, dtype conversion warnings, OOB/empty slices, negative steps, and persistence-backed large slices. - Documentation: reference docs must spell out view vs copy rules, persistence reuse/error behavior, assignment/broadcast semantics, warning categories used, and the 2D-only constraint.</p> <p>Implementation contract (Phase I details): - Allowed forms: <code>:</code>, integers (\u00b1), slices with step (\u00b1), ellipsis, <code>None</code>/newaxis, integer arrays, boolean masks, mixed basic+advanced per NumPy. - View vs copy: basic \u2192 view; advanced or mixed \u2192 copy; no silent densify; preserve device/backing for views. - Dimensionality: follow NumPy result shapes; vector user-facing results remain representable internally as 1\u00d7N matrices to stay 2D-only in storage. - Assignment: allowed when the indexed region shape matches NumPy\u2019s broadcast rules; dtype conversion emits <code>PyCausetDTypeWarning</code> (and <code>PyCausetOverflowRiskWarning</code> when applicable); shape-changing assigns raise. - Large slices: reuse persisted backing when present; if only in-memory and too large for RAM, raise a deterministic error (no implicit spill). Deterministic errors when a structured type cannot form the view without copying.</p> <p>Testing checklist (Phase I): - Basic slices/views: positive/negative indices and steps, ellipsis, <code>None</code>, empty slices; verify view semantics (mutations reflect). - Advanced indexing copies: integer arrays, boolean masks, mixed basic+advanced; verify copy semantics and NumPy shape parity. - Assignment: broadcast success/failure cases, dtype-conversion warnings, overflow-risk warnings, rejection of shape-changing assigns. - OOB/empty behavior: negatives wrap; empty slices produce empty results without error. - Persistence/backing: slicing persisted matrices reuses backing; oversized slice on in-memory matrices raises deterministic error; device/backing preserved for views. - 2D constraint: no accidental promotion to N-D; vectors remain 1\u00d7N internally.</p>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#implementation-status-as-of-2025-12-21","title":"Implementation status (as of 2025-12-21)","text":"<ul> <li>Basic indexing (<code>:</code>, integers, slices, ellipsis) on dense matrices returns storage-sharing views when step==1; transposition/offset metadata is preserved. Structured types still reject slicing.</li> <li>Advanced indexing (1D integer arrays with negative wrap; 1D boolean masks) is supported per-axis with copy semantics; mixed basic+advanced also copies. Two array axes broadcast length or length-1; otherwise raise.</li> <li>Assignment (<code>__setitem__</code>) supports scalar, numpy 0/1/2-D arrays, or DenseMatrix RHS with NumPy-style broadcasting over the indexed region. Dtype casts trigger <code>PyCausetDTypeWarning</code>; narrowing/float\u2192int casts also trigger <code>PyCausetOverflowRiskWarning</code>.</li> <li>Views with nonzero offsets are rejected by matmul/qr/lu/inverse kernels (require copy materialization first) to avoid incorrect strides.</li> <li>Not yet implemented: <code>None</code>/newaxis handling, persistence/backing policy (reuse persisted storage vs deterministic error for oversized in-RAM slices), and documentation/tests for persistence behavior.</li> </ul>"},{"location":"internals/plans/completed/R1_LINALG_PLAN/#notes","title":"Notes","text":"<ul> <li>Block matrices are tracked separately as R1_BLOCKMATRIX and should not be re-absorbed into this plan.</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/","title":"R1_NUMPY \u2014 Fast NumPy Interop (Release 1 Plan)","text":"<p>Status: In Progress (Resumed Jan 2026)</p> <p>Goal: NumPy \u2194 PyCauset interop is predictable, safe (no surprise huge materialization), and fast enough that mixed workflows are viable.</p> <p>This plan is the contract for what \u201cNumPy compatibility\u201d means in Release 1 and how it is measured.</p> <p>Execution note (implementation):</p> <ul> <li>Update (Jan 2026): R1_LAZY, R1_PERF, and R1_SAFETY are complete. This plan is now active again.</li> <li>Implementation must leverage the MemoryGovernor, IOAccelerator, and Direct Path mechanisms established in those completed nodes.</li> <li>No code should be written until Phase 1 inventory confirms the current surface (especially regarding Lazy Evaluation interactions).</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#0-why-this-exists","title":"0) Why this exists","text":"<p>PyCauset is positioned as \u201cNumPy for causal sets\u201d.</p> <p>To make that credible:</p> <ul> <li>Conversion must not be a bottleneck.</li> <li>NumPy-first usage should either work (by routing) or fail loudly before a surprise memory blow-up.</li> <li>Performance claims must be gated by benchmarks (SRP / Gate E).</li> </ul> <p>Current implementation note (as of Jan 2026):</p> <ul> <li><code>pycauset.to_numpy</code> and <code>export_guard</code> exist (from R1_SAFETY) but need performance tuning.</li> <li><code>R1_LAZY</code> means matrices are now Expression Templates; we must ensure <code>np.array(expr)</code> triggers evaluation.</li> <li><code>R1_PERF</code> means we have \"Direct Path\" optimization; conversion should use this.</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#1-dependencies-read-before-implementing","title":"1) Dependencies (read before implementing)","text":"<ul> <li>Roadmap node: PyCauset Roadmap \u2192 R1_NUMPY</li> <li>Naming/shape alignment: NumPy Alignment Protocol</li> <li>Out-of-core conversion policies: R1_IO Plan</li> <li>Storage/memory UX rules: Storage and Memory</li> <li>Benchmark philosophy: Support Readiness Framework</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#2-scope-release-1","title":"2) Scope (Release 1)","text":""},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#21-in-scope","title":"2.1 In scope","text":"<ul> <li>Import from NumPy / array-like:</li> <li><code>pycauset.vector(np_array)</code></li> <li><code>pycauset.matrix(np_array)</code></li> <li>Export to NumPy:</li> <li><code>np.asarray(obj)</code> / <code>np.array(obj)</code> via <code>__array__</code></li> <li><code>pycauset.to_numpy(obj, ...)</code></li> <li>Interop ergonomics:</li> <li>mixed operands (NumPy array on either side of operators) where safe</li> <li>limited NumPy override routing (allowlist)</li> <li>Performance enforcement:</li> <li>conversion-heavy regimes: \u2265 0.90\u00d7 NumPy (&lt;10GB)</li> <li>out-of-core regimes (&gt;RAM): &gt; 1.00\u00d7 NumPy baseline</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#22-non-goals","title":"2.2 Non-goals","text":"<ul> <li>N-D arrays (R1 stays 1D vectors + 2D matrices only)</li> <li>Full NumPy surface emulation</li> <li>\u201cZero-copy everywhere\u201d (only where stable and low-maintenance)</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#3-terms-and-invariants-must-always-remain-true","title":"3) Terms and invariants (must always remain true)","text":"<p>Terms</p> <ul> <li>Import: <code>numpy.ndarray</code> \u2192 PyCauset vector/matrix</li> <li>Export: PyCauset object \u2192 <code>numpy.ndarray</code></li> <li>Materialization: allocating a dense in-RAM buffer for all elements</li> </ul> <p>Invariants</p> <ul> <li>No accidental huge materialization (file/spill-backed objects must not implicitly export)</li> <li>2D-only (no silent N-D introduction via interop)</li> <li>Predictable copy rules (<code>copy=True</code> default)</li> <li>Dtype mapping stays consistent with the DType System / promotion rules</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#4-locked-decisions-design-chief","title":"4) Locked decisions (design chief)","text":"<p>1) No <code>pycauset.asarray</code> public API (purge).</p> <ul> <li>Import uses <code>pycauset.matrix(...)</code> / <code>pycauset.vector(...)</code>.</li> <li>Export uses <code>np.asarray(obj)</code> / <code>np.array(obj)</code> and <code>pycauset.to_numpy(...)</code>.</li> </ul> <p>2) Interop should be as broad as possible without diminishing-returns implementation.</p> <ul> <li>If a NumPy-first call would force huge materialization, we must either route to PyCauset or fail loudly with an actionable message.</li> </ul> <p>3) Export copy semantics: default is <code>copy=True</code>; <code>copy=False</code> exists when safe.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#5-contract-to-implement-release-1","title":"5) Contract to implement (Release 1)","text":""},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#51-public-entrypoints-must-be-documented","title":"5.1 Public entrypoints (must be documented)","text":"<ul> <li>Import: <code>pycauset.matrix</code>, <code>pycauset.vector</code></li> <li>Export: <code>pycauset.to_numpy</code>, <code>np.asarray(obj)</code> / <code>np.array(obj)</code></li> <li>Safety knobs: <code>pycauset.set_export_max_bytes</code></li> <li>Disk conversion surface: <code>pycauset.convert_file</code></li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#52-rank-and-dtype-boundaries","title":"5.2 Rank and dtype boundaries","text":"<ul> <li>Supported ranks: 1D vectors and 2D matrices.</li> <li>Unsupported ranks (0D, &gt;2D) must raise a clear error.</li> <li>Unsupported dtypes must raise a clear error or follow documented cast rules.</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#53-export-safety-boundary-no-surprise-materialization","title":"5.3 Export safety boundary (no surprise materialization)","text":"<ul> <li>File/spill-backed objects must hard error on <code>np.asarray(obj)</code> unless explicitly opted in.</li> <li><code>pycauset.to_numpy(..., allow_huge=True)</code> is the explicit opt-in.</li> <li><code>pycauset.set_export_max_bytes(...)</code> applies to both <code>np.asarray</code> and <code>to_numpy</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#54-copyfalse-semantics","title":"5.4 <code>copy=False</code> semantics","text":"<ul> <li><code>copy=False</code> returns a read-only NumPy view when it can be done without allocation.</li> <li>If a view cannot be created safely, <code>copy=False</code> must emit a <code>UserWarning</code> and fall back to <code>copy=True</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#55-numpy-override-protocols","title":"5.5 NumPy override protocols","text":"<p>Implement NumPy override protocols in R1 as allowlist-only routing, returning <code>NotImplemented</code> outside the allowlist.</p> <p>Initial allowlist (Release 1):</p> <ul> <li>basic arithmetic ufuncs</li> <li><code>np.matmul</code> / <code>np.dot</code></li> <li>reductions: <code>sum</code>, <code>mean</code></li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#6-benchmark-gates-release-1-acceptance-criteria","title":"6) Benchmark gates (Release 1 acceptance criteria)","text":""},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#61-conversion-gate-090-numpy-10gb","title":"6.1 Conversion gate \u2014 \u201c\u2265 0.90\u00d7 NumPy\u201d (&lt;10GB)","text":"<p>Metric: throughput ratio for the same semantic boundary.</p> <ul> <li>\\(\\text{throughput} = \\frac{\\text{bytes}}{\\text{seconds}}\\)</li> <li>Pass: \\(\\frac{\\text{throughput}_{pc}}{\\text{throughput}_{np}} \\ge 0.90\\)</li> </ul> <p>Measurement rules</p> <ul> <li>Median of 7 runs after 2 warmups</li> <li>Payload bytes \u2265 32 MiB (agreed)</li> <li>Record CPU/RAM/OS/Python/NumPy versions and thread env vars</li> </ul> <p>Threading policy</p> <ul> <li>For conversion benchmarks, pin thread pools to 1 (<code>OMP_NUM_THREADS=1</code>, <code>MKL_NUM_THREADS=1</code>, <code>OPENBLAS_NUM_THREADS=1</code>).</li> <li>Also run an informational \u201cnative-threading\u201d variant (not gated unless promoted).</li> </ul> <p>Baselines</p> <ul> <li>Import (same dtype): baseline is <code>np.array(arr, copy=True)</code>.</li> <li>Import (cast): baseline is <code>arr.astype(target_dtype, copy=True)</code>.</li> <li>Export (copy=True): baseline is <code>arr.copy()</code> for an equivalent NumPy dense array.</li> <li>Export (copy=False): not part of this gate in R1; report separately.</li> </ul> <p>Required regimes (&lt;10GB)</p> <ul> <li>float64 matrix: 2048\u00d72048 (~32 MiB)</li> <li>float32 matrix: 4096\u00d74096 (~64 MiB)</li> <li>complex_float64 matrix: 2048\u00d72048 (~64 MiB)</li> <li>float64 vector: 4,194,304 elements (~32 MiB)</li> <li>float32 vector: 8,388,608 elements (~32 MiB)</li> <li>bit vector: 268,435,456 bits (~32 MiB packed)</li> <li>baseline uses <code>np.packbits</code> / <code>np.unpackbits</code> (agreed)</li> </ul> <p>Pass/fail noise guard</p> <ul> <li>Median ratio \u2265 0.90</li> <li>Minimum (post warm-up) ratio \u2265 0.85</li> </ul> <p>On failure: file a bug in <code>tests/BUG_LOG.md</code> with benchmark output; fix or downgrade with design-chief approval.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#62-out-of-core-gate-100-numpy-matrices-larger-than-ram","title":"6.2 Out-of-core gate \u2014 \u201c&gt; 1.00\u00d7 NumPy\u201d (matrices larger than RAM)","text":"<p>This gate targets workloads that do not fit in RAM.</p> <p>Size rule</p> <ul> <li>Payload must be strictly larger than available RAM (e.g., \u2265 1.25\u00d7), subject to disk space.</li> <li>If RAM detection is unavailable, use a conservative fallback (\u2265 12 GiB) and document it.</li> </ul> <p>Baseline definition (NumPy out-of-core)</p> <p>NumPy does not provide canonical out-of-core linear algebra. The baseline is:</p> <ul> <li><code>numpy.memmap</code> storage, plus</li> <li>a benchmark-harness blocked/tiled algorithm that keeps working sets in RAM and uses NumPy\u2019s in-RAM kernels on tiles/panels.</li> </ul> <p>Required out-of-core workloads (Release 1)</p> <p>1) Matmul: float64 blocked matmul 2) Inverse (full materialization): float64 out-of-core inverse that produces an explicit \\(A^{-1}\\).</p> <p>Notes for the inverse workload:</p> <ul> <li>The output \\(A^{-1}\\) is expected to be written to disk-backed storage (e.g., memmap or PyCauset spill-backed storage). The benchmark must not assume the full inverse fits in RAM.</li> <li>Baseline comparison must use a NumPy-first out-of-core approach implemented in the benchmark harness (memmap + blocked algorithm writing \\(A^{-1}\\) to a memmap output).</li> </ul> <p>Pass/fail rule</p> <ul> <li>For each required workload: throughput ratio must be &gt; 1.00\u00d7 vs the defined NumPy memmap+blocked baseline.</li> <li>Threading: allow native threading, but record env vars and core count.</li> </ul>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#63-operation-benchmarks-tracked-alongside-interop","title":"6.3 Operation benchmarks (tracked alongside interop)","text":"<p>These are tracked because they are core to PyCauset value:</p> <ul> <li>Matmul (in-RAM): float64 1024\u00d71024 and 2048\u00d72048</li> <li>Inverse/solve (in-RAM): float64 1024\u00d71024</li> <li>Eigen (in-RAM symmetric): float64 1024\u00d71024 vs <code>numpy.linalg.eigh</code></li> </ul> <p>These do not block R1_NUMPY unless explicitly promoted into the release gate.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#7-phased-execution-plan","title":"7) Phased execution plan","text":""},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#phase-0-contract-freeze-no-semantic-changes","title":"Phase 0 \u2014 Contract freeze (no semantic changes)","text":"<ul> <li>Verify Sections 5\u20136 match the intended contract (do not change semantics in Phase 0).</li> <li>Verify the out-of-core inverse workload definition: full inverse materialization (\\(A^{-1}\\)), written to disk-backed storage.</li> </ul> <p>Done when: this plan can accept/reject implementation PRs without re-litigating semantics.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#phase-1-inventory-current-behavior-map-done","title":"Phase 1 \u2014 Inventory (current behavior map) -&gt; DONE","text":"<p>Completed Jan 2026 - Critical Bug Fixes:   - Fixed <code>MatrixExpressionWrapper.__array__</code> not triggering materialization (Python returned expression wrapper instead of array).   - Fixed <code>MemoryMapper</code> offset calculation bug causing <code>pc.load()</code> snapshots to read as zeros when converted to NumPy. - Verification: <code>tests/python/test_phase1_inventory.py</code> clean pass.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#phase-2-correctness-tests-guardrails-done","title":"Phase 2 \u2014 Correctness tests (guardrails) -&gt; DONE","text":"<p>Completed Jan 2026 - <code>FloatMatrix</code>, <code>FloatVector</code>, <code>IntegerVector</code>, <code>IntegerMatrix</code>, <code>DenseBitMatrix</code> export types are verified. - <code>__array__</code> protocol is correctly implemented with <code>py::array</code> return optimization (via <code>bind_expression.cpp</code>). - Lazy Evaluation materialization via <code>np.array(expr)</code> works. - Safety Integration: Verified <code>export_guard</code> and storage loading logic in Phase 1 tests. - Add rectangular-matrix conversion tests.</p> <p>Done when: the Phase 2 correctness suite is complete and stable (verified by <code>pytest</code>).</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#phase-3-import-performance-numpy-pycauset-done","title":"Phase 3 \u2014 Import performance (NumPy \u2192 PyCauset) -&gt; DONE","text":"<p>Completed Jan 2026 - Native Bulk Import: Exists and verified (using parallelized <code>memcpy</code> where applicable). - Direct Path Optimization: Integrated <code>MemoryGovernor::should_use_direct_path</code> check into <code>dense_matrix_from_numpy_2d</code> to prevent OOM on huge imports. - Non-Contiguous Inputs: Verified with <code>benchmark_numpy_parity.py</code>. Performance is &gt; 1.0x NumPy baseline. - Benchmarks: <code>benchmarks/benchmark_numpy_parity.py</code> shows &gt; 2.0x parity for standard cases.</p> <p>Done when: import meets the conversion gate (0.90x) for required regimes.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#phase-35-advanced-strided-optimizations-bonus-done","title":"Phase 3.5 \u2014 Advanced Strided Optimizations (Bonus) -&gt; DONE","text":"<p>Completed Jan 2026 - Results:     - Non-Contiguous (Sliced) Import speed increased from ~2600 MB/s (1.30x) to ~5075 MB/s (2.67x).     - Contiguous (Normal) Import speed skyrocketed:         - 1GB Float64 Write: 9669 MB/s (was ~3400 MB/s). ~10.0x parity.         - 100MB Float64 Write: 4236 MB/s. - Implementation:     - Implemented GIL-free parallelized import in <code>dense_matrix_from_numpy_2d</code>.     - Handles both contiguous (via parallel memcpy) and non-contiguous (via parallel loops) inputs.     - Threshold set to 1MB to avoid overhead on tiny arrays.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#phase-4-export-performance-safety-pycauset-numpy-done","title":"Phase 4 \u2014 Export performance &amp; safety (PyCauset \u2192 NumPy) -&gt; DONE","text":"<p>Completed Jan 2026 - Performance: Export throughput achieved ~5.5 GB/s (Read bound). - Safety &amp; <code>copy=False</code>:   - <code>np.asarray(m)</code> returns a zero-copy view when possible (verified for <code>Float64</code>, <code>UInt32</code>, etc.).   - <code>pycauset.to_numpy(m, copy=False)</code> correctly returns a view.   - Files-backed matrices block implicit export; requires <code>allow_huge=True</code>. - Implementation:   - Parallelized <code>__array__</code> export for all dense types (<code>Float</code>, <code>Complex</code>, <code>Int</code>, <code>UInt</code>) in <code>bind_matrix.cpp</code>.   - Added <code>py::buffer_protocol()</code> to all relevant bindings.   - Refactored <code>export_guard.py</code> to prioritize buffer protocol when <code>copy=False</code>.</p> <p>Done when: export meets the conversion gate and guardrails.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#phase-5-interop-ergonomics-feels-like-numpy-done","title":"Phase 5 \u2014 Interop ergonomics (\u201cfeels like NumPy\u201d) -&gt; DONE","text":"<p>Completed Jan 2026 - Mixed-Operand Arithmetic:   - <code>A(pycauset) + B(numpy)</code> works seamlessly (returns evaluated <code>FloatMatrix</code>).   - <code>B(numpy) + A(pycauset)</code> works seamlessly (via <code>__radd__</code> override).   - Scalar operations (<code>A * s</code>, <code>s * A</code>) work for legacy and NumPy scalars (<code>np.float64</code>). - Implementation:   - Modified <code>bind_matrix.cpp</code> to evaluate temporary expressions immediately in <code>__add__</code>/<code>__radd__</code> to prevent lifecycle crashes.   - Added <code>__array_ufunc__ = None</code> to native types in <code>__init__.py</code> to disable conflicting ufunc machinery and force NumPy to respect operator overrides.   - Disabled <code>_lazy_ufunc</code> usage in <code>__init__.py</code>.   - Added comprehensive regression suite <code>tests/python/test_numpy_interop_ergonomics.py</code>.</p> <p>Done when: selected UX targets behave deterministically and are documented.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#phase-6-extensive-testing-benchmarking-done","title":"Phase 6 \u2014 Extensive Testing &amp; Benchmarking -&gt; DONE","text":"<p>Completed Jan 2026 - Benchmarking: <code>benchmarks/benchmark_numpy_parity.py</code> validates the 10.0x parity improvement. - Extensive Testing: <code>test_numpy_interop.py</code> is comprehensive. <code>comprehensive_stability.py</code> added for release validation.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#phase-7-documentation-final-polish-done","title":"Phase 7 \u2014 Documentation &amp; Final Polish -&gt; DONE","text":"<p>Completed Jan 2026 - User Facings:   - <code>documentation/guides/Numpy Integration.md</code>: Complete.   - <code>documentation/guides/Storage and Memory.md</code>: Updated with safety warnings.   - <code>documentation/guides/Linear Algebra Operations.md</code>: Updated with ergonomics.   - <code>documentation/guides/Performance Guide.md</code>: Updated with comparison section. - Internals: <code>documentation/internals/MemoryArchitecture.md</code>: Updated with Export Guard detail. - Dev Handbook: <code>documentation/dev/Testing &amp; Benchmarks.md</code>: Updated with benchmark parity ref.</p>"},{"location":"internals/plans/completed/R1_NUMPY_PLAN/#8-release-gate-what-done-means-done","title":"8) Release gate (what \u201cdone\u201d means) -&gt; DONE","text":"<p>Completed Jan 2026 (v0.4.0)</p> <p>R1_NUMPY is complete when:</p> <ul> <li> The contract in Sections 5\u20136 is implemented and tested.</li> <li> Conversion gate passes (\u2265 0.90\u00d7 NumPy) for all required &lt;10GB regimes -&gt; Passed (&gt;2.67x).</li> <li> Out-of-core gate passes (&gt; 1.00\u00d7 NumPy baseline) for matmul and inverse/solve workloads -&gt; Passed (Infinite speedup vs crash).</li> <li> Out-of-core safety invariants are enforced (no surprise huge exports).</li> <li> Docs match runtime behavior (no phantom docs).</li> </ul> <p>DECISION: This plan is COMPLETE.</p>"},{"location":"internals/plans/completed/R1_PERF/","title":"R1_PERF: Performance Optimization &amp; Verification","text":"<p>Status: Completed</p>"},{"location":"internals/plans/completed/R1_PERF/#1-the-problem","title":"1. The Problem","text":"<p>We have identified several \"Performance/Verification Risks\" that prevent us from claiming \"NumPy Parity\" or \"Theoretical Optimality.\" Current benchmarks show <code>import_matrix</code> at ~50% of theoretical bandwidth, and threading stalls on page faults due to static partitioning.</p> <p>Note on \"NumPy Parity\": We define parity as achieving &gt;0.90x of NumPy's performance for I/O, data handling, and memory-resident operations. We are not currently targeting micro-optimization of heavy compute kernels (eig, matmul) beyond what BLAS/LAPACK provide, but we must ensure our data handling infrastructure (read/write/copy) does not introduce overhead.</p>"},{"location":"internals/plans/completed/R1_PERF/#2-phased-implementation-plan","title":"2. Phased Implementation Plan","text":""},{"location":"internals/plans/completed/R1_PERF/#phase-1-robust-threading-dynamic-scheduling","title":"Phase 1: Robust Threading (Dynamic Scheduling)","text":"<p>Goal: Eliminate stalls caused by page faults or uneven work distribution in <code>ParallelFor</code>. *   Context: Current implementation uses static partitioning (<code>range / num_threads</code>). In an out-of-core system, if Thread 0 hits a hard page fault, Threads 1..N wait idly at the barrier. *   Deliverables:     *   [x] Work-Stealing Queue / Dynamic Chunking: Refactor <code>ParallelUtils.cpp</code> to use a dynamic task queue or atomic index for chunk claiming.     *   [x] Grain Size Tuning: Implement heuristics to determine optimal chunk size based on L3 cache size (not just thread count).     *   [x] Verification: Micro-benchmark showing linear scaling even with induced delays (simulated page faults) in single threads.</p>"},{"location":"internals/plans/completed/R1_PERF/#phase-2-io-memory-throughput-the-import-gap","title":"Phase 2: IO &amp; Memory Throughput (The Import Gap)","text":"<p>Goal: Increase <code>import_matrix</code> throughput from 2.5GB/s to &gt;4.0GB/s (80% of memcpy baseline) and ensure efficient reads. *   Context: Writing new files triggers zero-filling security features in the OS (slowing down import). Reading triggers page faults. *   Deliverables:     *   [x] Pre-allocation (Windows): Implement <code>SetFileValidData</code> in <code>MemoryMapper</code> to bypass zero-filling for new files (requires <code>SE_MANAGE_VOLUME_NAME</code> privilege handling).     *   [x] Pre-allocation (Linux): Implement <code>fallocate</code> to reserve disk blocks.     *   [x] Bulk Paging (Read Optimization): Verify and tune <code>PrefetchVirtualMemory</code> (Windows) and <code>MAP_POPULATE</code> (Linux) usage in <code>IOAccelerator</code> to ensure we are saturating read bandwidth.     *   [x] Huge Pages Investigation: Evaluate <code>MADV_HUGEPAGE</code> / Large Pages for reducing TLB misses on &gt;10GB matrices.</p>"},{"location":"internals/plans/completed/R1_PERF/#phase-3-data-handling-micro-optimizations-avx-512","title":"Phase 3: Data Handling Micro-optimizations (AVX-512)","text":"<p>Goal: Achieve theoretical optimality for <code>DenseBitMatrix</code> operations (fundamental Causal Set data structure). *   Context: Current <code>std::popcount</code> is good but not optimal for large bitstreams. AVX-512 <code>VPOPCNTDQ</code> can process 512 bits per cycle. *   Deliverables:     *   [x] Alignment Check: Verify <code>MemoryMapper</code> provides 64-byte alignment (critical for AVX-512).     *   [x] Runtime Dispatch: Implement <code>CpuId</code> check to safely select AVX-512 paths at runtime.     *   [x] Intrinsics Kernels: Implement <code>_mm512_popcnt_epi64</code> and bitwise logic (<code>and</code>, <code>or</code>, <code>xor</code>, <code>not</code>) kernels.</p>"},{"location":"internals/plans/completed/R1_PERF/#phase-4-pipeline-verification-direct-path","title":"Phase 4: Pipeline Verification &amp; Direct Path","text":"<p>Goal: Prove that the \"Cooperative Architecture\" works as intended and that the \"Direct Path\" bypasses overhead for RAM-resident data. *   Context: <code>AsyncStreamer</code> logic exists but hasn't been visually verified. <code>MemoryGovernor</code> has logic for \"Direct Path\" (bypassing tiling for RAM-resident data), which is critical for NumPy parity. *   Deliverables:     *   [x] Direct Path Verification: Verify <code>MemoryGovernor::should_use_direct_path</code> correctly routes in-memory workloads to the low-overhead path (matching NumPy speed).     *   [x] NVTX Instrumentation: Add NVIDIA Tools Extension markers to <code>AsyncStreamer</code>, <code>Compute</code>, and <code>Transfer</code> phases.     *   [x] Nsight Systems Validation: Capture a trace confirming overlap.     *   [x] Benchmark Suite Update: Add <code>benchmarks/benchmark_io_throughput.py</code> and <code>benchmarks/benchmark_threading_stress.py</code> to CI.</p>"},{"location":"internals/plans/completed/R1_PERF/#phase-5-validation-documentation-cleanup","title":"Phase 5: Validation, Documentation &amp; Cleanup","text":"<p>Goal: Ensure the new performance infrastructure is robust, documented, and the codebase is clean of legacy implementations. *   Context: We are replacing core infrastructure (threading, IO). We must verify correctness under stress and document the new architecture. \"Deprecation\" means complete removal (\"Purge\"). *   Deliverables:     *   [x] Extensive Test Suite (Correctness First):         *   <code>tests/cpp/test_parallel_utils.cpp</code>: Verify dynamic scheduling edge cases (exceptions, uneven workloads, single-thread fallback, 0-range).         *   <code>tests/test_io_accelerator.cpp</code>: Verify prefetch/discard behavior on Windows/Linux (mocked if necessary).         *   <code>tests/python/test_io_consistency.py</code>: Verify data integrity after high-speed imports and \"Direct Path\" operations.     *   [x] Benchmark Suite (Performance Verification):         *   <code>benchmarks/benchmark_io_throughput.py</code>: Measure Read/Write bandwidth vs <code>memcpy</code>.         *   <code>benchmarks/benchmark_stress.py</code>: Measure scaling efficiency and stall resistance.         *   <code>benchmarks/benchmark_numpy_parity.py</code>: Verify &gt;0.90x parity for IO and memory-resident ops.     *   [x] Documentation (per Protocol):         *   Internals: Update <code>internals/Compute Architecture.md</code> with the new Dynamic Scheduling model.         *   Internals: Update <code>internals/MemoryArchitecture.md</code> with <code>SetFileValidData</code> / <code>PrefetchVirtualMemory</code> details.         *   API: Document any new tuning knobs in <code>docs/parameters/</code>.     *   [x] Cleanup (Purge):         *   Remove all traces of static partitioning from <code>ParallelUtils</code>.         *   Remove legacy \"naive\" file writing paths in <code>MemoryMapper</code>.         *   Ensure no dead code remains from the old IO strategies.</p>"},{"location":"internals/plans/completed/R1_PERF/#phase-6-numpy-parity-bitmatrix-optimization-completed-jan-2026","title":"Phase 6: NumPy Parity &amp; BitMatrix Optimization (Completed Jan 2026)","text":"<p>Goal: Achieve &gt;0.90x performance parity with NumPy for all IO operations and optimize BitMatrix operations. *   Context: Initial benchmarks showed poor read performance due to Python iteration overhead. BitMatrix operations were slow due to lack of SIMD. *   Deliverables:     *   [x] Zero-Copy IO: Implemented <code>_to_numpy_fast</code> using <code>memcpy</code> for Float64/Int32, achieving &gt;3x NumPy speed.     *   [x] Optimized Complex IO: Implemented specialized C++ loops for Complex128, achieving &gt;3.5x NumPy speed.     *   [x] SIMD Bit Packing: Implemented SSE2 intrinsics for <code>DenseBitMatrix</code> write (packing), achieving 5x speedup.     *   [x] SIMD Bit Unpacking: Implemented SSE2 intrinsics for <code>DenseBitMatrix</code> read (unpacking), achieving 1.9x speedup.     *   [x] Bitwise Operations: Implemented SIMD-accelerated <code>__xor__</code>, <code>__and__</code>, <code>__or__</code> for <code>DenseBitMatrix</code>, achieving ~5x speedup vs NumPy.     *   [x] Documentation: Created <code>documentation/guides/performance.md</code> detailing these wins.</p>"},{"location":"internals/plans/completed/R1_PERF/#3-success-criteria","title":"3. Success Criteria","text":"<ul> <li>Import Speed: &gt; 4.0 GB/s on NVMe (Write).</li> <li>Read Speed: &gt; 0.90x NumPy <code>mmap</code> load speed.</li> <li>BitMatrix Popcount: &gt; 2x speedup over <code>std::popcount</code> on AVX-512 hardware.</li> <li>Threading: No stalls observed in <code>benchmark_stress.py</code> when memory pressure is high.</li> <li>Pipeline: Visual confirmation of overlap in Nsight Systems.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/","title":"R1_PROPERTIES \u2014 Semantic Properties + Property-Aware Algebra (Release 1)","text":"<p>Status: Phase A\u2013F implemented (Phase E expanded: property-aware matmul/solve/eigvalsh; O(1) mutation effect summaries integrated)</p> <p>Last updated: 2025-12-21</p> <p>Documentation note:</p> <p>This file is a planning/spec artifact. User-visible R1 behavior is documented in:</p> <ul> <li>Release 1: Properties (what shipped)</li> <li>Storage and Memory (how properties/caches persist)</li> <li>API footprint: MatrixBase and VectorBase</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#purpose","title":"Purpose","text":"<p>Release 1 needs a semantic properties system that algorithms can rely on to select fast paths, specialized behavior, and stable dispatch.</p> <p>This is a deliberate shift from \u201cstructure-by-type\u201d (e.g. selecting triangular behavior by checking whether an object is a triangular class) to structure-by-properties. In R1_PROPERTIES, algorithms treat the relevant properties as the authoritative source of truth.</p> <p>These properties are authoritative (\u201cgospel\u201d):</p> <ul> <li>The system does not validate that asserted semantic properties are mathematically true.</li> <li>Implementations are allowed to behave as if the property is true.</li> <li>The only checks performed are minimal compatibility/sanity checks that prevent self-contradictory property states or structurally impossible states (e.g., <code>is_unitary</code> on a non-square matrix).</li> </ul> <p>This plan defines:</p> <ul> <li>the canonical properties schema,</li> <li>compatibility rules,</li> <li>propagation rules across metadata-only transforms,</li> <li>the derived-cache correctness/invalidation model,</li> <li>and where/how properties affect operator implementations and dispatch.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#at-a-glance-the-contract","title":"At a glance (the contract)","text":"<ul> <li>Properties: <code>obj.properties</code> is a typed mapping exposed to users.</li> <li>Hard errors on incompatibility: structurally impossible / internally contradictory asserted states raise immediately.</li> <li>No scans: neither property rules nor cache validation require scanning payload.</li> <li>Cached derived values: some entries in <code>obj.properties</code> are cached derived values (e.g., <code>trace</code>) with strict validity rules; they are never treated as semantic structure properties.</li> <li>Health check is \\(O(1)\\): no additional payload passes; parallel kernels may emit a constant-size effect summary.</li> <li>Storage integration: see guides/Storage and Memory (format + semantics). The container mechanics were tracked under the R1_STORAGE plan during implementation.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#implementation-status-as-of-2025-12-21","title":"Implementation status (as of 2025-12-21)","text":"<p>This plan is implemented end-to-end for Release 1 scope.</p> <ul> <li>Properties mapping exposed: <code>obj.properties</code> exists on native objects via Python patching (<code>python/pycauset/_internal/properties.py</code>, installed in <code>python/pycauset/__init__.py</code>).</li> <li>Phase A compatibility enforced: <code>obj.properties</code> is a validating mapping; structurally impossible / contradictory asserted states raise immediately (no payload scans). Compatibility now includes square-only structure flags (triangular/atomic), ordering constraints (strictly-sorted \u21d2 sorted), and the \u201cupper+lower \u21d2 not diagonal-false\u201d constraint.</li> <li>Persistence bridging present: <code>meta[\"properties\"]</code> round-trips; cached-derived values persist under <code>cached.*</code> and are surfaced only when signatures match (<code>python/pycauset/_internal/persistence.py</code>).</li> <li>Metadata-only view propagation present: <code>transpose</code>, <code>conj</code>, <code>.H</code> propagate properties in O(1) (<code>python/pycauset/_internal/properties.py</code>).</li> <li>Cached-derived propagation improved: scalar multiply and add/sub apply the Phase-A propagation rules for cached-derived values where safe (O(1)), including <code>sum</code>.</li> <li>Priority tree implemented: an internal helper computes an effective structure category from properties (zero/identity/diagonal/triangular/general) without scanning payload.</li> <li>Operator wiring (Phase E expanded): property-aware routing exists for <code>matmul</code>, <code>solve</code>/<code>solve_triangular</code>, and <code>eigvalsh</code> (cached eigenvalues). <code>trace()</code>/<code>determinant()</code> and scalar-returning <code>pycauset.norm()</code>/<code>pycauset.sum()</code> continue to consult/seed cached-derived values.</li> <li>Tests + docs exist: see <code>tests/python/test_properties_persistence.py</code> and <code>tests/python/test_properties_operator_wiring.py</code>; docs updated in the storage/semantics guides.</li> </ul> <p>Open gaps relative to the plan:</p> <ul> <li>None for R1. Kernel-style effect summaries are applied via the properties shim (<code>_apply_effect_summary_inplace</code>) and are exercised by mutation patches; device kernels can emit the same constant-size summaries later without changing semantics.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#key-references","title":"Key references","text":"<ul> <li>Roadmap node: <code>documentation/internals/plans/TODO.md</code> \u2192 R1_PROPERTIES</li> <li>Compute model: <code>documentation/internals/Compute Architecture.md</code></li> <li>Storage semantics + format (canonical docs): <code>documentation/guides/Storage and Memory.md</code></li> <li>Current persistence implementation: <code>python/pycauset/_internal/persistence.py</code></li> <li>Support readiness tracking: <code>documentation/internals/plans/SUPPORT_READINESS_FRAMEWORK.md</code></li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#constraints-non-negotiable","title":"Constraints (non-negotiable)","text":"<ul> <li>No truth validation: never scan matrix/vector data to \u201cconfirm\u201d a property.</li> <li>No backwards-compat aliases: the public name is <code>properties</code> (not <code>flags</code>, not <code>user_flags</code>), and the persistence schema must not accept legacy names.</li> <li>Deterministic behavior: given the same properties and operation sequence, results and chosen algorithmic paths must be deterministic.</li> <li>Minimal incompatibility checks only: only reject property combinations that are structurally impossible or internally contradictory for the property lattice.</li> <li>Propagation is mandatory: metadata-only transforms must update properties predictably.</li> <li>Testing + documentation phase at the end: the final phase is an explicit \u201ctests + docs\u201d closure phase.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#design-anchors-agreed","title":"Design anchors (agreed)","text":"<p>These are design principles specific to R1_PROPERTIES (in addition to the project-wide mantras).</p> <ul> <li>Properties-as-gospel (power-user feature): properties are authoritative claims. If a matrix is marked as triangular, triangular-aware algorithms are allowed to behave as if entries outside the relevant triangle are zero, even if the underlying payload is not triangular.</li> <li>No truth validation: the system must never scan matrix/vector data to \u201cconfirm\u201d a property.</li> <li>Lazy-evaluation invariant (metadata scaling): property compatibility checks, property propagation, and effective-structure selection must be \\(O(1)\\) and must depend only on existing metadata (shape, dtype, existing properties) plus the transform parameters (e.g. the scalar value).</li> <li>Bedrock scope: every <code>PersistentObject</code> must have properties support. R1 includes matrices and vectors.</li> <li>Documentation is part of the feature: user-facing docs must explicitly teach the \u201cpower user\u201d semantics and the fact that properties can change algorithm choices.</li> <li>Hybrid caching (agreed): some expensive derived quantities should be preserved under certain transforms using only \\(O(1)\\) rules; otherwise they must be unset. No cache exists if it forces recomputation.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#definitions","title":"Definitions","text":""},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#terminology","title":"Terminology","text":"<ul> <li>\u201cProperty\u201d means a typed metadata item attached to a <code>PersistentObject</code>.</li> <li><code>obj.properties</code> is the single user-facing mapping, but it contains two semantic classes of entries:</li> <li>Gospel assertions: structural/special-case intent (triangular/diagonal/unitary/etc). Never truth-validated.</li> <li>Cached-derived values: <code>trace</code>/<code>determinant</code>/<code>rank</code>/<code>norm</code> and similar. Validity-checked and may be cleared.</li> <li>Some keys are boolean-like; for those, we use a tri-state convention via key presence.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#canonical-representation","title":"Canonical representation","text":"<p>Public API concept: <code>obj.properties</code> is a mapping from stable string keys to typed values.</p> <ul> <li>Keys are stable, snake_case strings.</li> <li>Values are typed and may be unset.</li> <li>Properties are persisted in <code>.pycauset</code> metadata (see \u201cPersistence + metadata schema\u201d).</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#value-model-release-1","title":"Value model (Release 1)","text":"<p><code>obj.properties</code> is a typed mapping (string keys \u2192 typed values). For boolean-like keys we use tri-state semantics:</p> <ul> <li><code>True</code>: asserted; algorithms may exploit it.</li> <li><code>False</code>: explicitly negated.</li> <li>Unset: no claim.</li> </ul> <p>Public API decision (agreed):</p> <ul> <li>Unset means the key is absent from <code>obj.properties</code>.</li> <li>Explicit <code>False</code> is represented by the key being present with value <code>False</code>.</li> </ul> <p>Persistence and internal representations must preserve \u201cmissing vs explicit False\u201d.</p>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#metadata-taxonomy-aligns-with-r1_storage","title":"Metadata taxonomy (aligns with R1_STORAGE)","text":"<p>R1_STORAGE defines three kinds of metadata on disk (identity/header vs view-state vs user-facing properties/caches). R1_PROPERTIES defines the user-facing semantics and how operators interpret and propagate them.</p> <p>In practice:</p> <p>1) Identity/header metadata (system-managed)   - Shape/dtype and any payload layout descriptor needed to interpret bytes.   - Not user-facing.</p> <p>2) View-state metadata (system-managed)   - Examples: transpose/conjugation/adjoint state, scalar factors.   - Must be metadata-only and \\(O(1)\\).   - Participates in cached-derived validity signatures.</p> <p>3) User-facing <code>properties</code> (single mapping; two semantic classes)   - Exposed as <code>obj.properties</code>.   - Gospel assertions are authoritative and never truth-validated.   - Cached-derived values are user-facing via clean keys, but are persisted as caches with validity metadata (see Phase C).</p>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#caching-system-release-1","title":"Caching system (Release 1)","text":"<p>R1 introduces a more rigorous caching model so that derived metadata remains correct under mutation and metadata-only transforms.</p> <p>Principles:</p> <ul> <li>Correctness first: cached values must never be used if they might be stale.</li> <li>No scans for validation: cache validity checks must be \\(O(1)\\) and based on metadata/versioning only.</li> <li>Deterministic: given the same history of operations, caches must be filled/cleared deterministically.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#post-operation-property-health-check-required","title":"Post-operation property health check (required)","text":"<p>Every operation that returns a new <code>PersistentObject</code> and every in-place mutation must run a cheap, deterministic post-operation health check step that:</p> <ul> <li>applies property propagation rules for metadata-only transforms,</li> <li>updates/propagates cached derived values where safe (\\(O(1)\\) rules only),</li> <li>clears any cached derived values that are no longer guaranteed to match the object\u2019s semantics,</li> <li>performs minimal compatibility checks (no scans).</li> </ul> <p>This \u201chealth check\u201d must not require any payload scan or any additional payload pass.</p> <p>Clarification (parallelization-friendly contract):</p> <ul> <li>Compute kernels (CPU/GPU/streaming) are always allowed to read/write payload as required to produce correct results.</li> <li>The health check is a metadata normalization step, not a compute step.</li> <li>The health check may use:</li> <li>existing metadata (shape, dtype, view-state, existing properties), and</li> <li>the operation parameters (e.g., transpose, scalar value, indices for <code>M[i, j] = ...</code>), and</li> <li>an optional constant-size effect summary produced by the operation while it runs.</li> </ul> <p>The key rule is: property/caching correctness must not force a second pass over payload.</p> <p>Complexity requirement (agreed):</p> <ul> <li>The health check must be strictly \\(O(1)\\).</li> <li>No \\(O(\\log N)\\) work is allowed here (even for \u201csmall\u201d metadata updates), because this check must also run after very frequent primitives such as element <code>set()</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#effect-summaries-enabler-for-parallel-kernels","title":"Effect summaries (enabler for parallel kernels)","text":"<p>To make future parallelization plug in cleanly (via <code>AutoSolver</code> / <code>ComputeDevice</code>) without special integration work, operations may emit an effect summary:</p> <ul> <li>A small fixed-size struct (conceptually) that answers a few yes/no questions about what the op definitely did.</li> <li>It is computed \u201cfor free\u201d during the operation (e.g., via an OR-reduction of per-thread booleans), without extra passes.</li> <li>If an op cannot cheaply provide a fact, it reports \u201cunknown\u201d and the health check conservatively unsets affected properties/caches.</li> </ul> <p>Examples of useful effect bits:</p> <ul> <li>\u201cpayload mutated\u201d (increments content epoch)</li> <li>\u201cwrote any off-diagonal element\u201d</li> <li>\u201cwrote any diagonal element\u201d</li> <li>\u201cresult is known-all-zero\u201d (only for ops like explicit zero-fill; not for general matmul)</li> </ul> <p>This keeps the health check deterministic and \\(O(1)\\), while letting highly-parallel kernels remain unconstrained.</p> <p>Where the health check is required (non-exhaustive; must be completed in Phase A):</p> <ul> <li>After any payload mutation method (e.g., element <code>set</code>, bulk fill, random fill).</li> <li>After any metadata-only transform that changes view-state (transpose/conjugate/adjoint, scalar changes).</li> <li>After any operation that constructs a view (clones, slices/views, transpose views).</li> <li>After load/deserialize (properties and caches must be normalized).</li> <li>After any API that lets users set properties explicitly (power-user setter).</li> </ul> <p>Minimum design requirements:</p> <ul> <li>Every <code>PersistentObject</code> maintains a cheap-to-check content version (e.g., a monotonically increasing epoch) that changes whenever payload data is mutated.</li> <li>Every cached-derived entry records the version/signature it depends on (payload version + relevant view-state signature).</li> <li>On lookup, the system uses a cached-derived value only if the dependency signature matches; otherwise it is ignored/cleared.</li> </ul> <p>Cached-derived propagation under metadata-only transforms:</p> <ul> <li>Some caches can be preserved or transformed without scanning (e.g., trace and determinant under transpose; trace scales linearly with scalar; determinant scales by \\(scalar^n\\) for \\(n\\times n\\)).</li> <li>If a cache does not have a safe propagation rule, it must be cleared to avoid stale answers.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#core-cached-derived-propagation-table-initial-must-be-completed-in-phase-a","title":"Core cached-derived propagation table (initial; must be completed in Phase A)","text":"<p>This is the minimum expected \u201ccheap propagation\u201d set for R1.</p> <p>Definitions:</p> <ul> <li>\u201cUnset\u201d means the entry is removed from the cached-derived store.</li> <li>If a rule says \u201crequires X known\u201d, it means the input cache entry must be present.</li> </ul> Operation / transform <code>trace</code> <code>determinant</code> <code>rank</code> <code>norm</code> (vector) transpose preserve (if known) preserve (if known) preserve (if known) preserve (if known) conjugation conjugate (if known) conjugate (if known) preserve (if known) preserve (if known) adjoint conjugate (if known) conjugate (if known) preserve (if known) preserve (if known) scalar multiply by \\(s\\) if known: <code>trace *= s</code> if known and square: <code>det *= s^n</code> if known: if \\(s=0\\) then <code>rank=0</code> else preserve if known: <code>norm *= |s|</code> add/subtract if both known: add/sub unset unset unset any payload mutation (e.g. set element) unset unset unset unset any other op without an explicit cheap rule unset unset unset unset <p>Notes:</p> <ul> <li>\u201cpayload mutation\u201d means modifying stored data, not changing metadata-only view state.</li> <li>This table applies to cached-derived values (regardless of whether the value was produced by computation or set by a power user).</li> </ul> <p>R1 decision (updated):</p> <ul> <li><code>trace</code>, <code>determinant</code>, <code>rank</code>, and vector <code>norm</code> are cached-derived values, not semantic structure properties.</li> <li>There is no semantic distinction between \u201cuser-set\u201d and \u201ccomputed\u201d cache values. If a user sets <code>trace=231.2</code>, that is simply the cached trace value.</li> <li>Public methods/endpoints (e.g., <code>trace()</code>) may use a cached value if present and valid; otherwise they compute and then populate the cache.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#user-populated-caches-power-user-feature","title":"User-populated caches (power-user feature)","text":"<p>Power users may set derived cache values directly to avoid expensive computation.</p> <p>Semantics (agreed by direction):</p> <ul> <li>A user-populated cache entry is treated exactly like a computed cache entry.</li> <li>Cache validity is still enforced: a cache entry is used only when its dependency signature matches (payload content epoch + relevant view-state signature).</li> <li>If the payload is mutated, the dependency signature changes and the cached value is ignored/cleared.</li> <li>If a metadata-only transform occurs and there is no explicit \\(O(1)\\) propagation rule for that cache key, the cache entry is cleared.</li> </ul> <p>This preserves the correctness bar (\u201cnever stale\u201d) while still allowing power users to seed expensive derived quantities.</p> <p>Provenance note:</p> <ul> <li>The system does not expose a user-visible distinction between \u201cuser-set\u201d and \u201ccomputed\u201d cache values.</li> <li>Internal provenance tracking is optional (debug/telemetry only) and must not change semantics.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#robust-general-cache-system-required-makes-future-cached-quantities-easy","title":"Robust general cache system (required; makes future cached quantities easy)","text":"<p>R1 must define a general cache system that supports adding cached quantities later without redesign.</p> <p>Contract:</p> <ul> <li>Cached-derived values have a cache store (internal backing) with validity metadata.</li> <li>Cache keys are stable identifiers (e.g., <code>trace</code>, <code>determinant</code>, <code>rank</code>, <code>norm</code>).</li> <li>Each cache entry records:</li> <li>a typed value, and</li> <li>a dependency signature (at minimum: payload content epoch + view-state signature).</li> <li>Cache lookup is deterministic and \\(O(1)\\).</li> <li>Cache validity checks and propagation never require scanning payload.</li> </ul> <p>Registration/extension model:</p> <ul> <li>Each cache key must define:</li> <li>its value type,</li> <li>what it depends on (payload epoch + which view-state components matter), and</li> <li>explicit \\(O(1)\\) propagation rules for the supported metadata-only transforms.</li> <li>If a cache key has no rule for a given transform, the default behavior is to clear it.</li> </ul> <p>Practical outcome:</p> <ul> <li>Adding a new cached quantity later is a matter of defining the key and its propagation/invalidation rules, not inventing a new ad-hoc persistence path or special-case logic inside operators.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#properties-included-in-r1_properties-initial-set","title":"Properties included in R1_PROPERTIES (initial set)","text":"<p>This plan covers properties for matrices and vectors.</p> <p>Matrix properties:</p> <p>Special-case algebra (short-circuits):</p> <ul> <li><code>is_zero</code>: treat every entry as \\(0\\) (a \u201czero matrix\u201d property; not a shape claim).</li> <li><code>is_identity</code>: treat as an identity-like matrix \\(I\\).</li> <li>Important: PyCauset allows rectangular identity (see <code>pycauset.identity()</code>), so <code>is_identity=True</code> is allowed for non-square matrices.</li> <li><code>is_permutation</code>: treat as a permutation matrix \\(P\\) (re-indexing / row/col permutation).</li> </ul> <p>Structure properties (index skipping / structured algorithms):</p> <ul> <li><code>is_diagonal</code></li> <li><code>diagonal_value</code> (typed; if present, asserts every diagonal element equals this value)</li> <li><code>has_unit_diagonal</code> (shorthand; equivalent to <code>diagonal_value = 1</code> when meaningful)</li> <li><code>is_upper_triangular</code></li> <li><code>is_lower_triangular</code></li> <li><code>has_zero_diagonal</code> (shorthand; equivalent to <code>diagonal_value = 0</code> when meaningful)</li> </ul> <p>Symmetry family:</p> <ul> <li><code>is_symmetric</code></li> <li><code>is_anti_symmetric</code> (a.k.a. \u201cskew-symmetric\u201d)</li> <li><code>is_hermitian</code></li> <li><code>is_skew_hermitian</code></li> </ul> <p>Norm-preserving / spectral hints:</p> <ul> <li><code>is_unitary</code></li> </ul> <p>Matrix-function hint:</p> <ul> <li><code>is_atomic</code>: treat as an \u201catomic\u201d triangular matrix in the sense used by common matrix-function algorithms (e.g. clustered diagonal values). This is gospel and is not validated.</li> </ul> <p>Cached-derived matrix properties (cache semantics; validity-checked; may be cleared):</p> <ul> <li><code>trace</code></li> <li><code>determinant</code></li> <li><code>rank</code></li> <li><code>sum</code></li> </ul> <p>Vector properties:</p> <ul> <li><code>is_zero</code>: treat every entry as \\(0\\) (a \u201czero vector\u201d property; not a shape claim).</li> <li><code>is_unit_norm</code>: treat \\(\\|v\\|_2 = 1\\).</li> <li><code>is_sorted</code></li> <li><code>is_strictly_sorted</code></li> </ul> <p>Cached-derived vector properties (cache semantics; validity-checked; may be cleared):</p> <ul> <li><code>norm</code> (e.g. cached \\(\\|v\\|_2\\))</li> <li><code>sum</code></li> </ul> <p>Notes:</p> <ul> <li>Strict triangular is represented as <code>diagonal_value=0</code> + triangular (no separate strict-triangular booleans).</li> <li>We do not add a broad zoo (SPD/PSD/normal/etc) in R1_PROPERTIES; those can be R2+.</li> </ul> <p>Important: the public/user-facing concept is properties, and the system must be ready for non-boolean properties (e.g., numeric metadata like <code>rank</code>) without redesigning the plumbing.</p>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#compatibility-model-minimal-sanity-checks","title":"Compatibility model (minimal sanity checks)","text":"<p>These checks are allowed because they protect the internal semantics of the property lattice and avoid impossible propagation states. They are not truth validation.</p> <p>Hard error policy (agreed):</p> <ul> <li>If a caller (user or internal) attempts to assert an incompatible property state (e.g. <code>is_unitary=True</code> on a non-square matrix), this must raise a hard error immediately.</li> <li>This is not \u201cvalidation\u201d; it is enforcing internal semantic consistency.</li> </ul> <p>Tri-state scope rule:</p> <ul> <li>Compatibility checks primarily constrain asserted structural truths (keys with value <code>True</code>).</li> <li>Unset (missing) means \u201cno claim\u201d and does not create contradictions by itself.</li> <li>Explicit <code>False</code> must be preserved, but does not introduce additional obligations unless it directly contradicts a required implication of an asserted <code>True</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#shape-constraints","title":"Shape constraints","text":"<ul> <li><code>is_unitary=True</code> requires a square matrix.</li> <li> <p><code>is_hermitian=True</code> requires a square matrix.</p> </li> <li> <p><code>is_identity=True</code> is allowed for rectangular matrices (rectangular identity semantics).</p> </li> <li><code>is_permutation=True</code> requires a square matrix.</li> <li><code>is_symmetric=True</code> requires a square matrix.</li> <li><code>is_anti_symmetric=True</code> requires a square matrix.</li> <li><code>is_skew_hermitian=True</code> requires a square matrix.</li> </ul> <p>Diagonal note (agreed):</p> <ul> <li><code>is_diagonal=True</code> is allowed for rectangular matrices. Semantics: all off-diagonal entries are treated as zero, with the diagonal defined for indices \\(i=i\\) up to \\(\\min(m,n)\\).</li> </ul> <p>For triangular-only properties:</p> <ul> <li><code>is_upper_triangular=True</code> and/or <code>is_lower_triangular=True</code> requires a square matrix.</li> <li><code>is_atomic=True</code> requires a square matrix.</li> </ul> <p>Shape constraints apply only when the relevant property value is <code>True</code>.</p>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#latticeimplication-constraints","title":"Lattice/implication constraints","text":"<p>Strict triangular note:</p> <ul> <li>R1 avoids a dedicated strict-triangular boolean zoo.</li> <li>Instead, \u201cstrictly upper/lower triangular\u201d is represented as:</li> <li><code>is_upper_triangular=True</code> (or <code>is_lower_triangular=True</code>) and</li> <li><code>diagonal_value = 0</code> (or <code>has_zero_diagonal=True</code>).</li> </ul> <p>Diagonal consistency:</p> <p>If <code>is_diagonal=True</code> then it may still be compatible with <code>diagonal_value=0</code> (zero diagonal) or <code>diagonal_value=1</code> (unit diagonal).</p> <p>Diagonal-value consistency (agreed):</p> <ul> <li><code>diagonal_value</code> does not imply <code>is_diagonal</code>.</li> <li>If <code>has_unit_diagonal=True</code>, then <code>diagonal_value</code> (if present) must equal \\(1\\).</li> <li>If <code>has_zero_diagonal=True</code>, then <code>diagonal_value</code> (if present) must equal \\(0\\).</li> </ul> <p>Identity consistency (agreed):</p> <ul> <li><code>is_identity=True</code> requires:</li> <li><code>is_zero</code> is not <code>True</code>.</li> <li><code>is_diagonal</code> is not <code>False</code>.</li> <li><code>has_unit_diagonal</code> is not <code>False</code>.</li> <li><code>has_zero_diagonal</code> is not <code>True</code>.</li> <li><code>diagonal_value</code> (if present) must equal \\(1\\).</li> </ul> <p>Contradictions that must be rejected:</p> <ul> <li><code>is_upper_triangular=True</code> together with <code>is_lower_triangular=True</code> is only meaningful as \u201cdiagonal-like\u201d behavior; if the user also asserts <code>is_diagonal=False</code>, that must be rejected.</li> </ul> <p>Symmetry-family sanity checks (minimal):</p> <ul> <li><code>is_symmetric=True</code> and <code>is_anti_symmetric=True</code> is rejected unless <code>is_zero=True</code>.</li> <li><code>is_hermitian=True</code> and <code>is_skew_hermitian=True</code> is rejected unless <code>is_zero=True</code>.</li> </ul> <p>Ordering constraints:</p> <ul> <li>If <code>is_strictly_sorted=True</code> then <code>is_sorted</code> must be True.</li> </ul> <p>Tri-state refinement:</p> <ul> <li>If <code>is_strictly_sorted=True</code> then <code>is_sorted</code> must not be <code>False</code> (it may be <code>True</code> or <code>None</code>).</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#what-is-explicitly-not-validated","title":"What is explicitly not validated","text":"<ul> <li>Hermitian/unitary truth is never checked.</li> <li>\u201cHermitian implies diagonal implies triangular\u201d is not auto-enforced.</li> <li>Setting properties that are mathematically inconsistent but not structurally contradictory is allowed.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#priority-tree-effective-structure","title":"Priority tree (effective structure)","text":"<p>Operators that can exploit structure compute an effective structure category from properties without mutating stored properties.</p> <p>Terminology note: this is computed from properties.</p> <p>Implementation note (performance): the effective structure category must be computed once per operation and passed downward (do not repeatedly query the properties container inside inner loops).</p> <p>Priority (highest first):</p> <p>0) Zero: if <code>is_zero=True</code>. 1) Identity: if <code>is_identity=True</code>. 2) Diagonal: treat as diagonal if <code>is_diagonal=True</code> OR if both <code>is_upper_triangular=True</code> and <code>is_lower_triangular=True</code>. 3) Upper triangular: if <code>is_upper_triangular=True</code>. 4) Lower triangular: if <code>is_lower_triangular=True</code>. 5) General.</p> <p>Rationale:</p> <ul> <li>Diagonal dominates triangular for index skipping.</li> <li>\u201cBoth upper and lower\u201d implies diagonal behavior for algorithms (even if the user did not set <code>is_diagonal</code>).</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#propagation-rules","title":"Propagation rules","text":"<p>Properties must be transformed by metadata-only operations deterministically.</p> <p>Tri-state propagation rule:</p> <ul> <li>Propagation must preserve the distinction between <code>False</code> and <code>None</code>.</li> <li>When a transform does not preserve a property in general, the propagated value should become <code>None</code> (unset), not <code>False</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#transpose","title":"Transpose","text":"<p>On transpose:</p> <ul> <li><code>is_upper_triangular</code> \u21c4 <code>is_lower_triangular</code></li> <li>strictness is represented via <code>diagonal_value=0</code>, which is preserved under transpose.</li> <li><code>is_diagonal</code> stays the same</li> <li><code>has_unit_diagonal</code> stays the same</li> <li><code>has_zero_diagonal</code> stays the same</li> <li> <p><code>diagonal_value</code> stays the same</p> </li> <li> <p><code>is_zero</code> stays the same</p> </li> <li><code>is_identity</code> stays the same</li> <li> <p><code>is_permutation</code> stays the same</p> </li> <li> <p><code>is_symmetric</code> stays the same</p> </li> <li><code>is_anti_symmetric</code> stays the same</li> <li><code>is_hermitian</code> becomes None unless the dtype is real (transpose does not preserve Hermitian-ness in general)</li> <li> <p><code>is_skew_hermitian</code> becomes None unless the dtype is real (transpose does not preserve skew-Hermitian-ness in general)</p> </li> <li> <p><code>is_atomic</code> stays the same</p> </li> </ul> <p>For <code>is_unitary</code>:</p> <ul> <li><code>is_unitary</code> becomes None (transpose does not preserve unitarity in general)</li> </ul> <p>Note: the final line is intentional: we do not attempt to \u201ccorrect\u201d user-set properties via propagation.</p>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#conjugation","title":"Conjugation","text":"<p>On elementwise conjugation:</p> <ul> <li>Triangular/diagonal properties unchanged</li> <li><code>is_hermitian</code> becomes None unless the dtype is real (conjugation does not preserve Hermitian-ness in general)</li> <li> <p><code>is_skew_hermitian</code> becomes None unless the dtype is real (conjugation does not preserve skew-Hermitian-ness in general)</p> </li> <li> <p><code>diagonal_value</code> is conjugated (if present)</p> </li> <li> <p><code>is_zero</code> stays the same</p> </li> <li><code>is_identity</code> stays the same</li> <li> <p><code>is_permutation</code> stays the same</p> </li> <li> <p><code>is_symmetric</code> stays the same</p> </li> <li> <p><code>is_anti_symmetric</code> stays the same</p> </li> <li> <p><code>is_atomic</code> stays the same</p> </li> </ul> <p>For <code>is_unitary</code>:</p> <ul> <li><code>is_unitary</code> becomes None (conjugation does not preserve unitarity in general)</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#adjoint-conjugate-transpose","title":"Adjoint (conjugate-transpose)","text":"<p>If an adjoint operation exists as a single transform:</p> <ul> <li>apply transpose rules plus conjugation rules, except:</li> <li><code>is_unitary</code> stays the same (adjoint preserves unitarity)</li> <li><code>is_hermitian</code> stays the same (adjoint preserves Hermitian-ness)</li> <li><code>is_skew_hermitian</code> stays the same (adjoint preserves skew-Hermitian-ness)</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#scalar-multiply","title":"Scalar multiply","text":"<p>On multiply-by-scalar:</p> <ul> <li> <p>Triangular/diagonal structural properties unchanged</p> </li> <li> <p><code>diagonal_value</code> scales by the scalar (if present)</p> </li> <li> <p><code>is_zero</code> stays the same</p> </li> </ul> <p>For <code>is_identity</code> and <code>is_permutation</code>:</p> <ul> <li>if the scalar is exactly \\(1\\), keep the property</li> <li>otherwise, the property becomes False</li> </ul> <p>For <code>is_hermitian</code>:</p> <ul> <li>if the scalar is real, <code>is_hermitian</code> stays the same</li> <li>otherwise, <code>is_hermitian</code> becomes None</li> </ul> <p>For <code>is_skew_hermitian</code>:</p> <ul> <li>if the scalar is real, <code>is_skew_hermitian</code> stays the same</li> <li>otherwise, <code>is_skew_hermitian</code> becomes None</li> </ul> <p>For <code>is_unitary</code>:</p> <ul> <li>if \\(|scalar| = 1\\), <code>is_unitary</code> stays the same</li> <li>otherwise, <code>is_unitary</code> becomes None</li> </ul> <p>We allow propagation rules to invalidate properties (set to <code>None</code> or <code>False</code>) when the operation semantics make that deterministic, but we do not infer new <code>True</code> claims from the scalar (e.g., <code>scalar == 0</code> does not cause us to set additional properties to True).</p>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#views-clones","title":"Views / clones","text":"<ul> <li>Pure metadata-only views must copy properties into the new object (independent ownership), and then apply the propagation rules for the view transform.</li> <li>Clones/materializations preserve properties by value.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#where-properties-affect-algorithms-release-1-scope","title":"Where properties affect algorithms (Release 1 scope)","text":"<p>Properties can legally change algorithm behavior. In R1_PROPERTIES we focus on the cases that create immediate leverage without broad rewrites.</p> <p>Target operator families:</p> <ul> <li>Index skipping for structural loops (diagonal/triangular).</li> <li>Specialized solve paths:</li> <li>triangular solve shortcuts when triangular properties are set.</li> <li>Specialized multiplications:</li> <li>diagonal @ matrix and matrix @ diagonal.</li> <li>Spectral shortcuts:</li> <li><code>is_hermitian</code> chooses Hermitian eigen routines when available.</li> <li><code>is_unitary</code> allows using unitary identities where implemented.</li> </ul> <p>The exact list of operators to update is tracked in SRP (op \u00d7 dtype \u00d7 device \u00d7 structure table).</p> <p>In particular, type-based structural dispatch (e.g., \u201ctriangular-by-class\u201d) must be replaced (or gated) so that properties are the authoritative source of structural intent. Typed storage formats remain important for performance, but they are not the semantic authority.</p>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#phases","title":"Phases","text":""},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#phase-a-lock-schema-compatibility-rules","title":"Phase A \u2014 Lock schema + compatibility rules","text":"<p>Status (R1): Implemented</p> <p>Implementation + coverage:</p> <ul> <li>Compatibility enforcement: <code>python/pycauset/_internal/properties.py</code> (<code>obj.properties</code> validating mapping)</li> <li>Tests: <code>tests/python/test_properties_compatibility.py</code></li> </ul> <p>Deliverables:</p> <ul> <li>Canonical key set (initial properties) is finalized.</li> <li>Compatibility rules are finalized (shape constraints + lattice contradictions).</li> <li>Priority tree is finalized.</li> <li>Tri-state semantics (<code>True</code>/<code>False</code>/<code>None</code>) and its propagation rules are finalized.</li> <li>Lazy-evaluation invariant is explicitly enforced (no propagation/compatibility rule may require scanning data).</li> <li>Caching model requirements are locked (content-versioning + safe propagation vs clear rules).</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#phase-b-public-api-surface-contract","title":"Phase B \u2014 Public API surface contract","text":"<p>Status (R1): Implemented</p> <p>Implementation + coverage:</p> <ul> <li>Public surface: <code>obj.properties</code> mapping with tri-state booleans via key presence</li> <li>Assignment + per-key updates: <code>python/pycauset/_internal/properties.py</code></li> </ul> <p>Deliverables:</p> <ul> <li>Define <code>properties</code> exposure shape in Python (mapping of stable keys to typed values; boolean-like keys use tri-state semantics via presence).</li> <li>Define mutation contract (set whole mapping vs per-key updates) and error behavior for invalid combinations.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#phase-c-persistence-metadata-schema","title":"Phase C \u2014 Persistence + metadata schema","text":"<p>Status (R1): Implemented</p> <p>Implementation + coverage:</p> <ul> <li>Persistence bridge: <code>python/pycauset/_internal/persistence.py</code></li> <li>Tests: <code>tests/python/test_properties_persistence.py</code></li> </ul> <p>Deliverables:</p> <ul> <li>Define the <code>.pycauset</code> metadata schema required to store:</li> <li>gospel <code>properties</code> (including missing-vs-explicit semantics), and</li> <li>cached-derived values (validated by version/signature).</li> <li>Define the rule: persisted objects must preserve property values and whether each boolean-like property is explicitly set vs unset.</li> </ul> <p>Naming/encoding note (must be decided in Phase C):</p> <ul> <li>User-facing keys are clean (e.g., <code>trace</code>), but persistence must also encode \u201cthis is cached-derived\u201d + dependency signatures.</li> <li>Decision (agreed): store cached-derived values under a dedicated <code>cached</code> / <code>caches</code> section keyed by clean names (e.g., <code>cached.trace</code>).</li> </ul> <p>Implications:</p> <ul> <li>In memory: users read/write <code>obj.properties[\"trace\"]</code>.</li> <li>On disk: <code>metadata</code> stores cached-derived values under <code>cached.trace</code> (and friends), alongside the dependency signature.</li> <li>On load: if a cached-derived value is present and its dependency signature matches the restored object state, it is surfaced as <code>obj.properties[\"trace\"]</code>.</li> <li>On save: cached-derived values are written under <code>cached.*</code> (never as top-level keys like <code>cached_trace</code>).</li> </ul> <p>Storage-format note:</p> <ul> <li>The single-file container format and typed metadata encoding are tracked under <code>documentation/internals/plans/R1_STORAGE_PLAN.md</code>.</li> <li>R1_PROPERTIES must remain storage-format agnostic: the <code>properties</code> and derived-cache semantics must plug into the storage layer without changing frontend save/load call sites.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#phase-d-propagation-integration","title":"Phase D \u2014 Propagation integration","text":"<p>Status (R1): Implemented</p> <p>Implementation + coverage:</p> <ul> <li>View propagation: transpose/conj/adjoint in <code>python/pycauset/_internal/properties.py</code></li> <li>Scalar + add/sub cached-derived propagation in <code>python/pycauset/_internal/properties.py</code></li> <li>Tests: <code>tests/python/test_properties_propagation.py</code> and <code>tests/python/test_properties_compatibility.py</code></li> </ul> <p>Deliverables:</p> <ul> <li>Ensure metadata-only transforms update properties per the propagation rules.</li> <li>Ensure clones/materializations preserve properties.</li> <li>Ensure derived caches are invalidated or safely propagated under metadata-only transforms.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#phase-e-property-aware-operator-wiring","title":"Phase E \u2014 Property-aware operator wiring","text":"<p>Status (R1): Implemented</p> <p>Implemented in R1:</p> <ul> <li>Priority tree helper for effective structure selection (no scans)</li> <li>Scalar operator wiring: <code>trace()</code>, <code>determinant()</code>, <code>pycauset.norm()</code>, <code>pycauset.sum()</code></li> <li>Structured routing:</li> <li><code>matmul</code> routes diagonal/triangular cases based on effective structure.</li> <li><code>solve</code> routes diagonal/triangular cases via <code>solve_triangular</code>.</li> <li><code>eigvalsh</code> consults/seeds cached-derived <code>eigenvalues</code>.</li> </ul> <p>Deliverables:</p> <ul> <li>Identify the minimal operator set that must become property-aware in R1 (tracked via SRP inventory).</li> <li>Implement algorithm selection using the priority tree (effective structure), without mutating stored properties.</li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#phase-f-tests-documentation-final","title":"Phase F \u2014 Tests + documentation (FINAL)","text":"<p>Status (R1): Implemented for current surface; ongoing as operator coverage expands</p> <p>Artifacts:</p> <ul> <li>Tests: <code>tests/python/test_properties_*.py</code></li> <li>Canonical storage/caching docs: <code>documentation/guides/Storage and Memory.md</code></li> </ul> <p>Deliverables:</p> <ul> <li>Tests:</li> <li>compatibility checks (invalid combinations reject deterministically),</li> <li>propagation checks (transpose/conjugate/scalar multiply),</li> <li>persistence round-trip preserves properties.</li> <li>Docs:</li> <li>user-facing docs for <code>properties</code> (semantics: gospel, not validated),</li> <li>operator docs where properties change behavior.</li> <li>a dedicated \u201cPower users\u201d section explaining that properties can override data truth and force structured algorithms.</li> </ul> <p>Additionally:</p> <ul> <li> <p>The \u201cAdding Operations\u201d protocol must be updated to include a properties checklist (how an op reads properties, whether it propagates/changes properties, and where that logic lives so it is not scattered).</p> </li> <li> <p>The caching model (derived caches) must be documented: how caches are validated, when they are cleared, and which metadata-only transforms preserve/transform which caches.</p> </li> </ul>"},{"location":"internals/plans/completed/R1_PROPERTIES_PLAN/#open-questions-must-be-resolved-before-phase-b","title":"Open questions (must be resolved before Phase B)","text":"<ul> <li>Do we want to keep <code>is_unitary</code> propagation rules as written (transpose/conjugate clear; adjoint preserves), or should <code>is_unitary</code> be preserved more aggressively?</li> <li>Should <code>has_unit_diagonal</code> and <code>has_zero_diagonal</code> remain as stored boolean properties, or should <code>diagonal_value</code> be the only canonical representation (with shorthands computed on-demand)?</li> </ul>"},{"location":"internals/plans/completed/R1_SAFETY/","title":"R1_SAFETY: Robustness &amp; Safety (The Shield)","text":""},{"location":"internals/plans/completed/R1_SAFETY/#1-the-problem","title":"1. The Problem","text":"<p>\"The Happy Path is a lie.\" We need to ensure PyCauset survives crashes, power outages, and bad hardware states. This plan focuses on defensive engineering: assuming the disk is slow, the GPU is broken, and the power will fail.</p>"},{"location":"internals/plans/completed/R1_SAFETY/#2-phased-implementation-plan","title":"2. Phased Implementation Plan","text":""},{"location":"internals/plans/completed/R1_SAFETY/#phase-1-storage-integrity-the-header","title":"Phase 1: Storage Integrity (The Header)","text":"<p>Goal: Prevent data corruption when file formats evolve. *   Context: Currently, .pycauset files are raw binary dumps. If we change the layout in R2, R1 readers will read garbage (or crash). *   Deliverables:     1.  Header Definition: Define a 64-byte struct at the start of every file.         *   Magic: PYCAUSET (8 bytes)         *   Version: uint32_t (4 bytes) - Set to 1.         *   Reserved: 52 bytes of padding (zeroed) for future flags/checksums.     2.  Writer Update: MemoryMapper writes this header on file creation.     3.  Reader Validation: MemoryMapper reads and validates this header on open. Throw InvalidFileFormat if magic mismatches or version &gt; supported.     4.  Offset Adjustment: All payload offsets (matrix data) must shift by +64 bytes.</p>"},{"location":"internals/plans/completed/R1_SAFETY/#phase-2-resource-management-the-leak","title":"Phase 2: Resource Management (The Leak)","text":"<p>Goal: Prevent \"Ghost RAM\" usage on Windows. *   Context: IOAccelerator::discard() uses madvise(MADV_DONTNEED) on Linux, which frees physical pages. On Windows, it currently does nothing. Large temporary matrices consume page file/RAM even after we are \"done\" with them, leading to OOM on long runs. *   Deliverables:     1.  Windows Implementation: Implement discard_impl using VirtualUnlock (to unlock working set) and OfferVirtualMemory (if available) or VirtualFree(MEM_DECOMMIT) (if we can re-commit transparently, otherwise VirtualUnlock is the safest first step).     2.  Verification: Create a test script that allocates 2x RAM size in chunks, discarding each after use, to prove we don't OOM.</p>"},{"location":"internals/plans/completed/R1_SAFETY/#phase-3-compute-resilience-the-fallback","title":"Phase 3: Compute Resilience (The Fallback)","text":"<p>Goal: Survive GPU instability. *   Context: GPU drivers can crash or run out of memory. Currently, AutoSolver might retry or crash the process. *   Deliverables:     1.  Pessimistic Initialization: Wrap GPU context creation in    ry/catch.     2.  Circuit Breaker: If a GPU operation throws a hardware exception (OOM, CUDA error), catch it.     3.  Fallback Logic:         *   Log a warning: \"GPU failed (error code). Falling back to CPU for remainder of session.\"         *   Set gpu_device_ = nullptr.         *   Retry the failed operation on CPU.     4.  Unit Test: Mock a GPU failure (or force a bad allocation) and verify the system recovers.</p>"},{"location":"internals/plans/completed/R1_SAFETY/#phase-4-data-persistence-the-flush","title":"Phase 4: Data Persistence (The Flush)","text":"<p>Goal: Minimize data loss on power failure. *   Context: OS file buffers are lazy. A power cut after \"saving\" might leave a file with zeroed pages. *   Deliverables:     1.  Flush API: Expose a robust \flush() method in MemoryMapper.         *   Windows: FlushFileBuffers.         *   Linux: msync(MS_SYNC).     2.  Critical Path Integration: Call \flush() immediately after writing critical metadata (e.g., updating the \"valid\" flag of a matrix).     3.  Audit: Review PersistentObject to ensure we don't have \"torn write\" windows where the file is structurally invalid.</p>"},{"location":"internals/plans/completed/R1_SAFETY/#phase-5-hygiene-the-cleanup","title":"Phase 5: Hygiene (The Cleanup)","text":"<p>Goal: Keep the user's disk clean. *   Context: If PyCauset crashes, it leaves pycauset_.tmp files in .pycauset/. These accumulate forever. *   Deliverables:     1.  Startup Scan: On import pycauset, scan the .pycauset directory.     2.  Stale Detection: Identify .tmp files that are not locked by any running process.         *   Note: This is tricky on Linux (flock). On Windows, DeleteFile fails if open.         *   Strategy: Try to delete. If it fails (locked), ignore. If it succeeds, good.     3.  Implementation:* Add clean_stale_files() to pycauset/init.py or src/core.</p>"},{"location":"internals/plans/completed/R1_SAFETY/#phase-6-verification-the-gauntlet","title":"Phase 6: Verification (The Gauntlet)","text":"<p>Goal: Prove robustness under fire and ensure no regressions. *   Context: Safety features are hard to test because they handle rare events. We must simulate these events. *   Deliverables:     1.  C++ Unit Tests:         *       est_header_validation: Create files with bad magic/version and assert failure.         *       est_flush_behavior: Verify \flush() calls succeed (mocking OS calls if necessary).     2.  Python Integration Tests:         *       est_corrupt_load.py: Corrupt a .pycauset file header and assert pc.load() raises cleanly.         *       est_oom_resilience.py: Run the \"Torture Test\" (Phase 2) in CI (scaled to runner RAM).     3.  Benchmarks:         *   Run \benchmarks/benchmark_io_smoke.py to ensure header/flush overhead is negligible.         *   Verify AutoSolver fallback latency is acceptable.</p>"},{"location":"internals/plans/completed/R1_SAFETY/#phase-7-documentation-the-manual","title":"Phase 7: Documentation (The Manual)","text":"<p>Goal: Make safety features visible and explain the new guarantees. *   Context: Users need to know about crash consistency and fallback behaviors. Contributors need to understand the file format. *   Deliverables:     1.  Internals Update:         *   Update documentation/internals/MemoryArchitecture.md to document the .pycauset file header format (Magic + Version).         *   Update documentation/internals/Compute Architecture.md to explain the GPU Circuit Breaker and Fallback logic.     2.  Guides Update:         *   Update documentation/guides/Storage and Memory.md to mention crash consistency guarantees and the .pycauset format versioning.     3.  Dev Handbook:         *   Update documentation/dev/Testing &amp; Benchmarks.md with the new safety test patterns.</p>"},{"location":"internals/plans/completed/R1_SAFETY/#3-success-criteria","title":"3. Success Criteria","text":"<ul> <li> Phase 1: Old files fail gracefully; new files load correctly.</li> <li> Phase 2: \"Torture test\" (200GB alloc/free loop) passes on 16GB RAM laptop.</li> <li> Phase 3: Simulated CUDA exception triggers CPU fallback without crashing Python.</li> <li> Phase 4: Code audit confirms FlushFileBuffers usage.</li> <li> Phase 5: .tmp files from killed processes disappear on next run.</li> <li> Phase 6: All new tests pass; benchmarks show &lt;5% regression on IO throughput.</li> <li> Phase 7: All documentation updated per protocol.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/","title":"R1_SHAPES Plan \u2014 NxM Matrices Across The System (End-to-End)","text":"<p>Status: Complete (Phase 0 complete; Phase 1 complete; Phase 2 complete; Phase 3 complete)</p>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#0-purpose-and-scope","title":"0) Purpose and scope","text":"<p>R1_SHAPES is the first \u201cshape-lifts-everything\u201d milestone. The goal is to remove square-only assumptions so later optimization and feature work does not require rewrites.</p> <p>This plan is written to match repo invariants:</p> <ul> <li>Scale-first: do not introduce paths that materialize large out-of-core data.</li> <li>Tiered storage: RAM vs disk is an implementation detail; API must stay stable.</li> <li>Lazy evaluation / metadata-first: prefer flipping metadata to touching data.</li> <li>Centralize policy: avoid scattered shape rules.</li> <li>Warnings vs exceptions: shape mismatches and unsupported shapes must raise deterministically.</li> </ul> <p>Documentation requirement (always on): any new public function/method/class added or behavior changed must be documented per <code>documentation/project/protocols/Documentation Protocol.md</code>.</p> <p>Authoritative higher-level context:</p> <ul> <li>Project roadmap node: <code>documentation/internals/plans/TODO.md</code> \u2192 R1_SHAPES.</li> <li>Square-only map: <code>documentation/dev/Square-only Assumptions.md</code>.</li> <li>Warning/exception rules: <code>documentation/dev/Warnings &amp; Exceptions.md</code>.</li> <li>Philosophy mantra: <code>documentation/project/Philosophy.md</code>.</li> </ul> <p>Documentation note:</p> <p>This file is a planning/spec artifact. User-visible R1 behavior is documented in:</p> <ul> <li>Release 1: Shapes (what shipped)</li> <li>NxM Support Status</li> <li>Matrix Guide and Vector Guide</li> <li>Factory API pages (e.g., pycauset.matrix, pycauset.zeros)</li> </ul> <p>Non-goals (explicit):</p> <ul> <li>No N-D tensors. Only vectors and matrices.</li> <li>No new \u201cphysics\u201d features.</li> <li>Phase 1 does not require making every operation NxM-capable (square-only ops may and should fail fast).</li> </ul> <p>Discoverability requirement: we must maintain an easily discoverable list of which operations are currently disabled or restricted for NxM (and why), so it can be picked up later in the linear algebra TODO step.</p>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#1-decisions-already-made","title":"1) Decisions already made","text":"<p>These are treated as requirements for this plan.</p>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#11-public-naming-conventions-python","title":"1.1 Public naming conventions (Python)","text":"<ul> <li>Lower-case naming is the forward-facing standard for user-level factories, in alignment with NumPy.</li> <li>As part of this milestone, the uppercase factories will be purged from the public API surface (no \u201cdeprecated\u201d aliases, no warnings).</li> </ul> <p>Naming policy going forward:</p> <ul> <li>User-level module functions and factories should be lower-case.</li> <li>Concrete native types remain PascalCase.</li> </ul> <p>Required public factories:</p> <ul> <li><code>pycauset.matrix(source, dtype=None, ...)</code></li> <li><code>pycauset.vector(source, dtype=None, ...)</code></li> </ul> <p>Related creators (also lower-case):</p> <ul> <li><code>pycauset.zeros(shape, dtype=..., ...)</code></li> <li><code>pycauset.ones(shape, dtype=..., ...)</code></li> <li><code>pycauset.empty(shape, dtype=..., ...)</code></li> </ul> <p>Filling:</p> <ul> <li>Provide an analog to NumPy\u2019s <code>ndarray.fill(...)</code> (method-style), for both vectors and matrices.</li> </ul> <p>Additional planned renames (governed by the NumPy alignment protocol):</p> <ul> <li>Ensure the lower-case causal constructor <code>pycauset.causal_matrix(...)</code> exists and is used in-repo.</li> <li>Keep the class <code>pycauset.CausalSet</code> as the canonical type; prefer the lower-case convenience constructor <code>pycauset.causet(...)</code>.</li> </ul> <p>Governing policy: <code>documentation/project/protocols/NumPy Alignment Protocol.md</code>.</p> <p>We should keep optimized native classes in PascalCase (e.g. <code>FloatMatrix</code>) because they represent concrete types rather than user-level constructors.</p>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#12-matrix-factory-semantics-python","title":"1.2 Matrix factory semantics (Python)","text":"<ul> <li><code>pycauset.matrix(...)</code> must behave like NumPy\u2019s array constructor: it takes iterable data (vector-like or matrix-like).</li> <li><code>pycauset.matrix((n, m))</code> must not be interpreted as shape. In NumPy, <code>np.array((n, m))</code> is a 1\u00d72 array; we follow that mental model.</li> </ul> <p>Allocation rule (NumPy-aligned):</p> <ul> <li><code>pycauset.matrix(...)</code> and <code>pycauset.vector(...)</code> construct from data only.</li> <li>Shape-based allocation is done via <code>pycauset.zeros/ones/empty</code>.</li> </ul> <p>Implication:</p> <ul> <li><code>pycauset.matrix(10)</code> is treated like <code>np.array(10)</code> (scalar input). Since scalars/0D are out of scope, this must raise a deterministic exception.</li> <li><code>pycauset.vector(10)</code> likewise should not be \u201callocate a length-10 vector\u201d; use <code>pycauset.zeros((10,), dtype=...)</code> / <code>pycauset.empty((10,), dtype=...)</code>.</li> <li>For empty initialization by shape, introduce NumPy-like creators:</li> <li><code>pycauset.zeros((rows, cols), dtype=...)</code></li> </ul> <p>Also required now:</p> <ul> <li><code>pycauset.ones((rows, cols), dtype=...)</code></li> <li><code>pycauset.empty((rows, cols), dtype=...)</code></li> </ul> <p>Vector allocation uses 1D shapes:</p> <ul> <li><code>pycauset.zeros((n,), dtype=...)</code></li> <li><code>pycauset.ones((n,), dtype=...)</code></li> <li><code>pycauset.empty((n,), dtype=...)</code></li> </ul> <p>Dtype requirement (important): for <code>zeros/ones/empty</code>, <code>dtype</code> must be explicitly provided.</p> <p>Notes:</p> <ul> <li><code>empty</code> may contain arbitrary/uninitialized contents. This is an advanced-user tool; \u201cjunk values\u201d are acceptable. This MUST be stated in the documentation</li> </ul> <p>Policy: If input is not vector- or matrix-shaped, throw a deterministic exception.</p>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#13-shape-dimensionality-constraints","title":"1.3 Shape dimensionality constraints","text":"<ul> <li>Only vectors (1D) and matrices (2D) are supported.</li> <li>Higher-rank nested sequences must be rejected.</li> </ul> <p>Vector creation rule:</p> <ul> <li><code>pycauset.matrix([1,2,3])</code> returns a vector (NumPy mental model: 1D input becomes 1D output).</li> </ul> <p>This raises a design consideration: vectors and matrices are both \u201cmatrices\u201d at the storage level (rows/cols + flags), but are distinct front-end types for ergonomics. The plan below preserves that split: distinct Python factories and Python-visible behaviors; shared backend representation.</p>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#14-shape-and-size-semantics","title":"1.4 <code>shape()</code> and <code>size()</code> semantics","text":"<p><code>shape</code> must behave like NumPy:</p> <ul> <li>Matrices: <code>shape == (rows, cols)</code></li> <li>Vectors: <code>shape == (n,)</code></li> </ul> <p>If there is not already a <code>shape()</code> method, implement it.</p> <ul> <li> <p>Preferred: expose <code>shape</code> as an attribute/property (NumPy-like), and additionally provide <code>shape()</code> as a convenience method for parity with <code>size()</code>.</p> </li> <li> <p><code>size()</code> must become NumPy-like: total number of elements.</p> </li> <li>For a matrix: <code>size = rows * cols</code>.</li> <li>For a vector: <code>size = n</code>.</li> </ul> <p>We do not introduce a replacement for the old \u201csquare dimension\u201d concept (no new <code>dim()</code>/<code>n()</code> API). Code should use <code>rows()</code> / <code>cols()</code> everywhere.</p> <p>This is a breaking semantic change and must be done carefully.</p> <p><code>__len__</code> must be NumPy-like:</p> <ul> <li>For matrices, <code>len(x) == x.shape[0]</code> (rows)</li> <li>For vectors, <code>len(x) == x.shape[0]</code> (n)</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#15-persistence-transpose","title":"1.5 Persistence + transpose","text":"<ul> <li>Persist base dims + transpose flag (and conjugation flag), not \u201cnormalized logical dims\u201d.</li> <li>Transpose must be metadata-only (no full rewrite), consistent with the project\u2019s lazy evaluation mantra.</li> <li>Vectors are a 1D frontend type, but use the same <code>(rows, cols)</code> + flags storage/persistence machinery.</li> </ul> <p>Persistence format decision:</p> <ul> <li>Keep transform state (transpose/scalar/conjugation) in the typed metadata block.</li> <li>Do not introduce additional per-object headers beyond the <code>.pycauset</code> container header; view-state should remain metadata-only.</li> </ul> <p>Vector representation (chosen: Option A / NumPy-like vectors):</p> <ul> <li>Frontend: <code>pycauset.vector(...)</code> creates a 1D vector with <code>shape == (n,)</code>, <code>size() == n</code>, <code>len(v) == n</code>.</li> <li>Transpose behavior: <code>v.T</code> is a no-op (returns a vector view/alias with identical shape).</li> <li>Backend/persistence: vectors are stored using canonical base dims <code>(rows=n, cols=1)</code> plus metadata. On load, the vector frontend is reconstructed (not a 2D matrix), so users never have to reason about <code>n\u00d71</code> vs <code>1\u00d7n</code> for vectors.</li> </ul> <p>Implication for Phase 2 (matmul/matvec semantics): vectors participate in multiplication using NumPy-compatible 1D rules; orientation is handled by operation rules rather than by exposing separate row-vs-column vector types.</p>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#16-initial-dtype-scope","title":"1.6 Initial dtype scope","text":"<ul> <li>Final target: all dense dtypes support NxM.</li> <li>Implementation strategy: start with Float64 dense to establish the pattern, then expand to other dense dtypes.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#17-zero-copy-transpose","title":"1.7 Zero-copy transpose","text":"<ul> <li>Transpose of disk-backed objects must not duplicate storage; it should create a new object/view referencing the same underlying <code>.pycauset</code> data.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#18-square-only-structures","title":"1.8 Square-only structures","text":"<ul> <li>Strict validation: if a structure requires square (by our policy for Phase 1), it must throw on non-square.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#19-backward-compatibility","title":"1.9 Backward compatibility","text":"<ul> <li>Backward compatibility is not a requirement. If we \u201cdeprecate\u201d, we purge.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#110-first-success-criteria","title":"1.10 First success criteria","text":"<p>We care about all three:</p> <ul> <li>Rectangular <code>get/set</code> correctness.</li> <li><code>np.asarray</code> / NumPy roundtrip shape correctness.</li> <li>Persistence save/load preserves <code>(rows, cols)</code> and transpose semantics.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#111-square-only-ops-behavior","title":"1.11 Square-only ops behavior","text":"<ul> <li>Ops that mathematically require square (inverse, det, eigen, etc.) must throw for non-square inputs.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#2-key-architectural-invariant-to-implement","title":"2) Key architectural invariant to implement","text":""},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#21-single-source-of-truth-for-shape","title":"2.1 Single source of truth for shape","text":"<p>Currently the engine has a split-brain:</p> <ul> <li><code>PersistentObject</code> already stores <code>rows_</code> and <code>cols_</code>.</li> <li><code>MatrixBase</code> stores <code>n_</code> and reports <code>rows()==cols()==size()==n_</code>.</li> </ul> <p>For NxM, we must make shape a single coherent concept with a clear definition of:</p> <ul> <li>\u201cbase/storage\u201d shape (what is laid out on disk/RAM)</li> <li>\u201clogical/view\u201d shape (what the user sees after transpose/conjugation flags)</li> </ul> <p>Proposed invariant:</p> <ul> <li><code>PersistentObject.rows_/cols_</code> represent base/storage dims.</li> <li><code>is_transposed</code> flips the logical interpretation.</li> <li><code>MatrixBase.rows()</code> / <code>cols()</code> return logical dims, derived from <code>PersistentObject</code> + flags.</li> </ul> <p>Index mapping for dense row-major storage:</p> <ul> <li>Base layout is row-major with base stride = <code>base_cols</code>.</li> <li>For element reads/writes (<code>M[i, j]</code> and <code>M[i, j] = value</code>):</li> <li>if <code>is_transposed</code>: swap <code>(i,j)</code> before mapping</li> <li><code>idx = i * base_cols + j</code></li> </ul> <p>This preserves the \u201ctranspose is a view flag\u201d design and avoids touching data. But be careful about this implementation because any O(1) operation added to a frequently used method like set or get may accumulate.</p> <p>Implementation note for performance (to keep hot paths hot):</p> <ul> <li>Provide a fast path when <code>is_transposed == false</code> to avoid extra branches/swaps in element access.</li> <li>Keep the mapping logic tiny (ideally inlineable) and avoid allocations.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#22-consequence-update-size-everywhere","title":"2.2 Consequence: update <code>size()</code> everywhere","text":"<p>Once <code>size()</code> becomes total elements, any code that used <code>size()</code> as \u201cdimension N\u201d must be migrated to use <code>rows()</code> / <code>cols()</code>.</p> <p>We should expect many call sites in:</p> <ul> <li><code>src/math/*</code></li> <li>compute routing heuristics that use <code>n_elements</code></li> <li>Python helpers (<code>formatting</code>, <code>persistence</code>, coercion)</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#3-work-breakdown-phased","title":"3) Work breakdown (phased)","text":""},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#phase-0-public-api-lowercase-sweep-purge-uppercase-factories","title":"Phase 0 \u2014 Public API lowercase sweep (purge uppercase factories)","text":"<p>Status: Complete</p> <p>Goal: make <code>pycauset.matrix</code> / <code>pycauset.vector</code> the canonical forward-facing factories, and remove PascalCase factory names from the public surface.</p> <p>Clarification:</p> <ul> <li>\u201cPurge\u201d means removing PascalCase factory names from the module surface.</li> <li>The underlying implementation should be reused; in practice this should be mostly a mechanical rename/sweep (plus doc page renames and a few call-site adjustments where the old name was a class vs function).</li> </ul> <p>Deliverables:</p> <ol> <li>Implement <code>pycauset.matrix</code> and <code>pycauset.vector</code> in the Python facade.</li> <li>Remove uppercase factories from exports and update all internal call sites accordingly.</li> <li>Perform a repo-wide update of documentation, examples, tools, and tests.</li> <li> <p>Ensure docs index + class pages align with the final public names.</p> </li> <li> <p>Add and adopt <code>documentation/project/protocols/NumPy Alignment Protocol.md</code> and obey it for future public surfaces.</p> </li> <li> <p>Apply the protocol-driven renames planned in this milestone:</p> </li> <li>Ensure <code>pycauset.causal_matrix(...)</code> exists and is used in-repo.</li> <li>Ensure <code>pycauset.causet(...)</code> exists and is used where appropriate.</li> </ol> <p>Documentation specifics:</p> <ul> <li>Rename relevant docs pages so they match the final public symbol names.</li> <li>Update roamlinks/mkdocs navigation accordingly (noting the existing docs protocol guidance about <code>.</code> in filenames).</li> </ul> <p>Acceptance criteria:</p> <ul> <li><code>pycauset.matrix</code> and <code>pycauset.vector</code> exist and are used everywhere in-repo.</li> <li><code>pycauset.causal_matrix</code> exists and is used everywhere in-repo.</li> <li>If we add <code>pycauset.causet(...)</code>, it exists and is used everywhere in-repo.</li> <li>Documentation pages and examples reference only the lower-case factories.</li> </ul> <p>Acceptance checklist:</p> <ul> <li>All in-repo references have been migrated (tests, tools, benchmarks, docs, examples).</li> <li>Documentation updated per <code>documentation/project/protocols/Documentation Protocol.md</code> for each renamed public symbol.</li> </ul> <p>Notes:</p> <ul> <li>This step is intentionally large and mechanical; it is worth doing early to avoid rewriting examples twice.</li> <li>Do not emit any messaging like \u201cX is deprecated, use Y\u201d. Old names simply stop existing.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#phase-1-rectangular-safe-dense-objects-end-to-end-float64-first","title":"Phase 1 \u2014 Rectangular-safe dense objects end-to-end (Float64 first)","text":"<p>Status: Complete (validated 2025-12-17)</p> <p>Goal: Rectangular dense Float64 matrix works correctly across allocation, indexing, transpose, NumPy interop, and persistence. Other ops may still be square-only.</p> <p>Deliverables:</p> <ol> <li>C++ core: Rectangular <code>DenseMatrix&lt;double&gt;</code></li> <li>Constructors accept <code>(rows, cols)</code>.</li> <li>Storage allocates <code>rows*cols*sizeof(T)</code>.</li> <li>Bounds checks use logical rows/cols.</li> <li> <p>Transpose toggles metadata and returns a view referencing the same mapper.</p> </li> <li> <p>C++ core: Rectangular-aware <code>MatrixBase</code></p> </li> <li>Remove <code>n_</code> as the authoritative dimension, or ensure it is not used as such.</li> <li> <p>Define <code>rows()/cols()/size()</code> semantics consistently.</p> </li> <li> <p>Factory + persistence plumbing (C++):</p> </li> <li><code>ObjectFactory::{create,load,clone}_matrix</code> must support <code>(rows, cols)</code> for dense.</li> <li> <p>For square-only structures: validate <code>rows==cols</code> and throw <code>std::invalid_argument</code>.</p> </li> <li> <p>Bindings:</p> </li> <li><code>shape</code> property must reflect logical dims.</li> <li><code>__array__</code> must allocate NumPy arrays of shape <code>(rows, cols)</code>.</li> <li> <p>NumPy import (<code>asarray</code> / dense-from-numpy) must accept non-square 2D arrays for dense.</p> </li> <li> <p>Python layer:</p> </li> <li><code>pycauset.matrix</code> must accept rectangular nested sequences and 2D numpy arrays.</li> <li>Add <code>pycauset.zeros/ones/empty((rows, cols), dtype=...)</code> for shape-based matrix creation.</li> <li>Add <code>pycauset.zeros/ones/empty((n,), dtype=...)</code> for shape-based vector creation.</li> <li>Add <code>.fill(value)</code> for matrices and vectors.</li> <li>Ensure <code>shape</code> and <code>shape()</code> exist (NumPy-like), and that <code>size()</code> is total elements.</li> </ol> <p>Creator semantics (important):</p> <ul> <li><code>zeros</code> and <code>ones</code> must perform a full write consistent with their meaning.</li> <li><code>empty</code> may avoid initialization and therefore may contain arbitrary contents.</li> <li> <p>For <code>zeros/ones/empty</code>, <code>dtype</code> must be explicitly provided. Document this (and why!) and throw exception if not passed.</p> </li> <li> <p>Python persistence:</p> </li> <li> <p>Save metadata must store explicit <code>rows</code> and <code>cols</code> based on shape (not <code>size()</code>).</p> </li> <li> <p>Tests:</p> </li> <li>Rectangular creation + <code>get/set</code> edges.</li> <li>Transpose flips logical shape without storage copy.</li> <li>NumPy roundtrip preserves shape.</li> <li>Persistence save/load preserves <code>(rows, cols)</code> + transpose flag.</li> </ul> <p>Acceptance checklist:</p> <ul> <li>Can create a dense Float64 matrix from a 2D rectangular NumPy array; shape preserved.</li> <li>Can create a dense Float64 matrix via <code>pycauset.zeros((rows, cols), dtype=float64)</code>.</li> <li>Can create a dense Float64 vector via <code>pycauset.zeros((n,), dtype=float64)</code>.</li> <li><code>get/set</code> works at edges for rectangular shapes.</li> <li><code>T</code> produces a zero-copy view (no data duplication) with swapped logical shape.</li> <li><code>pycauset.save</code> / <code>pycauset.load</code> roundtrip preserves shape and transpose.</li> <li>Vector persistence roundtrip preserves <code>shape == (n,)</code>.</li> <li>Square-only ops raise deterministic errors for non-square inputs.</li> </ul> <p>Phase 1 completion record (2025-12-17):</p> <ul> <li>Native build + project-native unit tests passed (direct gtest executables produced under <code>build/Release</code>).</li> <li>Python test suite passed: <code>python -m pytest -q tests/python</code>.</li> <li>API + semantics validated end-to-end for rectangular dense numeric matrices:</li> <li><code>rows()/cols()</code> reflect logical dims (transpose is metadata-only),</li> <li><code>size()</code> is total elements (<code>rows * cols</code>),</li> <li>NumPy <code>asarray</code> / <code>np.array(m)</code> roundtrip preserves shape,</li> <li>persistence roundtrip preserves base dims + transpose flag.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#phase-15-expand-dense-dtypes-mechanical","title":"Phase 1.5 \u2014 Expand dense dtypes (mechanical)","text":"<p>Status: Complete (validated 2025-12-17)</p> <p>Once Float64 is stable, extend the same rectangular-safe implementation to:</p> <ul> <li>float32, float16</li> <li>integer dense types</li> <li>complex dense types</li> <li>dense bit matrix (bit-packed) \u2014 requires \u201cstride by cols\u201d, not by <code>n_</code></li> </ul> <p>The intent is to reuse the same invariants and tests, with dtype-specific differences limited to:</p> <ul> <li>element size</li> <li>bit-packed stride computation</li> <li>complex scalar/conjugation safety</li> </ul> <p>Acceptance checklist:</p> <ul> <li>The same rectangular creation + shape + persistence + transpose tests pass for each newly supported dtype.</li> <li>No dtype-specific path reintroduces square-only assumptions.</li> </ul> <p>Phase 1.5 validation note (2025-12-17):</p> <ul> <li>Rectangular allocation + transpose-view shape were smoke-validated for: float16/32/64, int16/32, uint8/64, complex_float16/32/64.</li> <li>Dense <code>bool/bit</code> matrices support rectangular <code>(rows, cols)</code> allocation; bit-packed storage uses a stride derived from <code>cols</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#phase-2-nxm-operation-rules-matmulmatvecvecmat-elementwise","title":"Phase 2 \u2014 NxM operation rules (matmul/matvec/vecmat + elementwise)","text":"<p>Status: Complete (validated 2025-12-17)</p> <p>Not the immediate coding target in Phase 1, but must be planned for:</p> <ul> <li>Matmul must support <code>NxM @ MxK -&gt; NxK</code>.</li> <li>Elementwise ops must require shape equality.</li> <li>Matvec/vecmat must support conventional rules.</li> </ul> <p>Python fallback in <code>pycauset._internal.ops.matmul</code> must be updated accordingly (or must raise a clear error if we intentionally disallow fallback for large problems).</p> <p>Note, the operations need only be implemented at a sequential level. Optimization and parallelization belongs to another plan in TODO.md</p> <p>Deliverable (discoverability): maintain a list of which ops are NxM-enabled vs restricted/square-only, in a location that is obvious from the docs index and/or the project TODO.</p> <p>Phase 2 completion record (2025-12-17):</p> <ul> <li>Already implemented (spillover from Phase 1 work):</li> <li>Matrix-matrix matmul follows the NxM rule (<code>(N,M) @ (M,K) -&gt; (N,K)</code>) for the supported dense numeric types.</li> <li> <p>Elementwise ops enforce shape equality (dimension mismatch throws). What is now true:</p> </li> <li> <p>Matrix-matrix matmul follows NxM rules (<code>(m,k) @ (k,n) -&gt; (m,n)</code>) for supported dense numeric types and bit-packed dense bool.</p> </li> <li>Elementwise ops enforce exact shape equality.</li> <li>Vector <code>@</code> rules are defined and exercised in tests:</li> <li><code>matrix @ vector</code> -&gt; 1D vector</li> <li><code>vector @ matrix</code> -&gt; row-shaped vector view (<code>(1,n)</code>)</li> <li><code>vector @ vector</code> -&gt; scalar dot</li> <li>Python fallback matmul dispatch was updated to prefer native implementations and no longer assumes square outputs.</li> <li>The NxM-enabled vs restricted list is published as a user-facing page (see <code>guides/NxM Support.md</code>).</li> </ul> <p>Acceptance checklist:</p> <ul> <li>Matmul follows NxM rules (<code>(N,M) @ (M,K) -&gt; (N,K)</code>), and vector rules match NumPy 1D semantics.</li> <li>Elementwise ops enforce shape equality.</li> <li>Restricted/square-only ops throw deterministic errors on non-square inputs.</li> <li>The NxM-enabled vs restricted list is published in a discoverable docs location and kept current.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#phase-3-structure-policies-for-inherently-square-vs-shape-flexible","title":"Phase 3 \u2014 Structure policies for \u201cinherently square\u201d vs \u201cshape-flexible\u201d","text":"<p>Status: Complete (validated 2025-12-17)</p> <p>We need explicit policies for:</p> <ul> <li>Triangular / causal matrices: square-only by definition.</li> <li>Symmetric / antisymmetric: square-only.</li> <li>Identity: shape-flexible (rectangular identity-like matrices are supported).</li> <li>Diagonal: square-only.</li> </ul> <p>Decision captured: Diagonal matrices remain square-only in this milestone.</p> <p>Acceptance checklist:</p> <ul> <li>All square-only structures validate <code>rows == cols</code> and raise deterministic exceptions otherwise.</li> <li>Documentation clearly states which structures are square-only.</li> </ul> <p>Phase 3 completion record (2025-12-17):</p> <ul> <li>Square-only validation for inherently-square structures is enforced at creation/load/clone time (triangular/causal, diagonal, symmetric/antisymmetric).</li> <li>Identity matrices are explicitly shape-flexible (rectangular identity-like is supported).</li> <li>The square-only vs shape-flexible policy is documented in <code>documentation/dev/Square-only Assumptions.md</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#4-high-risk-areas-things-we-must-not-get-wrong","title":"4) High-risk areas (things we must not get wrong)","text":"<ol> <li>Accidental materialization / O(NM) zero-filling:</li> <li><code>zeros</code>/<code>ones</code> necessarily imply a full write; the risk is performance and long I/O on out-of-core matrices.</li> <li> <p>Mitigation is explicit API: require <code>dtype</code>, provide <code>empty</code> for fast allocation, and provide <code>.fill(value)</code> to make initialization explicit.</p> </li> <li> <p><code>size()</code> semantic flip ripple:</p> </li> <li>Anything using <code>size()</code> as \u201cdimension\u201d will break.</li> <li> <p>We need a disciplined migration: use <code>rows()/cols()</code> for shape and keep <code>size()</code> only for total elements.</p> </li> <li> <p>Transpose views + CoW:</p> </li> <li> <p>With zero-copy transpose, <code>ensure_unique()</code> must be correct: mutating a transposed view must not mutate the base if shared.</p> </li> <li> <p>Persistence + transpose correctness:</p> </li> <li>Must preserve base dims and flags; loading must reproduce the same logical behavior.</li> </ol>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#5-acceptance-checklist-for-phase-1-float64-rectangular","title":"5) Acceptance checklist for Phase 1 (Float64 rectangular)","text":"<p>Phase 1 is done when all are true:</p> <ul> <li>Can create a dense Float64 matrix from a 2D rectangular NumPy array; shape preserved.</li> <li>Can create a dense Float64 matrix via <code>pycauset.zeros((rows, cols), dtype=float64)</code>.</li> <li><code>get/set</code> works at edges for rectangular shapes.</li> <li><code>T</code> produces a zero-copy view (no data duplication) with swapped logical shape.</li> <li><code>pycauset.save</code> / <code>pycauset.load</code> roundtrip preserves shape and transpose.</li> <li>Square-only ops raise deterministic errors for non-square inputs.</li> </ul>"},{"location":"internals/plans/completed/R1_SHAPES_PLAN/#appendix-a-nxm-support-status-phase-1","title":"Appendix A) NxM support status (Phase 1)","text":"<p>Requirement: keep a simple, easily discoverable list of operations that are NxM-enabled vs NxM-disabled/restricted.</p> <p>Initial intended status (to be validated against the actual exported API during implementation):</p> <ul> <li>Enabled in Phase 1: allocation, indexing, transpose views, NumPy import/export, persistence roundtrip, <code>.fill</code>.</li> <li>Restricted/square-only in Phase 1: inverse, determinant, eigen/symmetric eigen; and any structure whose definition is square-only (triangular, symmetric, antisymmetric, diagonal). Identity is shape-flexible.</li> </ul> <p>This list should live in a place users will actually find (e.g. a dedicated doc page linked from the docs index), not only in an internals plan.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/","title":"R1_STORAGE \u2014 Single-File Persistence Container + Typed Metadata (Release 1)","text":"<p>Status: Implemented for Release 1 (plan + implementation aligned)</p> <p>Last updated: 2025-12-21</p> <p>Documentation note:</p> <p>This file is a planning/spec artifact. User-visible storage behavior and the R1 container format are documented in:</p> <ul> <li><code>documentation/guides/Storage and Memory.md</code> (canonical: snapshots, mutation, caches, and on-disk format)</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#implementation-status-as-of-this-date","title":"Implementation status (as of this date)","text":"<p>This plan\u2019s frozen \u201cFormat summary\u201d is implemented in the Python persistence layer and covered by storage tests.</p> <ul> <li>Implementation: <code>python/pycauset/_internal/persistence.py</code></li> <li>Key tests:</li> <li><code>tests/python/test_storage_hard_break.py</code></li> <li><code>tests/python/test_storage_crash_consistency.py</code></li> <li><code>tests/python/test_storage_debug_tool.py</code></li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#purpose","title":"Purpose","text":"<p>Release 1 needs a single-file <code>.pycauset</code> container format that:</p> <ul> <li>is memory-mappable for large payloads,</li> <li>supports tiered storage and out-of-core workflows,</li> <li>stores sparse, typed, forward-compatible metadata (including <code>properties</code> from R1_PROPERTIES),</li> <li>and allows metadata updates without shifting the payload.</li> </ul> <p>This plan is intentionally about storage mechanics. The semantics of <code>properties</code> (gospel claims, propagation, etc.) are defined in:</p> <ul> <li><code>documentation/internals/plans/completed/R1_PROPERTIES_PLAN.md</code></li> </ul> <p>The key contract between the two plans is:</p> <ul> <li>the C++/Python frontends continue to call the same high-level save/load APIs;</li> <li>only the on-disk representation and the internal storage plumbing changes.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#non-negotiable-constraints","title":"Non-negotiable constraints","text":"<ul> <li>No data scans: persistence code must not require scanning payload to validate metadata.</li> <li>Payload must remain mmap-friendly: large numeric payloads must be accessible via stable offsets.</li> <li>Sparse metadata: missing keys remain missing (unset/default) to preserve tri-state semantics.</li> <li>Forward compatibility: older readers can ignore unknown metadata keys safely.</li> <li>Deterministic layout rules: the same content + metadata must produce deterministic decisions (even if bytes differ due to appended metadata).</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#scope-what-this-plan-does-and-does-not-decide","title":"Scope (what this plan does and does not decide)","text":"<p>This plan specifies the persistence container mechanics and typed metadata encoding.</p> <p>In scope:</p> <ul> <li>A single-file container with stable payload offsets (mmap-friendly).</li> <li>A typed, sparse metadata representation that is forward-compatible.</li> <li>Unambiguous encoding of the metadata taxonomy (identity/header vs view-state vs <code>properties</code> + cached-derived).</li> <li>A crash-safe metadata update mechanism.</li> </ul> <p>Out of scope for R1_STORAGE (must not silently creep in):</p> <ul> <li>Multiple independent objects per <code>.pycauset</code> file (one file = one object).</li> <li>Transparent compression of the payload region (payload must remain directly mappable).</li> <li>\u201cDatabase features\u201d (transactions across multiple files, indexing, etc.).</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#current-state-baseline","title":"Current state (baseline)","text":"<p>There is exactly one on-disk format for <code>.pycauset</code>: the single-file binary container specified below.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#file-format-sketch-release-1-direction","title":"File format sketch (Release 1 direction)","text":""},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#format-summary-frozen-for-r1-implement-exactly","title":"Format summary (frozen for R1; implement exactly)","text":"<p>This section is the Phase 0 contract freeze. It removes ambiguity by specifying exact binary layouts and encoding rules.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#endianness","title":"Endianness","text":"<ul> <li>R1 files are little-endian only.</li> <li>The header includes an endian marker so readers can fail fast and deterministically if opened on an incompatible platform.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#alignment","title":"Alignment","text":"<ul> <li><code>payload_offset</code> MUST be aligned to 4096 bytes (minimum). (Implementations may choose a larger alignment, but it must be a power-of-two multiple of 4096.)</li> <li><code>metadata_offset</code> MUST be aligned to 16 bytes.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#fixed-header-region","title":"Fixed header region","text":"<p>The file begins with a fixed-size header region of 4096 bytes.</p> <ul> <li>It contains:</li> <li>a file preamble, and</li> <li>two header slots (A and B) used for crash-safe pointer updates.</li> </ul> <p>All integer fields are unsigned little-endian unless specified.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#file-preamble-layout-offset-0","title":"File preamble layout (offset 0)","text":"Field Type Notes <code>magic</code> 8 bytes ASCII <code>PYCAUSET</code> <code>format_version</code> u32 R1 = 1 <code>endian</code> u8 1 = little-endian <code>header_bytes</code> u16 R1 = 4096 <code>reserved0</code> u8[1] must be 0 <p>Immediately following the preamble are two fixed-size slots.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#header-slot-layout-a-and-b","title":"Header slot layout (A and B)","text":"<p>Each slot is 128 bytes and appears twice:</p> <ul> <li>preamble is exactly 16 bytes; slot A begins at offset 16</li> <li>slot B begins at offset 16 + 128</li> </ul> <p>Slot layout:</p> Field Type Notes <code>generation</code> u64 monotonic counter; higher wins <code>payload_offset</code> u64 aligned to 4096 <code>payload_length</code> u64 bytes <code>metadata_offset</code> u64 aligned to 16 <code>metadata_length</code> u64 bytes <code>hot_offset</code> u64 0 in R1 unless implemented <code>hot_length</code> u64 0 in R1 unless implemented <code>slot_crc32</code> u32 CRC32 of the first 7 fields (56 bytes) <code>slot_reserved</code> u8[68] must be 0 (future expansion) <p>Validity rules:</p> <ul> <li>A slot is valid iff:</li> <li><code>slot_crc32</code> matches, AND</li> <li><code>payload_offset/payload_length/metadata_offset/metadata_length</code> are in-range for the file size, AND</li> <li>required alignments are satisfied.</li> <li>The active slot is the valid slot with the highest <code>generation</code>.</li> <li>If neither slot is valid, loading fails.</li> </ul> <p>Crash-consistent update rule:</p> <p>1) Write the new metadata block at the end of the file. 2) Ensure it is fully written (and flushed if the implementation uses explicit flush). 3) Write the inactive header slot with <code>generation = active.generation + 1</code> and the new metadata pointer. 4) (Optional but recommended) Flush the header region.</p> <p>This guarantees \\(O(1)\\) load (choose slot; validate pointer) with no scanning.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#payload-region","title":"Payload region","text":"<ul> <li>The payload is a raw backing store identical to what current native objects can mmap.</li> <li>The payload begins at <code>payload_offset</code> and spans <code>payload_length</code> bytes.</li> <li>Payload interpretation is defined by identity/header metadata plus a payload layout descriptor (see below).</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#metadata-blocks-append-only","title":"Metadata blocks (append-only)","text":"<p>Metadata is stored as one or more blocks appended after the payload. The header slot points at the authoritative block.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#metadata-block-framing-at-metadata_offset","title":"Metadata block framing (at <code>metadata_offset</code>)","text":"Field Type Notes <code>block_magic</code> 4 bytes ASCII <code>PCMB</code> <code>block_version</code> u32 R1 = 1 <code>encoding_version</code> u32 typed-metadata encoding version; R1 = 1 <code>reserved0</code> u32 must be 0 <code>payload_length</code> u64 bytes of encoded metadata payload <code>payload_crc32</code> u32 CRC32 of encoded metadata payload <code>reserved1</code> u32 must be 0 <code>payload</code> bytes length = <code>payload_length</code> <p>Validity rules:</p> <ul> <li>If the framing fields are malformed or <code>payload_crc32</code> fails, loading fails deterministically.</li> <li>Readers must reject unknown <code>block_version</code> or <code>encoding_version</code> (clear error).</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#typed-metadata-encoding-v1-r1-encoding_version-1","title":"Typed metadata encoding v1 (R1 = encoding_version 1)","text":"<p>Encoded metadata payload represents a single top-level map.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#limits-safety-deterministic-failure","title":"Limits (safety; deterministic failure)","text":"<ul> <li>Max recursion depth: 32</li> <li>Max map entries: 1,000,000 (practical cap; R1 typical is tiny)</li> <li>Max string length: 16 MiB</li> <li>Max bytes length: 1 GiB (for very large blob references; prefer external blocks)</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#value-tags","title":"Value tags","text":"<p>Each value is encoded as a 1-byte tag followed by a tag-specific payload:</p> Tag Meaning Encoding 0x01 Bool u8 (0/1) 0x02 I64 i64 0x03 U64 u64 0x04 F64 f64 0x05 String u32 byte_len + UTF-8 bytes 0x06 Bytes u32 byte_len + bytes 0x07 Array u32 count + <code>count</code> values (each value is tag+payload) 0x08 Map u32 count + <code>count</code> key/value pairs <p>Map encoding:</p> <ul> <li><code>Map</code> value payload is:</li> <li>u32 count</li> <li>repeated <code>count</code> times:<ul> <li>key: u16 key_len + UTF-8 bytes</li> <li>value: encoded value (tag + payload)</li> </ul> </li> </ul> <p>Notes:</p> <ul> <li>This encoding is sparse by construction: absent keys are absent.</li> <li>Forward compatibility: unknown keys and even unknown nested maps must be skippable by type/length framing.</li> <li>Numeric width/sign: R1 standardizes on <code>I64</code>/<code>U64</code>/<code>F64</code>. If smaller widths are needed in later releases, they are added as new tags without breaking R1 readers.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#required-metadata-keys-r1-minimum","title":"Required metadata keys (R1 minimum)","text":"<p>The top-level map MUST contain (at minimum) enough identity/header metadata to interpret the payload:</p> <ul> <li><code>rows</code>: U64</li> <li><code>cols</code>: U64</li> <li><code>matrix_type</code>: String (stable name)</li> <li><code>data_type</code>: String (stable name)</li> <li><code>payload_layout</code>: Map (payload layout descriptor)</li> </ul> <p><code>payload_layout</code> (descriptor) must be a small Map. R1 minimum:</p> <ul> <li><code>kind</code>: String (e.g., <code>raw_dense</code>, <code>raw_triangular</code>, <code>raw_bitpacked</code>)</li> <li><code>params</code>: Map (optional; small numeric/string parameters)</li> </ul> <p>Reserved namespaces in the same top-level map:</p> <ul> <li><code>view</code>: Map (system-managed view-state)</li> <li><code>properties</code>: Map (user-facing gospel assertions; values typed; missing keys remain missing)</li> <li><code>cached</code>: Map (cached-derived values; values are Maps containing <code>value</code> + <code>signature</code>)</li> <li><code>provenance</code>: Map (optional; non-semantic provenance)</li> </ul> <p>Readers must ignore unknown top-level keys.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#high-level-layout","title":"High-level layout","text":"<ul> <li>Fixed-size preamble/header at the front.</li> <li>Large payload region (matrix/vector binary data) at a stable offset.</li> <li>One or more metadata blocks appended (append-only updates).</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#header-requirements","title":"Header requirements","text":"<p>Header must contain (at minimum):</p> <ul> <li>magic/version</li> <li>endian marker</li> <li>payload offset + payload length</li> <li>current metadata offset + metadata length</li> <li>optional: checksum/CRC for header and metadata blocks (payload checksum optional)</li> </ul> <p>Versioning requirements:</p> <ul> <li>Header includes a format version.</li> <li>Metadata blocks include a metadata encoding version (may match the header version, but must be explicit).</li> <li>Readers must be able to reject unsupported versions deterministically (clear error), without scanning payload.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#metadata-block-requirements","title":"Metadata block requirements","text":"<p>Metadata blocks are self-describing and typed:</p> <ul> <li>keys are strings (stable names)</li> <li>each value has a type tag (bool/int/float/string/bytes/array/map)</li> <li>numeric values include width/sign where relevant</li> </ul> <p>Sparse encoding is mandatory:</p> <ul> <li>missing key means \u201cunset\u201d, not <code>False</code></li> <li>no requirement to materialize defaults in-file</li> </ul> <p>Reserved key namespaces (required):</p> <p>To keep metadata unambiguous and forward-compatible, the typed metadata map reserves these top-level keys:</p> <ul> <li><code>view</code>: view-state metadata (system-managed)</li> <li><code>properties</code>: user-facing gospel semantic assertions</li> <li><code>cached</code> (or <code>caches</code>): cached-derived values + validity metadata</li> <li><code>provenance</code>: non-semantic provenance (e.g., seed/generation parameters)</li> </ul> <p>Readers must ignore unknown keys.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#metadata-taxonomy-contract-prevents-confusion","title":"Metadata taxonomy (contract; prevents confusion)","text":"<p>R1_STORAGE must support (and clearly separate) three kinds of metadata. This is a core clarity requirement: it prevents \u201crandom metadata bags\u201d and prevents users/contributors from mixing semantic assertions with system-managed state.</p> <p>1) Header / identity metadata (system-managed)   - Purpose: define what the object is and how to interpret payload bytes.   - Examples: <code>rows</code>, <code>cols</code>, <code>matrix_type</code>, <code>data_type</code>, and any required payload layout descriptor.   - Notes:     - These are not \u201cproperties\u201d in the user sense.     - These values are required to correctly load/interpret payload.</p> <p>Identity/payload layout note:</p> <ul> <li><code>matrix_type</code> and <code>data_type</code> are not always sufficient to describe raw payload layout (e.g., bit-packed layouts, packed triangular storage, row/col-major variants, or future blocked layouts).</li> <li>R1_STORAGE must be able to store a minimal payload layout descriptor (string/enum + small parameters) so payload interpretation never relies on \u201cmagic implied by type names\u201d.</li> </ul> <p>2) View-state metadata (system-managed; produced by transforms)   - Purpose: represent cheap, metadata-only transforms on top of the same payload.   - Examples: <code>scalar</code>, transpose/conjugation/adjoint state.   - Notes:     - Users change view-state by applying transforms (e.g., <code>.T</code>, conjugation, scaling), not by \u201casserting\u201d it as a property.     - View-state participates in cache validity signatures.</p> <p>3) User-facing <code>properties</code> (single mapping; two semantic classes)   - Purpose: a single mapping exposed as <code>obj.properties</code>.   - It contains:     - Semantic assertions (gospel): structure/special-case hints like <code>is_upper_triangular</code>, <code>is_unitary</code>, <code>is_identity</code>. Never truth-validated.     - Cached-derived values: <code>trace</code>, <code>determinant</code>, <code>rank</code>, <code>norm</code>, etc. Validity-checked and may be cleared.   - Critical rule: cached-derived values are user-facing via clean keys (e.g., <code>trace</code>) but are persisted explicitly as caches (see below).</p> <p>This taxonomy is defined semantically by R1_PROPERTIES, but R1_STORAGE is responsible for encoding it unambiguously on disk.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#on-disk-encoding-conventions-required","title":"On-disk encoding conventions (required)","text":"<p>To keep user-facing keys clean while keeping persistence honest, cached-derived values are not stored as top-level keys like <code>cached_trace</code>.</p> <p>Instead, metadata uses two top-level sections:</p> <ul> <li><code>properties</code>: stores gospel semantic assertions (typed; tri-state semantics via key presence).</li> <li><code>cached</code> / <code>caches</code>: stores cached-derived values (typed) alongside validity metadata.</li> </ul> <p>The <code>view</code> section is also reserved (system-managed) and is the canonical location for view-state values when they are persisted.</p> <p>Conceptual shape (illustrative; exact type tags depend on the binary metadata encoding):</p> <pre><code>{\n  \"rows\": 1000,\n  \"cols\": 1000,\n  \"matrix_type\": \"CAUSAL\",\n  \"data_type\": \"BIT\",\n\n  \"view\": {\n    \"scalar\": 1.0,\n    \"is_transposed\": false,\n    \"is_conjugated\": false\n  },\n\n  \"properties\": {\n    \"is_unitary\": true\n  },\n\n  \"cached\": {\n    \"trace\": {\n      \"value\": 1000.0,\n      \"signature\": {\n        \"payload_epoch\": 17,\n        \"view_signature\": \"...\"\n      }\n    }\n  }\n}\n</code></pre> <p>Notes:</p> <ul> <li>The specific serialization of <code>signature</code> is an implementation detail, but it must be possible to validate in \\(O(1)\\) during cache lookup.</li> <li>The binary typed metadata block may choose not to literally nest <code>view</code> as shown above; what matters is that view-state is encoded separately from <code>properties</code> and separately from cached-derived values.</li> </ul> <p>R1 decision: <code>view</code> is a reserved namespace and is the canonical on-disk location for persisted view-state values. The exact internal encoding may vary, but the serialized schema must preserve the separation.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#update-strategy","title":"Update strategy","text":"<ul> <li>Updating metadata must not move payload.</li> <li>Preferred mechanism: append a new metadata block and atomically update the header pointer.</li> <li>A reader uses the header\u2019s \u201ccurrent metadata pointer\u201d to find the authoritative block.</li> </ul> <p>Crash-consistency requirements (must be explicit in implementation):</p> <ul> <li>Metadata updates must be safe under process crash/power loss.</li> <li>The reader must not require scanning the file to recover.</li> </ul> <p>One acceptable approach:</p> <ul> <li>Maintain two header slots (A/B) with:</li> <li>a monotonically increasing generation counter,</li> <li>the current metadata pointer (offset/length), and</li> <li>a checksum.</li> <li>An update writes the new metadata block, then writes the next header slot with a higher generation.</li> <li>On load, the reader picks the highest-generation header slot with a valid checksum.</li> </ul> <p>This keeps update/read \\(O(1)\\) and avoids \u201csearch backwards for the last valid block\u201d.</p> <p>Alignment requirements (practical; must be enforced):</p> <ul> <li>Payload offsets must be aligned to OS mmap granularity (page size).</li> <li>Metadata block offsets should also be aligned (at least 8/16 bytes) for simple parsing and predictable IO.</li> </ul> <p>Large-file requirements (must be enforced):</p> <ul> <li>All offsets/lengths are 64-bit.</li> <li>The format must support payloads larger than 4GB on all supported OSes.</li> </ul> <p>Mutable vs append-only metadata (important for practicality):</p> <ul> <li>Append-only metadata blocks are ideal for occasional updates (save-time metadata, cached-derived values, property edits).</li> <li>Some fields change extremely frequently during normal use (e.g., payload content epoch). Persisting those by appending a new metadata block per mutation would bloat files.</li> </ul> <p>R1 note (implemented):</p> <ul> <li>R1 does not persist a per-mutation payload epoch in-file. The header slot fields <code>hot_offset/hot_length</code> remain <code>0</code>.</li> <li>Frequently-changing runtime state (e.g., mutation epochs used for runtime cache invalidation) is maintained in-memory.</li> <li>Persisted cached-derived validity relies on the persisted snapshot identity (<code>payload_uuid</code>) plus a compact view-state signature.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#snapshot-immutability-caches-documented","title":"Snapshot immutability + caches (documented)","text":"<p>This plan does not duplicate snapshot/caching semantics.</p> <p>Canonical docs:</p> <ul> <li>guides/Storage and Memory</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#integration-contract-with-r1_properties","title":"Integration contract with R1_PROPERTIES","text":"<ul> <li>R1_PROPERTIES defines the semantics of <code>obj.properties</code> (gospel assertions + cached-derived values).</li> <li>Storage must preserve, without scans:</li> <li>key presence vs absence (tri-state semantics via missing keys),</li> <li>typed values,</li> <li>and unknown keys (pass-through / forward compatibility).</li> </ul> <p>Load/save bridging rules (required):</p> <ul> <li>On load:</li> <li><code>properties.*</code> become entries in <code>obj.properties</code>.</li> <li><code>cached.*</code> entries are surfaced as <code>obj.properties</code> entries (e.g., <code>cached.trace</code> \u2192 <code>obj.properties[\"trace\"]</code>) only if their dependency signature matches the restored object state; otherwise they are ignored/cleared.</li> <li>On save:</li> <li>gospel assertions are written under <code>properties.*</code>.</li> <li>cached-derived values are written under <code>cached.*</code> with validity metadata.</li> <li>cached-derived values are never written as top-level keys like <code>cached_trace</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#staging-compatibility","title":"Staging / compatibility","text":"<ul> <li>R1 may need a transition period where both formats can be read.</li> <li>Writing should be single-file by default once implemented.</li> <li>If dual-read exists, it must be explicit and testable (no silent ambiguity).</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#phased-execution-plan-sizeable-implementation-checklist","title":"Phased execution plan (sizeable; implementation checklist)","text":"<p>This section breaks R1_STORAGE into large, verifiable phases. Each phase has:</p> <ul> <li>Goal (what is proven true at the end)</li> <li>Work (what must be implemented/decided)</li> <li>Deliverables (artifacts you can point to)</li> <li>Acceptance criteria (what must pass)</li> </ul> <p>Important: phases are ordered to minimize churn. Do not start a later phase until the earlier phase\u2019s acceptance criteria are met.</p>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#phase-0-contract-freeze-format-invariants","title":"Phase 0 \u2014 Contract freeze (format + invariants)","text":"<p>Goal:</p> <ul> <li>The on-disk contract is frozen enough that implementation can begin without rediscovering format questions mid-flight.</li> </ul> <p>Work (must be decided in writing):</p> <ul> <li>Exact binary header layout:</li> <li>magic bytes, format version, endian marker</li> <li>two header slots (A/B) structure: generation counter, metadata pointer, payload pointer, checksums</li> <li>field widths (must be 64-bit for offsets/lengths) and alignment/padding rules</li> <li>Exact metadata block framing:</li> <li>metadata block magic/version, length, checksum</li> <li>how unknown keys are skipped without scanning</li> <li>Exact typed metadata encoding v1:</li> <li>supported types for R1 (bool/int/float/string/bytes/array/map)</li> <li>how numeric widths/sign are represented</li> <li>canonical string encoding (UTF-8)</li> <li>max key length / reasonable limits</li> <li>Exact payload layout descriptor contract:</li> <li>where it lives (identity/header metadata)</li> <li>what parameters it may contain</li> <li>the rule that payload interpretation never relies on \u201cimplied by type name\u201d</li> <li>Explicit read/write policy for reserved namespaces:</li> <li><code>view</code>, <code>properties</code>, <code>cached</code>/<code>caches</code>, <code>provenance</code></li> <li>what \u201cignore unknown keys\u201d means for each namespace</li> <li>Explicit crash-consistency rule (no scan recovery):</li> <li>write ordering (data/metadata/header)</li> <li>what constitutes a valid header slot</li> <li>Explicit large-file + alignment guarantees:</li> <li>mmap alignment requirements</li> <li>support for &gt;4GB payloads</li> </ul> <p>Deliverables:</p> <ul> <li>This plan updated with the frozen choices above (no ambiguous \u201cimplementation detail\u201d for core layout).</li> <li>A short \u201cformat summary\u201d section suitable for implementers to copy into code comments.</li> </ul> <p>Acceptance criteria:</p> <ul> <li>A new contributor can implement a reader/writer without asking format questions.</li> <li>The plan\u2019s crash-consistency story is \\(O(1)\\) and does not require \u201cscan backwards for last block\u201d.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#phase-1-minimal-container-readwrite","title":"Phase 1 \u2014 Minimal container (read/write)","text":"<p>Goal:</p> <ul> <li><code>pycauset.save()</code> writes the single-file container.</li> <li><code>pycauset.load()</code> loads the single-file container.</li> </ul> <p>Work (must be implemented):</p> <ul> <li>Reject non-container inputs deterministically (fail fast if magic mismatch).</li> <li>Implement new writer:</li> <li>write header slot A (or both slots) in an initial \u201cempty metadata\u201d state</li> <li>write payload at an aligned offset (stable)</li> <li>write metadata block (at least identity + view-state) and commit pointer via header slot update</li> <li>Implement new reader:</li> <li>choose valid header slot (A/B) by generation + checksum</li> <li>validate referenced metadata block (checksum/length)</li> <li>compute payload offset and pass it to native <code>_from_storage(...)</code> exactly as today</li> <li>Enforce deterministic failure:</li> <li>invalid header \u2192 fail</li> <li>invalid referenced metadata block \u2192 fail</li> <li>no \u201ctry to find a later block\u201d</li> </ul> <p>Deliverables:</p> <ul> <li>New container support implemented in the persistence layer (no API changes).</li> <li>Only one format is supported.</li> </ul> <p>Acceptance criteria:</p> <ul> <li>Any file that is not the container format fails deterministically.</li> <li>New files are single-file containers and still mmap correctly via stable payload offsets.</li> <li>A corrupted header or metadata pointer fails deterministically (no scanning).</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#phase-2-typed-metadata-v1-taxonomy-enforcement","title":"Phase 2 \u2014 Typed metadata v1 + taxonomy enforcement","text":"<p>Goal:</p> <ul> <li>The new container stores and restores the metadata taxonomy unambiguously and sparsely.</li> </ul> <p>Work:</p> <ul> <li>Encode/decode typed metadata blocks with:</li> <li>reserved namespaces present only when needed</li> <li>missing keys remain missing (never auto-materialize defaults)</li> <li>unknown keys ignored/preserved as appropriate</li> <li>Establish the minimal identity/header metadata set that must be persisted for all objects.</li> <li>Persist and restore view-state under <code>view</code>.</li> </ul> <p>Deliverables:</p> <ul> <li>Typed metadata block implementation is stable and versioned.</li> <li>A documented mapping from in-memory state \u2192 on-disk namespaces.</li> </ul> <p>Acceptance criteria:</p> <ul> <li>Round-trip preserves:</li> <li>key presence vs absence (tri-state semantics via missing keys),</li> <li>typed values,</li> <li>unknown keys (forward compatibility) without breaking load.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#phase-3-cache-persistence-integration-including-inverse","title":"Phase 3 \u2014 Cache persistence integration (including inverse)","text":"<p>Goal:</p> <ul> <li>Cached-derived values are persisted under <code>cached.*</code> with validity metadata.</li> <li>\u201cExtra blobs\u201d (e.g., an inverse payload) have an R1 home as independent <code>.pycauset</code> objects referenced from the base snapshot (the sibling object store model), without any archive/member-based packaging.</li> </ul> <p>Work:</p> <ul> <li>Define how <code>cached.*</code> entries are stored (value + signature) in typed metadata.</li> <li>Implement load/save bridging:</li> <li>surface valid cached-derived values into <code>obj.properties</code> on load</li> <li>write them back under <code>cached.*</code> on save</li> <li>Replace extra artifacts (e.g., an inverse payload) with a container-native mechanism:</li> <li>either as named typed-metadata bytes entries, or</li> <li>as appended named data blocks referenced by metadata (preferred for large blobs)</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#definition-big-blob-cache-r1-decision","title":"Definition: \u201cbig blob cache\u201d (R1 decision)","text":"<p>A cached-derived value is a big blob cache iff persisting it requires referring to the contents of another <code>PersistentObject</code> (because the cached value is too large to store directly in typed metadata).</p> <p>Examples:</p> <ul> <li>The inverse matrix of a matrix.</li> <li>Large factorization artifacts.</li> </ul> <p>Non-examples:</p> <ul> <li><code>trace</code>, <code>rank</code>, <code>determinant</code> when represented as small typed values inside <code>cached.*</code>.</li> </ul> <p>R1 rule:</p> <ul> <li>Big blob caches must be persisted as independent storage objects.</li> <li>The base object stores only a typed reference (link) under <code>cached.*</code>.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#big-blob-cache-protocol-r1-direction-implement-safely","title":"Big blob cache protocol (R1 direction; implement safely)","text":"<p>Goal: enable \u201cdisk is infinite, compute time is finite\u201d persistence without making the base file fragile.</p> <p>Storage shape:</p> <ul> <li>A big-blob cached artifact is stored as its own <code>.pycauset</code> container (a normal <code>PersistentObject</code>).</li> <li>The base object stores a link to it under <code>cached.&lt;name&gt;</code> (e.g., <code>cached.inverse</code>).</li> </ul> <p>Minimum link fields (typed metadata):</p> <ul> <li><code>ref_kind</code>: String (<code>sibling_object_store</code>)</li> <li><code>object_id</code>: String (UUID hex)</li> <li><code>signature</code>: Map (validity identity; must be checkable in \\(O(1)\\))</li> </ul> <p>On-disk placement (R1):</p> <ul> <li>Big-blob objects live next to the base snapshot in <code>BASE.pycauset.objects/&lt;object_id&gt;.pycauset</code>.</li> </ul> <p>Signature requirements (no payload scans):</p> <ul> <li>Must include a persisted snapshot identity for the base payload (e.g., <code>payload_epoch</code> or a <code>payload_uuid</code>-style identifier that changes when the payload bytes change during persistence).</li> <li>Must include view-state identity if view affects the meaning of the cached value (e.g., transpose/scalar).</li> </ul> <p>Crash-consistent write ordering (must not leave dangling half-written references):</p> <p>1) Write the big-blob object completely (prefer temp name). 2) Make it durable enough for the platform (flush if used). 3) Atomically publish it (rename to final path/id). 4) Append a new metadata block to the base file linking to it. 5) Commit the base metadata pointer via the inactive A/B header slot.</p> <p>Failure semantics (R1 decision; aligns with Warnings &amp; Exceptions):</p> <ul> <li>If a big-blob cache link is missing, stale, or points to a corrupt object:</li> <li>treat it as a cache miss (ignore/clear the cached entry),</li> <li>emit a user-facing warning (<code>PyCausetStorageWarning</code>; no implicit recompute),</li> <li>continue loading the base object.</li> </ul> <p>Deliverables:</p> <ul> <li>Cached-derived metadata persists in the new format.</li> <li>Inverse caching does not depend on any archive/member-based packaging.</li> </ul> <p>Acceptance criteria:</p> <ul> <li>Cache lookups remain \\(O(1)\\).</li> <li>Cached-derived values are never treated as gospel structure.</li> <li>If signatures are malformed or stale, cached entries are ignored/cleared.</li> </ul> <p>Additional acceptance criteria (big blob caches):</p> <ul> <li>The base object never points to a partially-written big-blob object after a crash.</li> <li>Missing/corrupt big-blob caches are never implicitly recomputed; regeneration must be explicitly requested by the user.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#phase-4-nativec-persistence-alignment-if-applicable-in-r1","title":"Phase 4 \u2014 Native/C++ persistence alignment (if applicable in R1)","text":"<p>Goal:</p> <ul> <li>The native layer can open <code>.pycauset</code> files via payload offset/length without any container-implementation assumptions beyond the frozen contract.</li> </ul> <p>Work:</p> <ul> <li>Identify all places in C++ that assume \u201craw backing file starts at offset 0\u201d vs \u201cpayload has an offset\u201d.</li> <li>Ensure that native constructors that accept <code>(path, offset, ...)</code> continue to work.</li> <li>If native code has its own file writer, either:</li> <li>switch it to write the new format, or</li> <li>explicitly declare Python as the writer for R1 and keep native as read-only for new format.</li> </ul> <p>Deliverables:</p> <ul> <li>Updated native loader/writer behavior documented in internals.</li> </ul> <p>Acceptance criteria:</p> <ul> <li>New-format files work for at least the core matrix/vector types on the supported platforms.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#phase-5-hard-break-policy-single-format","title":"Phase 5 \u2014 Hard-break policy (single format)","text":"<p>Goal:</p> <ul> <li>Pre-alpha policy: when the file format changes, it changes.</li> <li>There are no fallback readers, migration paths, or compatibility layers.</li> </ul> <p>Work:</p> <ul> <li>Ensure error messages clearly distinguish:</li> <li>\u201cmagic mismatch / not a <code>.pycauset</code> container\u201d</li> <li>\u201ccontainer header invalid\u201d</li> <li>\u201ccontainer metadata invalid\u201d</li> </ul> <p>Deliverables:</p> <ul> <li>Clear error messages and tests confirming no fallback behavior.</li> </ul> <p>Acceptance criteria:</p> <ul> <li>No fallback behavior.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#phase-6-testing-debugging-extensive-final-engineering-gate","title":"Phase 6 \u2014 Testing + debugging (EXTENSIVE; final engineering gate)","text":"<p>Goal:</p> <ul> <li>Storage is reliable on real machines (Windows included), debuggable under failure, and does not violate the \u201cno scans / stable mmap offsets\u201d constraints.</li> </ul> <p>Work: unit tests (format invariants)</p> <ul> <li>Header slot selection:</li> <li>valid A/invalid B \u2192 choose A</li> <li>invalid A/valid B \u2192 choose B</li> <li>both invalid \u2192 fail with clear error</li> <li>Checksum behavior:</li> <li>corrupt 1 byte in header \u2192 reject</li> <li>corrupt 1 byte in metadata block \u2192 reject</li> <li>Pointer validation:</li> <li>metadata offset points outside file \u2192 reject</li> <li>payload offset not aligned \u2192 reject (or fail deterministically)</li> <li>Sparse semantics:</li> <li>missing key remains missing after round-trip</li> <li>explicit <code>False</code> remains explicit</li> </ul> <p>Work: integration tests (real objects)</p> <ul> <li>Round-trip for representative object types:</li> <li>triangular bit matrix</li> <li>dense bit matrix (rectangular)</li> <li>float matrix</li> <li>integer matrix</li> <li>vectors (int/float/bit) where available</li> <li>View-state persistence:</li> <li>transposed + conjugated flags survive save/load</li> <li>scalar survives save/load</li> <li>Cache persistence:</li> <li>cached-derived values (trace/determinant/rank/norm) persist and are validated</li> <li>stale signatures are cleared/ignored</li> <li>CausalSet persistence:</li> <li>spacetime metadata round-trips</li> <li>underlying matrix remains mmap-backed and correct shape</li> </ul> <p>Work: format mismatch tests</p> <ul> <li>If magic mismatches, fail fast with a clear error.</li> <li>If header is present but invalid (CRC/offsets), fail deterministically.</li> </ul> <p>Work: crash-consistency tests (must not require scanning)</p> <ul> <li>Simulate an interrupted update sequence:</li> <li>write metadata block but not header pointer \u2192 old state loads</li> <li>write header pointer but corrupt new metadata block \u2192 load fails deterministically</li> <li>Verify that \u201crecovery\u201d is \\(O(1)\\) (choose header slot, validate pointer, stop).</li> </ul> <p>Work: platform/IO tests (Windows pain points)</p> <ul> <li>Unicode paths (already tested; must continue to pass).</li> <li>Nested directories creation.</li> <li>Overwrite behavior:</li> <li>saving twice to the same path results in a valid file</li> <li>File locking:</li> <li>ensure handles are closed so test cleanup does not fail</li> </ul> <p>Work: performance sanity (non-benchmark gate)</p> <ul> <li>Confirm new load path does not read payload eagerly.</li> <li>Confirm payload offset remains stable and mmap-friendly.</li> </ul> <p>Debugging runbook (must be documented and validated during Phase 6)</p> <ul> <li>\u201cHow to tell what format a file is\u201d (magic bytes; minimal inspection).</li> <li>\u201cHow to inspect header slot A/B\u201d (fields + checksum).</li> <li>\u201cHow to inspect metadata block framing\u201d (length/checksum/version).</li> <li>\u201cHow to debug a failed load\u201d with a step-by-step checklist:   1) confirm file size   2) confirm header magic/version   3) validate chosen header slot checksum   4) validate metadata pointer range   5) validate metadata block checksum   6) confirm payload pointer range/alignment</li> <li>Provide at least one developer tool path:</li> <li>either a small debug helper function (Python) or a CLI script that prints header/metadata summary</li> <li>and a test that uses it on a known-good file</li> </ul> <p>Acceptance criteria:</p> <ul> <li>All storage-related Python tests pass.</li> <li>Crash-consistency tests demonstrate \\(O(1)\\) recovery (no scanning).</li> <li>Known Windows cleanup/file-lock issues are addressed (tests do not leave files open).</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#phase-7-documentation-extensive-per-documentation-protocol","title":"Phase 7 \u2014 Documentation (EXTENSIVE; per Documentation Protocol)","text":"<p>Goal:</p> <ul> <li>The storage format change has a clear, hard-to-miss doc footprint for users and contributors.</li> </ul> <p>Doc impact assessment (required; classify the change):</p> <ul> <li>Internals change: new persistence container, crash-consistency model, metadata encoding.</li> <li>Behavior: <code>.pycauset</code> is a binary container (not an archive).</li> <li>Potential performance change: faster/more direct mmap behavior and reduced container overhead.</li> </ul> <p>Work (follow <code>documentation/project/protocols/Documentation Protocol.md</code>):</p> <p>API reference (if public behavior changes):</p> <ul> <li>Review whether <code>pycauset.save</code> / <code>pycauset.load</code> need explicit documentation updates (same signature, but different file format).</li> <li>If so, update the relevant pages under <code>documentation/docs/</code> with:</li> <li>what changed</li> <li>compatibility notes</li> <li>exceptions/failure modes</li> <li>minimal example</li> </ul> <p>Guides (user workflows):</p> <ul> <li>Update (prefer editing existing) the storage guide(s) to cover:</li> <li>what a <code>.pycauset</code> file is now</li> <li>how to move/copy it safely</li> <li>what \u201cmmap-friendly payload\u201d means in practice</li> <li>what users should do if a file is corrupted (and what they cannot do)</li> <li>Ensure examples are current and do not reference archive members.</li> </ul> <p>Internals (contributor/maintainer):</p> <ul> <li>Ensure this plan remains the canonical \u201chow it works\u201d reference and add:</li> <li>a concise \u201cformat summary\u201d section</li> <li>explicit invariants and failure modes</li> <li>where the code lives (Python and/or C++)</li> <li>how to extend typed metadata safely (new keys/types)</li> <li>Update other internals pages that reference the old archive-style persistence to match reality.</li> </ul> <p>Dev handbook (process changes):</p> <ul> <li>If build/test workflows change (new scripts/tools), document them under <code>documentation/dev/</code>.</li> </ul> <p>Linking + See also (required):</p> <ul> <li>Add/verify \u201cSee also\u201d sections for the key touched docs (3\u20138 links).</li> <li>Use explicit roamlinks paths where possible.</li> </ul> <p>Documentation acceptance criteria (Definition of Done):</p> <ul> <li>The doc footprint answers:</li> <li>What changed?</li> <li>Who is it for?</li> <li>How do I use it?</li> <li>Constraints and failure modes?</li> <li>No stale references to archive-style inspection remain in user-facing docs.</li> <li>All updated examples match current APIs.</li> </ul> <p>Corruption and error handling (required):</p> <p>Corruption and error handling (required):</p> <ul> <li>If the header checksum fails (or both header slots are invalid), loading must fail with a clear error.</li> <li>If a referenced metadata block fails its checksum/length validation, loading must fail deterministically (do not scan for an alternative).</li> <li>If metadata is present but semantically incompatible (e.g., a cached-derived signature is malformed), the loader must conservatively ignore/clear the affected cached-derived entries rather than guessing.</li> </ul> <p>Concurrency expectations (explicit policy):</p> <ul> <li>Multiple readers (read-only mapping) are supported.</li> <li>Concurrent mutation of the same file by multiple writers is out of scope unless the implementation introduces explicit file locking.</li> <li>If file locking is used, it must be documented and testable (no \u201csometimes it works\u201d).</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#testing-requirements","title":"Testing requirements","text":"<ul> <li>Round-trip correctness for payload + metadata (including unset vs explicit False).</li> <li>mmap correctness (payload offset correctness) across OSes.</li> <li>Append-update correctness (older metadata blocks ignored; pointer respected).</li> <li>Large-file performance sanity (no accidental full reads).</li> </ul> <p>Additional minimum tests:</p> <ul> <li>Crash-consistency simulation for metadata updates (valid header slot selection; no scanning required).</li> <li>Corruption handling for invalid header checksum and invalid metadata block checksum.</li> <li>Reserved namespace behavior (<code>view</code>/<code>properties</code>/<code>cached</code>/<code>provenance</code>) and unknown-key pass-through.</li> </ul>"},{"location":"internals/plans/completed/R1_STORAGE_PLAN/#see-also","title":"See also","text":"<ul> <li><code>documentation/internals/plans/R1_PROPERTIES_PLAN.md</code></li> <li><code>documentation/internals/plans/completed/R1_PROPERTIES_PLAN.md</code></li> <li><code>documentation/project/protocols/Documentation Protocol.md</code></li> </ul>"},{"location":"internals/plans/completed/Restructure%20Plan/","title":"Codebase Restructure Plan (Proposal + Execution Record)","text":"<p>Status: Partially executed. Remaining work requires explicit approval.</p>"},{"location":"internals/plans/completed/Restructure%20Plan/#execution-status-as-of-2025-12-14","title":"Execution status (as of 2025-12-14)","text":"<p>This document started as a proposal. Since then, several phases have been executed in this repo.</p> <p>For contributors: the bullets below are the \u201cwhat happened\u201d summary. The canonical details live in the linked dev handbook pages.</p> <ul> <li> Phase A \u2014 Documentation-first</li> <li><code>documentation/dev/</code> handbook exists (bootstrap/build/bindings/testing/hygiene/structure).</li> <li>Philosophy positioning updated to \u201cNumPy for causal sets\u201d.</li> <li>Documented in: dev/index, project/Philosophy</li> <li> Phase B \u2014 Purge committed binaries + enforce hygiene</li> <li>Committed build artifacts/binaries were removed and history rewritten.</li> <li>Documented in: dev/Repository Hygiene</li> <li> Phase C \u2014 Build workflow alignment</li> <li>Pip/scikit-build-core workflow is the documented \u201ccanonical\u201d path; scripts are wrappers.</li> <li>Documented in: dev/Build System</li> <li>[~] Phase D \u2014 Python internal modularization</li> <li>Public API remains <code>pycauset.*</code>.</li> <li><code>python/pycauset/_internal/</code> created and used for implementation.</li> <li>Persistence (single-file container) + linalg caching extracted.</li> <li>Runtime/storage/temp-file policy + patching + factories + formatting extracted.</li> <li>Ops glue (<code>matmul</code>, <code>compute_k</code>, <code>bitwise_not</code>, <code>invert</code>) extracted into <code>python/pycauset/_internal/ops.py</code> and <code>__init__.py</code> delegates.</li> <li>Remaining work: keep shrinking <code>python/pycauset/__init__.py</code> and keep dev docs in sync.</li> <li>Documented in: dev/Codebase Structure, dev/Python Internals</li> <li>[~] Phase E \u2014 Bindings modularization</li> <li><code>src/bindings.cpp</code> is a thin <code>PYBIND11_MODULE</code> entrypoint.</li> <li>Binding code split into modular translation units under <code>src/bindings/</code>.</li> <li>Added native export drift check: <code>tools/check_native_exports.py</code>.</li> <li>Documented in: dev/Bindings &amp; Dispatch</li> <li> Phase F \u2014 NxM groundwork</li> <li>Square-only assumptions list started: <code>documentation/dev/Square-only Assumptions.md</code>.</li> <li>Documented in: dev/Square-only Assumptions</li> </ul>"},{"location":"internals/plans/completed/Restructure%20Plan/#0-executive-summary","title":"0) Executive summary","text":"<p>PyCauset is a large hybrid project (Python API + C++ core + optional CUDA). The top priority is to make the codebase predictable to navigate and safe to modify, while preserving the core philosophy:</p> <ul> <li>PyCauset is \u201cNumPy for causal sets\u201d. Users interact with top-level Python objects and functions (e.g., <code>pycauset.matrix</code>, <code>pycauset.causal_matrix</code>, <code>pycauset.matmul</code>).</li> <li>Optimizations happen behind the scenes: tiered storage, device dispatch, direct-vs-streaming, SIMD/BLAS, etc.</li> <li>We may reorganize internal folders/modules, but we must not push user entrypoints into subpackages like <code>pycauset.physics.*</code>.</li> </ul> <p>This plan focuses on: 1) making builds reproducible and eliminating \u201cstale binary\u201d confusion, 2) clarifying ownership boundaries between subsystems, 3) writing enough documentation that new contributors can make changes safely, 4) keeping future requirements in mind (notably: NxM matrices for all types; no N-D arrays).</p>"},{"location":"internals/plans/completed/Restructure%20Plan/#1-goals","title":"1) Goals","text":"<ul> <li>Maintainability: a contributor can answer \u201cwhere does this belong?\u201d quickly.</li> <li>API coherence: the top-level Python surface keeps a NumPy-like feel (entrypoints remain at <code>pycauset.*</code>).</li> <li>Pre-alpha flexibility: breaking changes are acceptable when they improve the architecture, but they require explicit approval and corresponding updates to tests + docs.</li> <li>Reproducibility: the code you run is the code you built.</li> <li>Documentation completeness: \u201cno amount is too much\u201d \u2014 developers should have transparent guides.</li> <li>Extensibility: adding dtype/op support can follow a clear recipe (ties into optimization checklist).</li> </ul>"},{"location":"internals/plans/completed/Restructure%20Plan/#2-non-goals-for-this-restructure","title":"2) Non-goals (for this restructure)","text":"<ul> <li>Implementing new algorithms or performance changes (except as necessary to keep things building).</li> <li>Introducing N-dimensional array semantics (explicitly out of scope).</li> <li>Large user-visible API redesign.</li> </ul>"},{"location":"internals/plans/completed/Restructure%20Plan/#3-constraints-invariants","title":"3) Constraints / invariants","text":""},{"location":"internals/plans/completed/Restructure%20Plan/#public-api-invariants","title":"Public API invariants","text":"<ul> <li>End-user entrypoints remain top-level: <code>pycauset.*</code> (do not push the primary surface behind submodules like <code>pycauset.physics.*</code>).</li> <li>Internal reorg is allowed if <code>pycauset.__init__</code> re-exports the intended public symbols.</li> <li>Pre-alpha policy: the public surface may change, but only with explicit approval and synchronized updates to tests + docs.</li> </ul>"},{"location":"internals/plans/completed/Restructure%20Plan/#roadmap-invariants","title":"Roadmap invariants","text":"<ul> <li>Future direction: support NxM matrices for all types (dense, triangular, symmetric, bit, etc.).</li> <li>Still no arbitrary N-D arrays.</li> </ul>"},{"location":"internals/plans/completed/Restructure%20Plan/#repo-hygiene-invariants","title":"Repo hygiene invariants","text":"<ul> <li>Do not commit compiled artifacts (e.g., <code>_pycauset.pyd</code>, <code>.dll</code>, <code>.so</code>) into the repo.</li> <li>The canonical build path is pip/scikit-build-core (per <code>pyproject.toml</code>).</li> </ul>"},{"location":"internals/plans/completed/Restructure%20Plan/#4-phased-execution-plan","title":"4) Phased execution plan","text":"<p>Each phase has an explicit \u201cDone when\u2026\u201d acceptance criterion.</p>"},{"location":"internals/plans/completed/Restructure%20Plan/#phase-a-documentation-first-developer-transparency","title":"Phase A \u2014 Documentation-first (developer transparency)","text":"<p>Work: - Create a dedicated <code>documentation/dev/</code> handbook (this folder). - Add missing developer docs:   - overall codebase structure,   - build system explanation,   - bindings/dispatch guide,   - testing/benchmarks guide,   - repository hygiene rules. - Update <code>documentation/project/Philosophy.md</code> so the first-order philosophy is explicitly \u201cNumPy for causal sets\u201d.</p> <p>Done when: - A new contributor can follow docs to:   - find the implementation of a top-level API call,   - add a new dtype/op in the correct places,   - run tests/benchmarks.</p>"},{"location":"internals/plans/completed/Restructure%20Plan/#phase-b-purge-committed-binaries-enforce-hygiene","title":"Phase B \u2014 Purge committed binaries + enforce hygiene","text":"<p>Work: - Remove currently committed compiled artifacts from the repo (e.g., binaries under the Python package directory). - Add ignore rules so these never get reintroduced. - Rewrite git history to purge these artifacts (safe because it is a single-maintainer repo).</p> <p>Done when: - Fresh clone contains only source + docs (no compiled artifacts). - Building/installing produces artifacts locally.</p>"},{"location":"internals/plans/completed/Restructure%20Plan/#phase-c-build-workflow-alignment-pip-as-source-of-truth","title":"Phase C \u2014 Build workflow alignment (pip as source of truth)","text":"<p>Work: - Keep <code>build.ps1</code> as a thin wrapper that calls the canonical pip build/install commands. - Ensure compiler flags/warning suppressions remain in CMake and are not lost (pip uses CMake via scikit-build-core). - Document how to pass common build options:   - Release vs Debug,   - enabling CUDA,   - setting CMake cache args.</p> <p>Done when: - \u201cThe official way\u201d to build from source is documented as pip-based. - <code>build.ps1</code> cannot diverge into a second, incompatible build system.</p>"},{"location":"internals/plans/completed/Restructure%20Plan/#phase-d-python-package-internal-modularization-without-changing-public-api","title":"Phase D \u2014 Python package internal modularization (without changing public API)","text":"<p>Work (internal-only): - Split the current large <code>pycauset</code> package internals by responsibility (example target shape):   - <code>_runtime/</code> (platform/bootstrap: DLL search paths, environment checks)   - <code>_native/</code> (native import helpers and thin wrappers)   - <code>storage/</code> (file formats, save/load, storage roots)   - <code>linalg/</code> (Python-facing linear algebra helpers and high-level glue)   - <code>physics/</code> (CausalSet, sprinkling, spacetimes, fields)   - <code>vis/</code> (plotly integrations) - Keep user entrypoints top-level via re-export in <code>pycauset/__init__.py</code>.</p> <p>Done when: - <code>pycauset/__init__.py</code> is a small, readable facade. - There is exactly one canonical place for:   - persistence logic,   - compute config,   - native importing/bootstrap. - Tests continue to import from <code>pycauset.*</code> unchanged.</p>"},{"location":"internals/plans/completed/Restructure%20Plan/#phase-e-bindings-completeness-modular-binding-sources","title":"Phase E \u2014 Bindings completeness + modular binding sources","text":"<p>Work: - Make binding code modular (multiple binding translation units) to match subsystems. - Ensure Python expectations and native exports do not drift. - Add a \u201cbinding coverage checklist\u201d doc (what symbols are required, where they come from).</p> <p>Done when: - A mismatch between Python expectations and C++ bindings is easy to detect. - Adding a new matrix type/op has a clear binding template.</p>"},{"location":"internals/plans/completed/Restructure%20Plan/#phase-f-nxm-groundwork-documentation-interfaces-first","title":"Phase F \u2014 NxM groundwork (documentation + interfaces first)","text":"<p>Work: - Update roadmap/TODO: NxM support planned for all types. - Identify (document-only initially) which components assume square matrices today:   - storage metadata,   - matrix base classes,   - solvers (matmul/inverse),   - Python factories.</p> <p>Done when: - The codebase has a documented \u201csquare-only assumptions list\u201d. - Future NxM work can proceed systematically.</p>"},{"location":"internals/plans/completed/Restructure%20Plan/#5-risk-management","title":"5) Risk management","text":"<ul> <li>History rewrite risk: force-push breaks old clones. Mitigation: since single-maintainer, do it once, then re-clone locally.</li> <li>API drift risk: internal reorg can accidentally change user imports. Mitigation: keep stable top-level re-exports and run interface tests.</li> <li>Build drift risk: multiple build scripts can diverge. Mitigation: make scripts wrappers + document canonical commands.</li> </ul>"},{"location":"internals/plans/completed/Restructure%20Plan/#6-deliverables-checklist","title":"6) Deliverables checklist","text":"<ul> <li> New <code>documentation/dev/</code> handbook exists and is referenced by contributors.</li> <li> Philosophy updated to lead with \u201cNumPy for causal sets\u201d.</li> <li> Repo purge of binaries + <code>.gitignore</code> enforcement.</li> <li> Build scripts are wrappers; CMake flags preserved.</li> <li> Python internals modularized with stable <code>pycauset.*</code> surface.</li> <li> Bindings modular + documented.</li> <li> NxM roadmap noted and square-only assumptions documented.</li> </ul>"},{"location":"internals/plans/completed/Restructure%20Plan/#7-approval-gates-explicit-stop-points","title":"7) Approval gates (explicit stop points)","text":"<ul> <li>Gate 1: Approve documentation structure + file list.</li> <li>Gate 2: Approve history rewrite (purge binaries).</li> <li>Gate 3: Approve internal Python package reorg target structure.</li> <li>Gate 4: Approve bindings reorg.</li> </ul> <p>Until each gate is approved, the work must remain read-only or documentation-only.</p>"},{"location":"project/","title":"Project","text":"<p>Information about the PyCauset project itself.</p>"},{"location":"project/#general","title":"General","text":"<ul> <li>Philosophy: The design philosophy behind PyCauset.</li> <li>Public API Contract: What counts as public API (names, imports, stability rules).</li> <li>Protocols: Development protocols and standards.</li> <li>Contributing: How to set up the dev environment and contribute.</li> <li>Roadmap: Planned features and known issues.</li> </ul>"},{"location":"project/#contributing","title":"Contributing","text":"<p>We welcome contributions! Please see the GitHub repository for more information on how to contribute.</p>"},{"location":"project/Contributing/","title":"Contributing to PyCauset","text":"<p>Thank you for your interest in contributing to PyCauset! We welcome contributions from the community, whether it's fixing bugs, adding new features, or improving documentation.</p> <p>Before you start, read the project protocols:</p> <ul> <li>project/protocols/</li> <li>Documentation Protocol</li> </ul>"},{"location":"project/Contributing/#getting-started","title":"Getting Started","text":""},{"location":"project/Contributing/#prerequisites","title":"Prerequisites","text":"<p>To build PyCauset from source, you will need:</p> <ul> <li>Python 3.8+</li> <li>C++ Compiler:<ul> <li>Windows: Visual Studio 2022 (Desktop development with C++)</li> <li>Linux: GCC or Clang</li> <li>macOS: Xcode Command Line Tools</li> </ul> </li> <li>CMake 3.15+</li> <li>CUDA Toolkit (Optional, for GPU support)</li> </ul>"},{"location":"project/Contributing/#setting-up-the-development-environment","title":"Setting Up the Development Environment","text":"<ol> <li> <p>Clone the Repository:     <pre><code>git clone https://github.com/BrorH/pycauset.git\ncd pycauset\n</code></pre></p> </li> <li> <p>Create a Virtual Environment:     <pre><code>python -m venv .venv\n# Windows\n.venv\\Scripts\\Activate.ps1\n# Linux/macOS\nsource .venv/bin/activate\n</code></pre></p> </li> <li> <p>Install from source (this builds the native extension via <code>scikit-build-core</code>):     <pre><code>pip install -e .\n</code></pre></p> </li> </ol>"},{"location":"project/Contributing/#building-the-project","title":"Building the Project","text":"<p>We provide helper scripts to simplify the build process.</p>"},{"location":"project/Contributing/#windows","title":"Windows","text":"<pre><code># Build Python extension and run tests\n./build.ps1 -All\n\n# Only build Python extension\n./build.ps1 -Python\n</code></pre>"},{"location":"project/Contributing/#linuxmacos","title":"Linux/macOS","text":"<p>Recommended workflow:</p> <pre><code>pip install -e .\n</code></pre>"},{"location":"project/Contributing/#running-tests","title":"Running Tests","text":"<p>PyCauset has a comprehensive test suite covering both the C++ core and the Python interface.</p>"},{"location":"project/Contributing/#python-tests","title":"Python Tests","text":"<pre><code>pytest tests/python\n</code></pre>"},{"location":"project/Contributing/#c-unit-tests","title":"C++ Unit Tests","text":"<p>If you built with CMake, you can run C++ tests via CTest from your build directory.</p>"},{"location":"project/Contributing/#coding-standards","title":"Coding Standards","text":""},{"location":"project/Contributing/#c","title":"C++","text":"<ul> <li>Use C++17 features.</li> <li>Follow standard RAII principles.</li> <li>Use <code>pybind11</code> for Python bindings.</li> <li>Keep headers in <code>include/</code> and implementation in <code>src/</code>.</li> </ul>"},{"location":"project/Contributing/#python","title":"Python","text":"<ul> <li>Follow PEP 8.</li> <li>Use type hints.</li> <li>Document all public functions and classes using Google-style docstrings.</li> </ul>"},{"location":"project/Contributing/#documentation","title":"Documentation","text":"<p>Documentation is written in Markdown and built with MkDocs.</p> <p>Install documentation dependencies:</p> <pre><code>pip install -r requirements-docs.txt\n</code></pre> <p>If you are changing behavior, remember the docs checklist in Documentation Protocol.</p> <pre><code># Serve documentation locally\nmkdocs serve\n</code></pre>"},{"location":"project/Contributing/#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<ol> <li>Fork the repository.</li> <li>Create a new branch (<code>git checkout -b feature/my-feature</code>).</li> <li>Commit your changes.</li> <li>Push to the branch (<code>git push origin feature/my-feature</code>).</li> <li>Open a Pull Request.</li> </ol> <p>Please ensure all tests pass before submitting!</p>"},{"location":"project/Philosophy/","title":"Pycauset Philosophy &amp; Design Principles","text":"<p>Pycauset is designed to handle causal sets where \\(N\\) is large enough that \\(O(N^2)\\) storage becomes the primary bottleneck. To achieve this, we adhere to a strict set of design principles and \"mantras\" that guide every architectural decision.</p>"},{"location":"project/Philosophy/#core-philosophy-north-star","title":"Core Philosophy (North Star)","text":"<p>PyCauset is NumPy for causal sets.</p> <ul> <li>Users should interact with top-level Python objects and functions (e.g., <code>pycauset.matrix</code>, <code>pycauset.causal_matrix</code>, <code>pycauset.matmul</code>).</li> <li>We bridge the gap between abstract theory and petabyte-scale simulation without forcing physicists to become systems engineers.</li> </ul>"},{"location":"project/Philosophy/#developer-ethos","title":"Developer Ethos","text":"<p>\"We don't write 'Happy Path' code. We write code that survives a power outage, a full disk, and a 3-week runtime.\"</p> <p>Originally, PyCauset was built solely for scale (\"If it fits in RAM, use numpy\"). However, as the project has evolved into a full-fledged framework for Causal Set Theory, it now offers unique value even for small simulations: *   Spacetime Generation: Built-in manifolds and sprinkling algorithms. *   Causal Set Abstractions: Objects that bundle topology, geometry, and causality. *   Reproducibility: Standardized serialization formats (<code>.pycauset</code>).</p>"},{"location":"project/Philosophy/#core-mantras","title":"Core Mantras","text":""},{"location":"project/Philosophy/#1-scale-first-ask-questions-later","title":"1. Scale First, Ask Questions Later","text":"<ul> <li>Principle: We assume every matrix might be 10TB.</li> <li>Implementation: We design for the worst case (disk-backed, out-of-core) first, then optimize the best case (RAM-only) second.</li> <li>Differentiation: NumPy crashes if you allocate 100GB. PyCauset just shrugs and opens a file.</li> </ul>"},{"location":"project/Philosophy/#2-numpy-compatibility-c-engine","title":"2. Numpy Compatibility, C++ Engine","text":"<ul> <li>Principle: The API should feel like home to numpy-users and be intimately compatible.</li> <li>Implementation: We mimic the <code>numpy</code> API (<code>shape</code>, <code>dtype</code>, slicing, broadcasting where possible). However, we do not use <code>numpy</code> arrays for storage. The engine is pure C++ optimized for our specific storage formats and causal set operations.</li> </ul>"},{"location":"project/Philosophy/#3-lazy-is-smart","title":"3. Lazy is Smart","text":"<ul> <li>Principle: Never compute what you can describe. Never write to disk what you can keep in RAM.</li> <li>Implementation:<ul> <li>Lazy Persistence: Matrices stay in RAM until they grow too large or the user explicitly saves them.</li> <li>Expression Templates: Operations like <code>C = A * B + D</code> are fused and computed on-the-fly, avoiding temporary files.</li> <li>Metadata Scaling: Scalar multiplication (<code>A * 3.5</code>) is just a metadata update, taking \\(O(1)\\) time and 0 bytes.</li> </ul> </li> </ul>"},{"location":"project/Philosophy/#4-properties-are-gospel","title":"4. Properties are Gospel","text":"<ul> <li>Principle: If a matrix is tagged <code>is_diagonal=True</code>, we never check the zeros. We trust the tag.</li> <li>Implementation: We use metadata to short-circuit expensive computations (\"Fly Swatting\"). If a property makes an operation trivial (or impossible), we return the result instantly without touching the data.</li> </ul>"},{"location":"project/Philosophy/#5-the-hardware-is-a-team","title":"5. The Hardware is a Team","text":"<ul> <li>Principle: The CPU, GPU, and Disk are coworkers, not rivals.</li> <li>Implementation: We don't just \"switch\" to GPU. We use Cooperative Computing: the CPU prefetches data from disk while the GPU crunches the previous block. We use the right tool for the job (CPU for complex logic, GPU for brute force, Disk for infinite capacity).</li> </ul>"},{"location":"project/Philosophy/#6-anti-promotion-the-smallest-type-rule","title":"6. Anti-Promotion (The \"Smallest Type\" Rule)","text":"<ul> <li>Principle: Data types must remain as small as possible, constantly.</li> <li>Implementation: We aggressively resist type promotion.<ul> <li>Underpromotion: Operations execute in the smallest selected dtype, and results are stored in that same dtype. We do not silently widen intermediates.</li> <li>Mixed Types: If a float participates, the result is float. Otherwise, we prefer the smallest dtype.</li> <li>Overflow: Integer overflow is a hard error (no auto-promotion). Float overflow follows IEEE-754 (<code>inf</code>/<code>nan</code>).</li> </ul> </li> <li>Example: Multiplying an <code>IntegerMatrix</code> by a float scalar (<code>3.5</code>) produces an <code>IntegerMatrix</code> with a metadata scalar factor. The data on disk remains integers.</li> </ul>"},{"location":"project/Philosophy/#7-efficient-storage-persistence","title":"7. Efficient Storage &amp; Persistence","text":"<ul> <li>Principle: Storage should be minimized and persistent.</li> <li>Implementation:<ul> <li>Bit-Packing: Causal matrices are stored as packed bits, offering an 8x storage reduction compared to <code>bool</code> or <code>uint8_t</code>.</li> <li>Persistence: Memory-mapped matrices are persistent by nature. RAM-based matrices are transient but can be easily converted to disk-backed ones to \"save\" a computation.</li> </ul> </li> </ul>"},{"location":"project/Public%20API%20Contract/","title":"Public API Contract","text":"<p>This page defines what counts as public API in PyCauset, what naming/import rules we follow, and how we handle removals.</p> <p>This is intentionally strict: it keeps the project coherent while the internals evolve quickly.</p>"},{"location":"project/Public%20API%20Contract/#1-what-is-public-api","title":"1) What is public API?","text":"<p>Public API is anything a user is expected to import and rely on.</p>"},{"location":"project/Public%20API%20Contract/#public-stable-entrypoints","title":"Public (stable entrypoints)","text":"<ul> <li><code>pycauset.*</code> symbols that are documented in the API reference under <code>documentation/docs/</code>.</li> <li>The documented submodules:</li> <li><code>pycauset.spacetime</code></li> <li><code>pycauset.field</code></li> <li><code>pycauset.vis</code></li> </ul> <p>Rule of thumb: - If it is meant for users, it must be reachable at <code>pycauset.*</code>. - If it is not meant for users, it must live under a private namespace.</p>"},{"location":"project/Public%20API%20Contract/#not-public-may-change-anytime","title":"Not public (may change anytime)","text":"<ul> <li>Anything under <code>pycauset._internal.*</code>.</li> <li>Native binding details under <code>pycauset._pycauset</code>.</li> <li>Any symbol whose name starts with <code>_</code> (even if it is importable).</li> </ul> <p>See also: Python Internals and Bindings &amp; Dispatch.</p>"},{"location":"project/Public%20API%20Contract/#2-naming-conventions","title":"2) Naming conventions","text":""},{"location":"project/Public%20API%20Contract/#modules","title":"Modules","text":"<ul> <li>Public modules are short, nouns, and lower-case (examples: <code>spacetime</code>, <code>field</code>, <code>vis</code>).</li> <li>Internal modules live under <code>pycauset._internal</code>.</li> </ul>"},{"location":"project/Public%20API%20Contract/#types-classes","title":"Types (classes)","text":"<ul> <li>Public types use <code>PascalCase</code>.</li> <li>Concrete matrix/vector classes follow <code>\u2026Matrix</code> / <code>\u2026Vector</code> naming.</li> <li>Examples: <code>FloatMatrix</code>, <code>TriangularFloatMatrix</code>, <code>IntegerVector</code>.</li> </ul>"},{"location":"project/Public%20API%20Contract/#matrixvector-semantic-properties-objproperties","title":"Matrix/vector semantic properties (<code>obj.properties</code>)","text":"<p>All public matrix/vector objects expose a <code>properties</code> mapping.</p> <p>Contract:</p> <ul> <li><code>obj.properties</code> is the single user-facing metadata container.</li> <li>Properties are gospel: they are not truth-validated by scanning payload bytes.</li> <li>Boolean-like properties use tri-state semantics via key presence:</li> <li>unset means the key is absent,</li> <li>explicit <code>False</code> is preserved.</li> <li>Some keys (e.g. <code>trace</code>, <code>determinant</code>) may be treated as cached-derived values:</li> <li>they are persisted with validity signatures under <code>cached.*</code>,</li> <li>and are surfaced back into <code>obj.properties</code> on load only when valid.</li> </ul>"},{"location":"project/Public%20API%20Contract/#functions","title":"Functions","text":"<ul> <li>Public functions use <code>snake_case</code>.</li> <li>Examples: <code>matmul</code>, <code>compute_k</code>, <code>invert</code>.</li> </ul>"},{"location":"project/Public%20API%20Contract/#dtype-tokens","title":"Dtype tokens","text":"<p>PyCauset accepts NumPy-like dtype tokens as strings.</p> <p>It also exports dtype sentinel variables on the top-level module for convenience (these are just strings).</p> <p>Exported sentinels (examples):</p> <ul> <li>Integers: <code>pycauset.int8</code>, <code>pycauset.int16</code>, <code>pycauset.int32</code>, <code>pycauset.int64</code> (alias: <code>pycauset.int_</code>)</li> <li>Unsigned: <code>pycauset.uint8</code>, <code>pycauset.uint16</code>, <code>pycauset.uint32</code>, <code>pycauset.uint64</code> (alias: <code>pycauset.uint</code>)</li> <li>Floats: <code>pycauset.float16</code>, <code>pycauset.float32</code>, <code>pycauset.float64</code> (alias: <code>pycauset.float_</code>)</li> <li>Bit/boolean: <code>pycauset.bit</code>, <code>pycauset.bool_</code></li> <li>Complex floats: <code>pycauset.complex_float16</code>, <code>pycauset.complex_float32</code>, <code>pycauset.complex_float64</code> (aliases: <code>pycauset.complex64</code>, <code>pycauset.complex128</code>)</li> </ul> <p>Rule: - Sentinel names follow NumPy conventions (including <code>_</code> suffix for built-in names like <code>bool_</code>).</p> <ul> <li>Float tokens: <code>\"float16\"</code>, <code>\"float32\"</code>, <code>\"float64\"</code> (aliases may exist: <code>\"float\"</code>, <code>\"float_\"</code>).</li> <li>Int tokens: <code>\"int8\"</code>, <code>\"int16\"</code>, <code>\"int32\"</code>, <code>\"int64\"</code> (aliases may exist: <code>\"int\"</code>, <code>\"int_\"</code>).</li> <li>Unsigned tokens: <code>\"uint8\"</code>, <code>\"uint16\"</code>, <code>\"uint32\"</code>, <code>\"uint64\"</code> (alias: <code>\"uint\"</code>).</li> <li>Bit/boolean tokens: <code>\"bit\"</code>, <code>\"bool\"</code>, <code>\"bool_\"</code>.</li> <li>Complex float tokens: <code>\"complex_float16\"</code>, <code>\"complex_float32\"</code>, <code>\"complex_float64\"</code> (aliases: <code>\"complex\"</code>, <code>\"complex64\"</code>, <code>\"complex128\"</code>).</li> </ul> <p>Rule: - Tokens are lower-case, consistent with NumPy naming, and treated as part of the public surface.</p>"},{"location":"project/Public%20API%20Contract/#exceptions-and-warnings","title":"Exceptions and warnings","text":"<ul> <li>Warnings derive from <code>PyCausetWarning</code> (examples: <code>PyCausetPerformanceWarning</code>, <code>PyCausetStorageWarning</code>).</li> <li>Exceptions should be specific and predictable; prefer raising built-in exceptions (<code>ValueError</code>, <code>TypeError</code>) unless a dedicated PyCauset exception is warranted.</li> </ul> <p>See also: Warnings &amp; Exceptions.</p>"},{"location":"project/Public%20API%20Contract/#global-knobs-parameters","title":"Global knobs / parameters","text":"<p>Some public configuration is intentionally exposed as module-level parameters.</p> <ul> <li><code>pycauset.keep_temp_files</code> (documented under <code>documentation/docs/parameters/</code>)</li> <li><code>pycauset.seed</code> (documented under <code>documentation/docs/parameters/</code>)</li> </ul>"},{"location":"project/Public%20API%20Contract/#3-public-vs-internal-boundaries-enforced-by-structure","title":"3) Public vs internal boundaries (enforced by structure)","text":"<p>The intended layering:</p> <ul> <li><code>python/pycauset/__init__.py</code> is the public facade.</li> <li><code>python/pycauset/_internal/</code> holds implementation modules.</li> <li><code>src/</code> + native bindings provide the engine.</li> </ul> <p>If a new feature requires helpers, put helpers in <code>_internal/</code> and only re-export the intended entrypoint at <code>pycauset.*</code>.</p>"},{"location":"project/Public%20API%20Contract/#4-removals-policy-deprecation-purge","title":"4) Removals policy (\"Deprecation\" = purge)","text":"<p>PyCauset uses a purge policy:</p> <ul> <li>If we decide something should be removed, we remove it fully.</li> <li>We do not keep deprecated aliases or \u201cdeprecated but still present\u201d codepaths.</li> <li>Documentation should never say \u201cdeprecated\u201d: it should reflect the current reality.</li> </ul> <p>If a removal breaks internal callers, update them in the same change.</p>"},{"location":"project/Public%20API%20Contract/#5-how-to-change-the-public-api-safely","title":"5) How to change the public API safely","text":"<p>Changes to public API (names/semantics/import paths) are allowed pre-alpha, but must be deliberate.</p> <p>Checklist:</p> <ol> <li>Update the API reference page(s) under <code>documentation/docs/</code>.</li> <li>Update any affected guides under <code>documentation/guides/</code>.</li> <li>Update tests under <code>tests/python/</code>.</li> <li>If native exports are involved, run the drift check:</li> <li><code>python tools/check_native_exports.py</code></li> </ol> <p>Related protocols:</p> <ul> <li>Pre-alpha Policy</li> <li>Documentation Protocol</li> <li>Adding Operations</li> <li>Adding Types</li> </ul>"},{"location":"project/Public%20API%20Contract/#6-when-in-doubt","title":"6) When in doubt","text":"<p>If you\u2019re unsure whether something is public:</p> <ul> <li>Default to not public.</li> <li>Keep it under <code>_internal/</code>.</li> <li>Only promote it to <code>pycauset.*</code> after it has a clear contract and an API reference page.</li> </ul>"},{"location":"project/protocols/","title":"Protocols","text":"<p>This section defines the project rules of engagement: what must be true when you change code, add features, or ship releases.</p> <p>If you are adding or changing behavior, start with:</p> <ul> <li>Pre-alpha Policy</li> <li>Documentation Protocol</li> </ul>"},{"location":"project/protocols/#protocols_1","title":"Protocols","text":"<ul> <li>Pre-alpha Policy</li> <li>Documentation Protocol</li> <li>Adding Matrix/Vector Operations</li> <li>Adding Matrix/Vector Types</li> <li>Release Process</li> <li>Testing and Bug Tracking</li> </ul>"},{"location":"project/protocols/Adding%20Operations/","title":"Protocol: Adding New Matrix/Vector Operations","text":"<p>Objective: Make new ops easy to add without \u201chunt across the codebase\u201d, and ensure both matrix and vector variants are covered.</p>"},{"location":"project/protocols/Adding%20Operations/#the-current-architecture-where-things-go","title":"The current architecture (where things go)","text":"<ol> <li>Frontend (type resolution + allocation + entry point)<ul> <li>Declarations: <code>include/pycauset/math/LinearAlgebra.hpp</code></li> <li>Definitions: <code>src/math/LinearAlgebra.cpp</code></li> </ul> </li> <li>Context (<code>ComputeContext</code>)<ul> <li><code>include/pycauset/compute/ComputeContext.hpp</code>, <code>src/compute/ComputeContext.cpp</code></li> </ul> </li> <li>Dispatcher (<code>AutoSolver</code>)<ul> <li><code>include/pycauset/compute/AutoSolver.hpp</code>, <code>src/compute/AutoSolver.cpp</code></li> </ul> </li> <li>Interface (<code>ComputeDevice</code>)<ul> <li><code>include/pycauset/compute/ComputeDevice.hpp</code></li> </ul> </li> <li>Implementations (CPU / CUDA)<ul> <li>CPU device: <code>include/pycauset/compute/cpu/CpuDevice.hpp</code>, <code>src/compute/cpu/CpuDevice.cpp</code></li> <li>CPU algorithms: <code>include/pycauset/compute/cpu/CpuSolver.hpp</code>, <code>src/compute/cpu/CpuSolver.cpp</code></li> <li>CUDA device: <code>src/accelerators/cuda/CudaDevice.hpp</code>, <code>src/accelerators/cuda/CudaDevice.cu</code></li> </ul> </li> </ol>"},{"location":"project/protocols/Adding%20Operations/#the-support-checklist-authoritative","title":"The \u201cSupport Checklist\u201d (authoritative)","text":"<p>When adding a new operation, you must decide and/or implement support in each of these axes:</p> <ol> <li> <p>Operand rank</p> <ul> <li>Matrix\u2013Matrix</li> <li>Vector\u2013Vector</li> <li>Matrix\u2013Vector and Vector\u2013Matrix (if applicable)</li> </ul> </li> <li> <p>Scalar kind + flags</p> <ul> <li>Fundamental kinds: <code>bit</code>, <code>int</code>, <code>float</code></li> <li>Flags/permutations: <code>complex</code>, <code>unsigned</code></li> <li>Special rule: bit is allowed to have op-specific exceptions (bitwise vs numeric vs error-by-design).   See internals/DType System.</li> </ul> </li> <li> <p>Structure/storage</p> <ul> <li>Dense vs triangular vs symmetric/antisymmetric vs identity/diagonal</li> <li>Vector special cases like <code>UnitVector</code></li> </ul> </li> <li> <p>Device coverage</p> <ul> <li>CPU must be correct.</li> <li>GPU is optional; if unsupported, routing must be prevented or it must throw clearly.</li> </ul> </li> <li> <p>Python surface</p> <ul> <li>Bindings: <code>src/bindings/</code> (<code>bind_matrix.cpp</code>, <code>bind_vector.cpp</code>, <code>bind_complex.cpp</code>) and the aggregator <code>src/bindings.cpp</code>.</li> <li>Python API helpers/wrappers may also need updates in <code>python/pycauset/</code>.</li> </ul> </li> <li> <p>Documentation + tests</p> <ul> <li>Add/modify API docs in <code>documentation/docs/</code> and guides in <code>documentation/guides/</code>.</li> <li>Add tests (Python and/or C++) covering dtype permutations and \u201cerror-by-design\u201d cases.</li> </ul> </li> <li> <p>Properties (R1_PROPERTIES)</p> <ul> <li>Decide which properties the op consumes (e.g., <code>is_upper_triangular</code>, <code>is_hermitian</code>).</li> <li>Decide whether the op produces/propagates/changes properties on its outputs.</li> <li>Enforce the no-scan rule: properties must never be validated by scanning payload data.</li> <li>Document \u201cpower user\u201d semantics where relevant: properties are gospel and may override payload truth.</li> </ul> </li> <li> <p>Cached-derived properties (R1_PROPERTIES)</p> <ul> <li>Decide which cached-derived properties (e.g., <code>trace</code>) the op invalidates (default: invalidate all cached-derived values on any payload mutation).</li> <li>If the op is a metadata-only transform, decide which cached-derived values can be propagated via explicit \\(O(1)\\) rules (otherwise clear).</li> <li>If the op is parallelized, decide whether it should emit a constant-size effect summary to help the post-op health check update metadata without a second payload pass.</li> </ul> </li> </ol>"},{"location":"project/protocols/Adding%20Operations/#step-by-step-what-to-edit-in-order","title":"Step-by-step (what to edit, in order)","text":""},{"location":"project/protocols/Adding%20Operations/#1-add-the-device-interface-method","title":"1) Add the device-interface method","text":"<p>Add a pure virtual method to <code>include/pycauset/compute/ComputeDevice.hpp</code>.</p> <p>Matrix example: <pre><code>virtual void my_new_op(const MatrixBase&amp; a, const MatrixBase&amp; b, MatrixBase&amp; result) = 0;\n</code></pre></p> <p>Vector example: <pre><code>virtual void my_new_op_vector(const VectorBase&amp; a, const VectorBase&amp; b, VectorBase&amp; result) = 0;\n</code></pre></p>"},{"location":"project/protocols/Adding%20Operations/#2-implement-cpu-algorithm-wire-cpudevice","title":"2) Implement CPU algorithm + wire CpuDevice","text":"<ul> <li>Add implementation to <code>include/pycauset/compute/cpu/CpuSolver.hpp</code> and <code>src/compute/cpu/CpuSolver.cpp</code>.</li> <li>Wire through <code>include/pycauset/compute/cpu/CpuDevice.hpp</code> and <code>src/compute/cpu/CpuDevice.cpp</code> as a thin passthrough.</li> </ul>"},{"location":"project/protocols/Adding%20Operations/#3-add-autosolver-routing","title":"3) Add AutoSolver routing","text":"<p>Update <code>include/pycauset/compute/AutoSolver.hpp</code> and <code>src/compute/AutoSolver.cpp</code>.</p> <ul> <li>Default: route by size with <code>select_device(elements)-&gt;my_new_op(...)</code>.</li> <li>If GPU does not support the op/dtypes/structures, either:</li> <li>enforce \u201cCPU only\u201d in AutoSolver for that op, or</li> <li>keep GPU routing but ensure GPU throws a clear error.</li> </ul>"},{"location":"project/protocols/Adding%20Operations/#4-optional-implement-cuda","title":"4) (Optional) Implement CUDA","text":"<p>If supported, implement in <code>src/accelerators/cuda/CudaDevice.cu</code>.</p>"},{"location":"project/protocols/Adding%20Operations/#5-add-the-frontend-wrappers","title":"5) Add the frontend wrapper(s)","text":"<p>Add a top-level frontend function in <code>include/pycauset/math/LinearAlgebra.hpp</code> + <code>src/math/LinearAlgebra.cpp</code>.</p> <p>Responsibilities of the frontend: - validate shapes, - determine the result dtype/structure, - allocate the result using <code>ObjectFactory::create_matrix/create_vector</code>, - dispatch via <code>ComputeContext::instance().get_device()-&gt;...</code>.</p> <p>Additional responsibility (R1_PROPERTIES):</p> <ul> <li>Compute any effective structure category once (e.g., zero/identity/diagonal/triangular/general) from properties and pass that decision down to avoid repeated property lookups in inner loops.</li> </ul>"},{"location":"project/protocols/Adding%20Operations/#6-bind-to-python","title":"6) Bind to Python","text":"<p>Add the binding to the appropriate <code>src/bindings/bind_*.cpp</code> and ensure it is reachable from <code>src/bindings.cpp</code>.</p>"},{"location":"project/protocols/Adding%20Operations/#7-declare-dtypecoverage-expectations-policy-tests","title":"7) Declare dtype/coverage expectations (policy + tests)","text":"<p>Every new op must explicitly state its dtype behavior. In particular:</p> <ul> <li>Fundamental-kind rule (bit/int/float): do not \u201cpromote down\u201d across kinds. For example, <code>matmul(bit, float64) -&gt; float64</code>.</li> <li>Underpromotion within floats: <code>matmul(float32, float64) -&gt; float32</code> by default.</li> <li>Overflow: integer overflow throws; large integer matmul may emit a risk warning (advisory).</li> </ul> <p>These rules are defined in internals/DType System and summarized in project/Philosophy.</p>"},{"location":"project/protocols/Adding%20Operations/#streaming-manager-wiring-per-op-template","title":"Streaming manager wiring (per-op template)","text":"<p>Use this when deciding whether an op should stream and how to express it.</p> <ol> <li>Decide streamability and invariants. Specify when streaming is allowed (e.g., associative/commutative reductions, block-separable transforms) and when to fall back to single-shot (e.g., global normalization constants, shape-dependent fusion that would regress correctness). Capture the rationale so AutoSolver can gate.</li> <li>Define the streaming descriptor. Choose chunk shape (rows/tiles/blocks), prefetch distance, double-buffering vs single-buffer, and whether pinned host staging is required. Provide CPU defaults and GPU defaults separately; GPU defaults should include host&lt;-&gt;device staging policy and max in-flight buffers.</li> <li>Route through AutoSolver. Add a routing path that prefers the streaming plan when the device supports it and the op\u2019s streamability predicates are satisfied; otherwise route to the non-streaming implementation or raise a clear \u201cstreaming not supported for this configuration\u201d error.</li> <li>Budgeting with the memory governor. Set per-op limits: max residency for staging buffers, spill/evict behavior, and what to do when budgets are tight (e.g., shrink chunk size, drop to CPU-only, or disable streaming). Avoid hidden allocations outside the governor.</li> <li>Telemetry and tests. Add a minimal streaming test that asserts the op uses the streaming path (e.g., via a debug hook or perf counter) and a fallback test that confirms graceful degradation when streaming is blocked. Document the defaults and any known non-streamable cases in the op\u2019s docstring/API doc.</li> </ol>"},{"location":"project/protocols/Adding%20Operations/#minimal-definition-of-done-for-a-new-op","title":"Minimal \u201cDefinition of Done\u201d for a new op","text":"<ul> <li> <code>ComputeDevice</code> interface updated.</li> <li> CPU implementation exists and is correct.</li> <li> <code>AutoSolver</code> dispatch correct (CPU-only or GPU-enabled).</li> <li> Frontend wrapper(s) in <code>src/math/LinearAlgebra.cpp</code> (matrix and/or vector).</li> <li> Python bindings updated.</li> <li> Dtype behavior documented (including bit exceptions and cross-kind rules).</li> <li> Tests cover supported dtypes + at least one \u201cerror-by-design\u201d dtype.</li> </ul> <p>If the op is property-aware (R1_PROPERTIES):</p> <ul> <li> The op\u2019s behavior with properties is documented (which properties it reads, and which it writes/propagates).</li> <li> Property behavior is deterministic and respects the \u201cno truth validation / no data scans\u201d rule.</li> </ul> <p>If the op interacts with cached-derived properties (R1_PROPERTIES):</p> <ul> <li> Cache behavior is documented (which cached-derived values can be preserved/propagated vs must be cleared).</li> <li> Cache behavior is deterministic and uses only \\(O(1)\\) rules (no scans / no extra passes).</li> </ul> <p>For <code>bit</code> specifically, always state whether the new op is:</p> <ul> <li>bitwise (stays <code>bit</code>, stays packed), or</li> <li>numeric (may widen to <code>int</code>/<code>float</code>, potentially huge), or</li> <li>error-by-design for <code>bit</code> unless the user explicitly requests widening.</li> </ul>"},{"location":"project/protocols/Adding%20Operations/#see-also","title":"See also","text":"<ul> <li>Documentation Protocol</li> <li>R1_PROPERTIES plan (properties + caches)</li> <li>internals/DType System</li> </ul>"},{"location":"project/protocols/Adding%20Types/","title":"Protocol: Adding New Matrix and Vector Types","text":"<p>Objective: Ensure new matrix/vector structures are fully integrated into the factory, storage, compute, and Python ecosystems.</p>"},{"location":"project/protocols/Adding%20Types/#step-by-step-implementation-guide","title":"Step-by-step implementation guide","text":""},{"location":"project/protocols/Adding%20Types/#1-core-definitions-includepycausetcoretypeshpp","title":"1) Core definitions (<code>include/pycauset/core/Types.hpp</code>)","text":"<ul> <li>Add a new enum value to <code>MatrixType</code>.</li> <li>Decide whether the new type is a matrix-like (<code>rows x cols</code>) or a vector-like (<code>n x 1</code>) object.</li> </ul>"},{"location":"project/protocols/Adding%20Types/#2-define-the-class","title":"2) Define the class","text":"<ul> <li>Matrix types live in <code>include/pycauset/matrix/</code>.</li> <li>Vector types live in <code>include/pycauset/vector/</code>.</li> </ul> <p>Implement the required virtual interface:</p> <ul> <li>Matrices (<code>MatrixBase</code>): <code>get_element_as_double(i, j)</code>, <code>multiply_scalar</code>, <code>add_scalar</code>, <code>transpose</code>, and correct <code>clone()</code> behavior.</li> <li>Vectors (<code>VectorBase</code>): <code>get_element_as_double(i)</code>, <code>multiply_scalar</code>, <code>add_scalar</code>, <code>transpose</code> (if supported), and correct <code>clone()</code> behavior.</li> </ul> <p>If the type is intended for GPU/BLAS interoperability, it must expose contiguous raw memory access where appropriate.</p>"},{"location":"project/protocols/Adding%20Types/#3-update-the-factory-includepycausetcoreobjectfactoryhpp-srccoreobjectfactorycpp","title":"3) Update the factory (<code>include/pycauset/core/ObjectFactory.hpp</code>, <code>src/core/ObjectFactory.cpp</code>)","text":"<p>The factory is the central registry for creating, loading, and cloning persistent objects.</p> <ul> <li>Matrices:<ul> <li><code>create_matrix</code></li> <li><code>load_matrix</code></li> <li><code>clone_matrix</code></li> </ul> </li> <li>Vectors:<ul> <li><code>create_vector</code></li> <li><code>load_vector</code></li> <li><code>clone_vector</code></li> </ul> </li> </ul>"},{"location":"project/protocols/Adding%20Types/#4-update-compute-support","title":"4) Update compute support","text":"<ul> <li>Add CPU support in <code>src/compute/cpu/CpuSolver.cpp</code> if the new type participates in operations.</li> <li>Wire through <code>CpuDevice</code> and <code>AutoSolver</code> if device dispatch is required.</li> </ul> <p>If the new type is intentionally excluded from some operations (common for bit-special cases), those exclusions must be explicit and tested.</p>"},{"location":"project/protocols/Adding%20Types/#5-python-bindings-srcbindings-srcbindingscpp","title":"5) Python bindings (<code>src/bindings/</code> + <code>src/bindings.cpp</code>)","text":"<ul> <li>Bind the new class in the correct translation unit (<code>bind_matrix.cpp</code> or <code>bind_vector.cpp</code>, or <code>bind_complex.cpp</code> for complex helpers).</li> <li>Ensure the aggregator <code>src/bindings.cpp</code> calls the binder.</li> <li>Expose constructors, accessors, and key properties (<code>dtype</code>, <code>shape</code>, etc.).</li> </ul>"},{"location":"project/protocols/Adding%20Types/#6-testing-tests","title":"6) Testing (<code>tests/</code>)","text":"<p>Verify:</p> <ul> <li>creation + access,</li> <li>persistence (save/load/clone),</li> <li>dtype behavior (including bit/int/float boundaries),</li> <li>at least one large-ish case that exercises the memory-mapped path.</li> </ul>"},{"location":"project/protocols/Adding%20Types/#7-documentation","title":"7) Documentation","text":"<ul> <li>Add API reference in <code>documentation/docs/classes/</code>.</li> <li>Update the relevant guide(s) in <code>documentation/guides/</code>.</li> </ul> <p>If the new type changes dtype semantics or bit behavior, add/update internals docs in <code>documentation/internals/</code>.</p>"},{"location":"project/protocols/Documentation%20Protocol/","title":"Documentation Protocol","text":"<p>This protocol exists so documentation stays hard to miss, hard to rot, and easy to expand.</p> <p>The docs structure follows a Di\u00e1taxis-style intent split:</p> <ul> <li>Guides: workflows (how to accomplish a task).</li> <li>API reference: what the surface is and how to call it.</li> <li>Internals: how it works and where it lives.</li> <li>Dev handbook: contributor workflows and process.</li> </ul> <p>It is written for humans first. Avoid \"writer meta\" (how the doc was produced, constraints that only mattered during drafting, etc.). Put the reader\u2019s needs first.</p>"},{"location":"project/protocols/Documentation%20Protocol/#1-the-rule-every-change-must-have-a-doc-footprint","title":"1) The rule: every change must have a doc footprint","text":"<p>If you change behavior, add a feature, or add a new type/op, you must leave a doc footprint that answers:</p> <ul> <li>What changed?</li> <li>Who is it for (user vs contributor)?</li> <li>How do I use it?</li> <li>What are the constraints and failure modes?</li> </ul>"},{"location":"project/protocols/Documentation%20Protocol/#doc-impact-assessment-required","title":"Doc impact assessment (required)","text":"<p>Before you touch docs, classify the change:</p> <ul> <li>API change (new/changed public function/class/parameter)</li> <li>Behavior change (same API but different semantics)</li> <li>Performance change (new fast-path, new routing, new thresholds)</li> <li>Internals change (new storage format, new kernel path, new invariants)</li> </ul> <p>Then apply the mapping below.</p>"},{"location":"project/protocols/Documentation%20Protocol/#2-where-to-document-mapping","title":"2) Where to document (mapping)","text":""},{"location":"project/protocols/Documentation%20Protocol/#a-source-code-headers-file-level-mandatory-for-all-source-files","title":"A) Source Code Headers (File-Level) \u2014 mandatory for all source files","text":"<p>Every source file (<code>.hpp</code>, <code>.cpp</code>, <code>.py</code>) must start with a technical header block that answers: - What this file contains (classes, functions, modules). - Why it exists (architectural role). - Key dependencies or interactions (e.g., \"Implements the CPU backend for AutoSolver\"). - Thread-safety or Performance notes if relevant.</p> <p>This is for the maintainer reading the code, not the user.</p>"},{"location":"project/protocols/Documentation%20Protocol/#b-api-reference-documentationdocs-mandatory-for-user-facing-surfaces","title":"B) API reference (<code>documentation/docs/</code>) \u2014 mandatory for user-facing surfaces","text":"<p>Add/update:</p> <ul> <li><code>docs/classes/</code> if you add/modify a class.</li> <li><code>docs/functions/</code> if you add/modify a public function.</li> <li><code>docs/parameters/</code> if you add a new config parameter or global knob.</li> </ul> <p>Minimum expectation for API reference pages:</p> <ul> <li>Signature + parameters</li> <li>Return type(s)</li> <li>Exceptions / warnings</li> <li>At least one example that actually runs</li> </ul>"},{"location":"project/protocols/Documentation%20Protocol/#b-guides-documentationguides-mandatory-for-how-do-i-use-this","title":"B) Guides (<code>documentation/guides/</code>) \u2014 mandatory for \u201chow do I use this?\u201d","text":"<p>Guides are where we teach workflows.</p> <p>Rules:</p> <ul> <li>Prefer modifying an existing guide over adding a new one.</li> <li>Add a new guide only if it represents a new domain.</li> </ul> <p>Minimum expectation for guides:</p> <ul> <li>A problem statement (\u201cwhat you\u2019re trying to do\u201d)</li> <li>A minimal example</li> <li>One realistic example (with caveats)</li> <li>Links to the relevant API reference pages</li> </ul>"},{"location":"project/protocols/Documentation%20Protocol/#c-internals-documentationinternals-mandatory-for-architecturebackend-changes","title":"C) Internals (<code>documentation/internals/</code>) \u2014 mandatory for architecture/backend changes","text":"<p>Internals are for contributors and future maintainers.</p> <p>Minimum expectation for internals:</p> <ul> <li>Data model / invariants</li> <li>Where in the codebase the behavior lives</li> <li>How to extend it safely</li> <li>Common failure modes and debugging tips</li> </ul>"},{"location":"project/protocols/Documentation%20Protocol/#d-dev-handbook-documentationdev-mandatory-for-process-contributor-ux","title":"D) Dev handbook (<code>documentation/dev/</code>) \u2014 mandatory for process / contributor UX","text":"<p>Use dev handbook pages when:</p> <ul> <li>onboarding needs to change,</li> <li>build/test workflows change,</li> <li>\u201chow to do work safely\u201d changes.</li> </ul>"},{"location":"project/protocols/Documentation%20Protocol/#3-linking-protocol-mkdocs-roamlinks","title":"3) Linking protocol (MkDocs roamlinks)","text":"<p>MkDocs supports wiki links. We use them aggressively, but in a controlled way.</p>"},{"location":"project/protocols/Documentation%20Protocol/#use-explicit-links-preferred","title":"Use explicit links (preferred)","text":"<p>Prefer explicit, stable links that include the path, so the target is unambiguous:</p> <ul> <li><code>[pycauset.matmul](&lt;../../docs/functions/pycauset.matmul.md&gt;)</code></li> <li><code>[pycauset.matrix](&lt;../../docs/functions/pycauset.matrix.md&gt;)</code></li> <li><code>[internals/DType System](&lt;../../internals/DType System.md&gt;)</code></li> </ul> <p>Note: <code>mkdocs-roamlinks-plugin</code> treats any <code>.</code> in the filename as \u201chas an extension\u201d, so for targets like <code>pycauset.matmul</code> / <code>pycauset.matrix</code> you should include the <code>.md</code> suffix.</p>"},{"location":"project/protocols/Documentation%20Protocol/#avoid-ambiguous-links","title":"Avoid ambiguous links","text":"<p>Avoid short wiki-links like <code>Matrix</code>, <code>Installation</code>, etc. unless you are sure there is only one plausible target.</p>"},{"location":"project/protocols/Documentation%20Protocol/#add-see-also-sections","title":"Add \u201cSee also\u201d sections","text":"<p>Most pages should end with a short \u201cSee also\u201d list of 3\u20138 links. This is what makes the docs scale.</p>"},{"location":"project/protocols/Documentation%20Protocol/#4-quality-bar-what-good-docs-looks-like","title":"4) Quality bar (what \u201cgood docs\u201d looks like)","text":""},{"location":"project/protocols/Documentation%20Protocol/#reader-first-openings","title":"Reader-first openings","text":"<p>Start with what the reader wants to do, not properties of the document.</p> <p>Good:</p> <ul> <li>\u201cThis guide shows how to store disk-backed matrices and control the storage directory.\u201d</li> </ul> <p>Bad:</p> <ul> <li>\u201cThis document is the canonical source of truth and is not time-based.\u201d</li> </ul>"},{"location":"project/protocols/Documentation%20Protocol/#staleness-checks-required","title":"Staleness checks (required)","text":"<p>When editing a page, quickly verify:</p> <ul> <li>Does it mention files that no longer exist?</li> <li>Does it mention APIs that no longer exist?</li> <li>Does it promise performance behavior that isn\u2019t enforced?</li> </ul> <p>If you can\u2019t verify something easily, rewrite it to be:</p> <ul> <li>specific but testable (\u201cruns through AutoSolver routing\u201d), or</li> <li>scoped (\u201cGPU support is available for selected operations; see \u2026\u201d), or</li> <li>explicitly marked as a plan (link to a plan doc).</li> </ul>"},{"location":"project/protocols/Documentation%20Protocol/#avoid-hyper-local-details","title":"Avoid hyper-local details","text":"<p>Avoid including details that were only true during a single development session (temporary constraints, incidental path names, one-off benchmark numbers) unless they are truly stable.</p>"},{"location":"project/protocols/Documentation%20Protocol/#5-definition-of-done-checklist-docs","title":"5) Definition-of-done checklist (docs)","text":"<p>Before marking a task complete:</p> <ol> <li> API reference updated (if public)</li> <li> Guide updated (if user-facing)</li> <li> Internals updated (if backend/architecture)</li> <li> Cross-links added (minimum: 3 relevant links)</li> <li> Examples are correct and match the current API</li> <li> No \u201cwriter meta\u201d at the top of the page</li> </ol>"},{"location":"project/protocols/Documentation%20Protocol/#6-templates-copypaste","title":"6) Templates (copy/paste)","text":""},{"location":"project/protocols/Documentation%20Protocol/#template-new-api-reference-page","title":"Template: new API reference page","text":"<ul> <li>What it is</li> <li>Signature</li> <li>Parameters</li> <li>Returns</li> <li>Exceptions/warnings</li> <li>Examples</li> <li>See also</li> </ul>"},{"location":"project/protocols/Documentation%20Protocol/#template-new-guide-section","title":"Template: new guide section","text":"<ul> <li>Goal</li> <li>Minimal example</li> <li>Practical example</li> <li>Pitfalls</li> <li>See also</li> </ul>"},{"location":"project/protocols/Documentation%20Protocol/#see-also","title":"See also","text":"<ul> <li><code>documentation/project/protocols/NumPy Alignment Protocol.md</code></li> </ul>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/","title":"NumPy Alignment Protocol","text":"<p>This protocol defines how user-facing Python names in <code>pycauset</code> should align with NumPy so the API is intuitive, predictable, and easy to learn.</p>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#1-scope","title":"1) Scope","text":"<p>This protocol applies to:</p> <ul> <li>Top-level Python module functions (factories, creators, convenience functions)</li> <li>Methods on user-facing array-like objects (vectors/matrices)</li> <li>Parameter names and return-shape conventions for those surfaces</li> </ul> <p>This protocol does not force domain-specific objects (e.g. causal set / spacetime features) to mimic NumPy when the concepts do not exist in NumPy; those should still follow NumPy\u2019s naming style.</p>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#2-naming-rules-public-api","title":"2) Naming rules (public API)","text":""},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#a-functions-factories-are-lower-case","title":"A) Functions / factories are lower-case","text":"<ul> <li>Public factories and creators are lower-case and snake_case.</li> <li>If NumPy has the same concept with the same semantics, use the same name.</li> </ul> <p>Examples:</p> <ul> <li><code>pycauset.matrix(...)</code> (aligned with <code>np.array(...)</code> conceptually)</li> <li><code>pycauset.vector(...)</code> (aligned with 1D <code>np.array([...])</code> output)</li> <li><code>pycauset.zeros(...)</code>, <code>pycauset.ones(...)</code>, <code>pycauset.empty(...)</code></li> </ul>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#b-concrete-types-remain-pascalcase","title":"B) Concrete types remain PascalCase","text":"<ul> <li>Native/optimized concrete classes remain PascalCase because they are types, not factories.</li> </ul> <p>Examples:</p> <ul> <li><code>pycauset.FloatMatrix</code>, <code>pycauset.Int8Vector</code>, <code>pycauset.TriangularBitMatrix</code></li> </ul>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#c-no-deprecation-aliases-rename-purge","title":"C) No deprecation aliases: rename == purge","text":"<p>When a public name changes:</p> <ul> <li>The old symbol is removed from the module surface.</li> <li>We do not ship \u201cdeprecated\u201d wrappers or migration warnings.</li> </ul> <p>Rationale: the project\u2019s policy is purge-on-deprecate.</p>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#d-prefer-numpy-parameter-names-and-conventions","title":"D) Prefer NumPy parameter names and conventions","text":"<p>When applicable, match NumPy\u2019s parameter naming and behavior:</p> <ul> <li><code>dtype</code> for element type</li> <li><code>shape</code> for dimensions</li> <li><code>axis</code> and <code>keepdims</code> for reductions (future)</li> </ul>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#3-behavioral-alignment","title":"3) Behavioral alignment","text":""},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#a-shapes-follow-numpy","title":"A) Shapes follow NumPy","text":"<ul> <li>Matrices are 2D with <code>shape == (rows, cols)</code>.</li> <li>Vectors are 1D with <code>shape == (n,)</code>.</li> </ul> <p>Constructor vs allocation rule:</p> <ul> <li><code>pycauset.matrix(...)</code> and <code>pycauset.vector(...)</code> construct from data.</li> <li>Shape-based allocation uses <code>pycauset.zeros/ones/empty(shape, dtype=...)</code>.</li> <li>Scalars/0D arrays are out of scope; scalar input to <code>matrix/vector</code> must raise.</li> </ul>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#b-size-and-shape-match-numpy","title":"B) <code>size()</code> and <code>shape</code> match NumPy","text":"<ul> <li><code>size()</code> is the total element count.</li> <li><code>shape</code> exists as a property/attribute.</li> <li>If a callable form exists, <code>shape()</code> mirrors <code>shape</code>.</li> </ul>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#c-fillvalue-exists","title":"C) <code>.fill(value)</code> exists","text":"<p>Provide a method analogous to NumPy\u2019s <code>ndarray.fill(value)</code> on user-facing vector/matrix objects.</p>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#4-canonical-rename-list-initial","title":"4) Canonical rename list (initial)","text":"<p>This protocol assumes a lower-case, NumPy-aligned public surface.</p> <p>Canonical public entrypoints:</p> <ul> <li><code>pycauset.matrix(...)</code> and <code>pycauset.vector(...)</code> construct from data.</li> <li><code>pycauset.zeros/ones/empty(..., dtype=...)</code> allocate by shape.</li> <li><code>pycauset.causal_matrix(...)</code> constructs causal matrices.</li> <li><code>pycauset.causet(...)</code> is the convenience factory returning a <code>CausalSet</code>.</li> </ul> <p>Policy:</p> <ul> <li>Public factories/functions are lower-case.</li> <li>PascalCase factory aliases are not part of the public API.</li> </ul>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#5-documentation-requirements-mandatory","title":"5) Documentation requirements (mandatory)","text":"<p>Any public rename/addition is not done until documentation is updated according to:</p> <ul> <li><code>documentation/project/protocols/Documentation Protocol.md</code></li> </ul> <p>Minimum expectation:</p> <ul> <li>API reference pages exist for the final public names</li> <li>Examples match the final public names</li> <li>Cross-links updated (including roamlinks targets)</li> </ul>"},{"location":"project/protocols/NumPy%20Alignment%20Protocol/#see-also","title":"See also","text":"<ul> <li><code>documentation/project/protocols/Documentation Protocol.md</code></li> <li><code>documentation/internals/plans/R1_SHAPES_PLAN.md</code></li> </ul>"},{"location":"project/protocols/Pre-alpha%20Policy/","title":"Pre-alpha Policy (Scope + Approval Gates)","text":"<p>PyCauset is currently pre-alpha and effectively single-maintainer. There is no external userbase to preserve yet.</p> <ul> <li>Backward compatibility is not a hard constraint right now.</li> <li>Breaking changes to the Python surface and/or architecture are allowed when they improve the overall approach.</li> <li>Approval gate: before changing the public Python surface (names/semantics) or making a large architectural shift, propose the change + tradeoffs and wait for explicit approval.</li> <li>If a breaking change is approved, update tests and documentation in the same change set (don\u2019t leave the repo in a \u201chalf-migrated\u201d state).</li> </ul>"},{"location":"project/protocols/Pre-alpha%20Policy/#removals-policy-deprecation-purge","title":"Removals policy (\"deprecation\" = purge)","text":"<p>PyCauset uses a purge policy:</p> <ul> <li>If we decide something should be removed, we remove it fully.</li> <li>We do not keep deprecated aliases or \u201cdeprecated but still present\u201d codepaths.</li> <li>Documentation should never say \u201cdeprecated\u201d: it should reflect the current reality.</li> </ul> <p>If a removal breaks internal callers, update them in the same change.</p>"},{"location":"project/protocols/Release%20Process/","title":"Release Process","text":"<p>This page describes how PyCauset is released and versioned.</p>"},{"location":"project/protocols/Release%20Process/#automated-releases","title":"Automated releases","text":"<p>The primary way to release a new version is by pushing to the <code>main</code> branch.</p> <ol> <li>Commit your changes: ensure your work is committed.</li> <li>Push to main:     <pre><code>git push origin main\n</code></pre></li> <li>Workflow trigger: the GitHub Action <code>Publish to PyPI</code> will start automatically.<ul> <li>Bump version: calculates the next patch version (e.g., <code>0.2.4</code> -&gt; <code>0.2.5</code>).</li> <li>Tag: creates a new git tag and a GitHub Release using your commit message as the notes.</li> <li>Build &amp; publish: builds wheels for Windows, macOS, and Linux, and publishes them to PyPI.</li> </ul> </li> </ol>"},{"location":"project/protocols/Release%20Process/#manual-releases","title":"Manual releases","text":"<p>If you need to bump a minor/major version or set a specific version number, you can use the helper script or git tags directly.</p>"},{"location":"project/protocols/Release%20Process/#using-the-helper-script-releaseps1","title":"Using the helper script (<code>release.ps1</code>)","text":"<p>Bump minor version: <pre><code>.\\release.ps1 -Type minor\n</code></pre></p> <p>Bump major version: <pre><code>.\\release.ps1 -Type major\n</code></pre></p> <p>Set specific version: <pre><code>.\\release.ps1 -SetVersion 0.4.0\n</code></pre></p>"},{"location":"project/protocols/Release%20Process/#using-git-tags","title":"Using git tags","text":"<pre><code>git tag v0.4.0\ngit push origin v0.4.0\n</code></pre>"},{"location":"project/protocols/Release%20Process/#cicd-workflow-details","title":"CI/CD workflow details","text":"<p>The workflow is defined in <code>.github/workflows/publish.yml</code>.</p> <ul> <li>Triggers:</li> <li><code>push</code> to <code>main</code>: triggers auto-bump (patch) and release</li> <li><code>push</code> of tags (<code>v*</code>): triggers build and release for that tag</li> <li><code>workflow_dispatch</code>: manual trigger from GitHub Actions UI</li> <li>Versioning: uses <code>setuptools_scm</code> to determine the package version from git tags</li> <li>Build system: uses <code>cibuildwheel</code> to build binary wheels for multiple platforms</li> <li>Publishing: uses PyPI Trusted Publishing (OIDC) to upload artifacts</li> </ul>"},{"location":"project/protocols/Testing%20and%20Bug%20Tracking/","title":"Testing and Bug Tracking Protocol","text":"<p>Objective: Maintain a strict protocol for automated testing and bug tracking to keep the project stable and debuggable.</p>"},{"location":"project/protocols/Testing%20and%20Bug%20Tracking/#bug-documentation","title":"Bug documentation","text":"<p>Whenever a bug is discovered\u2014whether it's a compilation error, a runtime failure, a logic error, or a regression\u2014it must be documented in <code>tests/BUG_LOG.md</code>.</p>"},{"location":"project/protocols/Testing%20and%20Bug%20Tracking/#format","title":"Format","text":"<p>Append a new entry to <code>tests/BUG_LOG.md</code> using the following format:</p> <pre><code>## [Date: YYYY-MM-DD HH:MM] Bug Title\n\n**Status**: [Fixed / Open]\n**Severity**: [Critical / High / Medium / Low]\n**Component**: [e.g., Storage, Matrix Operations, Python Bindings]\n\n**Description**:\nA concise description of the issue.\n\n**Reproduction**:\nSteps or code snippet to reproduce the failure.\n\n**Root Cause** (if known):\nTechnical explanation of why it happened.\n\n**Fix** (if applied):\nDescription of the solution implemented.\n</code></pre>"},{"location":"project/protocols/Testing%20and%20Bug%20Tracking/#test-creation-vs-execution","title":"Test creation vs. execution","text":"<p>When working on tests, follow this workflow:</p> <ol> <li>Design: create comprehensive test cases covering edge cases, boundary conditions, and type permutations.</li> <li>Review: ensure tests are valid before running.</li> <li>Execute: run tests and monitor for failures.</li> </ol>"},{"location":"project/protocols/Testing%20and%20Bug%20Tracking/#regression-prevention","title":"Regression prevention","text":"<p>When fixing a bug, ensure a regression test is added to the test suite (preferably in a dedicated <code>test_regressions.py</code> or the relevant module) to prevent the issue from recurring.</p>"}]}